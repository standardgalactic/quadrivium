

Winfried Schirotzek
Nonsmooth Analysis
With 31 Figures

Winfried Schirotzek
Institut f¨ur Analysis
Fachrichtung Mathematik
Technische Universit¨at Dresden
01062 Dresden
Germany
e-mail: winfried.schirotzek@tu-dresden.de
Mathematics Subject Classiﬁcation (2000): 49-01, 49-02, 49J50, 49J52, 49J53, 49K27,
49N15, 58C06, 58C20, 58E30, 90C48
Library of Congress Control Number: 2007922937
ISBN-10: 3-540-71332-8 Springer Berlin Heidelberg New York
ISBN-13: 978-3-540-71332-6 Springer Berlin Heidelberg New York
This work is subject to copyright. All rights are reserved, whether the whole or part of the mater-
ial is concerned, speciﬁcally the rights of translation, reprinting, reuse of illustrations, recitation,
broadcasting, reproduction on microﬁlm or in any other way, and storage in data banks. Dupli-
cation of this publication or parts thereof is permitted only under the provisions of the German
Copyright Law of September 9, 1965, in its current version, and permission for use must always
be obtained from Springer. Violations are liable for prosecution under the German Copyright Law.
Springer is a part of Springer Science+Business Media
springer.com
◦c Springer-Verlag Berlin Heidelberg 2007
The use of general descriptive names, registered names, trademarks, etc. in this pub-
lication does not imply, even in the absence of a speciﬁc statement, that such names
are exempt from the relevant protective laws and regulations and therefore free for
general use.
Cover design: WMXDesign, Heidelberg
Typesetting by the authors and SPi using a Springer LATEX macro package
Printed on acid-free paper
SPIN: 12029495
41/2141/SPi
5 4 3 2 1 0

To the memory of my parents

Preface
One of the sources of the classical diﬀerential calculus is the search for min-
imum or maximum points of a real-valued function. Similarly, nonsmooth
analysis originates in extremum problems with nondiﬀerentiable data. By now,
a broad spectrum of reﬁned concepts and methods modeled on the theory of
diﬀerentiation has been developed.
The idea underlying the presentation of the material in this book is to start
with simple problems treating them with simple methods, gradually passing
to more diﬃcult problems which need more sophisticated methods. In this
sense, we pass from convex functionals via locally Lipschitz continuous func-
tionals to general lower semicontinuous functionals. The book does not aim
at being comprehensive but it presents a rather broad spectrum of important
and applicable results of nonsmooth analysis in normed vector spaces. Each
chapter ends with references to the literature and with various exercises.
The book grew out of a graduate course that I repeatedly held at the Tech-
nische Universität Dresden. Susanne Walther and Konrad Groh, participants
of one of the courses, pointed out misprints in an early script preceding the
book. I am particularly grateful to Heidrun P¨uhl and Hans-Peter Scheﬄer for
a time of proliﬁc cooperation and to the latter also for permanent technical
support. The Institut f¨ur Analysis of the Technische Universit¨at Dresden pro-
vided me with the facilities to write the book. I thank Quji J. Zhu for useful
discussions and two anonymous referees for valuable suggestions. I gratefully
acknowledge the kind cooperation of Springer, in particular the patient sup-
port by Stefanie Zoeller, as well as the careful work of Nandini Loganathan,
project manager of Spi (India).
My warmest thanks go to my wife for everything not mentioned above.
Dresden, December 2006
Winfried Schirotzek

Contents
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1
1
Preliminaries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5
1.1
Terminology . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5
1.2
Convex Sets in Normed Vector Spaces . . . . . . . . . . . . . . . . . . . . .
6
1.3
Convex Functionals: Deﬁnitions and Examples . . . . . . . . . . . . . .
8
1.4
Continuity of Convex Functionals . . . . . . . . . . . . . . . . . . . . . . . . . 11
1.5
Sandwich and Separation Theorems . . . . . . . . . . . . . . . . . . . . . . . 13
1.6
Dual Pairs of Vector Spaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19
1.7
Lower Semicontinuous Functionals . . . . . . . . . . . . . . . . . . . . . . . . 22
1.8
Bibliographical Notes and Exercises . . . . . . . . . . . . . . . . . . . . . . . 24
2
The Conjugate of Convex Functionals . . . . . . . . . . . . . . . . . . . . . 27
2.1
The Gamma Regularization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27
2.2
Conjugate Functionals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29
2.3
A Theorem of H¨ormander and the Bipolar Theorem . . . . . . . . . 34
2.4
The Generalized Farkas Lemma . . . . . . . . . . . . . . . . . . . . . . . . . . . 36
2.5
Bibliographical Notes and Exercises . . . . . . . . . . . . . . . . . . . . . . . 38
3
Classical Derivatives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39
3.1
Directional Derivatives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39
3.2
First-Order Derivatives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41
3.3
Mean Value Theorems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44
3.4
Relationship between Diﬀerentiability Properties . . . . . . . . . . . . 46
3.5
Higher-Order Derivatives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48
3.6
Some Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49
3.7
Implicit Function Theorems and Related Results . . . . . . . . . . . . 51
3.8
Bibliographical Notes and Exercises . . . . . . . . . . . . . . . . . . . . . . . 57

X
Contents
4
The Subdiﬀerential of Convex Functionals . . . . . . . . . . . . . . . . . 59
4.1
Deﬁnition and First Properties . . . . . . . . . . . . . . . . . . . . . . . . . . . 59
4.2
Multifunctions: First Properties . . . . . . . . . . . . . . . . . . . . . . . . . . . 63
4.3
Subdiﬀerentials, Fréchet Derivatives, and Asplund Spaces . . . . 64
4.4
Subdiﬀerentials and Conjugate Functionals . . . . . . . . . . . . . . . . . 73
4.5
Further Calculus Rules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76
4.6
The Subdiﬀerential of the Norm . . . . . . . . . . . . . . . . . . . . . . . . . . 78
4.7
Diﬀerentiable Norms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 83
4.8
Bibliographical Notes and Exercises . . . . . . . . . . . . . . . . . . . . . . . 89
5
Optimality Conditions for Convex Problems . . . . . . . . . . . . . . . 91
5.1
Basic Optimality Conditions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 91
5.2
Optimality Under Functional Constraints . . . . . . . . . . . . . . . . . . 92
5.3
Application to Approximation Theory . . . . . . . . . . . . . . . . . . . . . 96
5.4
Existence of Minimum Points and the Ritz Method. . . . . . . . . . 99
5.5
Application to Boundary Value Problems . . . . . . . . . . . . . . . . . . 105
5.6
Bibliographical Notes and Exercises . . . . . . . . . . . . . . . . . . . . . . . 110
6
Duality of Convex Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 111
6.1
Duality in Terms of a Lagrange Function. . . . . . . . . . . . . . . . . . . 111
6.2
Lagrange Duality and Gâteaux Diﬀerentiable Functionals . . . . 116
6.3
Duality of Boundary Value Problems . . . . . . . . . . . . . . . . . . . . . . 118
6.4
Duality in Terms of Conjugate Functions. . . . . . . . . . . . . . . . . . . 122
6.5
Bibliographical Notes and Exercises . . . . . . . . . . . . . . . . . . . . . . . 129
7
Derivatives and Subdiﬀerentials of Lipschitz Functionals . . . 131
7.1
Preview: Derivatives and Approximating Cones . . . . . . . . . . . . . 131
7.2
Upper Convex Approximations
and Locally Convex Functionals . . . . . . . . . . . . . . . . . . . . . . . . . . 135
7.3
The Subdiﬀerentials of Clarke and Michel–Penot . . . . . . . . . . . . 139
7.4
Subdiﬀerential Calculus . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 146
7.5
Bibliographical Notes and Exercises . . . . . . . . . . . . . . . . . . . . . . . 153
8
Variational Principles . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 155
8.1
Introduction. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 155
8.2
The Loewen–Wang Variational Principle . . . . . . . . . . . . . . . . . . . 156
8.3
The Borwein–Preiss Variational Principle . . . . . . . . . . . . . . . . . . 161
8.4
The Deville–Godefroy–Zizler Variational Principle . . . . . . . . . . . 162
8.5
Bibliographical Notes and Exercises . . . . . . . . . . . . . . . . . . . . . . . 166
9
Subdiﬀerentials of Lower Semicontinuous Functionals . . . . . . 167
9.1
Fréchet Subdiﬀerentials: First Properties . . . . . . . . . . . . . . . . . . . 167
9.2
Approximate Sum and Chain Rules . . . . . . . . . . . . . . . . . . . . . . . 172
9.3
Application to Hamilton–Jacobi Equations . . . . . . . . . . . . . . . . . 181
9.4
An Approximate Mean Value Theorem . . . . . . . . . . . . . . . . . . . . 182
9.5
Fréchet Subdiﬀerential vs. Clarke Subdiﬀerential . . . . . . . . . . . . 184

Contents
XI
9.6
Multidirectional Mean Value Theorems . . . . . . . . . . . . . . . . . . . . 185
9.7
The Fréchet Subdiﬀerential of Marginal Functions . . . . . . . . . . . 190
9.8
Bibliographical Notes and Exercises . . . . . . . . . . . . . . . . . . . . . . . 193
10
Multifunctions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 195
10.1
The Generalized Open Mapping Theorem . . . . . . . . . . . . . . . . . . 195
10.2
Systems of Convex Inequalities . . . . . . . . . . . . . . . . . . . . . . . . . . . 197
10.3
Metric Regularity and Linear Openness . . . . . . . . . . . . . . . . . . . . 200
10.4
Openness Bounds of Multifunctions . . . . . . . . . . . . . . . . . . . . . . . 209
10.5
Weak Metric Regularity and Pseudo-Lipschitz Continuity . . . . 211
10.6
Linear Semiopenness and Related Properties . . . . . . . . . . . . . . . 213
10.7
Linearly Semiopen Processes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 217
10.8
Maximal Monotone Multifunctions . . . . . . . . . . . . . . . . . . . . . . . . 219
10.9
Convergence of Sets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 225
10.10 Bibliographical Notes and Exercises . . . . . . . . . . . . . . . . . . . . . . . 227
11
Tangent and Normal Cones . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231
11.1
Tangent Cones: First Properties . . . . . . . . . . . . . . . . . . . . . . . . . . 231
11.2
Normal Cones: First Properties . . . . . . . . . . . . . . . . . . . . . . . . . . . 237
11.3
Tangent and Normal Cones to Epigraphs . . . . . . . . . . . . . . . . . . 241
11.4
Representation of Tangent Cones . . . . . . . . . . . . . . . . . . . . . . . . . 245
11.5
Contingent Derivatives and a Lyusternik Type Theorem . . . . . 252
11.6
Representation of Normal Cones . . . . . . . . . . . . . . . . . . . . . . . . . . 255
11.7
Bibliographical Notes and Exercises . . . . . . . . . . . . . . . . . . . . . . . 261
12
Optimality Conditions for Nonconvex Problems . . . . . . . . . . . 265
12.1
Basic Optimality Conditions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 265
12.2
Application to the Calculus of Variations . . . . . . . . . . . . . . . . . . 267
12.3
Multiplier Rules Involving Upper Convex Approximations . . . . 272
12.4
Clarke’s Multiplier Rule . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 278
12.5
Approximate Multiplier Rules . . . . . . . . . . . . . . . . . . . . . . . . . . . . 280
12.6
Bibliographical Notes and Exercises . . . . . . . . . . . . . . . . . . . . . . . 283
13
Extremal Principles and More Normals
and Subdiﬀerentials . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 285
13.1
Mordukhovich Normals and Subdiﬀerentials . . . . . . . . . . . . . . . . 285
13.2
Coderivatives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 294
13.3
Extremal Principles Involving Translations . . . . . . . . . . . . . . . . . 301
13.4
Sequentially Normally Compact Sets . . . . . . . . . . . . . . . . . . . . . . 309
13.5
Calculus for Mordukhovich Subdiﬀerentials . . . . . . . . . . . . . . . . . 315
13.6
Calculus for Mordukhovich Normals . . . . . . . . . . . . . . . . . . . . . . . 320
13.7
Optimality Conditions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 323
13.8
The Mordukhovich Subdiﬀerential of Marginal Functions. . . . . 327
13.9
A Nonsmooth Implicit Function Theorem . . . . . . . . . . . . . . . . . . 330
13.10 An Implicit Multifunction Theorem . . . . . . . . . . . . . . . . . . . . . . . 334

XII
Contents
13.11 An Extremal Principle Involving Deformations. . . . . . . . . . . . . . 337
13.12 Application to Multiobjective Optimization . . . . . . . . . . . . . . . . 340
13.13 Bibliographical Notes and Exercises . . . . . . . . . . . . . . . . . . . . . . . 343
Appendix: Further Topics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 347
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 351
Notation. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 363
Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 366

Introduction
Minimizing or maximizing a function subject to certain constraints is one of
the most important problems of real life and consequently of mathematics.
Among others, it was this problem that stimulated the development of
diﬀerential calculus.
Given a real-valued function f on a real normed vector space E and a
nonempty subset A of E, consider the following problem:
(Min) Minimize f(x) subject to x ∈A.
Let ¯x be a local solution of (Min). If ¯x is an interior point of A and f is
diﬀerentiable (in some sense) at ¯x, then ¯x satisﬁes the famous Fermat rule
f ′(¯x) = o,
which is thus a necessary optimality condition. If ¯x ∈A is not an interior
point of A but f goes on to be diﬀerentiable at ¯x, then a necessary optimality
condition still holds as a variational inequality, which for A convex reads
⟨f ′(¯x), x −¯x⟩≥0
for any x ∈A.
(0.1)
The assumption that f be diﬀerentiable at ¯x is not intrinsic to problem
(Min). Consider, for example, the classical problem of Chebyshev approxi-
mation, which is (Min) with E := C[a, b], the normed vector space of all
continuous functions x : [a, b] →R, and
f(x) := ∥x −z∥∞:= max
a≤t≤b |x(t) −z(t)|,
where z ∈C[a, b]\A is given. In this case the functional f fails to be (Gâteaux)
diﬀerentiable at “most” points x ∈C[a, b] and so the above-mentioned app-
roach no longer works.
However, if f is a convex functional, as is the functional in the Chebyshev
approximation problem, then a useful substitute for a nonexisting derivative

2
Introduction
f
0
x
¯x
x∗
a
n
epi f
Fig. 0.1
is a subgradient. A subgradient of f at ¯x is a continuous linear functional x∗
on E satisfying
⟨x∗, y⟩≤f(¯x + y) −f(¯x)
for all y ∈E.
Geometrically this means that the “parallel” aﬃne functional a(x) := ⟨x∗,
x −¯x⟩+ f(¯x) satisﬁes a(x) ≤f(x) for any x ∈E and a(¯x) = f(¯x) (see
Fig. 0.1). Typically a function admits many subgradients (if any) at a point of
nondiﬀerentiability. The set of all subgradients of f at ¯x is called subdiﬀerential
of f at ¯x and is denoted ∂f(¯x).
Initiated by Rockafellar [177] and Moreau [148], a rich theory of convex sets
and functions including optimality conditions in terms of subdiﬀerentials has
been developed. This theory is known as convex analysis after Rockafellar’s
now classical book [180]. In the convex case the notion of the conjugate func-
tional is the basis for associating with a given optimization problem another
problem, called the dual problem. The study of the relationship between the
two problems gives signiﬁcant insight into convex optimization.
Problems involving functionals that are neither diﬀerentiable nor convex
are more diﬃcult to handle. During the last three decades, however, consid-
erable progress has been made also in this area. One starting point is the
observation that in the convex case a subgradient x∗of f at ¯x can also be
characterized by the inequality
⟨x∗, y⟩≤fG(¯x, y)
for all y ∈E.
(0.2)
Here, fG(¯x, y) denotes the directional Gâteaux derivative of f at ¯x in the
direction y, i.e.,
fG(¯x, y) := lim
τ↓0
f(¯x + τy) −f(¯x)
τ
,

Introduction
3
which is a convex functional of y. If f is not convex, then in general the
functional fG(¯x, ·) is not convex either and a calculus ﬁnally resulting in op-
timality conditions is not available. The idea now is to replace fG(¯x, ·) by
a functional that behaves better. Pshenichnyi [170] and Neustadt [150] con-
sidered upper convex approximations, i.e., convex functionals that majorize
certain directional derivatives such as fG(¯x, ·). A crucial step was Clarke’s
doctoral thesis [33], which gives an intrinsic (nonaxiomatic) construction of
a convex local approximation of f at ¯x. Another such construction is due,
among others, to Michel and Penot [129,130]. An eﬀective calculus as well as
applicable optimality conditions in terms of these constructs can be developed
for the class of locally Lipschitz continuous functionals. This is elaborated
and applied to problems in the calculus of variations and optimal control
in the monograph [36] by Clarke, which also coined the notion nonsmooth
analysis.
For non-Lipschitz functionals, various derivative-like concepts have been
proposed as local approximations. For lower semicontinuous functionals, two
concepts are particularly promising: On the one hand smooth local approxi-
mations from below which led to the concept of viscosity subdiﬀerentials and
in particular to proximal subdiﬀerentials and on the other hand suitable direc-
tional limits that led to Fréchet subdiﬀerentials. Crucial progress was reached
when it turned out that in Fréchet smooth Banach spaces (Banach spaces
admitting an equivalent norm that is Fréchet diﬀerentiable at each nonzero
point) the two concepts coincide; this applies in particular to any reﬂexive
Banach space. Substantial contributions to this theory are due to Rockafellar,
Clarke, Borwein, Ioﬀe, and others.
We return to the problem (Min). Beside local approximations of the func-
tional f one also needs local approximations of the set A near the minimum
point ¯x. For various classes of optimization problems, tangent cones are ade-
quate local approximations. If f∗(¯x, ·) and T∗(A, ¯x) are a directional derivative
of f at ¯x and a tangent cone to A at ¯x, respectively, that “ﬁt together,” then
the variational inequality
f∗(¯x, y) ≥0
for any y ∈T∗(A, ¯x)
(0.3)
is a necessary optimality condition generalizing (0.1). Another method of lo-
cally approximating the set A is via normal cones. A conventional way to
deﬁne a normal cone is as (negative) polar of a tangent cone, which always
yields a convex cone. Polar cones can also be deﬁned as subdiﬀerentials of suit-
able functionals, which was done, among others, by Clarke [36] and Ioﬀe [96].
A third way to deﬁne normal cones is stimulated by the observation that
x∗∈E∗is a subgradient of the convex functional f at ¯x if and only if (x∗, −1)
is a normal vector to the epigraph of f (see the vector n in Fig. 0.1). In the
nonconvex case Mordukhovich [132] ﬁrst deﬁned normal cones by set limiting
operations and then subdiﬀerentials via normal cones to epigraphs.

4
Introduction
In terms of some normal cone N∗(A, ¯x) and an associated subdiﬀerential
∂∗f(¯x), a necessary optimality condition corresponding to (0.3) reads
−x∗∈N∗(A, ¯x)
for some x∗∈∂∗f(¯x).
This condition is the stronger the smaller N∗(A, ¯x) and ∂∗f(¯x) are. Under this
aspect, it turns out that convex normal cones may be too large.
In general, Fréchet subdiﬀerentials only admit an approximate (or fuzzy)
calculus and consequently approximate optimality conditions. It turned out
that the limiting normal cones and subdiﬀerentials studied by Mordukhovich,
Ioﬀe, and others admit a rich exact (nonapproximate) calculus at least in Asp-
lund spaces (a class of Banach spaces containing all Fréchet smooth Banach
spaces), provided the functionals and sets involved satisfy suitable compact-
ness assumptions in the inﬁnite dimensional case.
At this point, we must turn to the basic tools necessary for the respective
theory. The principal tool for treating problems with convex and, to a great
extent, locally Lipschitz continuous functionals are separation theorems and
related results such as sandwich theorems. For general lower semicontinuous
functionals, variational principle take over the part of separation theorems.
A variational principle says, roughly speaking, that near a point that “almost”
minimizes a functional f, there exists a point z that actually minimizes a
slightly perturbed functional. In the ﬁrst variational principle, discovered by
Ekeland [56], the perturbed functional is not diﬀerentiable at z. Borwein and
Preiss [19] were the ﬁrst to establish a smooth variational principle. By now
various smooth variational principles have been derived. A third fundamental
tool are extremal principles discovered by Mordukhovich [132]. An extremal
principle provides a necessary condition for a point to be extremal (in a cer-
tain sense) with respect to a system of sets. Mordukhovich largely develops
his theory with the aid of extremal principles. They work especially well in
Asplund spaces and in fact, Asplund spaces can be characterized by an ext-
remal principle. Therefore Asplund spaces are the appropriate framework for
variational analysis.
The book ﬁrst presents the theory of convex functionals (Chaps. 2–6). All
the following chapters are devoted to the analysis of nonconvex nondiﬀeren-
tiable functionals and related objects such as normal cones. A subdiﬀerential
of f, however it may be deﬁned, associates with each ¯x ∈E a (possibly empty)
subset of the dual space E∗and thus is a set-valued mapping or a multifunc-
tion. Therefore, nonsmooth analysis includes (parts of) multifunction theory;
this is contained in Chap. 10. Each chapter ends with references to the liter-
ature and exercises. The latter partly require to carry out proofs of results
given in the text, partly contain additional information and examples. Since
nonsmooth analysis is still a rapidly growing ﬁeld of research, many aspects
had to be omitted. The Appendix indicates some of them.

1
Preliminaries
1.1 Terminology
General Convention. Throughout these lectures, vector space always means
real vector space, and topological vector space always means Hausdorﬀtopo-
logical vector space. Unless otherwise speciﬁed, E will denote a normed vector
space.
Let N, R, and R+ denote the set of all positive integers, of all real num-
bers and of all nonnegative real numbers, respectively. Further set R :=
R ∪{−∞, +∞}. The operations in R are deﬁned as usual; in addition, we set
0·(±∞) = (±∞)·0 := 0, but we do not deﬁne (+∞)−(+∞). In Remark 1.3.5
below, we shall explain that it is reasonable to allow a functional to attain
values in R and not only in R.
The zero element of any vector space except R will be denoted o. If A and
B are nonempty subsets of a vector space E and if α, β ∈R, we write
αA + βB := {αx + βy | x ∈A, y ∈B},
R+ A := {λx | λ ∈R+, x ∈A}.
In particular we write A + y := A + {y}. If one of A, B is empty, we set
A + B := ∅.
A nonempty subset A of the vector space E is said to be convex if x, y ∈A
and λ ∈(0, 1) imply λx + (1 −λ)y ∈A. The empty set is considered to be
convex also.
Let E be a topological vector space. A subset A of E is said to be circled
if αA ⊆A whenever α ∈R and |α| ≤1. Recall that each topological vector
space admits a neighborhood base of zero, U, consisting of closed circled sets.
A neighborhood base of an arbitrary point x ∈E is then given by x + U,
where U ∈U.
The interior, the closure, and the boundary of a subset A of a topological
vector space are denoted int A, cl A and bd A, respectively. If A is convex, so
are int A and cl A.
A locally convex (vector) space is a topological vector space such that each
neighborhood of zero includes a convex neighborhood of zero. It follows that a

6
1 Preliminaries
locally convex space possesses a neighborhood base of zero consisting of open
convex sets, and also a neighborhood base of zero consisting of closed circled
convex sets.
If E is a topological vector space, E∗denotes the topological dual of E, i.e.,
the vector space of all continuous linear functionals x∗: E →R. If x∗∈E∗,
we write ⟨x∗, x⟩:= x∗(x) for each x ∈E.
Now let E be a normed vector space with norm ∥· ∥. If ¯x ∈E and ϵ > 0,
we set
BE(¯x, ϵ) := {x ∈E | ∥x −¯x∥≤ϵ},
BE := BE(o, 1),
˚BE(¯x, ϵ) := {x ∈E | ∥x −¯x∥< ϵ},
˚BE := ˚BE(o, 1).
If it is clear from the context, we simply write B(¯x, ϵ), B, ˚B(¯x, ϵ), and ˚B,
respectively. A normed vector space is a locally convex space with respect to
the topology induced by the norm. The inner product of a Hilbert space will
be denoted as (x | y).
1.2 Convex Sets in Normed Vector Spaces
Let E be a normed vector space. A nonempty subset A of E is said to be
absorbing if for each y ∈E there exists α0 > 0 such that αy ∈A whenever
|α| ≤α0. The core of A, written cr A, is the set of all x ∈A such that A −x
is absorbing, i.e.,
cr A := {x ∈A | ∀y ∈E ∃α0 > 0 ∀α ∈[−α0, α0] : x + αy ∈A}.
Each convex neighborhood of zero in E is an absorbing set. In a Banach
space, we have the following converse.
Proposition 1.2.1 If E is a Banach space, then each closed convex absorbing
subset A of E is a neighborhood of zero.
Proof. For each n ∈N let An := nA. Each An is closed, and since A is
absorbing, we have E = ∞
n=1 An. By the Baire category theorem it follows
that int(An) is nonempty for at least one n and so the set int A is nonempty.
Hence there exist x ∈A and ρ > 0 such that B(x, ρ) ⊆A. Since A is absorbing,
there further exists α > 0 such that −αx = α(−x) ∈A. Deﬁne ϵ :=
αρ
1+α. We
show that B(o, ϵ) ⊆A. Let y ∈B(o, ϵ) and set z := x+ 1+α
α y. Then z ∈B(x, ρ)
and so z ∈A. Since A is convex, we obtain
y =
1
1 + α(−αx) +
α
1 + αz ∈A.
⊓⊔
We strengthen the concept of a convex set. A nonempty subset A of E is
said to be cs-closed (for convex series closed) if λi ≥0 (i ∈N), ∞
i=1 λi = 1,
xi ∈A (i ∈N) and x := ∞
i=1 λixi ∈E imply x ∈A. It is clear that each
cs-closed set is convex. Lemma 1.2.2 provides examples of cs-closed sets.

1.2 Convex Sets in Normed Vector Spaces
7
Lemma 1.2.2 Closed convex sets and open convex sets in a normed vector
space are cs-closed.
Proof. See Exercise 1.8.1.
⊓⊔
It is obvious that int A ⊆cr A for each subset A of E. The following result
describes the relationship between core and interior more precisely.
Proposition 1.2.3 Let A be a nonempty subset of the normed vector space E.
(a) If A is convex and int A is nonempty, then cr A = int A.
(b) If E is a Banach space and A is cs-closed, then cr A = int A = int(cl A).
Proof.
(a) We ﬁrst show that for any α ∈[0, 1),
α cl A + (1 −α) int A ⊆int A.
(1.1)
Choose some x0 ∈int A. Then (1−α)(int A−x0) is an open neighborhood
of o and so
α cl A = cl (αA) ⊆αA + (1 −α)(int A −x0) ⊆A −(1 −α)x0.
Since this holds for any x0 ∈int A, the left-hand side of (1.1), which is
obviously open, is contained in A. This veriﬁes (1.1). To prove cr A = int A,
it suﬃces to show that cr A ⊆int A. Let x ∈cr A. Then there exists λ > 0
such that y := x + λ(x −x0) ∈A. By (1.1), it follows that
x =
1
1 + λy +
λ
1 + λx0 ∈int A.
(b) (I) First we verify, following Borwein and Zhu [24], that int A = int(cl A).
For this, it suﬃces to show that int(cl A) ⊆int A under the additional
assumption that int(cl A) ̸= ∅. Let y0 ∈int(cl A). Then there exists
ϵ > 0 such that B(y0, ϵ) ⊆cl A and so B ⊆1
ϵ (cl A−y0). Since together
with A, the set 1
ϵ (A−y0) is also cs-closed, we may assume that y0 = o
and B ⊆cl A ⊆A+ 1
2B. From this inclusion we obtain for i = 1, 2, . . . ,
1
2i B ⊆1
2i A+
1
2i+1 B
and so
1
2B ⊆1
2A+ 1
22 A+· · ·+ 1
2i A+
1
2i+1 B.
Thus, if y ∈1
2B, there exist x1, . . . , xi ∈A such that
y ∈1
2x1 + 1
22 x2 + · · · + 1
2i xi +
1
2i+1 B.
It follows that y = ∞
i=1 xi/2i and so y ∈A as A is cs-closed. Hence
1
2B ⊆A and therefore y0 = o ∈int A.
(II) In order to verify cr A = int A, it suﬃces to show cr A ⊆int A under
the additional assumption that cr A ̸= ∅. Let z0 ∈cr A ⊆cr(cl A).
Since cl A −z0 is closed and absorbing, the Baire category theorem
implies that int(cl A) ̸= ∅(cf. the proof of Proposition 1.2.1), and step
(I) shows that int A is nonempty. As the set A is cs-closed, it is also
convex. Therefore the assertion follows from (a).
⊓⊔

8
1 Preliminaries
1.3 Convex Functionals: Deﬁnitions and Examples
Convention. In this section, unless otherwise speciﬁed, E denotes a vector
space and M denotes a nonempty subset of E.
Deﬁnition 1.3.1 If f : M →R, then we call
dom f := {x ∈M | f(x) < +∞}
eﬀective domain of f,
epi f := {(x, t) ∈M × R | f(x) ≤t} epigraph of f.
Further, f is said to be proper (in German: eigentlich) if dom f ̸= ∅and
f(x) > −∞for each x ∈M.
Deﬁnition 1.3.2 is crucial for these lectures.
Deﬁnition 1.3.2 Let M ⊆E be nonempty and convex. The functional f :
M →R is called convex if
f

λx + (1 −λ)y

≤λf(x) + (1 −λ)f(y)
(1.2)
holds for all x, y ∈M and all λ ∈(0, 1) for which the right-hand side is
deﬁned, i.e., is not of the form (+∞) + (−∞) or (−∞) + (+∞). If (1.2) holds
with < instead of ≤whenever x ̸= y, then f is called strictly convex.
Lemma 1.3.3 Let M ⊆E be nonempty and convex and let f : M →R:
(a) f is convex if and only if epi f is a convex set.
(b) If f is convex, then for each λ ∈R, the set {x ∈M | f(x) ≤λ} is convex.
Proof. See Exercise 1.8.2.
⊓⊔
Lemma 1.3.4 Let E be a topological vector space and let f : E →R be
convex. If f(x0) > −∞for some x0 ∈int dom f, then f(x) > −∞for each
x ∈E.
Proof. Assume there exists x1 ∈E satisfying f(x1) = −∞. Since x0 ∈
int dom f, we have x2 := x0 + λ(x0 −x1) ∈dom f for each suﬃciently small
λ ∈(0, 1). Since x0 =
λ
1+λx1 +
1
1+λx2 and f is convex, we obtain
−∞< f(x0) ≤
λ
1 + λf(x1) +
1
1 + λf(x2),
which is contradictory.
⊓⊔
Remark 1.3.5 According to Lemma 1.3.4, it is quite pathological for a con-
vex functional on a topological vector space to attain the value −∞. The fol-
lowing construction shows that this is not so with the value +∞. Let M ⊆E

1.3 Convex Functionals: Deﬁnitions and Examples
9
be nonempty and convex, and let g : M →R be convex. Then the functional
f : E →R deﬁned by
f(x) :=

g(x)
if x ∈M,
+∞
if x ∈E \ M
is proper and convex. Conversely, if f : E →R is proper and convex, then
M := dom f is nonempty and convex and the restriction of f to M is ﬁnite
and convex. Therefore, we may assume that a convex functional is of the form
f : E →R.
We consider important classes of convex functionals.
Example 1.3.6 Let M ⊆E be nonempty. The functional δM : E →R
deﬁned by
δM(x) :=

0
if x ∈M,
+∞
if x ∈E \ M
is called indicator functional of M. Obviously, δM is proper and convex if and
only if M is nonempty and convex.
Example 1.3.7 Let E be a topological vector space and A a nonempty subset
of E∗. Then the support functional σA : E →R of A deﬁned by
σA(x) := sup
x∗∈A
⟨x∗, x⟩,
x ∈E,
is proper and convex. An analogous remark applies to the support functional
σM : E∗→R of a nonempty subset M of E.
Example 1.3.8 Let u : E →R be linear and c ∈R. The functional
f : E →R deﬁned by f(x) := u(x) + c for x ∈E, which is called aﬃne,
is convex.
Example 1.3.9 The functional f : E →R is said to be sublinear if f is
proper, nonnegatively homogeneous (i.e., f(λx) = λf(x) for any x ∈E and
any λ ≥0), and subadditive (i.e., f(x + y) ≤f(x) + f(y) for all x, y ∈E).
If f is sublinear, then f is also convex, and in particular f(o) = 0 (recall that
0 · (+∞) := 0). The norm functional of a normed vector space is sublinear
and so convex.
Example 1.3.10 Let E be a Hilbert space, let T : E →E be linear and self
adjoint, let x0 ∈E, and let c ∈R. Consider the quadratic functional
f(x) := 1
2(Tx | x) −(x0 | x) + c,
x ∈E.
Then
f is convex ⇐⇒T is positively semideﬁnite (i.e. (Tx | x) ≥0 ∀x ∈E).

10
1 Preliminaries
We indicate the proof of this statement.
=⇒: This follows immediately from
f
1
2x

≤1
2f(x) + 1
2f(o).
⇐=: Since x →−(x0 | x) + c, x ∈E, is aﬃne and so convex, it remains to
show that g(x) := (Tx | x), x ∈E, is convex. Let x, y ∈E and 0 < λ < 1.
Then
g

λx + (1 −λ)y

= λ2
T(x −y)
 x −y

+ λ

T(x −y)
 y

+ λ

Ty
 x −y

+

Ty
 y

.
Since λ2 < λ and, by assumption,

T(x −y)
 x −y

≥0, we have
λ2
T(x −y)
 x −y

≤λ

T(x −y)
 x −y

.
Using this and the self adjointness of T, we immediately obtain
g

λx + (1 −λ)y

≤λg(x) + (1 −λ)g(y).
Example 1.3.11 Let E be a normed vector space. If M ⊆E, then the dis-
tance functional x →dM(x) is deﬁned by
dM(x) := d(M, x) := d(x, M) := inf
y∈M ∥x −y∥, x ∈E.
Recall that inf ∅:= +∞. If M is nonempty and convex, then dM is easily seen
to be proper and convex.
Example 1.3.12 Let E be a topological vector space, let M ⊆E be non-
empty and set
pM(x) := inf{λ > 0 | x ∈λM}, x ∈E.
The functional pM : E →R is called Minkowski functional or gauge.
Lemma 1.3.13 summarizes important properties of pM.
Lemma 1.3.13 Let E be a topological vector space. If M ⊆E is nonempty
and convex and o ∈int M, then:
(a) 0 ≤pM(x) < +∞for all x ∈E.
(b) pM is sublinear and continuous.
(c) int M = {x ∈E | pM(x) < 1} ⊆M ⊆{x ∈E | pM(x) ≤1} = cl M.
(d) If, in addition, M is symmetric (i.e., x ∈M =⇒−x ∈M) and bounded,
then pM is a norm on E that generates the topology of E.
Proof. See, for instance, Aliprantis and Border [2].
⊓⊔

1.4 Continuity of Convex Functionals
11
1.4 Continuity of Convex Functionals
In this section, we study continuity properties of convex functionals.
Recall that if E is a normed vector space, then the proper functional
f : E →R is said to be locally Lipschitz continuous, or brieﬂy locally L-
continuous, around ¯x ∈domf if there exist ϵ > 0 and λ > 0 such that
|f(x) −f(y)| ≤λ∥x −y∥
∀x, y ∈B(¯x, ϵ).
Moreover, f is called locally L-continuous on the open subset D of E if f is
locally L-continuous around each ¯x ∈D.
Theorem 1.4.1 Let E be a topological vector space and let f : E →R be
proper, convex and bounded above on some nonempty open subset G of E.
Then f is continuous on int dom f. If, in particular, E is a normed vector
space, then f is locally L-continuous on int dom f.
Proof.
(I) By assumption, there exists a > 0 such that f(y) < a for each y ∈G. In
particular, G ⊆int domf. We ﬁrst show that f is continuous on G.
(Ia) To prepare the proof, we show the following: If ¯x ∈dom f, z ∈E,
¯x + z ∈dom f, ¯x −z ∈dom f, and λ ∈[0, 1], then
|f(¯x + λz) −f(¯x)| ≤λ max{f(¯x + z) −f(¯x), f(¯x −z) −f(¯x)}.
(1.3)
Veriﬁcation of (1.3): Since ¯x + λz = (1 −λ)¯x + λ(¯x + z) ∈dom f, we
have f(¯x + λz) ≤(1 −λ)f(¯x) + λf(¯x + z), hence
f(¯x + λz) −f(¯x) ≤λ

f(¯x + z) −f(¯x)

.
(1.4)
Analogously, with z replaced by −z, we obtain
f(¯x −λz) −f(¯x) ≤λ

f(¯x −z) −f(¯x)

.
(1.5)
From ¯x = 1
2(¯x + λz) + 1
2(¯x −λz) we conclude that f(¯x) ≤1
2f(¯x + λz) +
1
2f(¯x −λz) and so f(¯x) −f(¯x + λz) ≤f(¯x −λz) −f(¯x), which together
with (1.5) gives f(¯x) −f(¯x + λz) ≤λ

f(¯x −z) −f(¯x)

. From this and
(1.4) we obtain (1.3).
(Ib) Now let ¯x ∈G and let ϵ > 0. Then there exists a circled neighborhood U
of zero such that ¯x + U ⊆G. Let λ ∈(0, 1] be such that λ(a −f(¯x)) < ϵ.
Then (1.3) implies |f(y)−f(¯x)| < ϵ for all y in the neighborhood ¯x+λU
of ¯x. Hence f is continuous at ¯x.
(II) We show that f is continuous at ¯y ∈int dom f. Let ¯x and U be as in
step (Ib). Then there exists δ > 0 such that z := ¯y + δ(¯y −¯x) ∈dom f
(see Fig. 1.1). Set λ := δ/(1 + δ). If y ∈U, then ¯y + λy = λ¯x + (1 −λ)z
and so
f(¯y + λy) ≤λf(¯x + y) + (1 −λ)f(z) < λa + (1 −λ)f(z).

12
1 Preliminaries
z
¯y + λU
¯y
¯x
¯x + U
G
Fig. 1.1
Since f(z) < +∞, we see that f is bounded above on the neighborhood
¯y + λU of ¯y and so on the open set int(¯y + λU) that also contains ¯y. By
step (I), f is continuous at ¯y.
(III) Now let E be a normed vector space and let ¯y ∈int dom f. By step (II)
there exist c, ρ > 0 satisfying
|f(x)| ≤c
∀x ∈B(¯y, 2ρ).
(1.6)
Assume, to the contrary, that f is not locally L-continuous around ¯y.
Then there exist x, y ∈B(¯y, ρ) such that
f(x) −f(y) > 2c
ρ ∥x −y∥.
Set α :=
ρ
∥x−y∥and ˆx := x + α(x −y). Then we have x =
1
1+α ˆx +
α
1+αy
which implies f(x) ≤
1
1+αf(ˆx) +
α
1+αf(y) and so
f(ˆx) −f(x) ≥α

f(x) −f(y)

> 2c.
But this contradicts (1.6) as ˆx ∈B(¯y, 2ρ).
⊓⊔
Convex functions on a ﬁnite-dimensional normed vector space have a
remarkable continuity behavior.
Corollary 1.4.2 If f : Rn →R is proper and convex and int dom f is non-
empty, then f is locally L-continuous on int dom f.
Proof. We shall show that f is bounded above on a nonempty open subset G
of Rn; the assertion then follows from Theorem 1.4.1. Let ¯x = (¯x1, . . . , ¯xn) ∈
int dom f. Then there exists α > 0 such that int dom f contains the closed
cube C with center ¯x and edge length α. Let
G := {(x1, . . . , xn) ∈Rn  ¯xi < xi < ¯xi + α
n}.
Then G is nonempty, open, and contained in C (Fig. 1.2). Let

e(1), . . . , e(n)
denote the standard basis of Rn. If x ∈G, then we have

1.5 Sandwich and Separation Theorems
13
F
¯x + αe(2)
¯x + αe(1)
G
¯x
Fig. 1.2
x =
n
	
i=1
xie(i) =
n
	
i=1
xi−¯xi
α
(¯x + αe(i)) +

1 −
n
	
i=1
xi−¯xi
α

¯x
and so
f(x) ≤
n
i=1
xi−¯xi
α
f

¯x + αe(i)
+

1 −
n
i=1
xi−¯xi
α

f(¯x)
≤max

f

¯x + αe(1)
, . . . , f

¯x + αe(n)
, f(¯x)

.
⊓⊔
By Corollary 1.4.2, each R-valued convex function on Rn is locally L-
continuous. Notice that, in contrast to this, on each inﬁnite-dimensional
normed vector space there always exist even linear functionals that are dis-
continuous.
1.5 Sandwich and Separation Theorems
In this and in Sect. 1.6 we repeat, in a form appropriate to our purposes, some
facts from Functional Analysis that will be frequently needed in the sequel.
A nonempty subset P of a vector space E is called cone if x ∈P and λ > 0
imply λx ∈P. Moreover, P is called convex cone if P is a cone and a convex
set. Obviously, P is a convex cone if and only if x, y ∈P and λ, µ > 0 imply
λx + µy ∈P. By deﬁnition, the empty set is also a cone.
If P is a nonempty convex cone in E, then
x ≤P y
:⇐⇒
y −x ∈P
deﬁnes a relation ≤P on E that is transitive and compatible with the vector
space structure of E, i.e., for all x, y, z ∈E and λ ∈R we have
x ≤P y and y ≤P z
=⇒
x ≤P z,
x ≤P y
=⇒
x + z ≤P y + z,
x ≤P y and λ > 0
=⇒
λx ≤P λy.

14
1 Preliminaries
Moreover, we have
P = {x ∈E | o ≤P x}.
Notice that the zero element o need not belong to P and so the relation ≤P
need not be reﬂexive. We call ≤P the preorder generated by P.
Proposition 1.5.1 (Extension Theorem) Let M be a linear subspace of
the vector space E and P a nonempty convex cone in E satisfying P ⊆M −P.
Suppose further that u : M →R is linear and satisﬁes u(x) ≥0 for any
x ∈M ∩P. Then there exists a linear functional v : E →R such that
v(x) = u(x) for every x ∈M and v(x) ≥0 for every x ∈P.
Proof. Set E1 := span(M ∪P) = M + P −P and
p(x) := inf{u(y) | y ∈M, y −x ∈P},
x ∈E1.
Since P ⊂M −P, the functional p is easily seen to be ﬁnite on E1. Further
p is sublinear and satisﬁes u(x) ≤p(x) for any x ∈M. By the Hahn–Banach
theorem, there exists a linear functional v1 : E1 →R such that v1(x) = u(x)
for any x ∈M and v1(x) ≤p(x) for any x ∈E1. Setting v(x) := v1(x) for
every x ∈E1 and v(x) := 0 for every x in the algebraic complement of E1 in
E completes the proof.
⊓⊔
The following result will be a useful tool in the analysis of convex func-
tionals.
Theorem 1.5.2 (Sandwich Theorem) Let E be a topological vector space
and let p, q : E →R be proper, convex and such that −q(x) ≤p(x) for all
x ∈E. Suppose further that
(A1) (int dom p) ∩dom q ̸= ∅and p is continuous at some point of int dom p
or
(A2) dom p ∩(int dom q) ̸= ∅and q is continuous at some point of int dom q.
Then there exist v ∈E∗and c ∈R such that
−q(x) ≤⟨v, x⟩+ c ≤p(x)
∀x ∈E
(see Fig. 1.3 for E = R).
p
−q
v
v + c
Fig. 1.3

1.5 Sandwich and Separation Theorems
15
Proof. (I) We set
F := E × R × R,
M := {o} × {0} × R,
u(o, 0, ρ) := −ρ
∀ρ ∈R,
P := {β(y, 1, t) −α(x, 1, s)
 α, β ≥0; s, t ∈R;
x ∈dom p; y ∈dom q; p(x) ≤s; −q(y) ≥t}.
Then we have:
(a) u is a linear functional on the linear subspace M of F satisfying
u(z) ≥0 for any z ∈M ∩P.
(b) P is a convex cone in F.
(c) P ⊂M −P.
It is easy to verify (a) and (b). We prove (c). Let z ∈P, thus z =
β(y, 1, t) −α(x, 1, s). Suppose assumption (A1) holds. Then there exists
z0 ∈(int dom p) ∩dom q. For δ > 0 deﬁne
zδ := z0 + δ

βy −αx −(β −α)z0

.
It follows that zδ ∈dom p if δ is suﬃciently small. Hence, with δ and ρ
appropriately chosen, we obtain
z = 1
δ

zδ, 1, p(zδ)

−
 1
δ −β + α

z0, 1, −q(z0)

+ (o, 0, ρ) ∈−P + M.
(II) By Proposition 1.5.1 there exists a linear functional w : F →R satisfying
w(z) = u(z) for all z ∈M and w(z) ≥0 for all z ∈P. In particular, we
have w(o, 0, 1) = −1. Deﬁne
v(x) := w(x, o, 0)
∀x ∈E,
c := w(o, 1, 0).
Then v : E →R is linear and w(x, s, t) = v(x)+cs−t for all (x, s, t) ∈F.
If x ∈dom p, then z := −

x, 1, p(x)

∈P. It follows that
0 ≤w(z) = −v(x) −c + p(x) and so v(x) + c ≤p(x).
(1.7)
Analogously we obtain −q(x) ≤v(x) + c. Since p is continuous at
some point of int dom p, the second inequality in (1.7) implies that v is
bounded above on a nonempty open set and so, by Theorem 1.4.1, is
continuous.
(III) A similar argument applies under the assumption (A2).
⊓⊔
The sandwich theorem describes the separation of a concave functional −q
and a convex functional p by a continuous aﬃne functional. Now we consider
the separation of convex sets by a hyperplane.
Recall that a hyperplane in the topological vector space E is a set of the
form
[x∗= α] := {x ∈E | ⟨x∗, x⟩= α},
(1.8)

16
1 Preliminaries
A
B
[x∗= α]
Fig. 1.4
A
B
Fig. 1.5
where x∗∈E∗, x∗̸= o, and α ∈R. The hyperplane [x∗= α] separates the
space E into the half-spaces [x∗≤α] and [x∗≥α], where the notation is
analogous to (1.8).
The subsets A and B of E are said to be separated if there exists a hyper-
plane [x∗= α] such that (see Fig. 1.4)
A ⊆[x∗≤α]
and
B ⊆[x∗≥α].
(1.9)
Further we say that the subsets A and B of E are strongly separated if there
exist a hyperplane [x∗= α] and ϵ > 0 such that (see Fig. 1.5)
A ⊆[x∗≤α −ϵ]
and
B ⊆[x∗≥α + ϵ].
(1.10)
Theorem 1.5.3 (Weak Separation Theorem) Let A and B be nonempty
convex subsets of the topological vector space E and assume that int A ̸= ∅.
Then the following statements are equivalent:
(a) A and B are separated.
(b) (int A) ∩B = ∅.
Proof. (a) =⇒(b): Assume that there exists a nonzero x∗∈E∗such that (1.9)
holds. Suppose, to the contrary, that there exists ¯x ∈(int A) ∩B. Let y ∈E
be given. Then for ρ > 0 suﬃciently small, we have y± := ¯x ± ρ(y −¯x) ∈A
and so
α ≥⟨x∗, y±⟩= ⟨x∗, ¯x⟩± ρ⟨x∗, y −¯x⟩.

1.5 Sandwich and Separation Theorems
17
Since ⟨x∗, ¯x⟩= α it follows that ±⟨x∗, y −¯x⟩≤0 and so ⟨x∗, y⟩= ⟨x∗, ¯x⟩.
Since y ∈E is arbitrary and x∗is linear, we conclude that x∗= o : a contra-
diction.
(b) =⇒(a): Let x0 ∈int A and let p denote the Minkowski functional of
A −x0. Further deﬁne q : E →R by q(x) := −1 for all x ∈B −x0 and
q(x) := +∞for all x ∈E \ (B −x0). Applying Lemma 1.3.13, it is easy to
see that the assumptions of Theorem 1.5.2 are satisﬁed. Hence there exist
x∗∈E∗and c ∈R such that
⟨x∗, x⟩+ c ≤p(x) ∀x ∈E
and
⟨x∗, x⟩+ c ≥1 ∀x ∈B −x0.
It follows that x∗̸= o (consider x = o) and that the hyperplane [x∗= α],
where α := ⟨x∗, x0⟩+ 1 −c, separates A and B.
⊓⊔
Corollary 1.5.4 Let A be a convex cone in E, B a nonempty convex subset
of E, and assume that int A ̸= ∅but (int A) ∩B = ∅. Then there exists
x∗∈E∗, x∗̸= o, such that
⟨x∗, x⟩≤0 ∀x ∈A
and
⟨x∗, y⟩≥0 ∀y ∈B.
Proof. See Exercise 1.8.3.
⊓⊔
Let A ⊆E and ¯x ∈A. The hyperplane [x∗= α] is said to be a supporting
hyperplane of A at ¯x if
¯x ∈[x∗= α]
and
A ⊆[x∗≤α]
or
A ⊆[x∗≥α]
(Fig. 1.6).
A point ¯x ∈A admitting a supporting hyperplane of A is said to be a support
point of A. There is an obvious relationship to the support functional σA
of A. If ¯x is a support point of A and [x∗= α] is a supporting hyperplane
such that A ⊆[x∗≤α], then σA(x∗) = ⟨x∗, ¯x⟩. An immediate consequence of
Theorem 1.5.3 is:
Corollary 1.5.5 Let A be closed convex subset of the topological vector space
E and assume that int A is nonempty. Then any boundary point of A is a
support point of A.
A
¯x
[x∗= α]
[x∗≤α]
[x∗≥α]
Fig. 1.6

18
1 Preliminaries
We supplement the preceding results by two statements presented without
proof that refer to the case int A = ∅.
Theorem 1.5.6 (Bishop–Phelps Theorem) If A is a closed convex subset
of the Banach space E, then the set of support points of A is dense in the
boundary of A.
Proof. See, for instance, Phelps [165].
⊓⊔
Proposition 1.5.7 Let E be a ﬁnite-dimensional normed vector space, and
let A and B be nonempty convex subsets of E. Then the following statements
are equivalent:
(a) A and B are separated.
(b) A ∩B = ∅.
Proof. See, for instance, Holmes [92].
⊓⊔
Notice that the condition (b) of Theorem 1.5.3 is equivalent to o /∈
(int A) −B. Strengthening this condition, we obtain a result on strong sepa-
ration, provided we restrict ourselves to locally convex spaces.
Theorem 1.5.8 (Strong Separation Theorem 1) Assume that E is a lo-
cally convex space and that A and B are nonempty convex subsets of E. Then
the following statements are equivalent:
(a) A and B are strongly separated.
(b) o /∈cl (A −B).
Proof. (a) =⇒(b): Exercise 1.8.4.
(b) =⇒(a): By virtue of (b) there exists an open convex neighborhood U
of zero such that A ∩(B + U) = ∅. Moreover, B + U is open. Hence, by
Theorem 1.5.3, there exists a closed hyperplane [x∗= α′] such that A ⊆[x∗≤
α′] and B+U ⊆[x∗≥α′]. Choose some z0 ∈−U such that ⟨x∗, z0⟩> 0, which
exists since x∗̸= o. Set α := supx∈A⟨x∗, x⟩+ 1
2⟨x∗, z0⟩and ϵ := 1
2⟨x∗, z0⟩.
It follows that A ⊆[x∗≤α −ϵ] and B ⊆[x∗≥α + ϵ].
⊓⊔
The following is a frequently used special case of Theorem 1.5.8.
Theorem 1.5.9 (Strong Separation Theorem 2) Assume that A and B
are nonempty convex subsets of the locally convex space E such that A is
closed, B is compact, and A ∩B = ∅. Then A and B are strongly separated.
Proof. See Exercise 1.8.5.
⊓⊔
Simple examples, already with E = R2, show that Theorem 1.5.9 may fail
if “compact” is replaced by “closed.”
In analogy to Corollary 1.5.4 we now have:

1.6 Dual Pairs of Vector Spaces
19
Corollary 1.5.10 Let A be a closed convex cone in E, B a nonempty compact
convex subset of E, and assume that A ∩B = ∅. Then there exists x∗∈E∗,
x∗̸= o, and ϵ > 0 such that
⟨x∗, x⟩≤0
∀x ∈A
and
⟨x∗, y⟩≥ϵ
∀y ∈B.
Proof. See Exercise 1.8.6.
⊓⊔
1.6 Dual Pairs of Vector Spaces
For results in this section stated without proof, see the references at the end
of the chapter. The following notion will be the basis for the duality theory
of convex optimization.
Deﬁnition 1.6.1 Let E and F be vector spaces.
(a) A functional a : E × F →R is said to be bilinear if a(·, u) is linear on E
for each ﬁxed u ∈F and a(x, ·) is linear on F for each ﬁxed x ∈E.
(b) Let a : E × F →R be a bilinear functional with the following properties:
If a(x, u) = 0 for each x ∈E, then u = o,
if a(x, u) = 0 for each u ∈F, then x = o.
(1.11)
Then (E, F) is called dual pair of vector spaces with respect to a.
Example 1.6.2 Let E be a locally convex space. Then (E, E∗) is a dual pair
with respect to the bilinear functional
a(x, x∗) := ⟨x∗, x⟩
∀x ∈E
∀x∗∈E∗.
We verify (1.11). It is clear by deﬁnition that ⟨x∗, x⟩= 0 for each x ∈E implies
x∗= o. Now let ⟨x∗, x⟩= 0 for each x∗∈E∗. Assume that x ̸= o. Then
there exist a closed convex (circled) neighborhood U of zero not containing
x. By Theorem 1.5.9, the closed set U and the compact set {x} are strongly
separated. Hence there exist x∗∈E∗\ {o}, α ∈R and ϵ > 0 such that
⟨x∗, y⟩≤α −ϵ
∀y ∈U
and
⟨x∗, x⟩≥α + ϵ.
Considering y = o, we see that α−ϵ ≥0, and it follows that ⟨x∗, x⟩≥α+ϵ >
α −ϵ ≥0: a contradiction.
We shall now show that this example provides the prototype of a dual
pair. Let (E, F) be a dual pair with respect to the bilinear functional a. The
weak topology σ(E, F) on E is by deﬁnition the weakest topology on E such
that each linear functional x →a(x, u) is continuous; here u varies over F.
In other words, each u ∈F deﬁnes an element x∗
u of E∗via

20
1 Preliminaries
⟨x∗
u, x⟩:= a(x, u)
∀x ∈E.
(1.12)
By (1.11), if u ̸= v, then x∗
u ̸= x∗
v. Hence we can identify x∗
u with u, so that
we obtain F ⊆E∗. Proposition 1.6.3 states, among others, that each x∗∈E∗
is of the form x∗
u for some u ∈F. If we want to indicate the topology, say τ,
of a topological vector space E, we write E[τ] instead of E. Similarly, we use
E[ ∥· ∥].
Proposition 1.6.3 If (E, F) is a dual pair of vector spaces with respect to
the bilinear functional a, then:
(a) The weak topology σ(E, F) is a locally convex topology on E, a neighbor-
hood base of zero being formed by the sets
U(u1, . . . , um) := {x ∈E
 |a(x, ui)| < 1 for i = 1, . . . , m},
where m ∈N and u1, . . . , um ∈F.
(b) For each x∗∈E∗there exists precisely one u ∈F such that x∗= x∗
u (see
(1.12)). The dual E∗of the locally convex space E[σ(E, F)] can thus be
identiﬁed with F.
Of course, the same holds true with the roles of E and F exchanged, i.e.,
one deﬁnes analogously the weak topology σ(F, E) on F. Then the dual F ∗
of F[σ(F, E)] can be identiﬁed with E.
Let (E, F) be a dual pair with respect to some bilinear functional.
A locally convex topology τE on E is said to be compatible with the dual pair
(E, F) if E[τE]∗= F in the sense described above, analogously for a locally
convex topology on F. If (E, F) is a dual pair of vector spaces and if τE,
τF are compatible topologies on E and F, respectively, then (E[τE], F[τF ])
is called dual pair of locally convex spaces. A complete characterization of
compatible topologies (not needed in this book) is given by the Mackey–Arens
theorem.
Remark 1.6.4
(a) Let E[τ] be a locally convex space. Since (E, E∗) is a dual pair of vector
spaces (see Example 1.6.2), we can consider the weak topology σ(E, E∗)
on E, which is weaker than τ. On E∗, we have to distinguish between
the topologies σ(E∗, E∗∗) and σ(E∗, E). The latter is called weak star
topology or weak∗topology. Among others, we have the following dual
pairs of locally convex spaces:

E[τ], E∗[σ(E∗, E)]

and

E[σ(E, E∗)], E∗[σ(E∗, E)]

.
If A is a subset of E∗, we denote by cl∗A the σ(E∗, E)-closure of A and
by co∗A the σ(E∗, E)-closed convex hull of A. A sequence (xk) in E that
is σ(E, E∗)-convergent to x ∈E is said to be weakly convergent to x,

1.6 Dual Pairs of Vector Spaces
21
written xk
w
−→x as k →∞; this means that limk→∞⟨x∗, xk⟩= ⟨x∗, x⟩for
any x∗∈E∗. Analogously, a sequence (x∗
k) in E∗is weak∗convergent to
x∗∈E∗, written
x∗
k
w∗
−−→x∗
as k →∞,
if and only if limk→∞⟨x∗
k, x⟩= ⟨x∗, x⟩for any x ∈E.
(b) In view of Proposition 1.6.3, we usually denote any dual pair of vector
spaces by (E, E∗). Moreover, when there is no need to specify the topology,
we shall use (E, E∗) also to denote a dual pair of locally convex spaces,
tacitly assuming that E and E∗are equipped with topologies compatible
with the dual pair.
(c) Now let E[ ∥·∥] be a normed vector space and let ∥·∥∗denote the associated
norm on E∗. The weak topology σ(E, E∗) is weaker than the topology
generated by the norm ∥· ∥; the two topologies coincide if and only if E is
ﬁnite dimensional. In general, the topology generated by the norm ∥· ∥∗
on E∗is not compatible with the dual pair (E, E∗). However, if E is a
reﬂexive Banach space, then

E[∥· ∥], E∗[∥· ∥∗]

is a dual pair of locally convex spaces.
(d) If E is an inﬁnite-dimensional normed vector space, then the weak topol-
ogy σ(E, E∗) does not admit a countable base of neighborhoods of zero.
Hence properties referring to the weak topology can in general, not be
characterized by sequences. For instance, each weakly closed subset of E
is weakly sequentially closed but not conversely. In this connection, a sub-
set A of E is said to be weakly sequentially closed if each limit point of a
weakly convergent sequence in A is an element of A.
It turns out that certain topological properties important in the following
depend on the dual pair only.
Proposition 1.6.5 Let (E, E∗) be a dual pair of vector spaces, and let τ1
and τ2 be locally convex topologies on E compatible with the dual pair. Fur-
ther let A be a convex subset of E. Then: A is τ1-closed if and only if A is
τ2-closed.
Corollary 1.6.6 In a normed vector space, any convex closed subset is weakly
sequentially closed.
We conclude this section with two important results.
Theorem 1.6.7 (Eberlein–Šmulian Theorem) In
a
reﬂexive
Banach
space, any bounded weakly sequentially closed subset (in particular, any con-
vex bounded closed subset) is weakly sequentially compact.

22
1 Preliminaries
Theorem 1.6.8 (Krein–Šmulian Theorem) If E is a Banach space, then
a convex subset M of E∗is weak∗closed if and only if M ∩ρBE∗is weak∗
closed for any ρ > 0.
1.7 Lower Semicontinuous Functionals
Lower semicontinuous functionals will play an important part in these lectures.
We ﬁrst repeat the deﬁnition.
Deﬁnition 1.7.1 Let E be a topological vector space, M a nonempty subset
of E, and f : M →R:
(a) The functional f is called lower semicontinuous (l.s.c.) at ¯x ∈M if either
f(¯x) = −∞or for every k < f(¯x) there exists a neighborhood U of ¯x such
that
k < f(x)
∀x ∈M ∩U
(cf. Fig. 1.7).
f is said to be lower semicontinuous on M if f is l.s.c. at each ¯x ∈M.
Moreover, f is called upper semicontinuous at ¯x if −f is l.s.c. at ¯x.
(b) The functional f is said to be sequentially lower semicontinuous at ¯x ∈M
if for each sequence (xn) in M satisfying xn →¯x as n →∞one has
f(¯x) = lim infn→∞f(xn).
Lemma 1.7.2 characterizes these properties by properties of appropriate
sets.
Lemma 1.7.2 Let E be a topological vector space, M a nonempty subset of E,
and f : M →R. Then the following statements are equivalent:
(a) f is l.s.c. on M.
(b) For each λ ∈R, the set Mλ := {x ∈M | f(x) ≤λ} is closed relative to M.
(c) epi f is closed relative to M × R.
)
(
¯x
U
k
f(¯x)
Fig. 1.7

1.7 Lower Semicontinuous Functionals
23
Proof. We only verify (a) =⇒(c), leaving the proof of the remaining assertions
as Exercise 1.8.7. Thus let (a) hold. We show that (M × R) \ epi f is open.
Let (¯x, ¯t) ∈(M × R) \ epi f be given. Then f(¯x) > ¯t. Set δ := 1
2(f(¯x) −¯t).
Then f(¯x) > ¯t + δ. By (a) there exists a neighborhood U of ¯x in E such
that f(x) > ¯t + δ for each x ∈M ∩U. Then V := (M ∩U) × (¯t −δ, ¯t + δ)
is a neighborhood of (¯x, ¯t) relative to M × R. For any (x, t) ∈V we have
f(x) > ¯t + δ > t and so (x, t) /∈epi f.
⊓⊔
Proposition 1.7.3 Assume that E is a normed vector space, M ⊆E is
nonempty convex and closed, and f : E →R is proper and convex. Then the
following assertions are equivalent:
(a) f is l.s.c. on M.
(b) f is weakly l.s.c. on M.
(c) f is weakly sequentially l.s.c. on M.
Proof. We only verify (a) =⇒(c), leaving the veriﬁcation of the remaining
assertions as Exercise 1.8.8. Thus let (a) hold. Suppose, to the contrary, that
f is not weakly sequentially l.s.c. at some ¯x ∈M. Then there exists a sequence
(xn) in M satisfying xn
w
−→¯x and f(¯x) > limn→∞f(xn). Choose λ ∈R and
n0 ∈N such that f(¯x) > λ ≥f(xn) for all n ≥n0. Since M is closed and Mλ
is closed relative to M (Lemma 1.7.2), the latter set is closed. In addition, Mλ
is convex (Lemma 1.3.3). By Corollary 1.6.6, Mλ is weakly sequentially closed.
Hence xn
w
−→¯x implies ¯x ∈Mλ, which is a contradiction to f(¯x) > λ.
⊓⊔
Proposition 1.7.4 Let E be a Banach space. If f : E →R is proper convex
l.s.c. and int dom f is nonempty, then f is continuous on int dom f.
Proof. We may assume that o ∈int dom f. Choose a number λ > f(o) and
set A := {x ∈E | f(x) ≤λ}. Then A is convex and closed. We show that A is
also absorbing. Let x ∈E, x ̸= o, be given. By Corollary 1.4.2 the restriction
of f to the one-dimensional subspace {τx | τ ∈R} is continuous at zero. This
and f(o) < λ imply that there exists α0 > 0 such that f(αx) < λ and so
αx ∈A whenever |α| ≤α0. By Proposition 1.2.1 the set A is a neighborhood
of zero. Now Theorem 1.4.1 completes the proof.
⊓⊔
Let A be a nonempty subset of E. A set M ⊆A is called extremal subset
of A if the following holds:
∀λ ∈(0, 1)
∀x, y ∈A :
λx + (1 −λ)y ∈M
=⇒
x, y ∈M.
Further, ¯x ∈A is called extreme point of A if {¯x} is an extremal subset of A.
If A is convex, then ¯x ∈A is an extreme point of A if and only if the set
A \ {¯x} is also convex. We write ep A for the set of all extreme points of A.
Example 1.7.5 In Rn, the set ep(B(o, 1)) consists of the boundary of B(o, 1)
for the Euclidean norm and of ﬁnitely many points (which?) for the l1 norm.

24
1 Preliminaries
Lemma 1.7.6 If M is an extremal subset of A, then ep(M) = M ∩ep(A).
Proof. See Exercise 1.8.9.
⊓⊔
We recall an important result of Functional Analysis. In this connection,
co B denotes the closed convex hull of the set B ⊆E, i.e., the intersection of
all closed convex sets containing B.
Theorem 1.7.7 (Krein–Milman Theorem) Let E be a locally convex
space and A a nonempty subset of E:
(a) If A is compact, then ep A ̸= ∅.
(b) If A ⊆E is compact and convex, then A = co(ep A).
Proposition 1.7.8 (Bauer’s Maximum Theorem) Let E be a locally
convex space, A a nonempty compact convex subset of E, and g : A →R an
upper semicontinuous convex functional. Then there exists ¯x ∈ep A such that
g(¯x) = maxx∈A g(x).
Proof. Let
M := {¯x ∈A | g(¯x) = max
x∈A g(x)}.
We have to prove that M ∩ep A ̸= ∅. Let m := maxx∈A g(x). We ﬁrst
show that M is an extremal subset of A. In fact, if λ ∈(0, 1); x, y ∈A and
λx + (1 −λ)y ∈M, then
m = g

λx + (1 −λ)y

≤λg(x) + (1 −λ)g(y) ≤λm + (1 −λ)m = m
and so λg(x) + (1 −λ)g(y) = m. Consequently, x, y ∈M. Hence M is an
extremal subset of A, and Lemma 1.7.6 implies that M ∩ep A = ep M.
The hypotheses on A and g entail that M is nonempty and compact. By
Theorem 1.7.7(a), we have ep M ̸= ∅.
⊓⊔
1.8 Bibliographical Notes and Exercises
Concerning separation theorems and dual pairs, we refer to standard
textbooks on Functional Analysis, for example Aliprantis and Border [2],
Holmes [92], Werner [215], or Yosida [218]. A good introductory presentation
of convex functionals give Roberts and Varberg [174]. For cs-closed sets see
Jameson [103]. The present form of the sandwich theorem (Theorem 1.5.2) is
due to Landsberg and Schirotzek [116]. Ernst et al. [61] establish results on
the strict separation of disjoint closed sets in reﬂexive Banach spaces.
Exercise 1.8.1 Prove Lemma 1.2.2.
Exercise 1.8.2 Verify Lemma 1.3.3.
Exercise 1.8.3 Prove Corollary 1.5.4.

1.8 Bibliographical Notes and Exercises
25
Exercise 1.8.4 Verify the implication (a) =⇒(b) in Theorem 1.5.8.
Exercise 1.8.5 Prove Theorem 1.5.9.
Exercise 1.8.6 Verify Corollary 1.5.10.
Exercise 1.8.7 Prove the remaining assertions of Lemma 1.7.2
Exercise 1.8.8 Verify the remaining assertions of Proposition 1.7.3.
Exercise 1.8.9 Prove Lemma 1.7.6.
Exercise 1.8.10 Show that the norm functional on the normed vector space
E is weakly l.s.c. and the norm functional on E∗is weak∗l.s.c.
Exercise 1.8.11 Let E be a normed vector space, let f : E →R be a proper
functional, and deﬁne the lower semicontinuous closure f : E →R of f by
f(x) := lim inf
y→x f(y),
x ∈E.
Show that f is the largest l.s.c. functional dominated by f.

2
The Conjugate of Convex Functionals
2.1 The Gamma Regularization
Convention. Throughout this chapter unless otherwise speciﬁed, (E, E∗)
denotes any dual pair of locally convex spaces (cf. Remark 1.6.4 and
Proposition 1.6.5).
In this section, we show that a l.s.c. convex functional is the upper envelope
of continuous aﬃne functionals.
Deﬁnition 2.1.1 For f : E →R let
A(f) := {a : E →R | a is continuous and aﬃne, a ≤f}.
The functional f Γ : E →R deﬁned by
f Γ (x) := sup{a(x) | a ∈A(f)},
x ∈E,
is called Gamma regularization of f. Recall that sup ∅:= −∞.
Figure 2.1 suggests the following result.
f
a1
a2
x
Fig. 2.1

28
2 The Conjugate of Convex Functionals
Proposition 2.1.2 If f : E →R is proper, then the following statements are
equivalent:
(a) f = f Γ .
(b) f is l.s.c. and convex.
Proof.
(a) =⇒(b): See Exercise 2.5.2.
(b) =⇒(a): It is clear that f Γ ≤f. Assume now that, for some x0 ∈E
and some k ∈R, we had f Γ (x0) < k < f(x0). We shall show that there
exists a ∈A(f) satisfying k < a(x0) (cf. Fig. 2.2), which would imply the
contradiction f Γ (x0) > k.
Since f is l.s.c., epi f is closed (Lemma 1.7.2). Furthermore, epi f is con-
vex (Lemma 1.3.3) and (x0, k) ̸∈epi f. By the strong separation theorem 2
(Theorem 1.5.9) applied with A := epi f and B := {(x0, k)}, there exist
w ∈(E × R)∗and α ∈R such that
w(x, t) ≤α ∀(x, t) ∈epi f
and
w(x0, k) > α.
(2.1)
We have
w(x, t) = ⟨x∗, x⟩+ ct,
where ⟨x∗, x⟩:= w(x, 0), c := w(o, 1).
(2.2)
It is obvious that x∗∈E∗. Further, since (x, t) ∈epi f entails (x, t′) ∈epi f
for each t′ > t, we obtain
c ≤α −⟨x∗, x⟩
t′
∀t′ > max{0, t}
and so, letting t′ →+∞, c ≤0. Now we distinguish two cases.
Case 1. Assume that f(x0) < +∞. Then (2.1) with t := f(x0) and (2.2) imply
⟨x∗, x0⟩+ cf(x0) ≤α < ⟨x∗, x0⟩+ ck.
f(x0)
epi f
f
a
k
x0
Fig. 2.2

2.2 Conjugate Functionals
29
Since k < f(x0), it follows that c < 0. The functional a : E →R deﬁned by
a(x) := α
c −1
c⟨x∗, x⟩,
x ∈E,
is continuous and aﬃne. If x ∈dom f, we have by (2.1),
a(x) = 1
c

α −w(x, f(x))

+ f(x) ≤f(x).
If x /∈dom f, then a(x) < +∞= f(x). Hence a ∈A(f). Moreover, we have
a(x0) = 1
c

α −⟨x∗, x0⟩

> k.
Case 2. Assume that f(x0) = +∞. If c < 0, then deﬁne a as in Case 1. Now
suppose that c = 0. Since f is proper, there exists y0 ∈dom f. According to
Case 1, with y0 instead of x0, there exists a0 ∈A(f). Deﬁne a : E →R by
a(x) := a0(x) + ρ

⟨x∗, x⟩−α

,
where ρ := |k −a0(x0)|
⟨x∗, x0⟩−α + 1.
Then a is continuous and aﬃne. Further we have a(x) ≤a0(x) ≤f(x) for each
x ∈dom f and so a ∈A(f). Finally, noting that a0(x0)+|k −a0(x0)| ≥k and
⟨x∗, x0⟩> α, we obtain
a(x0) = a0(x0) + |k −a0(x0)| + ⟨x∗, x0⟩−α > k,
and the proof is complete.
⊓⊔
2.2 Conjugate Functionals
The concept of the conjugate functional, which has its roots in the Legendre
transform of the calculus of variations, will be crucial for the duality theory
in convex optimization to be developed later.
Deﬁnition 2.2.1 Let f : E →R. The functional f ∗: E∗→R deﬁned by
f ∗(x∗) := sup
x∈E

⟨x∗, x⟩−f(x)

,
x∗∈E∗,
is called the Fenchel conjugate (or brieﬂy, the conjugate) of f.
If f is proper, the deﬁnition immediately implies the Young inequality
⟨x∗, x⟩≤f(x) + f ∗(x∗)
∀x ∈E ∀x∗∈E∗.
(2.3)

30
2 The Conjugate of Convex Functionals
Geometric Interpretation
Let x∗∈E∗be such that f ∗(x∗) ∈R. Then the function a : E →R deﬁned by
a(x) := ⟨x∗, x⟩−f ∗(x∗),
x ∈E,
belongs to A(f). For each ϵ > 0 there exists xϵ ∈E satisfying ⟨x∗, xϵ⟩−f(xϵ) >
f ∗(x∗) −ϵ and so a(xϵ) > f(xϵ) −ϵ. Hence, for E = R, a may be interpreted
as a tangent to f, and we have a(o) = −f ∗(x∗) (Fig. 2.3).
−f ∗(x∗)
f
a
x∗
x
0
Fig. 2.3
Example 2.2.2 Let p ∈(1, +∞) be given. Deﬁne f : R →R by f(x) := |x|p
p .
We compute f ∗. For E = R we have E∗= R. With x∗∈R ﬁxed, set ϕ(x) :=
x∗x −f(x). The function ϕ : R →R is concave (i.e., −ϕ is convex) and
diﬀerentiable. Hence ϕ has a unique maximizer x0 which satisﬁes ϕ′(x0) = 0,
i.e., x∗−sgn(x0)|x0|p−1 = 0. It follows that
f ∗(x∗) = ϕ(x0) = |x∗|q
q
,
where 1
p + 1
q = 1.
Thus in this case the Young inequality (2.3) is just the classical Young in-
equality for real numbers:
x∗x ≤|x|p
p
+ |x∗|q
q
.
Proposition 2.2.3 If f : E →R, then the following holds:
(a) f ∗is convex and l.s.c.
(b) If dom f ̸= ∅, then f ∗(x∗) > −∞for every x∗∈E∗.
(c) If f is proper, convex, and l.s.c., then f ∗is proper, convex, and l.s.c.
Proof.
(a) It is easy to see that f ∗is convex. To prove the second assertion, notice
that for each x ∈E, the functional ϕx(x∗) := ⟨x∗, x⟩−f(x), x∗∈E∗, is
continuous and so f ∗= supx∈E ϕx is l.s.c.

2.2 Conjugate Functionals
31
f
f ∗∗
Fig. 2.4
(b) is obvious.
(c) Since f is proper, we have A(f) ̸= ∅(see the proof of Proposition 2.1.2).
Hence there exist x∗∈E∗and c ∈R such that ⟨x∗, x⟩+ c ≤f(x) for each
x ∈E. It follows that
f ∗(x∗) = sup
x∈E

⟨x∗, x⟩−f(x)

≤−c < +∞
and so x∗∈dom f ∗.
⊓⊔
For g : E∗→R, the conjugate g∗: E →R is deﬁned analogously by
g∗(x) := sup
x∗∈E∗

⟨x∗, x⟩−g(x∗)

,
x ∈E.
In this connection, we make use of the fact that, since (E, E∗) is a dual pair,
the dual of E∗can be identiﬁed with E. Now let f : E →R be given. Applying
the above to g := f ∗, we obtain the biconjugate f ∗∗: E →R of f:
f ∗∗(x) = sup
x∗∈E∗

⟨x∗, x⟩−f ∗(x∗)

,
x ∈E.
Geometrically, Theorem 2.2.4 says that f ∗∗can be interpreted as a con-
vexiﬁcation of f from below (Fig. 2.4).
Theorem 2.2.4 (Biconjugation Theorem) Let f : E →R.
(a) One always has f ∗∗= f Γ ≤f.
(b) If f is proper, then f ∗∗= f if and only if f is convex and l.s.c.
Proof.
(a) It is clear that f Γ ≤f. We show that f ∗∗= f Γ . For x∗∈E∗and c ∈R,
we have
⟨x∗, x⟩+ c ≤f(x) ∀x ∈E
⇐⇒
f ∗(x∗) = sup
x∈E

⟨x∗, x⟩−f(x)

≤−c
and so
f Γ (x) = sup{⟨x∗, x⟩+ c | x∗∈E∗, c ∈R, c ≤−f ∗(x∗)}.
(2.4)

32
2 The Conjugate of Convex Functionals
If f ∗(x∗) > −∞for all x∗∈E∗, then
f Γ (x) =
(2.4) sup{⟨x∗, x⟩−f ∗(x∗) | x∗∈E∗} = f ∗∗(x)
∀x ∈E.
If f ∗(x∗) = −∞for some x∗∈E∗, then f Γ (x) = +∞= f ∗∗(x) for all
x ∈E.
(b) This follows from (a) and Proposition 2.1.2.
⊓⊔
Example 2.2.5 For the indicator functional δA of a nonempty subset A of E,
we have
δ∗
A(x∗) = σA(x∗)
∀x∗∈E∗,
where σA : E∗→R denotes the support functional of A. If, in particular, E
is a normed vector space and A = BE (the closed unit ball in E), then
δ∗
BE(x∗) = σBE(x∗) = sup
∥x∥≤1
⟨x∗, x⟩= ∥x∗∥
∀x∗∈E∗.
Example 2.2.6 Let again E be a normed vector space and f(x)
=
∥x∥, x ∈E. Consider the dual pair (E[∥· ∥], E∗[σ(E∗, E)]). We want to
determine f ∗:
(I) Let x∗∈E∗, ∥x∗∥≤1. Then ⟨x∗, x⟩≤∥x∗∥∥x∥≤∥x∥for all x ∈E and
⟨x∗, o⟩= 0 = ∥o∥. Hence
f ∗(x∗) = sup
x∈E

⟨x∗, x⟩−∥x∥

= 0.
(II) Let x∗∈E∗, ∥x∗∥> 1. Then there exists x0 ∈E such that α :=
⟨x∗, x0⟩−∥x0∥> 0. For each ρ > 0 we have ⟨x∗, ρx0⟩−∥ρx0∥= αρ. Let-
ting ρ →+∞, we see that f ∗(x∗) = +∞. We conclude that f ∗= δBE∗.
Therefore we obtain
∥x∥= f(x) = f ∗∗(x) = δ∗
BE∗(x) =
sup
∥x∗∥≤1
⟨x∗, x⟩
∀x ∈E;
here, the second equation follows from Theorem 2.2.4 and the last follows
by applying Example 2.2.5 to E∗instead of E. As a consequence of the
Hahn–Banach theorem the supremum is attained, i.e.,
∥x∥= max
∥x∗∥≤1⟨x∗, x⟩
∀x ∈E.
The following operation is a useful device for calculating the conjugate of
a sum.
Deﬁnition 2.2.7 Let f0, f1 : E →R be proper. The functional f0 ⊕f1 :
E →R deﬁned by
f0 ⊕f1(x) := inf
y∈E

f0(x −y) + f1(y)

∀x ∈E
is called inﬁmal convolution of f0 and f1.

2.2 Conjugate Functionals
33
Theorem 2.2.8 (Sum Theorem) Let f0, f1 : E →R be proper.
(a) One always has
f ∗
0 + f ∗
1 =

f0 ⊕f1
∗
and

f0 + f1
∗≤f ∗
0 ⊕f ∗
1 .
(b) Suppose, in addition, that f0 and f1 are convex and that there exists ¯x ∈
dom f0 ∩int dom f1 such that f1 is continuous at ¯x. Then one has

f0 + f1
∗= f ∗
0 ⊕f ∗
1 .
Moreover, for each x∗∈dom

f0+f1
∗there exist x∗
i ∈dom f ∗
i for i = 0, 1
such that
x∗= x∗
0 + x∗
1
and

f0 + f1
∗(x∗) = f ∗
0 (x∗
0) + f ∗
1 (x∗
1),
(2.5)
i.e., the inﬁmum in (f ∗
0 ⊕f ∗
1 )(x∗) is attained.
Proof.
(a) See Exercise 2.5.3.
(b) Let x∗∈E∗and α :=

f0 + f1
∗(x∗). If α = +∞, then (a) implies

f ∗
0 ⊕f ∗
1

(x∗) = +∞and so we have equality. Now suppose that α <
+∞. We have to show that

f ∗
0 ⊕f ∗
1

(x∗) ≤α. Since ¯x ∈dom(f0 + f1),
we have α > −∞(Proposition 2.2.3) and so α ∈R. Set p := f0 and
q := f1 −x∗+ α. If x ∈dom f0 ∩dom f1, then α ≥⟨x∗, x⟩−(f0 + f1)(x),
which implies p(x) ≥−q(x) for each x ∈E. Moreover, q is continuous
at ¯x. By the sandwich theorem (Theorem 1.5.2) there exist x′
0 ∈E∗and
c ∈R satisfying
⟨x′
0, x⟩+c ≤f0(x)
and
c+⟨x′
0, x⟩≥⟨x∗, x⟩−f1(x)−α
∀x ∈E. (2.6)
From the ﬁrst inequality in (2.6) we obtain f ∗
0 (x′
0) ≤−c and so x′
0 ∈
dom f ∗
0 . For x′
1 := x∗−x′
0, the second inequality of (2.6) implies f ∗
1 (x′
1)−
c ≤α. It follows that x′
1 ∈dom f ∗
1 and
f ∗
0 (x′
0) + f ∗
1 (x′
1) ≤α.
(2.7)
We have x∗= x′
0 + x′
1 and so

f ∗
0 ⊕f ∗
1

(x∗) =
inf
y′∈E∗

f ∗
0 (x∗−y′) + f ∗
1 (y′)

≤α.
This ﬁnally yields

f0 + f1
∗(x∗) = α =

f ∗
0 ⊕f ∗
1

(x∗) =
(2.7) f ∗
0 (x′
0) + f ∗
1 (x′
1).
⊓⊔
As a ﬁrst simple application of conjugate functionals we derive a duality
formula of approximation theory. Recall that if A ⊆E, we write dA(x) :=
infy∈A ∥x −y∥.

34
2 The Conjugate of Convex Functionals
Proposition 2.2.9 If A ⊆E is nonempty and convex, then
dA(x) = max
∥x∗∥≤1

⟨x∗, x⟩−sup
y∈A
⟨x∗, y⟩

∀x ∈E.
Proof. Setting f0(x) := ∥x∥and f1(x) := δA(x), we have
(f0 ⊕f1)(x) = inf
y∈E

∥x −y∥+ δA(y)

= dA(x).
We further set B := BE∗. Since the distance function x →dA(x) is proper,
convex and continuous on E, we obtain
dA(x) = (f0 ⊕f1)∗∗(x) =

f ∗
0 + f ∗
1
∗(x)
= sup
x∗∈E∗

⟨x∗, x⟩−

δB(x∗) + sup
y∈A
⟨x∗, y⟩

= sup
x∗∈B

⟨x∗, x⟩−sup
y∈A
⟨x∗, y⟩

.
Since, with respect to σ(E∗, E), the set B is compact (Alaoglu Theorem)
and the functional x∗→⟨x∗, x⟩−supy∈A⟨x∗, y⟩is upper semicontinuous, the
supremum over B is attained and so is a maximum.
⊓⊔
2.3 A Theorem of H¨ormander and the Bipolar Theorem
The following result states, roughly speaking, that convex closed subsets of E∗
can be described by sublinear l.s.c. functionals on E and vice versa. In this
connection, recall the convention at the beginning of this chapter. Also recall
that the support functional σM of the set M ⊆E∗is deﬁned by
σM(x) := sup
x∗∈M
⟨x∗, x⟩, x ∈E.
Theorem 2.3.1 (H¨ormander Theorem)
(a) Let M be a nonempty, convex, closed subset of E∗. Then the support
functional σM is proper, sublinear, and l.s.c., and one has
M = {x∗∈E∗| ⟨x∗, x⟩≤σM(x) ∀x ∈E}.
(2.8)
(b) Let p : E →R be proper, sublinear, and l.s.c. Then the set
Mp := {x∗∈E∗| ⟨x∗, x⟩≤p(x) ∀x ∈E}
is nonempty, convex, and closed, and one has σMp = p.
(c) If M1 and M2 are nonempty, convex, closed subsets of E∗, then
M1 ⊆M2
⇐⇒
σM1(x) ≤σM2(x)
∀x ∈E.

2.3 A Theorem of H¨ormander and the Bipolar Theorem
35
Proof.
(a) It is easy to see that σM is proper, sublinear, and l.s.c. We show that (2.8)
holds. By Theorem 2.2.4 and Example 2.2.5 (with E∗in place of E) we
obtain
δM =

δ∗
M
∗= σ∗
M,
σ∗
M(x∗) = sup
x∈E

⟨x∗, x⟩−σM(x)

= δMp(x∗) ∀x∗∈E∗,
where p := σM.
Hence δM = δMp and so M = Mp.
(b) (I) Mp ̸= ∅: Since p is l.s.c. and p(o) = 0, there exists a neighborhood U
of zero in E such that −1 < p(x) for each x ∈U. Deﬁne q : E →R by
q(x) := 1 for x ∈U and q(x) := +∞for x ∈E \ U. By the sandwich
theorem (Theorem 1.5.2) there exist x∗∈E∗and c ∈R satisfying
⟨x∗, x⟩+ c ≤p(x) ∀x ∈E
and
−1 ≤⟨x∗, x⟩+ c ∀x ∈U.
Since p is sublinear, it follows that ⟨x∗, x⟩≤p(x) for each x ∈E and
so x∗∈Mp.
(II) Mp is closed: For each x ∈E, let ϕx(x∗) := ⟨x∗, x⟩, x∗∈E∗. Then
ϕx is continuous. Hence the set
Mx := {x∗∈E∗| ⟨x∗, x⟩≤p(x)} = ϕ−1
x

−∞, p(x)

is closed and so is Mp = 
x∈E Mx.
(III) σMp = p: We have
p∗(x∗) = sup
x∈E

⟨x∗, x⟩−p(x)

= δMp
and so, using Theorem 2.2.4 and Example 2.2.5,
p = p∗∗= δ∗
Mp = σMp.
(c) The implication =⇒holds by deﬁnition, and ⇐= is a consequence of (2.8).
⊓⊔
We shall now derive a well-known result of Functional Analysis, the bipolar
theorem, which in turn will yield statements on inequality systems.
If A ⊆E is nonempty, then
A◦:= {x∗∈E∗| ⟨x∗, x⟩≤0 ∀x ∈A}
is a convex cone, the (negative) polar cone of A. Furthermore, the bipolar cone
of A is
A◦◦:= {x ∈E | ⟨x∗, x⟩≤0 ∀x∗∈A◦}.
We denote by cc A the intersection of all closed convex cones containing A,
analogously for nonempty subsets of E∗.

36
2 The Conjugate of Convex Functionals
Lemma 2.3.2
(a) If A ⊆E is nonempty, then

cc A
◦= A◦.
(b) If A ⊆E is nonempty and convex, then cc A = cl

λ≥0 λA

.
Proof. See Exercise 2.5.4.
⊓⊔
Proposition 2.3.3 (Bipolar Theorem) If A
⊆
E is nonempty, then
A◦◦= ccA.
Proof. Let C := cc A. By Theorem 2.3.1(a) with the roles of E and E∗
exchanged, we have
C = {x ∈E | ⟨x∗, x⟩≤σC(x∗) ∀x∗∈E∗}.
Since C is a cone containing o, a direct calculation gives σC = δC◦. Hence
C = C◦◦, and Lemma 2.3.2(a) shows that C◦◦= A◦◦.
⊓⊔
2.4 The Generalized Farkas Lemma
In this section, we characterize solutions of systems of equations and inequal-
ities. We make the following hypotheses:
(H) (E, E∗) and (F, F ∗) are dual pairs of locally convex spaces.
P ⊆E and Q ⊆F are closed convex cones.
T : E →F is a continuous linear mapping.
Recall that the adjoint T ∗: F ∗→E∗of T is deﬁned by
⟨T ∗y∗, x⟩= ⟨y∗, Tx⟩
∀x ∈E
∀y∗∈F ∗.
Lemma 2.4.1 There always holds cl(P ◦+ T ∗(Q◦)) = (P ∩T −1(Q))◦.
Proof. For any x ∈E we have
x ∈(P ◦+ T ∗(Q◦))◦
⇐⇒
⟨y′, x⟩+ ⟨z∗, Tx⟩≤0
∀(y′, z∗) ∈P ◦× Q◦
⇐⇒
(x, Tx) ∈(P ◦× Q◦)◦.
Since (P ◦× Q◦)◦= P ◦◦× Q◦◦= P × Q (the latter by the bipolar theorem),
we see that
(P ◦+ T ∗(Q◦))◦= P ∩T −1(Q)
and another application of the bipolar theorem proves the assertion.
⊓⊔
An immediate consequence of this lemma is:
Proposition 2.4.2 (Generalized Farkas Lemma) If
P ◦+ T ∗(Q◦)
is
closed, then for each x∗∈E∗the following statements are equivalent:

2.4 The Generalized Farkas Lemma
37
(a) ∃z∗∈Q◦: x∗−T ∗z∗∈P ◦.
(b) ∀x ∈P : Tx ∈Q =⇒⟨x∗, x⟩≤0.
Frequently the result is formulated in terms of the negation of (b) which is:
(¯b) ∃x ∈P : Tx ∈Q and ⟨x∗, x⟩> 0.
Proposition 2.4.2 then states that either (a) or (¯b) holds. In this formulation,
the result is called theorem of the alternative.
If, in particular, P = E and so P ◦= {o}, then Proposition 2.4.2 gives a
necessary and suﬃcient condition for the linear operator equation T ∗z∗= x∗
to have a solution z∗in the cone Q◦.
In view of Proposition 2.4.2, it is of interest to have suﬃcient conditions
for P ◦+ T ∗(Q◦) to be closed.
Proposition 2.4.3 If E and F are Banach spaces and T(E) −Q = F, then
P ◦+ T ∗(Q◦) is σ(E∗, E)-closed.
Proof. In the following, topological notions in E∗and F ∗refer to the weak*
topology. We show that for any ρ > 0 the set
K := (P ◦+ T ∗(Q◦)) ∩BE∗(o, ρ)
is closed in BE∗(o, ρ); the assertion then follows by the Krein–Šmulian theorem
(Theorem 1.6.8). Thus let (z∗
α) be a net (generalized sequence) in K converging
to some z∗∈BE∗(o, ρ). Then there exist nets (x∗
α) in P ◦and (y′
α) in Q◦such
that z∗
α = x∗
α + T ∗y′
α for any α. Now let z ∈F be given. Since T(P) −Q = F,
there exist x ∈P and y ∈Q satisfying z = Tx −y. Hence for any α we have
⟨y′
α, z⟩=⟨y′
α, Tx⟩−⟨y′
α, y⟩≥⟨T ∗y′
α, x⟩=⟨z∗
α, x⟩−⟨x∗
α, x⟩≥⟨z∗
α, x⟩≥−ρ∥x∥.
Analogously there exists ˜x ∈P such that ⟨y′
α, −z⟩≥−ρ∥˜x∥for any α. Hence
the net (y′
α) is pointwise bounded and so, by the Banach–Steinhaus theorem,
norm bounded in F ∗. The Alaoglu theorem now implies that some subnet
(y′
α′) of (y′
α) has a limit y′. Since Q◦is closed, we have y′ ∈Q◦. Since x∗
α′ =
z∗
α′ −T ∗y′
α′ and z∗
α′ →z∗, it follows that (x∗
α′) converges to z∗−T ∗y′, and so
z∗−T ∗y′ ∈P ◦. We conclude that z∗∈K.
⊓⊔
We supplement Proposition 2.4.3 by a suﬃcient condition for T(P)−Q=F.
Lemma 2.4.4 If T(P) ∩int Q ̸= ∅, then T(P) −Q = F.
Proof. By assumption, there exist x0 ∈P such that Tx0 ∈int Q. Let V be a
neighborhood of zero in F such that Tx0 + V ⊆Q. Now let y ∈F be given.
Then ρ(−y) ∈V for some ρ > 0 and so z := Tx0 −ρy ∈Q. It follows that
y = T( 1
ρx0) −1
ρz ∈T(P) −Q.
⊓⊔

38
2 The Conjugate of Convex Functionals
Concerning the ﬁnite-dimensional case, let
E = P = Rm, F = Rn, Q = −Rn
+.
Further let A be the matrix representation of T : Rm →Rn with respect to the
standard bases. Then T ∗Q◦= A⊤Rn
+ is a polyhedral cone (as the nonnegative
hull of the column vectors of A) and so is closed (see, for example, Bazaraa
and Shetty [12] or Elster et al. [59]). Hence Proposition 2.4.2 implies
Corollary 2.4.5 (Classical Farkas Lemma) Let A be an (n, m)-matrix.
Then for each x∗∈Rm, the following statements are equivalent:
(a) ∃z∗∈Rn
+ : A⊤z∗= x∗.
(b) ∀x ∈Rm : Ax ∈−Rn
+ =⇒⟨x∗, x⟩≤0.
2.5 Bibliographical Notes and Exercises
Concerning conjugate functionals we refer to the Bibliographical Notes at
the end of Chap. 4. For theorems of the alternative in ﬁnite-dimensional
spaces, see Borwein and Lewis [18], Elster et al. [59], and the references
therein. Concerning related results in inﬁnite-dimensional spaces, for linear
and nonlinear mappings, we refer to Craven [43, 44], Craven et al. [45],
Ferrero [68], Giannessi [70], Glover et al. [75], Jeyakumar [104], Lasserre [117],
and Schirotzek [193,195]. Proposition 2.4.3 is due to Penot [160]; for further
closedness conditions of this kind, see Schirotzek [196, p. 220 ﬀ]. We shall
come back to this subject in Sect. 10.2.
Exercise 2.5.1 Calculate the conjugate of the following functions f : R →R:
(a) f(x) := ex, x ∈R.
(b) f(x) := ln x if x > 0, f(x) := +∞if x ≤0.
(c)
f(x) :=
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎩
+∞
if x < −2,
−x
if −2 ≤x < 0,
x(2 −x)
if 0 ≤x < 2,
2x
if x ≥2.
Exercise 2.5.2 Verify the implication (a) =⇒(b) in Proposition 2.1.2.
Exercise 2.5.3 Prove assertion (a) of Theorem 2.2.8.
Exercise 2.5.4 Prove Lemma 2.3.2.

3
Classical Derivatives
3.1 Directional Derivatives
Convention. Throughout this chapter, unless otherwise speciﬁed, we assume
that E and F are normed vector spaces, D ⊆E is nonempty and open, ¯x ∈D,
and f : D →F.
We will recall some classical concepts and facts. To start with, we consider
directional derivatives. We write
∆f(¯x, y) := f(¯x + y) −f(¯x)
∀y ∈D −¯x.
We use the following abbreviations: G-derivative for Gâteaux derivative,
H-derivative for Hadamard derivative, F-derivative for Fréchet derivative.
Deﬁnition 3.1.1 Let y ∈E. We call
fG(¯x, y) := lim
τ↓0
1
τ ∆f(¯x, τy)
directional G-derivative,
f s
G(¯x, y) := lim
τ↓0
x→¯x
1
τ ∆f(x, τy) strict directional G-derivative,
fH(¯x, y) := lim
τ↓0
z→y
1
τ ∆f(¯x, τz) directional H-derivative,
f s
H(¯x, y) := lim
τ↓0
x→¯x
z→y
1
τ ∆f(x, τz) strict directional H-derivative
of f at ¯x in the direction y, provided the respective limit exists.
Lemma 3.1.2
(a) If fH(¯x, y) exists, then fG(¯x, y) also exists and both directional derivatives
coincide.
(b) If f is locally L-continuous around ¯x, then fH(¯x, y) exists if and only if
fG(¯x, y) exists.

40
3 Classical Derivatives
Proof. (a) is obvious. We verify (b). Assume that fG(¯x, y) exists. Let ϵ > 0
be given. Then there exists δ1 > 0 such that
 1
τ ∆f(¯x, τy) −fG(¯x, y)
 < ϵ
2
whenever 0 < τ < δ1.
Since f is locally L-continuous around ¯x, there further exist λ > 0 and δ2 > 0
such that
∥f(x1) −f(x2)∥≤λ∥x1 −x2∥
∀x1, x2 ∈B(¯x, δ2).
Now set
δ3 := ϵ
2λ
and
δ4 := min

δ1,
δ2
δ3 + ∥y∥

.
If z ∈B(y, δ3) and 0 < τ < δ4, then we obtain ∥τy∥< δ2 and
∥τz∥≤τ(∥z −y∥+ ∥y∥) ≤τ(δ3 + ∥y∥) ≤δ2
and so
 1
τ ∆f(¯x, τz) −fG(¯x, y)

≤1
τ
f(¯x + τz) −f(¯x + τy)
 +
 1
τ ∆f(¯x, τy) −fG(¯x, y)

≤λ∥z −y∥+ ϵ
2 < ϵ.
We conclude that fH(¯x, y) exists and equals fG(¯x, y).
⊓⊔
Lemma 3.1.3 If the directional H-derivative fH(¯x, ·) exists in a neighborhood
of y0 ∈E, then it is continuous at y0.
Proof. Let ρ0 > 0 be such that fH(¯x, y) exists for each y ∈B(y0, ρ0). Let
ϵ > 0 be given. Then there exists ρ ∈(0, ρ0) such that
 1
τ ∆f(¯x, τy) −fH(¯x, y0)
 ≤ϵ
whenever 0 < τ < ρ and y ∈B(y0, ρ).
Letting τ ↓0, we obtain
∥fG(¯x, y) −fH(¯x, y0)∥≤ϵ
∀y ∈B(y0, ρ).
By Lemma 3.1.2 we have fG(¯x, y) = fH(¯x, y) for each y ∈B(y0, ρ0), and the
assertion follows.
⊓⊔
Now we consider a proper function f : E →R. If D := int dom f is
nonempty, then of course the above applies to f|D. In addition, we deﬁne the
following directional derivatives:
f G(¯x, y) := lim sup
τ↓0
1
τ ∆f(¯x, τy) upper directional G-derivative,
f G(¯x, y) := lim inf
τ↓0
1
τ ∆f(¯x, τy) lower directional G-derivative,
f H(¯x, y) := lim sup
τ↓0
z→y
1
τ ∆f(¯x, τz) upper directional H-derivative,
f H(¯x, y) := lim inf
τ↓0
z→y
1
τ ∆f(¯x, τz) lower directional H-derivative.

3.2 First-Order Derivatives
41
Notice that these directional derivatives generalize the Dini derivates of a
function f : I →R (I ⊆R an interval) which are deﬁned at ¯x ∈int I by
D+f(¯x) := lim sup
h↓0
f(¯x + h) −f(¯x)
h
,
D+f(¯x) := lim inf
h↓0
f(¯x + h) −f(¯x)
h
,
D−f(¯x) := lim sup
h↑0
f(¯x + h) −f(¯x)
h
,
D−f(¯x) := lim inf
h↑0
f(¯x + h) −f(¯x)
h
.
If ¯x ∈I is the left boundary point of I, then D+f(¯x) and D+f(¯x) still make
sense; an analogous remark applies to the right boundary point of I. Notice
that, among others, D+f(¯x) = f G(¯x, 1). If D+f(¯x) = D+f(¯x), then this
common value is called the right derivative of f at ¯x and is denoted f ′
+(¯x).
The left derivative f ′
−(¯x) is deﬁned analogously.
3.2 First-Order Derivatives
Our aim in this section is to recall various kinds of derivatives. For this, the
following notion will be helpful.
Deﬁnition 3.2.1 A nonempty collection β of subsets of E is called bornology
if the following holds:
each S ∈β is bounded and

S∈β
S = E,
S ∈β
=⇒
−S ∈β,
S ∈β and λ > 0
=⇒
λS ∈β,
S1, S2 ∈β
=⇒
∃S ∈β : S1 ∪S2 ⊂S.
In particular:
–
The G-bornology βG is the collection of all ﬁnite sets.
–
The H-bornology βH is the collection of all compact sets.
–
The F-bornology βF is the collection of all bounded sets.
We set
L(E, F) := vector space of all continuous linear mappings T : E →F.
Deﬁnition 3.2.2 Let β be a bornology on E.
(a) The mapping f : D →F is said to be β-diﬀerentiable at ¯x if there exists
T ∈L(E, F), the β-derivative of f at ¯x, such that
lim
τ→0 sup
y∈S
 1
τ

f(¯x + τy) −f(¯x)

−T(y)
 = 0
∀S ∈β.
(3.1)

42
3 Classical Derivatives
(b) The mapping f : D →F is said to be strictly β-diﬀerentiable at ¯x if there
exists T ∈L(E, F), the strict β-derivative of f at ¯x, such that
lim
τ→0
x→¯x
sup
y∈S
 1
τ

f(x + τy) −f(x)

−T(y)
 = 0
∀S ∈β.
(3.2)
(c) In particular, f is said to be G-diﬀerentiable or strictly G-diﬀerentiable
if (3.1) or (3.2), respectively, holds with β = βG. In this case, T is
called (strict) G-derivative of f at ¯x. Analogously we use (strictly) H-
diﬀerentiable if β = βH and (strictly) F-diﬀerentiable if β = βF . In the
respective case, T is called (strict) H-derivative or (strict) F-derivative
of f at ¯x.
Remark 3.2.3
(a) If the β-derivative T of f at ¯x exists for some bornology β, then
T(y) = lim
τ→0
1
τ

f(¯x + τy) −f(¯x)

= fG(¯x, y)
∀y ∈E.
Hence if two of the above derivatives exist, then they coincide. This jus-
tiﬁes denoting them by the same symbol; we choose
f ′(¯x) := T.
Condition (3.1) means that we have
lim
τ→0
 1
τ

f(¯x+τy)−f(¯x)

−f ′(¯x)y
=0 uniformly in y ∈S for each S ∈β.
An analogous remark applies to (3.2). Here and in the following we write
f ′(¯x)y instead of f ′(¯x)(y). If f : D →R, then f ′(¯x) ∈E∗and as usual we
also write ⟨f ′(¯x), y⟩instead of f ′(¯x)(y).
(b) Now let E be a (real) Hilbert space with inner product (x | y) and f : E →
R a functional. If f is G-diﬀerentiable at ¯x ∈E, then the G-derivative
f ′(¯x) is an element of the dual space E∗. By the Riesz representation
theorem, there is exactly one z ∈E such that ⟨f ′(¯x), y⟩= (z | y) for all
y ∈E. This element z is called gradient of f at ¯x and is denoted ∇f(¯x) .
In other words, we have
⟨f ′(¯x), y⟩= (∇f(¯x) | y)
∀y ∈E.
Proposition 3.2.4 says that f is G-diﬀerentiable at ¯x if and only if the
directional G-derivative y →fG(¯x, y) exists and is linear and continuous
on E. An analogous remark applies to strict G-diﬀerentiability as well as
(strict) H-diﬀerentiability. Recall that if g : E →F, then
g(x) = o(∥x∥), x →o
means
lim
x→o
g(x)
∥x∥= o.

3.2 First-Order Derivatives
43
Proposition 3.2.4
(i) f is G-diﬀerentiable at ¯x if and only if there exists f ′(¯x) ∈L(E, F) such
that f ′(¯x)y = fG(¯x, y) for all y ∈E.
(ii) f is H-diﬀerentiable at ¯x if and only if there exists f ′(¯x) ∈L(E, F) such
that f ′(¯x)y = fH(¯x, y) for all y ∈E.
(iii) The following assertions are equivalent:
(a) f is strictly H-diﬀerentiable at ¯x.
(b) There exists f ′(¯x) ∈L(E, F) such that f ′(¯x)y = f s
H(¯x, y) for y ∈E.
(c) f is locally L-continuous around ¯x and strictly G-diﬀerentiable at ¯x.
(iv) f is F-diﬀerentiable at ¯x if and only if there exists f ′(¯x) ∈L(E, F) such
that

f(¯x + z) −f(¯x)

−f ′(¯x)z = o(∥z∥), z →o.
(v) f is strictly F-diﬀerentiable at ¯x if and only if there exists f ′(¯x) ∈L(E, F)
such that

f(x + z) −f(x)

−f ′(¯x)z = o(∥z∥), z →o, x →¯x.
Proof. We only verify (iii), leaving the proof of the remaining assertions as
Exercise 3.8.4.
(a) =⇒(c): Let (a) hold. We only have to show that f is locally L-continuous
around ¯x. Assume this is not the case. Then there exist sequences (xn) and
(x′
n) in B(¯x, 1
n) such that
∥f(xn) −f(x′
n)∥> n∥xn −x′
n∥
∀n ∈N.
(3.3)
Setting τn := √n∥xn −x′
n∥and yn :=
1
τn (x′
n −xn), we obtain as n →∞,
0 ≤τn ≤√n(∥xn −¯x∥+ ∥¯x −x′
n∥) <
2
√n →0
and
∥yn∥=
1
√n →0.
By (3.3) we have
 1
τn ∆f(xn, τnyn)
 >
1
τn · n∥τnyn∥= √n
∀n ∈N,
and the continuity of f ′(¯x) implies that, with some n0 ∈N, we obtain ∥f ′(¯x)∥·
∥yn∥< 1
2 for each n > n0. It follows that
 1
τn ∆f(xn, τnyn) −f ′(¯x)yn)

≥
 1
τn ∆f(xn, τnyn)
 −∥f ′(¯x)∥· ∥yn∥> √n −1
2
∀n > n0,
which contradicts (3.2) for the compact set S := {o} ∪{yn | n > n0}.
(c) =⇒(b): Let y ∈E and ϵ > 0 be given. Since f is strictly G-diﬀerentiable
at ¯x, there exists δ1 > 0 such that
 1
τ ∆f(x, τy) −f ′(¯x)y
 < ϵ
whenever 0 < |τ| < δ1, ∥x −¯x∥< δ1.
(3.4)

44
3 Classical Derivatives
Since f is locally L-continuous around ¯x, there further exist λ > 0 and δ2 > 0
such that
∥f(x1) −f(x2)∥< λ∥x1 −x2∥
∀x1, x2 ∈B(¯x, δ2).
(3.5)
Setting x1 := x + τz and x2 := x + τy, we have the estimates
∥x1 −¯x∥≤∥x −¯x∥+ |τ|(∥z −y∥+ ∥y∥)
and
∥x2 −¯x∥≤∥x −¯x∥+ |τ|∥y∥
which show that x1, x2 ∈B(¯x, δ2) provided |τ|, ∥z −y∥, and ∥x −¯x∥are
suﬃciently small. Under this condition, (3.4) and (3.5) imply that
 1
τ ∆f(x, τz) −f ′(¯x)y

≤
1
|τ|
f(x + τz) −f(x + τy)
 +
 1
τ ∆f(x, τy) −f ′(¯x)y
 ≤λ∥z −y∥+ ϵ.
This veriﬁes (b).
(b) =⇒(a): Let (b) hold and assume that (a) does not hold. Let T ∈L(E, F)
be given. Then for some compact subset S of E, the relation (3.2) does not
hold. Hence there exist ϵ0 > 0 as well as sequences τn ↓0, yn ∈S, and xn →¯x
such that
 1
τ ∆f(xn, τnyn) −T(yn)
 > ϵ0
∀n ∈N.
Since S is compact, a subsequence of (yn), again denoted (yn), converges to
some y ∈S. It follows that for any n > n0 we have
 1
τ ∆f(xn, τnyn) −T(y)

≥
 1
τ ∆f(xn, τnyn) −T(yn)




> ϵ0
−∥T∥· ∥yn −y∥



< ϵ0/2
> ϵ0
2 ;
(3.6)
in this connection, we exploited that T is linear and continuous. However, the
relation (3.6) contradicts (b).
⊓⊔
Proposition 3.2.5 If f : D →F is H-diﬀerentiable at ¯x, then f is continu-
ous at ¯x.
Proof. See Exercise 3.8.5.
⊓⊔
3.3 Mean Value Theorems
We recall a variant of the classical mean value theorem (see, for instance,
Walter [212]).
Proposition 3.3.1 (Mean Value Theorem in Terms of Dini Derivates)
Let I and J be intervals in R and let A ⊆I be a countable set. Further let
f : I →R be continuous, let D ∈{D+, D+, D−, D−}, and assume that
Df(x) ∈J
∀x ∈I \ A.

3.3 Mean Value Theorems
45
Then
f(b) −f(a)
b −a
∈J
∀a, b ∈I, a ̸= b.
If f : [a, b] →R is continuous on [a, b] and diﬀerentiable on (a, b), then
by the intermediate value theorem for derivatives the set J := {f ′(x) | x ∈
(a, b)} is an interval and so the usual mean value theorem follows from
Proposition 3.3.1.
Now we return to the setting described by the convention at the beginning
of the chapter. If x, z ∈E, we write
[x, z] := {λx + (1 −λ)z | 0 ≤λ ≤1}.
If f : D →F is G-diﬀerentiable on D (i.e., G-diﬀerentiable at any x ∈D),
then we may consider the mapping f ′ : x →f ′(x) of D to L(E, F).
Deﬁnition 3.3.2 Let f be G-diﬀerentiable on D. The mapping f ′ is said to
be radially continuous if for all x, y ∈E such that [x, x+ y] ⊆D, the function
τ →f ′(x + τy)y is continuous on [0, 1].
Proposition 3.3.3 (Mean Value Theorem in Integral Form) Let f
:
D →R be G-diﬀerentiable and let f ′ be radially continuous. Then for all
x, y ∈D such that [x, x + y] ⊆D one has
f(x + y) −f(x) =
 1
0
⟨f ′(x + τy), y⟩dτ.
(3.7)
Proof. For τ ∈[0, 1] let ϕ(τ) := f(x + τy). By assumption ϕ is continuously
diﬀerentiable and ϕ′(τ) = ⟨f ′(x + τy), y⟩. The main theorem of calculus gives
ϕ(1) −ϕ(0) =
 1
0
ϕ′(τ) dτ,
which is (3.7).
⊓⊔
The above result is formulated for functionals only, in which case it will be
used later. In Proposition 4.3.8 below we shall describe an important class of
functionals to which the mean value formula (3.7) applies. We mention that,
by an appropriate deﬁnition of the Riemann integral, the formula extends to
a mapping f : D →F provided F is a Banach space.
If β is a bornology of E, we denote by Lβ(E, F) the vector space L(E, F)
equipped with the topology of uniform convergence on the sets S ∈β.
In particular, LβF (E, F) denotes L(E, F) equipped with the topology gen-
erated by the norm ∥T∥:= sup{∥Tx∥| x ∈BE}. In particular we write
E∗
β := Lβ(E, R).

46
3 Classical Derivatives
Proposition 3.3.4 (Mean Value Theorem in Inequality Form) Let
y ∈E be such that [¯x, ¯x + y] ⊆D and f is G-diﬀerentiable on [¯x, ¯x + y].
Further let T ∈LβF (E, F). Then one has
∥

f(¯x + y) −f(¯x)

−Ty∥≤∥y∥
sup
0≤τ≤1
∥f ′(¯x + τy) −T∥.
Proof. Set g(x) := f(x) −T(x −¯x), x ∈E. By the Hahn–Banach theorem,
there exists v ∈F ∗satisfying ∥v∥= 1 and

v, ∆g(¯x, y)
 
= ∥∆g(¯x, y)∥. Now
deﬁne ϕ(τ) :=

v, g(¯x+τy)
 
, τ ∈[0, 1]. It is easy to see that ϕ is diﬀerentiable,
and one has
ϕ′(τ) =

v, g′(¯x + τy)y
 
=

v, f ′(¯x + τy)y −Ty
 
.
(3.8)
By the classical mean value theorem, there exists τ ∈(0, 1) such that ϕ′(τ) =
ϕ(1) −ϕ(0). This together with (3.8) and

v, f ′(¯x + τy)y −Ty
  ≤∥v∥∥f ′(¯x + τy)y −Ty∥≤∥f ′(¯x + τy) −T∥∥y∥
completes the proof.
⊓⊔
3.4 Relationship between Diﬀerentiability Properties
In this section we will study the interrelations between the various diﬀeren-
tiability properties. First we introduce some terminology.
Deﬁnition 3.4.1
(a) The mapping f : D →F is said to be β-smooth at ¯x if f is β-diﬀerentiable
for any x in an open neighborhood U of ¯x and the mapping f ′ : x →f ′(x)
of U to Lβ(E, F) is continuous on U.
(b) The mapping f : D →F is said to be continuously diﬀerentiable at ¯x if
f is G-diﬀerentiable for any x in an open neighborhood U of ¯x and the
mapping f ′ : x →f ′(x) of U to LβF (E, F) is continuous at ¯x.
(c) If f : D →F is continuously diﬀerentiable at every point of D, then f is
said to be a C1-mapping on D, written f ∈C1(D, F).
We shall make use of the following abbreviations:
(G):
f is G-diﬀerentiable at ¯x,
(SG): f is strictly G-diﬀerentiable at ¯x,
(CD): f is continuously diﬀerentiable at ¯x.
In analogy to (G), (SG) we use (H), (SH), (F), and (SF).

3.4 Relationship between Diﬀerentiability Properties
47
Proposition 3.4.2 The following implications hold true:
(CD) =⇒(SF) =⇒
←−(SH) =⇒
←−(SG)
⇓
⇓
⇓
(F) =⇒
←−(H)
=⇒
←−(G)
In this connection, ←−means implication provided E is ﬁnite dimensional,
and ←−means implication provided f is locally L-continuous around ¯x.
Proof. In view of the foregoing, it only remains to verify the implication (CD)
=⇒(SF). Thus let (CD) hold. Then there exists ρ > 0 such that f is G-
diﬀerentiable on B(¯x, 2ρ). If x ∈B(¯x, ρ) and y ∈B(o, ρ), then [x, x + y] ⊂
B(¯x, 2ρ). By Proposition 3.3.4 with T := f ′(¯x), we obtain
∥f(x + y) −f(x) −f ′(¯x)y∥≤∥y∥
sup
0≤τ≤1
∥f ′(x + τy) −f ′(¯x)∥.
(3.9)
Now let ϵ > 0 be given. Since f ′ is continuous at ¯x, there exists δ > 0 such
that
sup
0≤τ≤1
∥f ′(x + τy) −f ′(¯x)∥< ϵ
∀x ∈B(¯x, δ)
∀y ∈B(o, δ).
This together with (3.9) implies (SF).
⊓⊔
Remark 3.4.3 By Proposition 3.4.2 it is clear that if f is continuously dif-
ferentiable on an open neighborhood U of ¯x, then f is β-smooth at any ¯x ∈U
for any bornology β ⊆βF . In particular, f is F-diﬀerentiable at any ¯x ∈U
and the F-derivative f ′ is continuous from U to LβF (E, F).
Beside E and F let G be another normed vector space. Beside f : D →F
let g : V →G be another mapping, where V is an open neighborhood of
¯z := f(¯x) in F. Assume that f(D) ⊂V . Then the composition g ◦f : D →G
is deﬁned.
Proposition 3.4.4 (Chain Rule) Assume that f and g are H-diﬀerentiable
at ¯x and ¯z, respectively. Then g ◦f is H-diﬀerentiable at ¯x, and there holds
(g ◦f)′(¯x) = g′(¯z) ◦f ′(¯x).
An analogous statement holds true if H-diﬀerentiable is replaced by F-diﬀeren-
tiable.
The proof is the same as in multivariate calculus. An analogous chain rule
for G-diﬀerentiable mappings does not hold (see Exercise 3.8.3).

48
3 Classical Derivatives
3.5 Higher-Order Derivatives
We again use the notation introduced at the beginning of the chapter. Ass-
ume that f ∈C1(D, F). If the (continuous) mapping f ′ : D →LβF (E, F)
is continuously diﬀerentiable on D, then f is said to be a twice continuously
diﬀerentiable mapping on D, or a C2-mapping on D, with second-order deriv-
ative f ′′ := (f ′)′. The set of all twice continuously diﬀerentiable mappings
f : D →F is denoted C2(D, F).
Notice that f ′′ maps D into H := LβF

E, LβF (E, F)

. Parallel to H we
consider the vector space B(E, F) of all continuous bilinear mappings b :
E × E →F, which is normed by
∥b∥:= sup{∥b(y, z)∥| ∥y∥≤1, ∥z∥≤1}.
(3.10)
If h ∈H, then
bh(y, z) := h(y)z
∀(y, z) ∈E × E
deﬁnes an element bh ∈B(E, F). Conversely, given b ∈B(E, F), set
h(y) := b(y, ·)
∀y ∈E.
Then h ∈H and bh = b. Evidently the mapping h →bh is an isomorphism of
H onto B(E, F). Therefore H can be identiﬁed with B(E, F). In this sense,
we interpret f ′′(¯x) as an element of B(E, F) and write f ′′(¯x)(y, z) instead of

f ′′(¯x)y

z. If, in particular, f ∈C2(D, R), then f ′′(¯x) is a continuous bilinear
form on E × E.
Proposition 3.5.1 (Taylor Expansion) Assume that D is open and f ∈
C2(D, R). Then for all ¯x ∈D, y ∈D −¯x one has
f(¯x + y) = f(¯x) + ⟨f ′(¯x), y⟩+ 1
2f ′′(¯x)(y, y) + r(y),
where lim
y→o
r(y)
∥y∥2 = o.
In particular, there exist σ > 0 and ϵ > 0 such that
f(¯x + y) ≥f(¯x) + ⟨f ′(¯x), y⟩−σ∥y∥2
∀y ∈B(o, ϵ).
(3.11)
Proof. The ﬁrst assertion follows readily from the classical Taylor expansion
of the function ϕ(τ) := f(¯x + τy), τ ∈[0, 1]. From the ﬁrst result we obtain
(3.11) since in view of (3.10) we have
| 1
2f ′′(¯x)(y, y)| ≤1
2∥f ′′(¯x)∥∥y∥2
∀y ∈E,
and the limit property of r entails the existence of κ > 0 such that |r(y)| ≤
κ∥y∥2 if ∥y∥is suﬃciently small.
⊓⊔
We only mention that in an analogous manner, derivatives of arbitrary
order n, where n ∈N, can be deﬁned using n-linear mappings, which leads to
higher-order Taylor expansions.

3.6 Some Examples
49
3.6 Some Examples
For illustration and later purposes we collect some examples. Further examples
are contained in the exercises.
Example 3.6.1 Let E be a normed vector space and a : E×E →R a bilinear
functional. Recall that a is said to be symmetric if a(x, y) = a(y, x) for all
x, y ∈E, and a is said to be bounded if there exists κ > 0 such that
|a(x, y)| ≤κ∥x∥∥y∥
∀x, y ∈E.
Consider the quadratic functional f : E →R deﬁned by
f(x) := 1
2a(x, x),
x ∈E,
where a is bilinear, symmetric, and bounded. It is left as Exercise 3.8.6 to show
that f is continuously diﬀerentiable on E and to calculate the derivative.
In particular, if E is a Hilbert space with inner product (x | y), then the
functional
g(x) := 1
2∥x∥2 = 1
2(x | x),
x ∈E,
is continuously diﬀerentiable on E with ⟨g′(x), y⟩= (x | y) for all x, y ∈E.
Hence ∇g(x) = x for any x ∈E. Finally, concerning the norm functional
ω(x) := ∥x∥=
!
2g(x), the chain rule gives ∇ω(x) =
x
∥x∥for any x ̸= o.
Example 3.6.2 Let again E denote a Hilbert space with inner product (x | y)
and deﬁne g : E →R by
g(x) :=

δ2 + 2δ(u | x −¯x) −∥x −¯x∥21/2,
where the positive constant δ and the element u ∈E are ﬁxed. Choose ϵ > 0
such that the term (· · · ) is positive for each x ∈˚B(¯x, ϵ). Deﬁne ψ : (0, +∞) →
R by ψ(z) := z1/2 and ϕ : ˚B(¯x, ϵ) →R by
ϕ(x) := δ2 + 2δ(u | x −¯x) −∥x −¯x∥2.
Then we have g = ψ ◦ϕ, and the chain rule implies
(g′(x) | y) =
δ(u | y)

δ2 + 2δ(u | x −¯x) −∥x −¯x∥21/2
∀x ∈˚B(¯x, ϵ)
∀y ∈E.
In particular, (g′(¯x) |y ) = (u | y) for all y ∈E, which means ∇g(¯x) = u.
Moreover, it is easy to see that g is a C2-mapping on ˚B(¯x, ϵ). This example
will be used later in connection with proximal subdiﬀerentials.
In view of Example 3.6.3, recall that an absolutely continuous function
x : [a, b] →R is diﬀerentiable almost everywhere, i.e., outside a Lebesgue null
set N ⊆[a, b]. Setting ˙x(t) := 0 for each t ∈N, which we tacitly assume

50
3 Classical Derivatives
from now on, the function ˙x : [a, b] →R belongs to L1[a, b] and one has
"
[a,b] ˙x(t) dt = x(b) −x(a). In this connection, also recall that Lp[a, b], where
p ∈[1, +∞), denotes the vector space of all Lebesgue measurable functions g :
[a, b] →R such that |g|p is Lebesgue integrable over [a, b]. In addition, L∞[a, b]
denotes the vector space of all Lebesgue measurable functions g : [a, b] →R
such that ess supx∈[a,b]|g(x)| < +∞. We denote by AC∞[a, b] the vector space
of all absolutely continuous functions x : [a, b] →R such that ˙x ∈L∞[a, b].
Notice that AC∞[a, b] is a Banach space with respect to the norm
∥x∥1,∞:= max{∥x∥∞, ∥˙x∥∞}.
Example 3.6.3 Let E := AC∞[a, b], where a < b, and consider the varia-
tional functional
f(x) :=
 b
a
ϕ

t, x(t), ˙x(t)

dt
∀x ∈AC∞[a, b].
If ¯x ∈AC∞[a, b] is ﬁxed, we write ϕ(t) := ϕ

t, ¯x(t), ˙¯x(t)

for any t ∈[a, b].
Assume that the function (t, x, v) →ϕ(t, x, v) is continuous on [a, b] × R × R
and has continuous ﬁrst-order partial derivatives with respect to x and v
there. We shall show that the functional f is continuously diﬀerentiable at
any ¯x ∈AC∞[a, b] and that
⟨f ′(¯x), y⟩=
 b
a

ϕx(t) · y(t) + ϕv(t) · ˙y(t)

dt
∀y ∈AC∞[a, b].
(3.12)
Proof.
(I) The directional G-derivative fG(¯x, y) exists for all ¯x, y ∈AC∞[a, b]. In
fact, we have
fG(¯x, y) = ∂
∂τ f(¯x + τy)

τ=0
=
 b
a
∂
∂τ
#
ϕ(t, ¯x(t) + τy(t), ˙¯x(t) + τ ˙y(t))
$
τ=0
dt
=
 b
a
[ ¯ϕx(t)y(t) + ¯ϕv(t) ˙y(t)] dt.
Notice that the assumptions on ϕ and ¯x imply that the integrand in
the last term is bounded, which allows diﬀerentiating under the integral
sign.
(II) It is easy to verify that the functional y →fG(¯x, y) is linear and contin-
uous. Hence the G-derivative is given by (3.12).
(III) f is continuously diﬀerentiable at any ¯x ∈AC∞[a, b]. For arbitrary
x, ¯x, y ∈AC∞[a, b] we have
[f ′(x) −f ′(¯x)]y
=
 b
a
[ϕx(t, x, ˙x) −ϕx(t, ¯x, ˙¯x)]y dt +
 b
a
[ϕv(t, x, ˙x) −ϕv(t, ¯x, ˙¯x)] ˙y dt

3.7 Implicit Function Theorems and Related Results
51
and so
∥f ′(x) −f ′(¯x)∥=
sup
∥y∥1,∞≤1
|[f ′(x) −f ′(¯x)]y|
≤
 b
a
|ϕx(t, x, ˙x) −ϕx(t, ¯x, ˙¯x)| dt +
 b
a
|ϕv(t, x, ˙x) −ϕv(t, ¯x, ˙¯x)| dt,
< ϵ
if ∥x −¯x∥1,∞is suﬃciently small.
Justiﬁcation of the last line: According to hypothesis, ϕx and ϕv are
continuous on [a, b]×R×R, hence uniformly continuous on the compact
set
{(t, ξ, ζ) ∈R3 | t ∈[a, b], |ξ −¯x(t)| ≤1, |ζ −˙¯x(t)| ≤1}.
Thus, for each ϵ > 0 there exists δ ∈(0, 1) such that
|ϕx(t, x(t), ˙x(t)) −ϕx(t, ¯x(t), ˙¯x(t))| <
ϵ
2(b −a)
whenever t ∈[a, b], |x(t) −¯x(t)| ≤δ, and | ˙x(t) −˙¯x(t)| ≤δ. An analogous
estimate holds for ϕv.
⊓⊔
3.7 Implicit Function Theorems and Related Results
Now we make the following assumptions:
(A) E, F, and G are normed vector spaces.
U and V are open neighborhoods of ¯x ∈E and ¯y ∈F, respectively.
f : U × V →G.
Deﬁne g1 : U →G by g1(x) := f(x, ¯y), x ∈U. We denote the derivative
(in the sense of Gâteaux, Hadamard, or Fréchet) of g1 at ¯x, whenever it exists,
by f 1(¯x, ¯y) or by D1f(¯x, ¯y) and call it partial derivative of f, with respect
to the ﬁrst variable, at (¯x, ¯y). Notice that f 1(¯x, ¯y) is an element of L(E, G).
If f 1(x, y) exists, say, for all (x, y) ∈U × V , then
f 1 : (x, y) →f 1(x, y),
(x, y) ∈U × V,
deﬁnes the mapping f 1 : U × V →L(E, G). An analogous remark applies to
f 2(x, y) and D2f(¯x, ¯y).
As in classical multivariate calculus, we have the following relationship.
Proposition 3.7.1 Let the assumptions (A) be satisﬁed.
(a) If f is G-diﬀerentiable at (¯x, ¯y), then the partial G-derivatives f 1(¯x, ¯y)
and f 2(¯x, ¯y) exist and one has
f ′(¯x, ¯y)(u, v) = f 1(¯x, ¯y)u + f 2(¯x, ¯y)v
∀(u, v) ∈E × F.
(3.13)
An analogous statement holds for H- and F-derivatives.

52
3 Classical Derivatives
(b) Assume that the partial G-derivatives f 1 and f 2 exist on U × V and are
continuous at (¯x, ¯y). Then f is F-diﬀerentiable at (¯x, ¯y) and (3.13) holds
true.
Now we establish two implicit function theorems: one under standard
hypotheses and one under relaxed diﬀerentiability hypotheses but with G
ﬁnite dimensional.
Theorem 3.7.2 (Classical Implicit Function Theorem) In addition to
(A), let the following hold:
(a) E, F, and G are Banach spaces.
(b) f is continuous at (¯x, ¯y) and f(¯x, ¯y) = 0.
(c) The partial F-derivative f 2 exists on U × V and is continuous at (¯x, ¯y).
(d) The (continuous linear) mapping f 2(¯x, ¯y) : F →G is bijective.
Then:
(i)
There exist neighborhoods U ′ ⊆U and V ′ ⊆V of ¯x and ¯y, respectively,
such that for each x ∈U ′ there is precisely one ϕ(x) ∈V ′ satisfying
f

x, ϕ(x)

= o
∀x ∈U ′.
(ii)
If f is continuous in a neighborhood of (¯x, ¯y), then the function ϕ : x →
ϕ(x) is continuous in a neighborhood of ¯x.
(iii) If f is continuously diﬀerentiable in a neighborhood of (¯x, ¯y), then ϕ is
continuously diﬀerentiable in a neighborhood of ¯x and there holds
ϕ′(x) = −f 2

x, ϕ(x)
−1 ◦f 1

x, ϕ(x)

.
(3.14)
Concerning the proof of the theorem, which is based on the Banach ﬁxed point
theorem, see for instance Dieudonné [53], Schirotzek [196], or Zeidler [222].
Observe that the assumptions on f 2 guarantee that f 2

x, ϕ(x)
−1 exists as
an element of L(G, F) provided ∥x −¯x∥is suﬃciently small.
Now we relax the diﬀerentiability assumptions on f 2.
Proposition 3.7.3 In addition to (A), let the following hold:
(a) G is ﬁnite dimensional.
(b) f is continuous in a neighborhood of (¯x, ¯y) and f(¯x, ¯y) = 0.
(c) The partial F-derivative f 2(¯x, ¯y) exists and is surjective.
Then, for each neighborhood V ′ ⊆V of ¯y there exist a neighborhood U ′ ⊆U
of ¯x and a function ϕ : U ′ →V ′ such that the following holds:
(i) f

x, ϕ(x)

= o
∀x ∈U ′,
ϕ(¯x) = ¯y.
(ii) ϕ is continuous at ¯x.

3.7 Implicit Function Theorems and Related Results
53
Proof.
(I) Without loss of generality we may assume that ¯y = o. Further we
set T
:= f 2(¯x, o). By assumption, T is a continuous linear map-
ping of F onto the ﬁnite-dimensional space G. Hence there exists a
ﬁnite-dimensional linear subspace ˜F of F such that the linear mapping
T −1 : G →˜F satisfying TT −1(z) = z for any z ∈G is a linear iso-
morphism. In order to verify the assertions (i) and (ii), we may replace
f : E × F →G by its restriction to E × ˜F. But ˜F can be identiﬁed
with G and so we may assume that F = G. Then T is a bijective linear
mapping of G onto G.
(IIa) Let ϵ > 0 be such that BF (o, ϵ) ⊆V and f is continuous on the neigh-
borhood BE(¯x, ϵ) × BF (o, ϵ) of (¯x, o). Let α ∈(0, ϵ) be such that
|f(¯x, y) −T(y)| ≤
α
2∥T −1∥
∀y ∈BF (o, α).
(3.15)
Since f is continuous and BF (o, α) is compact, there further exists β ∈
(0, ϵ) such that
|f(¯x, y) −f(x, y)| ≤
α
2∥T −1∥
∀x ∈BE(¯x, β)
∀y ∈BF (o, α).
(3.16)
(IIb) For any x ∈BE(¯x, β) deﬁne hx : BF (o, α) →F by hx(y) := y −
T −1f(x, y). Notice that hx is continuous.
(IIc) We now show that hx maps BF (o, α) into itself. Let any y ∈BF (o, α)
be given. We have
∥hx(y)∥≤∥y −T −1f(¯x, y)∥+ ∥T −1
f(¯x, y) −f(x, y)

∥.
(3.17)
Furthermore, we obtain
∥y −T −1f(¯x, y)∥= ∥T −1
T(y) −f(¯x, y)

∥
≤∥T −1∥· ∥T(y) −f(¯x, y)∥
≤
(3.15)
α
2
(3.18)
as well as
∥T −1
f(¯x, y) −f(x, y)

∥
≤
(3.16)
∥T −1∥·
α
2∥T −1∥= α
2 .
Hence (3.17) shows that hx maps BF (o, α) into itself.
(IId) In view of (IIb) and (IIc) the Brouwer ﬁxed-point theorem applies, ensu-
ring that hx has a ﬁxed point ψ(x) in BF (o, α). This deﬁnes a mapping
ψ : x →ψ(x) of BE(¯x, β) into V satisfying
ψ(x) −T −1f

x, ψ(x)

= hx

ψ(x)

= ψ(x)
and so f

x, ψ(x)

= o for any x ∈BE(¯x, β).

54
3 Classical Derivatives
(III) Let a neighborhood V ′ ⊆V of o be given. Choose ν ∈N such that
BF (o, 1
ν ) ⊆V ′ and set Vi := BF (o,
1
ν+i) for i = 1, 2, . . . By step (II) we
know that for each i there exist a neighborhood Ui of ¯x and a function
ψi : Ui →Vi satisfying f

x, ψi(x)

= o for any x ∈Ui. Without loss
of generality we may assume that Ui+1 is a proper subset of Ui for
i = 1, 2, . . . and that ∞
i=1 Ui = {¯x}. Now let U ′ := U1 and deﬁne
ϕ : U ′ →V ′ by
ϕ(¯x) := o = ¯y,
ϕ(x) := ψi(x)
whenever x ∈Ui \ Ui+1.
Then (i) holds by deﬁnition of ϕ. We verify (ii). Thus let η > 0 be given.
Then we have Vi ⊆BF (o, η) for some i and ψi : Ui →Vi. It follows that
∥ϕ(x) −o∥= ∥ψi(x) −o∥≤η
whenever x ∈Ui \ Ui+1.
By the construction of Ui and Vi, we conclude that ϕ(Ui) ⊆BF

o, η

.
⊓⊔
Theorem 3.7.4 (Halkin’s Implicit Function Theorem) In addition to
(A), let the following hold:
(a) G is ﬁnite dimensional.
(b) f is continuous in a neighborhood of (¯x, ¯y) and f(¯x, ¯y) = 0.
(c) f is F-diﬀerentiable at (¯x, ¯y) and the partial F-derivative f 2(¯x, ¯y) is sur-
jective.
Then there exist a neighborhood U ′ of ¯x and a function ϕ : U ′ →V satisfying:
(i) f

x, ϕ(x)

= o
∀x ∈U ′,
ϕ(¯x) = ¯y.
(ii) ϕ is F-diﬀerentiable at ¯x and there holds
f 1(¯x, ¯y) + f 2(¯x, ¯y) ◦ϕ′(¯x) = o.
(3.19)
Proof.
(I) With the same argument as in step (I) of the proof of Proposition 3.7.3 we
may assume without loss of generality that F = G. We may also assume
that ¯x = o and ¯y = o. We set S := f 1(o, o) and T := f 2(o, o). Notice
that T is a bijective linear mapping of G onto G.
(II) By Proposition 3.7.3, there exist a neighborhood U ′ of ¯x = o and a
function ϕ : U ′ →V such that (i) holds and ϕ is continuous at o. We verify
(ii). Since f is F-diﬀerentiable at o, there exists a function r : U ′ →F
such that
f ′(o, o)

x, ϕ(x)

+ r

x, ϕ(x)

= o
∀x ∈U ′,
(3.20)
lim
∥x∥+∥y∥→0
r(x, y)
∥x∥+ ∥y∥= o.
(3.21)

3.7 Implicit Function Theorems and Related Results
55
By Proposition 3.7.1, (3.20) passes into
S(x) + T

ϕ(x)

+ r

x, ϕ(x)

= o
∀x ∈U ′,
i.e.,
ϕ(x) = −T −1S(x) −T −1r

x, ϕ(x)

∀x ∈U ′.
(3.22)
(III) We estimate ∥ϕ(x)∥. Let σ > 0 be such that BE(o, σ) ⊆U ′ and
∥r(x, y)∥≤(∥x∥+ ∥y∥)
2∥T −1∥
whenever ∥x∥≤σ, ∥y∥≤σ.
(3.23)
Since ϕ is continuous at o, there further exists α ∈(0, σ) such that
∥ϕ(x)∥≤σ for all x ∈BE(o, α). It follows that
∥ϕ(x)∥
≤
(3.22)
∥T −1S∥· ∥x∥+ ∥T −1∥· ∥r

x,¸ϕ(x)

∥
≤
(3.23)

∥T −1S∥+ 1
2

· ∥x∥+ 1
2∥ϕ(x)∥
∀x ∈BE(o, α)
and so
∥ϕ(x)∥≤(2∥T −1S∥+ 1) · ∥x∥
∀x ∈BE(o, α).
(3.24)
We also have
∥T −1r

x, ϕ(x)

∥≤∥T −1∥· ∥r

x, ϕ(x)

∥.
The latter inequality, (3.21) and (3.24) show that ∥T −1r

x, ϕ(x)

∥/∥x∥
is arbitrarily small for all x in a suﬃciently small neighborhood of
¯x = o. In view of (3.22), we conclude that ϕ is F-diﬀerentiable at o,
with derivative ϕ′(o) = −T −1S.
⊓⊔
To prepare the next result, recall (once more) that if the mapping
f : E →G is F-diﬀerentiable at ¯x ∈E, then with some neighborhood
U of ¯x, one has
f(x) = f(¯x) + f ′(¯x)(x −¯x) + r(x)
∀x ∈U,
where lim
x→¯x
r(x)
∥x −¯x∥= o.
Our aim now is to replace the correction term r(x) for the function values
on the right-hand side by a correction term ρ(x) for the argument on the
left-hand side:
f

x + ρ(x)

= f(¯x) + f ′(¯x)(x −¯x)
∀x ∈U,
where lim
x→¯x
ρ(x)
∥x −¯x∥= o.
(3.25)
Theorem 3.7.5 says that this is possible under appropriate hypotheses.

56
3 Classical Derivatives
Theorem 3.7.5 (Halkin’s Correction Theorem) Let
E
and
G
be
normed vector spaces with G ﬁnite dimensional. Further let f : E →G
and ¯x ∈E. Assume the following:
(a) f is continuous in a neighborhood of ¯x.
(b) The F-derivative f ′(¯x) exists and is surjective.
Then there exist a neighborhood U of ¯x and a function ρ : U →E such that
(3.25) holds. The function ρ satisﬁes ρ(¯x) = o and is F-diﬀerentiable at ¯x with
ρ′(¯x) = o.
Proof. Let F be the ﬁnite-dimensional linear subspace of E which f ′(¯x) maps
onto G. Deﬁne ˜f : E × F →G by
˜f(x, y) := f(x + y) −f ′(¯x)(x −¯x) −f(¯x).
Notice that ˜f is F-diﬀerentiable at (¯x, o) and that
˜f 1(¯x, o) = o,
˜f 2(¯x, o) = f ′(¯x).
(3.26)
Hence Theorem 3.7.4 applies to ˜f at (x, o). Thus there exist a neighborhood
U of ¯x and a function ϕ : U →F that is F-diﬀerentiable at ¯x and is such that
˜f

x, ϕ(x)

= o
∀x ∈U,
ϕ(¯x) = o,
˜f 1(¯x, o) + ˜f 2(¯x, o) ◦ϕ′(¯x) = o.
Setting ρ := ϕ, the deﬁnition of ˜f gives
f

x + ρ(x)

= f(¯x) + f ′(¯x)(x −¯x)
∀x ∈U.
Moreover, by (3.26) we have f ′(¯x)◦ρ′(¯x) = o. Since f ′(¯x) : F →G is bijective,
it follows that ρ′(¯x) = o. From this and ρ(¯x) = o we ﬁnally deduce that
ρ(x)/∥x −¯x∥→o as x →¯x.
⊓⊔
Theorem 3.7.5 will be a key tool for deriving a multiplier rule for a non-
smooth optimization problem in Sect. 12.3.
Theorem 3.7.6 (Halkin’s Inverse Function Theorem) Let
E
be
a
ﬁnite-dimensional normed vector space. Further let f : E →E and ¯x ∈E.
Assume the following:
(a) f is continuous in a neighborhood of ¯x.
(b) The F-derivative f ′(¯x) exists and is surjective.
Then there exist a neighborhood U of ¯x and a function ϕ : U →E such that
the following holds:
(i) f

ϕ(x)

= x
∀x ∈U,
ϕ

f(¯x)

= ¯x.
(ii) ϕ is F-diﬀerentiable at f(¯x), with ϕ′
f(¯x)

= f ′(¯x)−1.

3.8 Bibliographical Notes and Exercises
57
Proof. Deﬁne ˜f : E ×E →E by ˜f(u, v); = u−f(v) and set ¯u := f(¯x), ¯v := ¯x.
Then ˜f is F-diﬀerentiable at (¯u, ¯v), with ˜f 1(¯u, ¯v) = idE and ˜f 2(¯u, ¯v) =
−f ′(¯x). By Theorem 3.7.4 applied to ˜f at (¯u, ¯v), there exist a neighborhood
U of ¯u and a function ϕ : U →E such that ˜f

u, ϕ(u)

= o for any u ∈U and
ϕ(¯u) = ¯v. Moreover, ϕ is F-diﬀerentiable at ¯u and satisﬁes
˜f 1(¯u, ¯v) + ˜f 2(¯u, ¯v) ◦ϕ′(¯u) = o.
It is obvious that ϕ meets the assertions of the theorem.
⊓⊔
3.8 Bibliographical Notes and Exercises
The subject of this chapter is standard. We refer to Dieudonné [53],
Schirotzek [196], Schwartz [197], and Zeidler [222] for diﬀerential calculus
in Banach spaces and to Zeidler [221, 224] for diﬀerentiability properties of
integral functionals on Sobolev spaces. The results from Proposition 3.7.3 to
the end of Sect. 3.7 are due to Halkin [82]. See also the Bibliographical Notes
to Chap. 4.
Exercise 3.8.1 Deﬁne g : R2 →R by
g(x1, x2) :=

x3
1
x2
if x2 ̸= 0,
0
if x2 = 0.
Show that g is G-diﬀerentiable but not H-diﬀerentiable at ¯x = (0, 0).
Exercise 3.8.2 Show that the function
f(x) := x2 sin(1/x) if x ∈R \ {0},
f(x) := 0 if x = 0
is F-diﬀerentiable but not continuously diﬀerentiable at ¯x = 0.
In Sect. 4.6 we shall show that the maximum norm on C[a, b], where a < b,
is H-diﬀerentiable at certain points but nowhere F-diﬀerentiable; compare this
and the preceding two examples with Proposition 3.4.2.
Exercise 3.8.3 Deﬁne f
: R2 →R2 by f(x1, x2) := (x1, x3
2) and let
g : R2 →R be the function of Exercise 3.8.1. Then f is F-diﬀerentiable
(and so G-diﬀerentiable) on R2 and g is G-diﬀerentiable at ¯x = (0, 0). Is the
composite function g ◦f G-diﬀerentiable at ¯x?
Exercise 3.8.4 Carry out the omitted proofs for Proposition 3.2.4.
Exercise 3.8.5 Prove Proposition 3.2.5.

58
3 Classical Derivatives
Exercise 3.8.6 Show that the functional f(x) := 1
2a(x, x), x ∈E, where a :
E ×E →R is bilinear, symmetric, and bounded, is continuously diﬀerentiable
on E and calculate its derivative (cf. Example 3.6.1).
Exercise 3.8.7 Assume that ϕ : [a, b] × R × R →R is continuous and
possesses continuous partial derivatives with respect to the second and the
third variable. Modeling the proof in Example 3.6.3, show that the functional
f : C1[a, b] × [a, b] × [a, b] deﬁned by
f(x, σ, τ) :=
 τ
σ
ϕ

t, x(t), ˙x(t)

dt,
x ∈C1[a, b],
σ, τ ∈(a, b),
is continuously diﬀerentiable and calculate its derivative. (Functionals of this
kind appear in variable-endpoint problems in the classical calculus of varia-
tions.)

4
The Subdiﬀerential of Convex Functionals
4.1 Deﬁnition and First Properties
For convex functionals, the following notion provides an appropriate substitute
for a nonexisting derivative.
Deﬁnition 4.1.1 Let f : E →R be proper and convex, and let ¯x ∈dom f.
The set
∂f(¯x) := {x∗∈E∗| ⟨x∗, x −¯x⟩≤f(x) −f(¯x) ∀x ∈E}
is called subdiﬀerential of f at ¯x (in the sense of convex analysis). Each
x∗∈∂f(¯x) is called subgradient of f at ¯x.
A geometric interpretation is given in Fig. 0.1 in the Introduction.
Remark 4.1.2 The main purpose of the subdiﬀerential is to detect minimum
points. We ﬁrst consider free minimization. If f : E →R is convex and ¯x ∈
dom f, then we obtain
f(¯x) = min
x∈E f(x)
⇐⇒
0 ≤f(x) −f(¯x) ∀x ∈E
⇐⇒
o ∈∂f(¯x).
Hence the condition o ∈∂f(¯x) is a substitute for the optimality condition
f ′(¯x) = o in the diﬀerentiable case. Concerning constrained minimization, for
A ⊆E nonempty and convex, we have
f(¯x) = min
x∈A f(x) ⇐⇒(f + δA)(¯x) = min
x∈E(f + δA)(x) ⇐⇒o ∈∂(f + δA)(¯x).
For further exploitation, we need at least a sum rule of the form
∂(f1 + f2)(¯x) ⊆∂f1(¯x) + ∂f2(¯x).
This, among others, will be derived below.

60
4 The Subdiﬀerential of Convex Functionals
The subdiﬀerential of a convex functional f can also be characterized by
the directional G-derivative of f. This relationship will later be the starting
point for deﬁning subdiﬀerentials for certain classes of nonconvex functionals.
Theorem 4.1.3 Let f : E →R be proper and convex.
(a) If ¯x ∈domf and y ∈E, the function τ →1
τ

f(¯x+τy)−f(¯x)

is monotone
increasing on R \ {0}; hence the limit fG(¯x, y) exists in R and one has
f(¯x) −f(¯x −y) ≤fG(¯x, y) = inf
τ>0
f(¯x + τy) −f(¯x)
τ
≤f(¯x + y) −f(¯x).
(4.1)
(b) If ¯x ∈domf, the functional fG(¯x, ·) of E to R is sublinear.
(c) If ¯x ∈int dom f and y ∈E, then fG(¯x, y) ∈R.
(d) If ¯x ∈int dom f and f is continuous at ¯x, then fH(¯x, ·) exists, is contin-
uous on E, and equals fG(¯x, ·).
Proof.
(a) Since f is proper and convex, so is ϕ(τ) := f(¯x + τy), τ ∈R. Let τ1 <
τ2 < τ3 and τik := τi −τk for i, k = 1, 2, 3. Since τ2 = τ32
τ31 τ1 + τ21
τ31 τ3, it
follows that
ϕ(τ2) ≤τ32
τ31
ϕ(τ1) + τ21
τ31
ϕ(τ3)
and so
ϕ(τ2) −ϕ(τ1)
τ2 −τ1
≤ϕ(τ3) −ϕ(τ1)
τ3 −τ1
≤ϕ(τ3) −ϕ(τ2)
τ3 −τ2
.
(4.2)
From this, by appropriate choices of τi, we obtain the monotonicity of the
function
τ →1
τ

ϕ(τ) −ϕ(0)

= 1
τ

f(¯x + τy) −f(¯x)

as well as the relation (4.1).
(b) For y, z ∈E, the convexity of f implies
f

¯x+τ(y+z)

= f
 1
2(¯x+2τy) + 1
2(¯x+2τz)

≤1
2f(¯x+2τy) + 1
2f(¯x+2τz)
and so
fG(¯x, y + z) ≤fG(¯x, y) + fG(¯x, z).
It is evident that fG(¯x, ·) is positively homogeneous.
(c) Since ¯x ∈int dom f, there exists ϵ > 0 such that ¯x±ϵy ∈dom f. Applying
(4.1) with ϵy instead of y, we see that ϵ fG(¯x, y) (= fG(¯x, ϵy)) is ﬁnite.
(d) There exists an open neighborhood U of zero in E such that
f(¯x + y) −f(¯x) ≤1
∀y ∈U.
This and (4.1) imply that the convex functional fG(¯x, ·) is bounded above
on U and so, by Theorem 1.4.1, is continuous on int dom fG(¯x, ·) which is
equal to E. Likewise by Theorem 1.4.1, f is locally L-continuous. Hence
by Lemma 3.1.2, fH(¯x, ·) exists and equals fG(¯x, ·).
⊓⊔

4.1 Deﬁnition and First Properties
61
τ1
τ2
τ3
P1
P2
P3
ϕ
Fig. 4.1
Remark 4.1.4 For a proper convex function ϕ : R →R, the inequalities
(4.2) have a simple geometric meaning. With the notation of Fig. 4.1, the
inequalities say that
slope(P1P2) ≤slope(P1P3) ≤slope(P2P3).
If ϕ is a function deﬁned on R, then obviously ϕG(τ, 1) = ϕ′
+(τ), where ϕ′
+(τ)
denotes the right derivative of ϕ at τ (cf. Sect. 3.1). Hence Theorem 4.1.3
immediately leads to:
Corollary 4.1.5 Let ϕ : R →R be proper and convex. For any τ0 ∈dom ϕ,
the right derivative ϕ′
+(τ0) exists in R and satisﬁes
ϕ′
+(τ0) = inf
τ>0
ϕ(τ0 + τ) −ϕ(τ0)
τ
.
In particular, if τ0 ∈int dom ϕ, then ϕ′
+(τ0) ∈R. If τ0 ∈dom ϕ is the left
boundary point of dom ϕ, then ϕ′
+(τ0) ∈R ∪{−∞}.
The subdiﬀerential can be characterized by the directional G-derivative
and vice versa.
Proposition 4.1.6 Let f : E →R be proper and convex.
(a) If ¯x ∈dom f, then
∂f(¯x) = {x∗∈E∗ ⟨x∗, y⟩≤fG(¯x, y) ∀y ∈E}.
(4.3)
(b) If ¯x ∈int dom f and f is continuous at ¯x, then ∂f(¯x) is nonempty convex
and σ(E∗, E)-compact, and one has
fH(¯x, y) = fG(¯x, y) = max{⟨x∗, y⟩| x∗∈∂f(¯x)}
∀y ∈E.
(4.4)
Proof.
(a) Let x∗∈∂f(¯x). For each τ > 0, we have
τ⟨x∗, y⟩= ⟨x∗, ¯x + τy⟩−⟨x∗, ¯x⟩≤f(¯x + τy) −f(¯x)

62
4 The Subdiﬀerential of Convex Functionals
and so ⟨x∗, y⟩≤fG(¯x, y). Conversely, if x∗belongs to the right-hand side
of (4.3), then it follows from (4.1) that
⟨x∗, ¯x + y⟩−⟨x∗, ¯x⟩= ⟨x∗, y⟩≤f(¯x + y) −f(¯x)
and so x∗∈∂f(¯x).
(b) By Theorem 4.1.3, the functional p(y) := fG(¯x, y), y ∈E, is ﬁnite, sub-
linear, and continuous. By (a), we have ∂f(¯x) = Mp; here we use the
notation introduced in the H¨ormander theorem (Theorem 2.3.1). Accord-
ing to this result, Mp is nonempty, convex, and σ(E∗, E)-closed, and we
have σMp = p, i.e.,
sup{⟨x∗, y⟩| x∗∈∂f(¯x)} = fG(¯x, y)
∀y ∈E.
(4.5)
We show that ∂f(¯x) is σ(E∗, E)-compact. Since f is continuous at ¯x, the
set
U := {y ∈E | f(¯x + y) −f(¯x) ≤1}
is a neighborhood of zero in E. Setting U ⋄:= {x∗∈E∗| ⟨x∗, y⟩≤1 ∀y ∈
U}, we have ∂f(¯x) ⊆U ⋄. By the Alaoglu theorem, U ⋄is σ(E∗, E)-
compact and so is ∂f(¯x) as a σ(E∗, E)-closed subset. For ﬁxed y ∈E,
the functional x∗→⟨x∗, y⟩, x∗∈E∗, is σ(E∗, E)-continuous and so
the supremum in (4.5) is attained. Finally, by Theorem 4.1.3(d) we may
replace fG by fH.
⊓⊔
The representation formula (4.4) can be reﬁned using the concept of ext-
reme point.
Proposition 4.1.7 If f : E →R is proper, convex, and continuous at ¯x ∈
int dom f, then
fH(¯x, y) = fG(¯x, y) = max

⟨x∗, y⟩
 x∗∈ep

∂f(¯x)

∀y ∈E.
Proof. By virtue of Proposition 4.1.6(b), we may apply Proposition 1.7.8 to
E∗[σ] instead of E, A := ∂f(¯x), and g(x∗) := ⟨x∗, y⟩, x∗∈E.
⊓⊔
Now we characterize G-diﬀerentiability of convex functionals.
Proposition 4.1.8 (Diﬀerentiability Criterion) Let f : E →R be proper
and convex, and let ¯x ∈dom f.
(a) If f is G-diﬀerentiable at ¯x, then ∂f(¯x) = {f ′(¯x)}.
(b) If f is continuous at ¯x and ∂f(¯x) consists of exactly one element x∗∈E∗,
then f is H-diﬀerentiable (and so G-diﬀerentiable) at ¯x and f ′(¯x) = x∗.
Proof.
(a) On the one hand, we have
⟨f ′(¯x), ¯x+y⟩−⟨f ′(¯x) , ¯x⟩= ⟨f ′(¯x), y⟩= fG(¯x, y) ≤f(¯x+y)−f(¯x)
∀y ∈E

4.2 Multifunctions: First Properties
63
and so f ′(¯x) ∈∂f(¯x). On the other hand, if x∗∈∂f(¯x), then by
Proposition 4.1.6 we obtain
⟨x∗, y⟩≤fG(¯x, y) = ⟨f ′(¯x), y⟩
∀y ∈E.
This implies, by the linearity of x∗and f ′(¯x), that x∗= f ′(¯x).
(b) By Proposition 4.1.6, we conclude that fG(¯x, y) = ⟨x∗, y⟩∀y ∈E. Hence
the functional fG(¯x, ·) is linear and continuous. Thus f is G-diﬀerentiable
at ¯x, and we have f ′(¯x) = x∗. Moreover, f is locally L-continuous around
¯x (Theorem 1.4.1) and so H-diﬀerentiable at ¯x (Proposition 3.4.2).
⊓⊔
Proposition 4.1.9 (Semicontinuity Criterion) Let f : E →R be proper,
convex, and G-diﬀerentiable at ¯x. Then f is lower semicontinuous at ¯x.
Proof. Let k > 0 be given. Since f ′(¯x) is continuous at y = o in particular,
there exists a neighborhood U of o in E such that
k −f(¯x) < ⟨f ′(¯x), y⟩≤f(¯x + y) −f(¯x)
∀y ∈U.
⊓⊔
4.2 Multifunctions: First Properties
The subdiﬀerential of a convex function f : E →R associates with each
x ∈E a (possibly empty) subset ∂f(x) of E∗. The study of this and related
objects will be the prominent purpose in the sequel. We now introduce some
appropriate concepts.
Deﬁnition 4.2.1 Let E and F be vector spaces. A mapping Φ : E →2F ,
which associates to x ∈E a (possibly empty) subset Φ(x) of F, is called a
multifunction or set-valued mapping and is denoted Φ : E ⇒F. The graph
and the domain of Φ are deﬁned, respectively, by
graph Φ := {(x, y) ∈E × F | x ∈E, y ∈Φ(x)},
Dom Φ := {x ∈E | Φ(x) ̸= ∅}.
Observe that the notation distinguishes the domain of a multifunction
from the eﬀective domain dom f of a functional f : E →R. If A is a subset
of E, we write Φ(A) := ∪x∈AΦ(x).
Remark 4.2.2 A mapping T : E →F can be identiﬁed with the (single-
valued) multifunction %T : E ⇒F deﬁned by %T(x) := {Tx}, x ∈E. Concepts
deﬁned below for multifunctions will be applied to a mapping T : E →F
according to this identiﬁcation.
As indicated above, the prototype of a multifunction is the subdiﬀerential
mapping ∂f : E ⇒E∗of a convex functional f : E →R, which associates to
each x ∈dom f the subdiﬀerential ∂f(x) and to each x /∈dom f the empty
set.

64
4 The Subdiﬀerential of Convex Functionals
Deﬁnition 4.2.3 Let Φ : E ⇒F be a multifunction between locally convex
spaces E and F.
(a) Φ is said to be upper semicontinuous at ¯x ∈Dom Φ if for each open set V
in F containing Φ(¯x) there exists an open neighborhood U of ¯x such that
Φ(U) ⊆V .
(b) Φ is said to be lower semicontinuous at ¯x ∈Dom Φ if for each open set V
in F such that V ∩Φ(¯x) ̸= ∅, there exists an open neighborhood U of ¯x
such that V ∩Φ(x) ̸= ∅for any x ∈U.
(c) Φ is said to be upper [lower] semicontinuous if Φ is upper [lower] semicon-
tinuous at any point ¯x ∈Dom Φ (cf. Exercise 4.8.1).
(d) Φ is said to be locally bounded at ¯x ∈E if there exists a neighborhood U
of ¯x such that Φ(U) is a bounded subset of F.
(e) A mapping ϕ : E →F is said to be a selection of the multifunction Φ if
ϕ(x) ∈Φ(x) for each x ∈Dom Φ.
Recall that if ψ : R →R is diﬀerentiable, then
ψ is convex
⇐⇒
ψ′ is monotone increasing
⇐⇒

ψ′(y) −ψ′(x)

· (y −x) ≥0
∀x, y ∈R.
(4.6)
If we want to generalize this relationship to a G-diﬀerentiable functional f :
E →R, we must ﬁrst deﬁne a suitable monotonicity concept for the mapping
f ′ : E →E∗. In view of the nondiﬀerentiable case and the subdiﬀerential
mapping, we at once consider multifunctions.
Deﬁnition 4.2.4 The multifunction Φ : E ⇒E∗is said to be
monotone
if ⟨y∗−x∗, y −x⟩≥0,
strictly monotone
if ⟨y∗−x∗, y −x⟩> 0,
uniformly monotone if ⟨y∗−x∗, y −x⟩≥c · ∥y −x∥γ;
the respective inequality is assumed to hold for all x, y ∈Dom Φ, x ̸= y,
x∗∈Φ(x) and y∗∈Φ(y). In the last inequality, c > 0 and γ > 1 are constants.
If Φ is uniformly monotone with γ = 2, then Φ is called strongly monotone.
According to Remark 4.2.2, a mapping T : E →E∗is monotone if and
only if
⟨T(y) −T(x), y −x⟩≥0
∀x, y ∈E.
An analogous remark applies to strict and to uniform monotonicity.
4.3 Subdiﬀerentials, Fréchet Derivatives,
and Asplund Spaces
In this section we study the subdiﬀerential mapping ∂f : E ⇒E∗. This will
eventually lead to remarkable results on the F-diﬀerentiability of continuous
convex functionals and, in this connection, to Asplund spaces.

4.3 Subdiﬀerentials, Fréchet Derivatives, and Asplund Spaces
65
Recall again that, unless otherwise speciﬁed, E is a normed vector space
and the dual E∗is equipped with the norm topology.
Proposition 4.3.1 Let f : E →R be proper and convex. If f is continuous
at ¯x ∈int domf, then the subdiﬀerential mapping ∂f is locally bounded at ¯x.
Proof. Since f is locally L-continuous at ¯x (Theorem 1.4.1), there exist ϵ > 0
and λ > 0 such that |f(x) −f(y)| ≤λ∥x −y∥for all x, y ∈B(¯x, ϵ). Thus
if x ∈B(¯x, ϵ) and x∗∈∂f(x), then ⟨x∗, y −x⟩≤f(y) −f(x) ≤λ∥x −y∥.
It follows that
∥x∗∥≤λ
∀x∗∈∂f(x)
∀x ∈B(¯x, ϵ),
(4.7)
which completes the proof.
⊓⊔
Proposition 4.3.2 Let f : E →R be proper and convex, and continuous on
the nonempty set int domf.
(a) The subdiﬀerential mapping ∂f : E ⇒E∗is norm-to-weak* upper semi-
continuous on int domf.
(b) If f is F-diﬀerentiable at ¯x ∈int domf, then ∂f is norm-to-norm upper
semicontinuous at ¯x.
Proof.
(a) Assume that x ∈int domf and V is a weak* open subset of E∗containing
∂f(x). It suﬃces to show that for any sequence (xn) in int domf with
xn →x as n →∞, we have ∂f(xn) ⊆V for all suﬃciently large n.
Suppose this would not hold. Then for some subsequence of (xn), again
denoted (xn), we could ﬁnd x∗
n ∈∂f(xn) \ V . Since ∂f is locally bounded
at x, there exists c > 0 such that ∂f(xn) ⊆BE∗(o, c) for all suﬃ-
ciently large n (compare (4.7)). Since BE∗(o, c) is weak* compact (Alaoglu
theorem), the sequence (x∗
n) admits a weak* cluster point x∗. From
x∗
n ∈∂f(xn) \ V we can easily conclude that x∗∈∂f(x) \ V which is
a contradiction to ∂f(x) ⊆V .
(b) Let V be an open neighborhood of f ′(¯x) ∈E∗. Assume that for any
neighborhood U of ¯x, we would have ∂f(U) \ V ̸= ∅. Then there exist
ϵ > 0, a sequence (xn) in int domf, and x∗
n ∈∂f(xn) such that xn →¯x
as n →∞but ∥x∗
n −f ′(¯x)∥> 2ϵ. The latter implies that there exists a
sequence (zn) in E satisfying ∥zn∥= 1 and ⟨x∗
n −f ′(¯x), zn⟩> 2ϵ for all n.
On the other hand, by F-diﬀerentiability we have for some δ > 0,
f(¯x + y) −f(¯x) −⟨f ′(¯x), y⟩≤ϵ∥y∥
whenever y ∈E and ∥y∥< δ. For these y we further obtain
⟨x∗
n, (¯x + y) −xn⟩≤f(¯x + y) −f(xn)
and so
⟨x∗
n, y⟩≤f(¯x + y) −f(¯x) + ⟨x∗
n, xn −¯x⟩+ f(¯x) −f(xn).

66
4 The Subdiﬀerential of Convex Functionals
Setting yn := δzn, the choice of zn implies ∥yn∥= δ and so
2ϵδ < ⟨x∗
n −f ′(¯x), yn⟩
≤

f(¯x + yn) −f(¯x) −⟨f ′(¯x), yn⟩

+ ⟨x∗
n, xn −¯x⟩+ f(¯x) −f(xn)
≤ϵδ + ⟨x∗
n, xn −¯x⟩+ f(¯x) −f(xn).
(4.8)
Since f is locally bounded at ¯x, the sequence (x∗
n) is bounded and so
⟨x∗
n, xn −¯x⟩→0 as n →∞. Moreover, since f is continuous at ¯x, we
also have f(¯x) −f(xn) →0 as n →∞. Hence the right-hand side of (4.8)
tends to ϵδ as n →∞which contradicts the left-hand side.
⊓⊔
Proposition 4.3.3 Let f : E →R be proper and convex, and continuous
on the nonempty set int domf. Then f is F-diﬀerentiable [G-diﬀerentiable] at
¯x ∈int domf if and only if there exists a selection ϕ : E →E∗of ∂f which is
norm-to-norm continuous [norm-to-weak* continuous] at ¯x.
Proof. We verify the statement concerning F-diﬀerentiability, leaving the case
in brackets as Exercise 4.8.2.
(I) Necessity. If f is F-diﬀerentiable at ¯x, then ∂f(¯x) is a singleton, and by
Proposition 4.3.2 the subdiﬀerential mapping ∂f is upper semicontinuous
at ¯x. Hence any selection of ∂f is continuous at ¯x.
(II) Suﬃciency. Let ϕ be a selection of ∂f that is continuous at ¯x. Since
int domf ⊆Dom ∂f, we have ϕ(¯x) ∈∂f(¯x) and ϕ(y) ∈∂f(y) for each
y ∈int domf. For these y it follows that
⟨ϕ(¯x), y −¯x⟩≤f(y) −f(x)
and
⟨ϕ(y), ¯x −y⟩≤f(¯x) −f(y).
Combining these inequalities, we obtain, again for all y ∈int domf,
0 ≤f(y)−f(¯x)−⟨ϕ(¯x), y−¯x⟩≤⟨ϕ(y)−ϕ(¯x), y−¯x⟩≤∥ϕ(y)−ϕ(¯x)∥·∥y−¯x∥.
Since ϕ is continuous at ¯x, we have ∥ϕ(y)−ϕ(¯x)∥≤1 for all y in a neigh-
borhood of ¯x. Hence the above inequality shows that f is F-diﬀerentiable
at ¯x, with derivative ϕ(¯x).
⊓⊔
Corollary 4.3.4 If f : E →R is proper and convex, and F-diﬀerentiable
on the nonempty set int domf, then f is continuously F-diﬀerentiable on
int domf.
Applying the statement in brackets in Proposition 4.3.3, we obtain an
analogous result concerning the norm-to-weak* continuity of the G-derivative.
In this connection, the functional f has to be assumed to be continuous on
the nonempty set int dom f. Below we shall establish a related result under
relaxed assumptions (see Proposition 4.3.8).

4.3 Subdiﬀerentials, Fréchet Derivatives, and Asplund Spaces
67
Proposition 4.3.5 (Convexity Criterion) Iff : E →RisG-diﬀerentiable,
then the following statements are equivalent:
(a) f is [strictly] convex.
(b) f ′ is [strictly] monotone.
Proof. See Exercise 4.8.3.
⊓⊔
Example 4.3.6 Consider the functional
f(x) := 1
2a(x, x),
x ∈E,
where a : E ×E →R is bilinear, symmetric, and bounded. By Example 3.6.1,
f is continuously diﬀerentiable and the derivative satisﬁes ⟨f ′(x), y⟩= a(x, y)
for all x, y ∈E. Assume now that, in addition, a is strongly positive, i.e., there
exists a constant c > 0 such that a(x, x) ≥c ∥x∥2 for any x ∈E. Then we
obtain
⟨f ′(y) −f ′(x), y −x⟩= a(y −x, y −x) ≥c∥y −x∥2
∀x, y ∈E
and so f ′ is strongly monotone. In particular, f ′ is strictly monotone and so
f is strictly convex.
If f is convex but not G-diﬀerentiable, we still have the following result.
Proposition 4.3.7 If f : E →R is proper and convex, then ∂f is monotone.
Proof. See Exercise 4.8.4.
⊓⊔
Now we establish the continuity result on the derivative announced after
Corollary 4.3.4.
Proposition 4.3.8 If f : E →R is proper and convex, and G-diﬀerentiable
on the nonempty set int domf, then f ′ is radially continuous on int domf.
Proof. For ﬁxed x, y ∈D, deﬁne ψx,y : [0, 1] →R by ψx,y(τ) := f

x+τ(y−x)

for any τ ∈[0, 1]. Then we have
ψ′
x,y(τ) =

f ′
x + τ(y −x)

, y −x
 
and it remains to show that ψ′
x,y is continuous on [0, 1].
(I) First we show that ψ′
x,y is continuous at any τ ∈(0, 1). Since ψx,y is
convex, Theorem 4.1.3 applies ensuring that for any ρ, σ satisfying ρ > σ
we have
ψ′
x,y(τ + σ) ≤
1
ρ −σ
&
ψx,y

(τ + σ) + (ρ −σ)

−ψx,y(τ + σ)

.

68
4 The Subdiﬀerential of Convex Functionals
Since ψx,y is continuous on (0, 1) (Corollary 1.4.2), we obtain letting σ ↓0
and then ρ ↓0,
lim
σ↓0 ψ′
x,y(τ+σ) ≤1
ρ
#
ψx,y(τ+ρ)−ψx,y(τ)
$
and
lim
σ↓0 ψ′
x,y(τ+σ) ≤ψ′
x,y(τ).
On the other hand, since ψ′
x,y is monotone (increasing), we have
limσ↓0 ψ′
x,y(τ + σ) ≥ψ′
x,y(τ). Hence ψ′
x,y is right continuous at τ.
Analogously it is shown that ψ′
x,y is left continuous at τ.
(II) To see that ψ′
x,y is continuous on the closed interval [0, 1], notice that
since D is open, x and y may be replaced in the above argument by
x −δ(y −x) and y + δ(y −x), respectively, where δ > 0 is suﬃciently
small.
⊓⊔
Proposition 4.3.9 If f : E →R is G-diﬀerentiable and f ′ is uniformly
monotone with constants c > 0 and γ > 1, then f is strictly convex and
f(y) −f(x) ≥⟨f ′(x), y −x⟩+ c
γ ∥y −x∥γ
∀x, y ∈E.
(4.9)
Proof. By assumption, f ′ is strictly monotone and so f is strictly convex.
Furthermore, by Proposition 4.3.8 the mean value formula (3.7) applies to f.
Hence for any x, y ∈E we have
f(y) −f(x) = ⟨f ′(x), y −x⟩+
 1
0

f ′
x + τ(y −x)

−f ′(x), τ(y −x)
 dτ
τ
≥⟨f ′(x), y −x⟩+
 1
0
cτ γ ∥y −x∥γ dτ
τ ,
and (4.9) follows.
⊓⊔
Remark 4.3.10 The above result will later be used to ensure that f has a
(unique) global minimum point ¯x. This point satisﬁes f ′(¯x) = o. Hence if (xn)
is a sequence of approximate solutions of f ′(¯x) = o, then we obtain from (4.9)
the error estimate
c
γ ∥xn −¯x∥γ ≤f(xn) −f(¯x).
The next result says that F-diﬀerentiability of a continuous convex func-
tional can be characterized without referring to a potential derivative. It will
serve us to characterize the set of points where a continuous convex functional
is F-diﬀerentiable.
Lemma 4.3.11 Let f : E →R be proper, convex, and continuous on the
nonempty set int dom f. Then f is F-diﬀerentiable at ¯x ∈int dom f if and
only if for each ϵ > 0 there exists δ > 0 such that
f(¯x + τy) + f(¯x −τy) −2f(¯x) < τϵ
(4.10)
whenever y ∈E, ∥y∥= 1 and 0 < τ < δ.

4.3 Subdiﬀerentials, Fréchet Derivatives, and Asplund Spaces
69
Proof.
(I) Necessity. See Exercise 4.8.5.
(II) Suﬃciency. Assume that the above condition is satisﬁed and choose some
x∗∈∂f(¯x) (which exists by Proposition 4.1.6). Let y ∈E satisfying
∥y∥= 1 be given. For all τ > 0 suﬃciently small such that ¯x ± τy ∈D
we have
⟨x∗, τy⟩= ⟨x∗, (¯x + τy) −¯x⟩≤f(¯x + τy) −f(¯x),
(4.11)
−⟨x∗, τy⟩= ⟨x∗, (¯x −τy) −¯x⟩≤f(¯x −τy) −f(¯x).
(4.12)
Now let ϵ > 0 be given and choose δ > 0 such that (4.10)–(4.12) hold
whenever ∥y∥= 1 and 0 < τ < δ. Adding the inequalities (4.11) and
(4.12), we obtain for these y and τ,
0 ≤f(¯x + τy) −f(¯x) −⟨x∗, τy⟩≤τϵ.
Hence f is F-diﬀerentiable at ¯x.
⊓⊔
Recall that a subset of E is said to be a Gδ set if it is the intersection of
a countable number of open sets.
Proposition 4.3.12 Let f : E →R be proper, convex, and continuous on
the nonempty set D := int dom f. Then the set ∆of all x ∈D, where f is
F-diﬀerentiable, is a (possibly empty) Gδ set.
Proof. For each n ∈N let Gn denote the set of all x ∈D for which there
exists δ > 0 such that
sup
∥y∥=1
f(x + δy) + f(x −δy) −2f(x)
δ
< 1
n .
By Theorem 4.1.3, for ﬁxed x and y the functions
τ →f(x + τ(±y)) −f(x)
τ
are decreasing as τ ↓0. Thus Lemma 4.3.11 shows that ∆= ∩∞
n=1Gn.
It remains to verify that each Gn is open. Let x ∈Gn be given. Since f
is locally L-continuous (Theorem 1.4.1), there exist δ1 > 0 and λ > 0 such
that |f(u) −f(v)| ≤λ∥u −v∥for all u, v ∈B(x, δ1), where B(x, δ1) ⊆D.
Moreover, since x ∈Gn, there are δ > 0 and r > 0 such that for all y ∈E
satisfying ∥y∥= 1 we have x ± δy ∈D and
f(x + δy) + f(x −δy) −2f(x)
δ
≤r < 1
n .
Now take δ2 ∈(0, δ1) so small that B(x, δ2) ⊆D and r + 4λδ2/δ < 1/n. We
are going to show that B(x, δ2) ⊆Gn. Thus let z ∈B(x, δ2). Then for any
y ∈E satisfying ∥y∥= 1 it follows that

70
4 The Subdiﬀerential of Convex Functionals
f(z + δy) + f(z −δy) −2f(z)
δ
≤f(x + δy) + f(x −δy) −2f(x)
δ
+ 2|f(z) −f(x)|
δ
+ |f(z + δy) −f(x + δy)|
δ
+ |f(z −δy) −f(x −δy)|
δ
≤r + 4λ∥z −x∥
δ
≤r + 4λδ2
δ
< 1
n
and so z ∈Gn.
⊓⊔
Deﬁnition 4.3.13 A Banach space E is said to be an Asplund space if every
continuous convex functional deﬁned on a nonempty open convex subset D of
E is F-diﬀerentiable on a dense subset of D.
Usually a Banach space E is said to be an Asplund space if every contin-
uous convex functional is generically F-diﬀerentiable, i.e., F-diﬀerentiable on
a dense Gδ subset of D. Proposition 4.3.12 shows that this is equivalent to
the above deﬁnition.
Recall that the (inﬁnite dimensional) normed vector space E is said to be
separable if some countable subset is dense in E. Our aim is to verify that a
Banach space with a separable dual is an Asplund space. For this, we need a
geometric concept.
Deﬁnition 4.3.14
(a) Let x∗∈E∗, x∗̸= o, and 0 < α < 1. The set
K(x∗, α) := {x ∈E | α∥x∥∥x∗∥≤⟨x∗, x⟩},
which is a closed convex cone, is called Bishop–Phelps cone associated
with x∗and α.
(b) The set A ⊆E is said to be α-cone meager, where 0 < α < 1, if for every
x ∈A and ϵ > 0 there exist z ∈B(x, ϵ) and x∗∈E∗, x∗̸= o, such that
A ∩

z + int K(x∗, α)

= ∅.
(c) The set A ⊆E is said to be angle-small if for every α ∈(0, 1), A can be
expressed as the union of a countable number of α-cone meager sets.
Example 4.3.15 Consider Rn with inner product (x∗| x) and identify (Rn)∗
with Rn. Let x∗∈Rn, x∗̸= o, and α ∈(0, 1) be given. For any x ̸= o we have
x ∈K(x∗, α)
⇐⇒
α ≤

x∗
∥x∗∥

x
∥x∥

,
i.e., the projection of the unit vector x/∥x∥in the direction of x∗is at least α.
The “ice cream cone” in R3 is thus a typical example of a Bishop–Phelps cone.

4.3 Subdiﬀerentials, Fréchet Derivatives, and Asplund Spaces
71
   c
x
z
B(x, ϵ)
c + K(x∗, α)
z + K(x∗, α)
Fig. 4.2
Example 4.3.16 Let A ⊆R2 consist of a circle and its center c. Then A is
not α-cone meager for any α ∈(0, 1) but it is the union of two α-cone meager
sets and so is angle-small (Fig. 4.2).
Recall that a set A ⊆E is said to be nowhere dense if cl A has empty
interior or, equivalently, if E \ cl A is dense in E. Further, A is said to be of
ﬁrst category (or to be meager) if A is the union of a countable number of
nowhere dense sets.
Lemma 4.3.17 If A ⊆E is α-cone meager for some α ∈(0, 1), then A is
nowhere dense. Hence any angle-small subset of E is of ﬁrst category.
Proof. See Exercise 4.8.6.
⊓⊔
The converse of Lemma 4.3.17 does not hold. In fact, an α-cone meager
subset of R contains at most two elements. Hence a subset of R is angle-small
if and only if it is countable. On the other hand, the Cantor set is an example
of an uncountable set of ﬁrst category.
Now we can establish a remarkable result on monotone multifunctions.
Theorem 4.3.18 Let E be a Banach space with a separable dual. If Φ : E ⇒
E∗is a monotone multifunction, then there exists an angle-small set A ⊆
Dom Φ such that Φ is single-valued and upper semicontinuous on (Dom Φ)\A.
Proof. Set
A := {x ∈Dom Φ | lim
δ↓0 diam Φ

B(x, δ)

> 0}.
(I) It is left as an exercise to show that if x ∈(Dom Φ) \ A, then Φ(x) is a
singleton and Φ is upper semicontinuous at x.
(II) It remains to show that A is angle-small. We have A = ∪∞
n=1An, where
An := {x ∈Dom Φ | lim
δ↓0 diam Φ

B(x, δ)

> 1/n}.

72
4 The Subdiﬀerential of Convex Functionals
Let (x∗
k) be a dense sequence in E∗, let α ∈(0, 1) and set
An,k := {x ∈An | d(x∗
k, Φ(x)) < α/(4n)}.
Then obviously An = ∪∞
k=1An,k for all n. Hence it suﬃces to show that each
An,k is α-cone meager. Let x ∈An,k and ϵ > 0 be given. Since x ∈An, there
exist δ ∈(0, ϵ) as well as elements zi ∈B(x, δ) and z∗
i ∈Φ(zi) for i = 1, 2
such that ∥z∗
1 −z∗
2∥> 1/n. Hence if x∗∈Φ(x), then ∥z∗
1 −x∗∥> 1/(2n) or
∥z∗
2 −x∗∥> 1/(2n). Choose x∗∈Φ(x) such that ∥x∗
k −x∗∥< α/(4n) (which
is possible since x ∈An,k). According to what we said about zi, z∗
i , where
i = 1, 2, we can ﬁnd points z ∈B(x, ϵ) and z∗∈Φ(z) satisfying
∥z∗−x∗
k∥≥∥z∗−x∗∥−∥x∗
k −x∗∥> 1/(2n) −α/(4n) > 1/(4n).
We are going to show that An,k ∩(z + int K(z∗−x∗
k), α) = ∅, i.e.,
An,k ∩{y ∈E | ⟨z∗−x∗
k, y −z⟩> α∥z∗−x∗
k∥· ∥y −z∥} = ∅.
Suppose y ∈Dom Φ is such that ⟨z∗−x∗
k, y −z⟩> α∥z∗−x∗
k∥· ∥y −z∥and
let y∗∈Φ(y). Then
⟨y∗−x∗
k, y −z⟩= ⟨y∗−z∗, y −z⟩+ ⟨z∗−x∗
k, y −z⟩
≥⟨z∗−x∗
k, y −z⟩> α∥z∗−x∗
k∥· ∥y −z∥≥α∥y −z∥/(4n).
It follows that ∥y∗−x∗
k∥≥α/(4n) and so y /∈An,k.
⊓⊔
With the aid of Theorem 4.3.18 we can now easily establish a suﬃcient
condition for a Banach space to be an Asplund space.
Theorem 4.3.19 If the dual of the Banach space E is separable, then E is
an Asplund space.
Proof. Let f
: E →R be proper and convex, and continuous on the
nonempty set D:=int dom f. Then ∂f is monotone (Proposition 4.3.7). By
Theorem 4.3.18, there exists an angle-small set A such that ∂f is single-valued
and upper semicontinuous on D \ A and so any selection of ∂f is continuous
on D \ A. By Proposition 4.3.3, f is F-diﬀerentiable on D \ A. Since A is of
ﬁrst category (Lemma 4.3.17), the set D \ A is dense in D (and a Gδ set).
⊓⊔
Remark 4.3.20
(a) Notice that we actually showed somewhat more than stated, namely that
any proper convex continuous functional f is F-diﬀerentiable outside an
angle-small subset of int dom f.
(b) According to Theorem 4.3.19, the following spaces are Asplund spaces:
the sequence spaces c0 and lp as well as the function spaces Lp[a, b], where
1 < p < ∞, furthermore any separable reﬂexive Banach space. It can
be shown that any reﬂexive Banach space is an Asplund space (see Deville
et al. [50] or Phelps [165]). Notice that c0 is an example of a nonreﬂexive
Asplund space while l1 and l∞are Banach spaces that are not Asplund
spaces.

4.4 Subdiﬀerentials and Conjugate Functionals
73
Recall that for any normed vector space the closed unit ball of the dual
space is weak∗compact (Alaoglu theorem). It turns out that Asplund spaces
have an important additional property.
Theorem 4.3.21 If E is an Asplund space, then BE∗is weak∗sequentially
compact.
Concerning the proof we refer to Stegall [200] and Yost [219]. For a larger
class of Banach spaces having the above property see Diestel [52].
4.4 Subdiﬀerentials and Conjugate Functionals
Convention. The dual pair underlying the conjugation will be

E[∥· ∥], E∗[σ(E∗, E)]

unless we have to refer to the norm on E∗in which case we explicitly assume
that E is a reﬂexive Banach space (cf. Remark 1.6.4).
Recall that the deﬁnition of subdiﬀerential and conjugate functional of
f : E →R is given by
∂f(x) := {x∗∈E∗| ⟨x∗, y −x⟩≤f(y) −f(x) ∀y ∈E},
x ∈dom f,
f ∗(x∗) := supx∈E

⟨x∗, x⟩−f(x)

,
x∗∈E∗.
Proposition 4.4.1 Let f : E →R be proper and convex, let x ∈dom fand
x∗∈E∗. Then there holds
⟨x∗, x⟩≤f(x) + f ∗(x∗)
(Young inequality),
(4.13)
⟨x∗, x⟩= f(x) + f ∗(x∗)
⇐⇒
x∗∈∂f(x).
(4.14)
Proof. See Exercise 4.8.7.
⊓⊔
Remark 4.4.2 If f and x are as in Proposition 4.4.1, we have
f(x) = min
y∈E f(y)
⇐⇒
o ∈∂f(x)
⇐⇒
(4.14)
f(x) = −f ∗(o),
i.e., the global minimum of f is −f ∗(o).
If the functional f is G-diﬀerentiable on E, then we know that ∂f(·) =
{f ′(·)}. In this case, there is a close relationship between the Gâteaux deriv-
ative and the conjugate functional.

74
4 The Subdiﬀerential of Convex Functionals
Proposition 4.4.3 Let E be a reﬂexive Banach space, further let f : E →R
be G-diﬀerentiable with f ′ : E →E∗uniformly monotone. Then (f ′)−1 exists
on E∗and is continuous as well as strictly monotone. Moreover, the following
holds:

f ∗′ =

f ′−1,
(4.15)
f(x) = f(o) +
 1
0

f ′(τx), x
 
dτ
∀x ∈E,
(4.16)
f ∗(x∗) = f ∗(o) +
 1
0

x∗, (f ′)−1(τx∗)
 
dτ
∀x∗∈E∗,
(4.17)
f ∗(o) = −f

(f ′)−1(o)

.
(4.18)
Proof.
(I) We postpone the veriﬁcation of the existence of (f ′)−1 : E∗→E to
Sect. 5.4 (see Theorem 5.4.7 and Remark 5.4.8).
(II) Since f ′ is uniformly monotone, there exist constants c > 0 and γ > 1
such that
c ∥y −x∥γ ≤⟨f ′(y) −f ′(x), y −x⟩≤∥f ′(y) −f ′(x)∥∥y −x∥
∀x, y ∈E.
Setting x∗= f ′(x) and y∗= f ′(y), we have
c ∥(f ′)−1(y∗) −(f ′)−1(x∗)∥γ−1 ≤∥y∗−x∗∥
∀x∗, y∗∈E∗,

y∗−x∗, (f ′)−1(y∗) −(f ′)−1(x∗)
 
=

f ′(y) −f ′(x), y −x
 
> 0 ∀x ̸= y.
These two relations show that (f ′)−1 is continuous and strictly monotone.
(III) Now we verify (4.15)–(4.18). First notice that the integrals exist in the
Riemann sense since f ′ is radially continuous by Proposition 4.3.8 and
f ′−1 is continuous by step (II).
Ad (4.15). Let x, y ∈E, x∗:= f ′(x), y∗:= f ′(y). Since f is G-
diﬀerentiable, we have ∂f(x) = {x∗} and so Proposition 4.4.1 yields
f ∗(x∗) + f(x) = ⟨x∗, x⟩.
(4.19)
This and an analogous formula with y and y∗leads to
f ∗(y∗) −f ∗(x∗) = f(x) −f(y) −

f ′(y), x −y
 
+

f ′(y) −f ′(x), x
 
(4.20)
≥0 +

f ′(y) −f ′(x), x
 
=

y∗−x∗, (f ′)−1(x∗)
 
; (4.21)
here, the inequality sign follows from Theorem 4.1.3(a). Interchanging
x∗and y∗, we eventually obtain

y∗−x∗, (f ′)−1(x∗)
 
≤f ∗(y∗) −f ∗(x∗) ≤

y∗−x∗, (f ′)−1(y∗)
 
.

4.4 Subdiﬀerentials and Conjugate Functionals
75
This yields for each z∗∈E∗,

(f ∗)′(x∗), z∗ 
= lim
τ→0
1
τ

f ∗(x∗+ τz∗) −f ∗(x∗)

=

z∗, (f ′)−1(x∗)
 
E =

(f ′)−1(x∗), z∗ 
E∗;
here, we exploited the continuity of the function τ →

(f ′)−1(x∗+
τz∗), z∗ 
at τ = 0.
Ad (4.18). By (4.19), we have
f ∗
f ′(x)

+ f(x) =

f ′(x), x
 
∀x ∈E
which, with x := (f ′)−1(o), implies (4.18).
Ad (4.16). This is the mean value formula established in Proposition 3.3.3.
Ad (4.17). The monotonicity of (f ′)−1 and (4.15) entail that (f ∗)′ is
monotone. Therefore (4.17) holds in analogy to (4.16).
⊓⊔
The formulas (4.17) and (4.18) will turn out to be crucial for calculating
the conjugate in connection with boundary value problems.
Equation (4.15) means that for all x ∈E(= E∗∗) and all x∗∈E∗we have
x∗= f ′(x)
⇐⇒
x = (f ′)−1(x∗)
⇐⇒
x = (f ∗)′(x∗).
(4.22)
The simpler one of these equivalences, namely x∗= f ′(x) ⇐⇒x = (f ∗)′(x∗),
will now be generalized to nondiﬀerentiable convex functionals.
Proposition 4.4.4 Let f : E →R be proper and convex.
(i) There always holds
x ∈dom f, x∗∈∂f(x)
=⇒
x∗∈dom f ∗, x ∈∂f ∗(x∗).
(ii) If, in addition, E is reﬂexive and f is l.s.c., then
x ∈dom f, x∗∈∂f(x)
⇐⇒
x∗∈dom f ∗, x ∈∂f ∗(x∗).
Proof.
(i) If x ∈dom f and x∗∈∂f(x), then Proposition 4.4.1 gives f ∗(x∗) =
⟨x∗, x⟩−f(x). Hence x∗∈dom f ∗. For each y∗∈E∗, we obtain using
(4.13),
⟨y∗−x∗, x⟩≤

f(x) + f ∗(y∗)

−

f(x) + f ∗(x∗)

= f ∗(y∗) −f ∗(x∗)
and so x ∈∂f ∗(x∗).
(ii) ⇐=: By Proposition 2.2.3 and since x∗∈dom f ∗, we may apply (4.14)
with f ∗instead of f which gives ⟨x∗, x⟩= f ∗(x∗) + f ∗∗(x) and so x ∈
dom f ∗∗. By Theorem 2.2.4 we have f ∗∗= f. Hence applying (4.14) again,
we obtain x∗∈∂f(x).
⊓⊔

76
4 The Subdiﬀerential of Convex Functionals
4.5 Further Calculus Rules
In this section, we establish computation rules for the subdiﬀerential. The
following sum rule will be crucial for deriving optimality conditions (cf.
Remark 4.1.2).
Proposition 4.5.1 (Sum Rule) Let f0, f1, . . . , fn : E →R be proper and
convex. Assume there exists ¯x ∈(dom f0) ∩(int dom f1) ∩· · · ∩(int dom fn)
such that fi is continuous at ¯x for i = 1, . . . , n. Then for each x ∈(dom f0) ∩
(dom f1) ∩· · · ∩(dom fn), there holds
∂(f0 + f1 + · · · + fn)(x) = ∂f0(x) + ∂f1(x) + · · · + ∂fn(x).
Proof. It is easy to see that (even without the continuity assumption) the
inclusion ⊇holds. We now verify the inclusion ⊆for n = 1; for an arbitrary
n ∈N the assertion then follows by induction.
Let x∗∈∂(f0 + f1)(x) be given. Set p := f0 and deﬁne q : E →R by
q(y) :=

⟨x∗, x −y⟩+ f1(y) −f1(x) −f0(x)
if y ∈dom f1,
+∞
otherwise.
Then all assumptions of the sandwich theorem (Theorem 1.5.2) are fulﬁlled
and this theorem guarantees the existence of y∗
0 ∈E∗and c ∈R such that
−q(y) ≤⟨y∗
0, y⟩+ c ≤p(y)
∀y ∈E.
Since −q(x) = p(x), we have c = p(x) −⟨y∗
0, x⟩and so y∗
0 ∈∂f0(x). For
y∗
1 := x∗−y∗
0 we analogously obtain y∗
1 ∈∂f1(x). Therefore x∗= y∗
0 + y∗
1 ∈
∂f0(x) + ∂f1(x).
⊓⊔
Finally we characterize the subdiﬀerential of a functional of the form
f(x) := max
s∈S fs(x),
x ∈E.
(4.23)
We denote the directional G-derivative of fs at ¯x by fs,G(¯x, ·). We set
S(¯x) := {s ∈S | fs(¯x) = f(¯x)}.
Notice that if each fs is convex, then so is f. Recall that co ∗M denotes the
σ(E∗, E)-closed convex hull of M ⊆E∗.
Proposition 4.5.2 (Maximum Rule) Let S be a compact Hausdorﬀspace.
For any s ∈S, let fs : E →R be convex on E and continuous at ¯x ∈E.
Assume further that there exists a neighborhood U of ¯x such that for every
z ∈U, the functional s →fs(z) is upper semicontinuous on S. Then the
functional f : E →R deﬁned by (4.23) satisﬁes
fG(¯x, y) = sup
s∈S(¯x)
fs,G(¯x, y)
∀y ∈E,
(4.24)
∂f(¯x) = co ∗ 
s∈S(¯x)
∂fs(¯x)

.
(4.25)

4.5 Further Calculus Rules
77
Proof.
(I) We verify (4.24). Thus let y ∈E be given.
(Ia) If s ∈S(¯x), then
1
τ

fs(¯x + τy) −fs(¯x)

≤1
τ

f(¯x + τy) −f(¯x)

and so fs,G(¯x, y) ≤fG(¯x, y) for each s ∈S(¯x).
(Ib) In view of step (Ia), (4.24) is veriﬁed as soon as we showed that for each
ϵ > 0 there exists s ∈S(¯x) such that
fG(¯x, y) −ϵ ≤fs,G(¯x, y).
(4.26)
Since f is convex, we have fG(¯x, y) = infτ>0 1
τ

f(¯x + τy) −f(¯x)

and so
fG(¯x, y) −ϵ < 1
τ

f(¯x + τy) −f(¯x)

∀τ > 0.
Now let τ > 0 be ﬁxed. Then ϵτ := 1
τ

f(¯x + τy) −f(¯x)

−fG(¯x, y) + ϵ is
positive. By the deﬁnition of f, there exists s ∈S such that
1
τ f(¯x + τy) −ϵτ ≤1
τ fs(¯x + τy).
Therefore
fG(¯x, y) −ϵ ≤1
τ

fs(¯x + τy) −f(x)

.
(4.27)
In other words, the set Sτ of all s ∈S satisfying (4.27) is nonempty.
(Ic) Let τ0 > 0 be such that ¯x + τy ∈U for each τ ∈(0, τ0). Since s →
fs(¯x+τy) is upper semicontinuous, the set Sτ is closed for each τ ∈(0, τ0).
(Id) We show that 0 < σ < τ implies Sσ ⊆Sτ. Thus let s ∈Sσ be given.
Then
fG(¯x, y) −ϵ ≤1
σ

fs(¯x + σy) −f(¯x)

.
Since ¯x + σy =

1 −σ
τ

+ σ
τ

¯x + τy

and fs is convex, we obtain
fG(¯x, y) −ϵ ≤1
σ
&
1 −σ
τ

fs(¯x) + σ
τ fs(¯x + τy) −f(¯x)

≤1
τ
&
fs(¯x + τy) −f(¯x)

;
here, the second inequality follows from fs(¯x) ≤f(¯x). Therefore, s ∈Sτ.
(Ie) In view of the above, the Cantor intersection theorem shows that the
intersection of all Sτ, where τ ∈(0, τ0), is nonempty. If s is any element
of this intersection, then
τ

fG(¯x, y) −ϵ

≤fs(¯x + τy) −f(¯x)
∀τ ∈(0, τ0).
(4.28)
Recalling that fs is continuous at ¯x and letting τ ↓0, we deduce 0 ≤
fs(¯x) −f(¯x) and so s ∈S(¯x). Hence (4.28) holds with f(¯x) replaced by
fs(¯x) and from this we obtain (4.26) on dividing by τ and letting τ ↓0.

78
4 The Subdiﬀerential of Convex Functionals
(II) We verify (4.25).
(IIa) It is easy to see that ∂fs(¯x) ⊆∂f(¯x) for each s ∈S(¯x). Since ∂f(¯x) is
convex and σ(E∗, E)-closed, we conclude that
Q := co ∗ 
s∈S(¯x)
∂fs(¯x)

⊆∂f(¯x).
(IIb) Suppose there exists x∗∈∂f(¯x) \ Q. By the strong separation theorem
(Theorem 1.5.9) applied to E∗&
σ(E∗, E)

there exists z ∈E such that
⟨x∗, z⟩> sup
y∗∈Q
⟨y∗, z⟩.
(4.29)
We further have
fG(¯x, z) =
max
z∗∈∂f(¯x)⟨z∗, z⟩≥⟨x∗, z⟩,
sup
y∗∈Q
⟨y∗, z⟩≥sup
s∈S(¯x)
sup
z∗∈∂fs(¯x)
⟨z∗, z⟩= sup
s∈S(¯x)
fs,G(¯x, z).
In view of (4.29) we conclude that fG(¯x, z) > sups∈S(¯x) fs,G(¯x, z) which
contradicts (4.24). Therefore ∂f(¯x) = Q.
⊓⊔
Remark 4.5.3 If,inparticular,thesetS isﬁnite,thenitisacompactHausdorﬀ
space with respect to the discrete topology. For this topology, the function
s →fs(z) is continuous on S for any fs and every z ∈E.
4.6 The Subdiﬀerential of the Norm
With z ∈E ﬁxed we consider the functional ωz : E →R deﬁned by
ωz(x) := ∥x −z∥
∀x ∈E.
(4.30)
We simply write ω for ωo, i.e., we set
ω(x) := ∥x∥
∀x ∈E.
The results to be derived will reveal interesting properties of the norm func-
tional. In addition, they will later be applied to the problem of best approxi-
mation. Given A ⊆E and z ∈E \ A, ﬁnd ¯x ∈A satisfying
ωz(¯x) = inf
x∈A ωz(x).
For this purpose, we now deduce suitable representations of the subdiﬀer-
ential ∂ωz(¯x) and the directional H-derivative ωz,H(¯x, ·) of ωz. Notice that ωz
is continuous and convex. Deﬁne
S(x) := {x∗∈E∗ ∥x∗∥≤1, ⟨x∗, x⟩= ∥x∥}, x ∈E.

4.6 The Subdiﬀerential of the Norm
79
Remark 4.6.1 The Hahn–Banach theorem implies that S(x) ̸= ∅for each
x ∈E. Further, it is easy to see that
S(x) =

{x∗∈E∗ ∥x∗∥= 1, ⟨x∗, x⟩= ∥x∥}
if x ̸= o,
BE∗
if x = o.
Proposition 4.6.2 The functional ωz deﬁned by (4.30) satisﬁes
∂ωz(¯x) = S(¯x −z)
∀¯x ∈E,
(4.31)
ωz,H(¯x, y) = max{⟨x∗, y⟩
 x∗∈S(¯x −z) ∩ep S(o)}
∀¯x, y ∈E.
(4.32)
Proof. We only consider the case ¯x ̸= z which is important for the approxi-
mation problem; the veriﬁcation in the case ¯x = z is left as an exercise.
Ad (4.31):
(Ia) Let x∗∈∂ωz(¯x). Then we obtain
⟨x∗, x−¯x⟩≤∥x−z∥−∥¯x−z∥∀x ∈E, in particular ⟨x∗, z−¯x⟩≤−∥¯x−z∥.
Further we have
⟨x∗, ¯x −z⟩= ⟨x∗, 2¯x −z⟩−⟨x∗, ¯x⟩≤∥(2¯x −z) −z∥−∥¯x −z∥= ∥¯x −z∥.
It follows that ⟨x∗, ¯x −z⟩= ∥¯x −z∥.
(Ib) Now we show that ∥x∗∥= 1. Since
⟨x∗, x⟩= ⟨x∗, x + ¯x⟩−⟨x∗, ¯x⟩≤∥(x + ¯x) −z∥−∥¯x −z∥≤∥x∥
∀x ∈E,
we conclude that ∥x∗∥≤1. Recalling that ¯x ̸= z, we set x2 :=
¯x−z
∥¯x−z∥.
Then (Ia) implies ⟨x∗, x2⟩= 1. Further we have ∥x2∥= 1 and so ∥x∗∥= 1.
(II) If x∗∈S(¯x −z), then we immediately obtain
⟨x∗, x −¯x⟩= ⟨x∗, x −z⟩−⟨x∗, ¯x −z⟩≤∥x −z∥−∥¯x −z∥
and so x∗∈∂ωz(¯x).
Ad (4.32):
By Proposition 4.1.7 we have
ωz,H(¯x, y) = max{⟨x∗, y⟩
 x∗∈ep S(¯x −z)}
∀¯x, y ∈E.
We show that S(¯x −z) is an extremal subset of S(o); then Lemma 1.7.6
implies that ep S(¯x −z) = S(¯x −z) ∩ep S(o) and the assertion follows. Thus,
let x∗, y∗∈S(o), λ ∈(0, 1), and λx∗+ (1 −λ)y∗∈S(¯x −z). Then
⟨λx∗, ¯x −z⟩+ ⟨(1 −λ)y∗, ¯x −z⟩= ∥¯x −z∥.
Since ⟨x∗, ¯x −z⟩≤∥x∗∥· ∥¯x −z∥≤∥¯x −z∥and analogously for y∗, we
deduce that ⟨x∗, ¯x −z⟩= ∥¯x −z∥and analogously for y∗. Therefore we have
x∗, y∗∈S(¯x −z).
⊓⊔

80
4 The Subdiﬀerential of Convex Functionals
Remark 4.6.3 We indicate the relationship to the duality mapping of E,
which is the multifunction J : E ⇒E∗deﬁned by
J(x) := ∂j(x),
where j(x) := 1
2∥x∥2,
x ∈E.
Similarly to the proof of (4.31), it can be shown that J(x) = ∥x∥S(x) for any
x ∈E (see Exercise 4.8.8). This is also an immediate consequence of (4.31)
and a chain rule to be established below (Corollary 7.4.6).
Application: The Maximum Norm
Now we want to apply Proposition 4.6.2 to
E := C(T), with norm ∥x∥∞:= max
t∈T |x(t)|,
where T is a compact Hausdorﬀspace.
Recall that C(T) denotes the vector space of all continuous functions x :
T →R. Also recall that the dual space

C(T)
∗is norm isomorphic to, and
so can be identiﬁed with, the vector space M(T) of all ﬁnite regular signed
Borel measures µ on T, with norm ∥µ∥:= |µ|(T) := µ+(T) + µ−(T) (see, for
instance, Elstrodt [60]). Here, µ+ and µ−denote the positive and the negative
variation of µ, respectively. The isomorphism between x∗∈

C(T)
∗and the
associated µ ∈M(T) is given by
⟨x∗, x⟩=

T
x(t) dµ(t)
∀x ∈C(T).
The signed measure µ ∈M(T) is said to be concentrated on the Borel set
B ⊆T if |µ|(T \ B) = 0. Now let z ∈C(T) be ﬁxed. For ¯x ∈C(T), we set
T +(¯x) := {t ∈T
 ¯x(t) −z(t) = ∥¯x −z∥∞},
T −(¯x) := {t ∈T
 ¯x(t) −z(t) = −∥¯x −z∥∞},
T(¯x)
:= T +(¯x) ∪T −(¯x).
As announced, we consider the functional
ωz(x) := ∥x −z∥∞, x ∈C(T).
(4.33)
Proposition 4.6.4 The functional ωz deﬁned by (4.33) satisﬁes
∂ωz(¯x) =

µ ∈M(T)
 ∥µ∥= 1, µ+ resp. µ−is concentrated
on T +(¯x) resp. on T −(¯x)

∀¯x ∈C(T),
(4.34)
ωz,H(¯x, y) = max
t∈T (¯x)

sgn

¯x(t) −z(t)

y(t)

∀¯x, y ∈C(T).
(4.35)

4.6 The Subdiﬀerential of the Norm
81
Proof. Ad (4.34). In view of Proposition 4.6.2 it will do to show that S(¯x−z)
equals the right-hand side of (4.34).
(I) Let µ be an element of the latter. Then it follows that

T

¯x(t) −z(t)

dµ(t) =

T

· · ·

dµ+(t) −

T

· · ·

dµ−(t)
=

T +(¯x)

· · ·

dµ+(t) −

T −(¯x)

· · ·

dµ−(t)
= ∥¯x −z∥∞

µ+(T) + µ−(T)

= ∥¯x −z∥∞.
We also have ∥µ∥= 1. Therefore µ ∈S(¯x −z).
(II) Now let µ ∈S(¯x −z). Then ∥µ∥= 1 and
∥¯x −z∥∞=

T

¯x(t) −z(t)

dµ+(t) −

T

¯x(t) −z(t)

dµ−(t)
≤∥¯x −z∥∞

µ+(T) + µ−(T)

= ∥¯x −z∥∞,
which implies

T

¯x(t) −z(t)

dµ+(t) = ∥¯x −z∥∞µ+(T),
(4.36)

T

¯x(t) −z(t)

dµ−(t) = −∥¯x −z∥∞µ−(T).
Assume there exists a Borel set B ⊆T satisfying B ∩T +(¯x) = ∅and
µ+(B) > 0. Then it follows that

T

¯x(t) −z(t)

dµ+(t) =

T \T +(¯x)

· · ·

dµ+(t) +

T +(¯x)

· · ·

dµ+(t)
< ∥¯x −z∥∞
#
µ+
T \ T +(¯x)

+ µ+
T +(¯x)
$
;
(4.37)
here the sign < holds since µ+(T \T +(¯x)) ≥µ+(B) > 0. But the relations
(4.36) and (4.37) are contradictory. Hence µ+ is concentrated on T +(¯x).
The argument for µ−is analogous.
Ad (4.35). For t ∈T let ϵt denote the Dirac measure on T, i.e., for each Borel
set B ⊆T we have
ϵt(B) :=

1
if t ∈B,
0
if t ∈T \ B.
It is well known (see, for instance, K¨othe [115]) that
ep S(o) = {ϵt | t ∈T} ∪{−ϵt | t ∈T}.

82
4 The Subdiﬀerential of Convex Functionals
This together with (4.31) and (4.34) gives
S(¯x −z) ∩ep S(o) = {ϵt | t ∈T +(¯x)} ∪{−ϵt | t ∈T −(¯x)}.
Applying (4.32), we ﬁnally obtain
ωH(¯x, y) = max
t∈T (¯x)

T +(¯x)
y(s) dϵt(s), −

T −(¯x)
y(s) dϵt(s)
'
= max

{y(t) | t ∈T +(¯x)} ∪{−y(t) | t ∈T −(¯x)}

,
and the latter is equal to the right-hand side of (4.35).
⊓⊔
We now consider the special case E := C[a, b], where a < b. A function ¯x ∈
C[a, b] is called peaking function if there exists t∗∈[a, b] such that |¯x(t∗)| >
|¯x(t)| for each t ̸= t∗. In this case, t∗is called peak point of ¯x.
Proposition 4.6.5 Let ω be the maximum norm on C[a, b], where a < b, and
let ¯x ∈C[a, b]. Then:
(a) ω is H-diﬀerentiable at ¯x if and only if ¯x is a peaking function. If t∗is the
peak point of ¯x, then one has
⟨ω′(¯x), y⟩= sgn

¯x(t∗)

y(t∗)
∀y ∈C[a, b].
(4.38)
(b) ω is nowhere F-diﬀerentiable on C[a, b].
Proof. (a) We shall utilize the derivative of the function ξ →|ξ| at ξ ∈R\{0}:
lim
h→0
|ξ + h| −|ξ|
h
= sgn(ξ)
∀ξ ̸= 0.
(I) Let ω be H-diﬀerentiable at ¯x. Take t∗∈[a, b] with ω(¯x) = |¯x(t∗)|.
Now let y ∈C[a, b] and τ ̸= 0. Then
ω(¯x + τy) −ω(¯x) ≥|¯x(t∗) + τy(t∗)| −|¯x(t∗)|.
Dividing by τ, this implies, respectively,
⟨ω′(¯x), y⟩≥sgn(¯x(t∗)) y(t∗)
(letting τ ↓0),
⟨ω′(¯x), y⟩≤sgn(¯x(t∗)) y(t∗)
(letting τ ↑0).
Hence (4.38) holds. It remains to show that t∗is unique. Assume,
to the contrary, that with some t∗̸= t∗we also had ω(¯x) = |¯x(t∗)|.
According to what has already been shown, it follows that
⟨ω′(¯x), y⟩= sgn

¯x(t∗)

y(t∗)
∀y ∈C[a, b].
(4.39)

4.7 Diﬀerentiable Norms
83
Choose y ∈C[a, b] such that y(t∗) = 0 and y(t∗) = ¯x(t∗). Then (4.38)
and (4.39) are contradictory. Hence ¯x is a peaking function.
(II) Now let ¯x be a peaking function with peak point t∗. Then T(¯x) = {t∗}
and so (4.35) passes into
ωH(¯x, y) = sgn

¯x(t∗)

y(t∗).
Hence the functional ωH(¯x, ·) is linear and continuous and so is a
H-derivative, i.e., (4.38) holds.
(b) Assume, to the contrary, that ω is F-diﬀerentiable at some ¯x ∈C[a, b].
Then ω is also H-diﬀerentiable at ¯x (Proposition 3.4.2). According to (a),
¯x is a peaking function with a peak point t∗, and (4.38) holds true. Let
(tn) be a sequence in [a, b] such that tn ̸= t∗for each n and tn →t∗as
n →∞. Since t∗is a peak point of ¯x and so ¯x(t∗) ̸= 0, we may assume
that ¯x(tn) ̸= 0 for each n. Let ϕn : [a, b] →[0, 1] be a continuous function
satisfying ϕn(tn) = 1 and ϕn(t) = 0 for each t in a neighborhood of t∗
(depending on n). Further let
yn(t) := 2 sgn

¯x(tn)

|¯x(tn) −¯x(t∗)| ϕn(t)
∀t ∈[a, b].
Then
∥yn∥∞= |yn(tn)| = 2|¯x(tn) −¯x(t∗)|.
(4.40)
It follows that
∥¯x + yn∥∞≥|¯x(tn)+yn(tn)| = ∥¯x∥∞+ |¯x(tn) −¯x(t∗)| = ∥¯x∥∞+ 1
2∥yn∥∞
and so
ω(¯x + yn) −ω(¯x)
∥yn∥∞
≥1
2
∀n.
(4.41)
On the other hand, from (4.38) and yn(t∗) = 0 we obtain ⟨ω′(¯x), yn⟩= 0.
Since ω′(¯x) is assumed to be an F-derivative and ∥yn∥∞→0 as n →∞
(see (4.40)), we must have
lim
n→∞
ω(¯x + yn) −ω(¯x) −0
∥yn∥∞
= 0.
But this contradicts (4.41).
⊓⊔
4.7 Diﬀerentiable Norms
Let again E be a normed vector space and z ∈E. Notice that, except for
the trivial case E = {o}, the functional ωz : x →∥x −z∥, x ∈E, cannot be
G-diﬀerentiable at z since τ →|τ|, τ ∈R, is not diﬀerentiable at τ = 0. For
points diﬀerent from z, Proposition 4.1.8 and (4.31) immediately yield

84
4 The Subdiﬀerential of Convex Functionals
Proposition 4.7.1 For each ¯x ̸= z the following statements are equivalent:
(a) ωz is G-diﬀerentiable at ¯x.
(b) ωz is H-diﬀerentiable at ¯x.
(c) S(¯x −z) consists of exactly one element.
If one, and so each, of these statements holds true, then S(¯x −z) = {ω′
z(¯x)},
hence
∥ω′
z(¯x)∥= 1,
⟨ω′
z(¯x), ¯x −z⟩= ∥¯x −z∥.
(4.42)
Geometrical Interpretation
Let ¯x ∈E, ¯x ̸= o. By Corollary 1.5.5, the point ¯x is a support point of the
ball B(o, ∥¯x∥), i.e., it admits a supporting hyperplane.
Lemma 4.7.2 Let ¯x ∈E, ¯x ̸= o.
(i) If H is a supporting hyperplane of B(o, ∥¯x∥) at ¯x, then there exists x∗∈
E∗such that H = [x∗= ∥¯x∥].
(ii) If x∗∈E∗, x∗̸= o, then the following statements are equivalent:
(a) [x∗= ∥¯x∥] is a supporting hyperplane of B(o, ∥¯x∥) at ¯x.
(b) [x∗= 1] is a supporting hyperplane of B(o, 1) at
¯x
∥¯x∥.
(c) x∗∈S(¯x).
Proof. (i) Let H = [y∗= β], where y∗∈E∗, y∗̸= o, and β ∈R. We may
assume that ⟨y∗, y⟩≤β for each y ∈B(o, ∥¯x∥) (if ⟨y∗, y⟩≥β, we replace
y∗and β with −y∗and −β, respectively). If we had β ≤0, then ⟨y∗, y⟩≤0
for each y ∈E and so y∗= o, which is not the case. Therefore β > 0. Set
x∗:= ∥¯x∥
β y∗. Then we have
y ∈H
⇐⇒
⟨y∗, y⟩= β
⇐⇒
y ∈[x∗= ∥¯x∥].
(ii) We only verify (a) =⇒(c), the remaining implications are immediately
clear. So assume that (a) holds. Then ⟨x∗, ¯x⟩= ∥¯x∥and ⟨x∗, y⟩≤∥¯x∥for
each y ∈B(o, ∥¯x∥). (Choose y := o to see that we cannot have ⟨x∗, y⟩≥
∥¯x∥for each y ∈B(o, ∥¯x∥).) It follows that
∥¯x∥= sup{⟨x∗, y⟩| y ∈B(o, ∥¯x∥)} = ∥x∗∥∥¯x∥.
Here the second equation holds according to the deﬁnition of ∥x∗∥. We
thus obtain ∥x∗∥= 1. Hence x∗∈S(¯x).
⊓⊔
Roughly speaking, the lemma says that S(¯x) contains “as many” elements
as there are supporting hyperplanes of B(o, 1) at
¯x
∥¯x∥. This gives rise to Deﬁ-
nition 4.7.3.
Deﬁnition 4.7.3 The normed vector space E is said to be smooth if B(o, 1)
possesses exactly one supporting hyperplane at each boundary point (in other
words, if S(x) consists of exactly one element for each x ̸= o).

4.7 Diﬀerentiable Norms
85
o
o
¯x
¯x
Fig. 4.3
B(o, 1)
o
x
y
1
2(x + y)
≥δ(ϵ, x)
Fig. 4.4
Proposition 4.7.1 (with z = o) and Lemma 4.7.2 immediately yield:
Proposition 4.7.4 The following assertions are equivalent:
(a) ∥· ∥is G-diﬀerentiable at each nonzero point.
(b) ∥· ∥is H-diﬀerentiable at each nonzero point.
(c) E is smooth.
Example 4.7.5 Figure 4.3 shows B(o, 1) in R2 for the Euclidean norm and for
the maximum norm. The Euclidean norm is G-diﬀerentiable at each nonzero
point of R2 while the maximum norm is not G-diﬀerentiable at the corner
points of B(o, 1). The same holds true in Rn for n > 2.
We now reﬁne the investigation.
Deﬁnition 4.7.6 The normed vector space E is said to be locally uniformly
convex if the following holds (Fig. 4.4):
∀ϵ ∈(0, 2]
∀x ∈E, ∥x∥= 1
∃δ(ϵ, x) > 0
∀y ∈E :
∥y∥= 1, ∥x −y∥≥ϵ
=⇒
∥1
2(x + y)∥≤1 −δ(ϵ, x).
If δ(ϵ, x) can be chosen to be independent of x, then E is said to be uniformly
convex.
It is clear that with respect to the maximum norm, Rn for n ≥2 is not
locally uniformly convex. However, we have the following positive results.

86
4 The Subdiﬀerential of Convex Functionals
Example 4.7.7 If E is a Hilbert space, then E is uniformly convex with
respect to the norm generated by the inner product. In fact, the parallelogram
identity reads
 1
2(x + y)
2 = 1
2
x
2 +
y
2
−1
4
x −y
2.
Hence, given ϵ > 0, we obtain for all x, y ∈E satisfying ∥x −y∥≥ϵ,
 1
2 (x + y)
2 ≤1 −ϵ2
4 ≤

1 −ϵ2
8
2
,
i.e., we may choose δ(ϵ, x) := ϵ2
8 which is independent of x. In particular, Rn
is uniformly convex with respect to the Euclidean norm.
Example 4.7.8 For any measure space (X, A, µ) and each p ∈(1, +∞), the
Lebesgue space Lp(X, A, µ) is uniformly convex (Theorem of Clarkson). We
verify this for p ≥2; for 1 < p < 2 see, for instance, Cioranescu [32].
(I) We ﬁrst show that for arbitrary a, b ∈R and p ≥2 we have
|a + b|p + |a −b|p ≤2p−1(|a|p + |b|p).
(4.43)
Let α > 0, β > 0, and set c :=
!
α2 + β2. Then 0 < α
c < 1 and 0 < β
c < 1,
hence
α
c
p
+
β
c
p
≤
α
c
2
+
β
c
2
= 1,
and so αp + βp ≤cp = (α2 + β2)p/2. We deduce that
|a + b|p + |a −b|p ≤

|a + b|2 + |a −b|2p/2 = 2p/2
|a|2 + |b|2p/2. (4.44)
Since 2
p + p−2
p
= 1, the H¨older inequality (applied to p
2 and
p
p−2) yields
|a2·1|+|b2·1| ≤

a2p/2 +

b2p/22/p
·(1+1)
p−2
p
=

|a|p+|b|p2/p·2
p−2
p .
This together with (4.44) gives (4.43).
(II) Now we show that Lp(X, A, µ) is uniformly convex. For all f, g ∈
Lp(X, A, µ) the inequality (4.43) implies
 1
2(f + g)
p
p ≤1
2
f
p
p +
g
p
p

−1
2p
f −g
p
p.
Now we can argue as in Example 4.7.7.
Locally uniformly convex spaces have a nice convergence property. To de-
scribe it, we introduce the following concept. The norm ∥·∥of a Banach space
E is said to be a Kadec norm if xn
w
−→x and ∥xn∥→∥x∥as n →∞implies
xn →x as n →∞.

4.7 Diﬀerentiable Norms
87
Lemma 4.7.9 The norm of a locally uniformly convex Banach space is a
Kadec norm.
Proof. Let xn
w
−→x and ∥xn∥→∥x∥. The conclusion is obvious if x = o. So
let x ̸= o and set y :=
x
∥x∥, yn :=
xn
∥xn∥which makes sense for all n suﬃciently
large. It follows that yn + y
w
−→2y. Hence (yn + y) considered as a sequence
in E∗∗is bounded (Banach–Steinhaus theorem). More precisely, we have
2 = ∥2y∥≤lim inf
n→∞∥yn + y∥≤lim sup
n→∞∥yn + y∥≤lim
n→∞∥yn∥+ ∥y∥= 2
and so limn→∞∥yn +y∥= 2. Since E is locally uniformly convex, we conclude
that limn→∞∥yn −y∥= 0 and so (since ∥xn∥→∥x∥) we ﬁnally obtain
∥xn −x∥→0.
⊓⊔
Proposition 4.7.10 Let E be reﬂexive and E∗locally uniformly convex.
Then the norm functional ω is continuously diﬀerentiable on E \ {o}.
Proof. (I) Let x ∈E, x ̸= o. We show that S(x) contains exactly one
element. Assume that x∗
1, x∗
2 ∈S(x), i.e., ∥x∗
i ∥= 1 and ⟨x∗
i , x⟩= ∥x∥for
i = 1, 2. We then have
2 = ∥x∗
1∥2 + ∥x∗
2∥2 =
(
x∗
1 + x∗
2, x
∥x∥
)
≤∥x∗
1 + x∗
2∥· 1
and so ∥1
2(x∗
1 + x∗
2)∥≥1. Since E∗is locally uniformly convex, we
conclude that x∗
1 = x∗
2 (otherwise we could choose δ(ϵ, x) > 0 for ϵ :=
∥x∗
1 −x∗
2∥).
(II) By step (I) and Proposition 4.7.1 we know that ω is G-diﬀerentiable
at each nonzero point. Now we show that xn →x implies ω′(xn)
w
−→
ω′(x) as n →∞. Thus let xn →x. Since S(xn) = {ω′(xn)}, we have
∥ω′(xn)∥= 1 for each n. Since E is reﬂexive, some subsequence (ω′(xnj))
of (ω′(xn)) is weakly convergent to some y∗∈E∗as j →∞. For each
y ∈E we thus obtain
⟨y∗, y⟩= lim
j→∞

ω′(xnj), y
 
≤lim
j→∞∥ω′(xnj)∥· ∥y∥= ∥y∥
and so ∥y∗∥≤1. Moreover, we have
⟨y∗, x⟩= lim
j→∞

ω′(xnj), xnj
 
=
(4.42) lim
j→∞∥xnj∥= ∥x∥.
Therefore y∗∈S(x) and step (I) tells us that y∗= ω′(x). Since each
weakly convergent subsequence of (ω′(xn)) has the same limit ω′(x), we
conclude that
ω′(xn)
w
−→ω′(x).
(4.45)

88
4 The Subdiﬀerential of Convex Functionals
(III) Now let xn →x. We then have
∥ω′(xn)∥= ∥xn∥→∥x∥= ∥ω′(x)∥.
This together with (4.45) gives ω′(xn) →ω′(x) by Lemma 4.7.9.
⊓⊔
Example 4.7.11 The space Lp := Lp(X, A, µ), where 1 < p < +∞, is reﬂex-
ive and the dual space can be identiﬁed with Lq, where 1
p + 1
q = 1. Moreover,
by Example 4.7.8, Lq is uniformly convex. Proposition 4.7.10 therefore im-
plies that the norm ω := ∥· ∥p is continuously diﬀerentiable away from zero.
Explicitly we have
ω′(x) = sgn(x)
∥x∥p−1
p
|x|p−1
∀x ∈Lp \ {o}.
This is easily veriﬁed by showing that the right-hand side is an element of
S(x).
Example 4.7.5 showed that the diﬀerentiability properties of the norm may
change by passing to an equivalent norm. In this connection, the following deep
result is of great importance; concerning its proof we refer to Cioranescu [32],
Deville et al. [50], or Diestel [51].
Theorem 4.7.12 (Renorming Theorem) If E
is a
reﬂexive Banach
space, then there exists an equivalent norm on E such that E and E∗are both
locally uniformly convex.
Deﬁnition 4.7.13 The Banach space E is said to be Fréchet smooth if it
admits an equivalent norm that is F-diﬀerentiable on E \ {o}.
Recall that by Corollary 4.3.4 the norm functional is F-diﬀerentiable if and
only if it is continuously diﬀerentiable. Hence Theorem 4.7.12 together with
Proposition 4.7.10 leads to:
Proposition 4.7.14 If E is a reﬂexive Banach space, then there exists an
equivalent norm on E that is continuously diﬀerentiable on E \ {o}, and the
same holds true for the associated norm on E∗. In particular, every reﬂexive
Banach space is Fréchet smooth.
For later use we present the following result; for a proof we refer to Deville
et al. [50] and Phelps [165].
Proposition 4.7.15 Every Fréchet smooth Banach space is an Asplund
space.

4.8 Bibliographical Notes and Exercises
89
4.8 Bibliographical Notes and Exercises
The theory of the subdiﬀerential and the conjugate of convex functionals
as well as its various applications originated in the work of Moreau and
Rockafellar in the early 1960s (see Moreau [148] and Rockafellar [177]). The
now classic text on the subject in ﬁnite-dimensional spaces is Rockafellar [180].
Concerning ﬁnite-dimensional spaces, see also Bazaraa et al. [11], Borwein
and Lewis [18], Elster et al. [59], Hiriart-Urruty and Lemaréchal [88,89], and
Rockafellar and Wets [189] (comprehensive monograph).
In the inﬁnite-dimensional case, we recommend Aubin [6] (application to
mathematical economics), Barbu and Precupanu [9] (application to control
problems), Ekeland and Temam [58] (application to variational problems
involving partial diﬀerential equations), Ioﬀe and Tikhomirov [101] (ap-
plication to the calculus of variations and control problems), Pallaschke
and Rolewicz [156] (abstract approach with many concrete applications),
Pshenichnyi [170] (application to control problems), Schirotzek [196] (ap-
plication to the calculus of variations), and Zeidler [221] (comprehensive
monograph with many applications). For applications of the conjugation to
density functionals in quantum physics see Eschrig [62].
The results on Asplund spaces in Sect. 4.3 are mainly taken from
Phelps [165]. Theorem 4.3.18 is essentially due to Preiss and Zajíček [167],
our presentation follows Phelps [165]. Theorem 4.3.19 was established by
Asplund [3]. The famous renorming result of Theorem 4.7.12 is due to
Kadec [108] and Troyanski [208]. Concerning diﬀerentiability properties of
convex functionals, especially of the norm functional, see also Beauzamy [13],
Cioranescu [32], Deville et al. [50], Diestel [51], Sundaresan [205], and Ya-
mamuro [216]. For applications to approximation theory see Braess [27],
Krabs [112], and Laurent [118].
Exercise 4.8.1 Let Φ : E ⇒F be a multifunction between Banach spaces E
and F. Verify the following:
(a) Φ is upper semicontinuous if and only if for any open set V ⊆F the set
{x ∈E | Φ(x) ⊆V } is open.
(b) Φ is lower semicontinuous if and only if for any open set V ⊆F the set
{x ∈E | Φ(x) ∩V ̸= ∅} is open.
Exercise 4.8.2 Let f : E →R be proper and convex, and continuous on the
nonempty set int domf. Show that f is G-diﬀerentiable at ¯x ∈int domf if
and only if there exists a selection ϕ : E →E∗of ∂f which is norm-to-weak*
continuous at ¯x (cf. Proposition 4.3.3).
Exercise 4.8.3 Prove Proposition 4.3.5.

90
4 The Subdiﬀerential of Convex Functionals
Exercise 4.8.4 Verify Proposition 4.3.7.
Exercise 4.8.5 Verify the necessity part of Lemma 4.3.11.
Exercise 4.8.6 Prove Lemma 4.3.17.
Exercise 4.8.7 Prove Proposition 4.4.1.
Exercise 4.8.8 Show that the duality mapping J : E ⇒E∗satisﬁes J(x) =
∥x∥S(x) for any x ∈E (cf. Remark 4.6.3).
Exercise 4.8.9 Let E be a Banach space and assume that the duality map-
ping J : E ⇒E∗is linear, i.e., x∗∈J(x), y∗∈J(y), and λ ∈R imply
x∗+ y∗∈J(x + y) and λx∗∈J(λx). Show the following:
(a) E is a Hilbert space.
(b) J is single-valued and satisﬁes ⟨J(x), y⟩= (y | x) for all x, y ∈E, i.e., J is
the norm isomorphism of E onto E∗according to the Riesz representation
theorem.
Exercise 4.8.10 Let L be a linear subspace of the normed vector space E,
let f : E →R be proper and convex, and let ¯x ∈L∩dom f. Denote by ∂Lf(¯x)
the subdiﬀerential of f|L (the restriction of f to L) at ¯x. Verify the following
assertions (cf. Singer [199]):
(a) For any x∗∈ep(∂Lf(¯x)) there exists y∗∈ep(∂f(¯x)) such that y∗|L = x∗.
(b) If dim L = n, then for any x∗∈ep(∂Lf(¯x)) there exist y∗
1, . . . , y∗
n+1 ∈
ep(∂f(¯x)) and λ1, . . . , λn+1 ≥0 such that
n+1
	
i=1
λi = 1
and
n+1
	
i=1
λi y∗
i (x) = x∗(x)
∀x ∈L.
Hint: By a Theorem of Carathéodory, any point of a compact convex
subset C of Rn is the convex combination of at most n+1 extreme points
of C.

5
Optimality Conditions for Convex Problems
5.1 Basic Optimality Conditions
We consider the following basic convex optimization problem:
(P1) Minimize f(x) subject to x ∈M,
which we also formally write f(x) −→min, x ∈M. We assume that
f : E →R is a proper convex functional,
M is a nonempty convex subset of dom f.
Theorem 4.1.3 shows that under this assumption, fG(¯x, ·) exists as an R-valued
functional.
The point ¯x ∈M is called a global minimizer of f on M, or brieﬂy a global
solution of (P1), if f(¯x) ≤f(x) for any x ∈M. Moreover, ¯x ∈M is called a
local minimizer of f on M, or brieﬂy a local solution of (P1), if there exists a
neighborhood U of ¯x in E such that f(¯x) ≤f(x) for any x ∈M ∩U.
Proposition 5.1.1 The following statements are equivalent:
(a) ¯x is a global solution of (P1).
(b) ¯x is a local solution of (P1).
(c) fG(¯x, x −¯x) ≥0 for all x ∈M.
Proof. (a) =⇒(b) is clear.
(b) =⇒(c): If (b) holds, then for some neighborhood U of ¯x, we have f(y) −
f(¯x) ≥0 for each y ∈M ∩U. Now let x ∈M. Since M is convex, we see that
y := ¯x + τ(x −¯x) = τx + (1 −τ)¯x ∈M
∀τ ∈(0, 1).
Further, if τ ∈(0, 1) is suﬃciently small, we also have y ∈U and so
1
τ

f

¯x + τ(x −¯x)

−f(¯x)

≥0.

92
5 Optimality Conditions for Convex Problems
Letting τ ↓0, the assertion follows.
(c) =⇒(a): Theorem 4.1.3 shows that fG(¯x, x −¯x) ≤f(x) −f(¯x) for any
x ∈M. Hence (c) implies (a).
⊓⊔
Condition (c) is called variational inequality (as x varies over M). Some-
times a variational inequality passes into a variational equation.
Corollary 5.1.2 Assume that ¯x ∈int M and f : M →R is G-diﬀerentiable
at ¯x. Then the following conditions are equivalent:
(a) f(¯x) = minx∈M f(x)
(minimum problem).
(b)

f ′(¯x), y
 
= 0
∀y ∈E (variational equation).
(c) f ′(¯x) = o
(operator equation).
Proof. By Proposition 5.1.1, (a) is equivalent to
⟨f ′(¯x), x −¯x⟩≥0
∀x ∈M.
(5.1)
Since the implications (b) =⇒(5.1) and (b) ⇐⇒(c) are obvious, it remains
to show that (5.1) implies (b). Thus let y ∈E be given. Since ¯x is an interior
point of M, we have x := ¯x + τy ∈M whenever τ ∈R is such that |τ| is
suﬃciently small. Hence for these τ we deduce from (5.1) that τ

f ′(¯x), y
 
≥0.
Therefore (b) holds.
⊓⊔
5.2 Optimality Under Functional Constraints
We consider the following convex optimization problem:
(P2) Minimize f(x)
subject to gi(x) ≤0 (i = 1, . . . , m), x ∈A,
which of course means
minimize f(x) on M := {x ∈E | gi(x) ≤0 (i = 1, . . . , m), x ∈A}.
In this connection, the assumptions are:
(A) f, g1, . . . , gm : E →R are proper convex functionals,
A is a nonempty convex subset of D := dom f ∩dom g1 ∩· · · ∩dom gm.
Our aim is to characterize points ¯x ∈M that minimize f under the func-
tional constraints gi(x) ≤0 (i = 1, . . . , m) and the residual constraint x ∈A.
We therefore consider the statement
(Min 2) ¯x ∈M is a global solution of (P2).
We deﬁne functionals *L : D × Rm+1
+
→R and L : D × Rm
+ →R by

5.2 Optimality Under Functional Constraints
93
*L(x; λ, µ1, . . . , µm) := λf(x) +
m
	
i=1
µigi(x),
L(x; µ1, . . . , µm)
:= f(x) +
m
	
i=1
µigi(x).
The functionals *L and L are called Lagrange functionals associated with (P2).
Furthermore, the point (¯x, ¯µ) ∈A × Rm
+, where ¯µ := (¯µ1, . . . , ¯µm), is called
saddle point of L with respect to A × Rm
+ if
L(¯x, µ) ≤L(¯x, ¯µ) ≤L(x, ¯µ)
∀(x, µ) ∈A × Rm
+.
We consider the following statements:
(*L) ∃(¯λ, ¯µ1, . . . , ¯µm) ∈Rm+1
+
\ {o} :
*L(¯x; ¯λ, ¯µ1, . . . , ¯µm) = min
x∈A
*L(x; ¯λ, ¯µ1, . . . , ¯µm),
¯µi gi(¯x) = 0
(i = 1, . . . , m).
(L) ∃(¯µ1, . . . , ¯µm) ∈Rm
+ :
L(¯x; ¯µ1, . . . , ¯µm) = min
x∈A L(x; ¯µ1, . . . , ¯µm),
¯µi gi(¯x) = 0
(i = 1, . . . , m).
(SP) ∃¯µ ∈Rm
+ : (¯x, ¯µ) is a saddle point of L with respect to A × Rm
+.
Finally we consider the Slater condition
∃x0 ∈A : gi(x0) < 0 for i = 1, . . . , m.
(5.2)
Theorem 5.2.1 (Global Kuhn–Tucker Theorem) Let the assumptions
(A) be satisﬁed.
(a) There always holds
(SP)
⇐⇒
(L)
=⇒
(Min 2)
=⇒
(*L).
(b) If the Slater condition (5.2) is satisﬁed, then there holds
(SP)
⇐⇒
(L)
⇐⇒
(Min 2)
⇐⇒
(*L).
Proof. (a) (SP) ⇐⇒(L) =⇒(Min 2): Exercise 5.6.1.
(Min 2) =⇒(*L): Deﬁne
K :=

−

f(x) −f(¯x), g1(x), . . . , gm(x)
  x ∈A

.

94
5 Optimality Conditions for Convex Problems
Since the functions f, g1, . . . , gm are convex, K is a convex subset of Rm+1.
Furthermore, (Min 2) implies K ∩int Rm+1
+
= ∅. By Corollary 1.5.4, there
exists ¯µ := (¯λ, ¯µ1, . . . , ¯µm) ∈Rm+1 satisfying
¯µ ̸= o,
(¯µ| y) ≤0 ∀y ∈K,
(¯µ| z) ≥0 ∀z ∈Rm+1
+
.
The assertion now follows immediately.
(b) It suﬃces to show that (*L) implies (L). Assume that (*L) holds with ¯λ = 0.
Then we have (¯µ1, . . . , ¯µm) ̸= o and so, by (5.2), ¯µi gi(x0) < 0 for at
least one i ∈{1, . . . , m}. On the other hand, the minimum property of (*L)
entails
0 =
m
	
i=1
¯µi gi(¯x) ≤
m
	
i=1
¯µi gi(x)
∀x ∈A,
which is contradictory. Hence ¯λ ̸= 0 and we may (replacing ¯µi by ¯µi / ¯λ if
necessary) assume that ¯λ = 1. Therefore, (L) holds.
⊓⊔
Remark 5.2.2 (a) Roughly speaking, Theorem 5.2.1 states that the mini-
mization of f under functional and residual side conditions can be replaced
by the minimization of the Lagrange functional L or *L under the residual
side condition x ∈A alone, the functional side conditions being integrated
into the Lagrange functional.
(b) If ¯λ = 0, then the functional f to be minimized does not appear in the
optimality conditions. In this case, the conditions are not well suited for
detecting possible minimizers. A condition ensuring that ¯λ ̸= 0, and so
(*L) ⇐⇒(L), is called regularity condition. Theorem 5.2.1(b) shows that
the Slater condition is a regularity condition. A more thorough study of
regularity conditions shows that these are generally conditions on the con-
straint functionals (as is the Slater condition). Therefore regularity condi-
tions are also called constraint qualiﬁcations.
We now establish local optimality conditions for (Min 2) by using subdif-
ferentials. Consider the following statements.
(J) ∃(¯λ, ¯µ1, . . . , ¯µm) ∈Rm+1
+
\ {o} :
o ∈¯λ∂f(¯x) + ¯µ1∂g1(¯x) + · · · + ¯µm∂gm(¯x) + ∂δA(¯x),
¯µi gi(¯x) = 0
(i = 1, . . . , m).
(KKT)
∃(¯µ1, . . . , ¯µm) ∈Rm
+ :
o ∈∂f(¯x) + ¯µ1∂g1(¯x) + · · · + ¯µm∂gm(¯x) + ∂δA(¯x),
¯µi gi(¯x) = 0
(i = 1, . . . , m).
The conditions (J) and (KKT) are the
(Fritz) John conditions and the
Karush–Kuhn–Tucker conditions, respectively.

5.2 Optimality Under Functional Constraints
95
Theorem 5.2.3 (Local John–Karush–Kuhn–Tucker Theorem) In
addition to the assumptions (A), let the functionals f, g1, . . . , gm be con-
tinuous at some point of A ∩int D.
(a) There always holds (KKT) =⇒(Min 2) =⇒(J).
(b) If the Slater condition (5.2) is satisﬁed, then there holds (KKT) ⇐⇒
(Min 2) ⇐⇒(J).
Proof. See Exercise 5.6.2.
Remark 5.2.4 (a) Since −∂δA(¯x) = {x∗∈E∗| ⟨x∗, ¯x⟩= min
x∈A⟨x∗, x⟩}, the
John condition (J) is equivalent to
∃(¯λ, ¯µ1, . . . , ¯µm) ∈Rm+1
+
\ {o}
∃x∗∈∂f(¯x)
∃y∗
i ∈∂gi(¯x) (i = 1, . . . , m) :

¯λ x∗+ ¯µ1 y∗
1 + · · · + ¯µm y∗
m

(¯x) = min
x∈A

¯λ x∗+ ¯µ1 y∗
1 + · · · + ¯µm y∗
m

(x),
¯µi gi(¯x) = 0 (i = 1, . . . , m).
(b) If f is continuous at a point of A ∩int dom f, then
f(¯x) = min
x∈A f(x)
⇐⇒
∃x∗∈∂f(¯x) : ⟨x∗, ¯x⟩= min
x∈A⟨x∗, x⟩.
This follows from Theorem 5.2.3(b) by choosing m = 1, g1(x) := −1 if
x ∈D, g1(x) := +∞if x ∈E \ D.
(c) If f is continuous at a point of A ∩int dom f and G-diﬀerentiable at ¯x,
then
f(¯x) = min
x∈A f(x)
⇐⇒

f ′(¯x), x −¯x
 
≥0 ∀x ∈A.
If, in addition, ¯x ∈int A (in particular, if A = E), then
f(¯x) = min
x∈A f(x)
⇐⇒

f ′(¯x), y
 
= 0 ∀y ∈E
⇐⇒
f ′(¯x) = o.
This follows from (b) above noting that now ∂f(¯x) = {f ′(¯x)} by Proposi-
tion 4.1.8.
Remark 5.2.4(b) and Proposition 5.1.1 give the following result.
Proposition 5.2.5 Let f : E →R be a continuous convex functional, let A be
a nonempty convex subset of E, and let ¯x ∈A. Then the following statements
are equivalent:
(a) f(¯x) = minx∈A f(x).
(b) ∃x∗∈∂f(¯x) : ⟨x∗, ¯x⟩= minx∈A⟨x∗, x⟩.
(c) ∀x ∈A : fG(¯x, x −¯x) ≥0.

96
5 Optimality Conditions for Convex Problems
5.3 Application to Approximation Theory
Let A be a nonempty subset of E and z ∈E. Recall that an element ¯x ∈A
is said to be a best approximation of z with respect to A, or a projection of z
onto A, if
∥¯x −z∥= min
x∈A ∥x −z∥.
We write projA(z) for the set (possibly empty) of all projections of z onto A,
i.e., we put
projA(z) := {¯x ∈A | ∥¯x −z∥= dA(z)},
where dA denotes the distance function. This deﬁnes the multifunction projA :
E ⇒E, called the projector associated with the set A. It is clear that z ∈A
implies projA(z) = {z}. We now assume that
A ⊆E is nonempty and convex, and z ∈E \ A.
Our aim is to characterize projA(z). This can be done by applying the pre-
ceding results to the functional
f(x) := ∥x −z∥,
x ∈E.
(5.3)
Best Approximation in a Hilbert Space
Proposition 5.3.1 Let E be a Hilbert space with inner product (x | y). Then
one has
¯x ∈projA(z)
⇐⇒
(z −¯x | x −¯x) ≤0
∀x ∈A.
Proof. See Exercise 5.6.3.
⊓⊔
Remark 5.3.2 Recall that, by the Cauchy–Schwarz inequality, the formula
cos αx := (z −¯x | x −¯x)
∥z −¯x∥∥x −¯x∥
deﬁnes an angle αx for any x ∈A, x ̸= ¯x. Proposition 5.3.1 thus says that
¯x is a projection of z onto A if and only if αx is obtuse (see Fig. 5.1, where
E = R2).
If A is a linear subspace of E, then
A⊥:= {y ∈E | (y|˜x) = 0
∀˜x ∈A}
denotes the orthogonal complement of A. As an immediate consequence of
Proposition 5.3.1 we have:
Corollary 5.3.3 Let E be a Hilbert space and A a linear subspace of E. Then
¯x ∈projA(z) if and only if z −¯x ∈A⊥(see Fig. 5.2, where E = R3).

5.3 Application to Approximation Theory
97
A
z
¯x
x
αx
Fig. 5.1
z
x
¯x
A
Fig. 5.2
Best Approximation in a Normed Vector Space
We want to characterize best approximations in an arbitrary normed vector
space. From Propositions 4.6.2 and 5.2.5 we immediately obtain:
Proposition 5.3.4 (Characterization of Best Approximations) If
E
is a normed vector space, the following statements are equivalent:
(a) ¯x ∈projA(z).
(b) ∃x∗∈S(¯x −z) : ⟨x∗, ¯x⟩= min
x∈A⟨x∗, x⟩.
(c) ∀x ∈A : max{⟨y∗, x −¯x⟩
 y∗∈S(¯x −z) ∩ep S(o)} ≥0.
Best Approximation in C(T )
Now we apply the above results to
E := C(T), with norm ∥x∥∞:= max
t∈T |x(t)|,
where T is a compact Hausdorﬀspace. We consider the functional
ωz(x) := ∥x −z∥∞, x ∈C(T).
(5.4)
Concerning the terminology, we refer to Sect. 4.6.
Combining Propositions 4.6.4 and 5.3.4(a)⇔(c), we obtain the follow-
ing characterization of best approximations in C(T). Notice that in the
Kolmogorov condition the signum operation can now be omitted.

98
5 Optimality Conditions for Convex Problems
Proposition 5.3.5 Let A be a nonempty convex subset of C(T), let z ∈
C(T) \ A, and let ¯x ∈A. Then the following statements are equivalent:
(a) ¯x ∈projA(z).
(b) ∀x ∈A : maxt∈T (¯x)

¯x(t) −z(t)

x(t) −¯x(t)

≥0
(Kolmogorov condi-
tion).
We leave it to the reader to formulate the corresponding characterization
following from Proposition 5.2.5(a)⇔(b).
As a special case, we now choose T = [a, b]. Recall that each (positive)
Borel measure ν on [a, b] is regular and can be represented by a nondecreasing
right continuous function ψ : [a, b] →R such that

[a,b]
x(t) dν(t) =

[a,b]
x(t) dψ(t)
∀x ∈C[a, b],
the integral on the right-hand side being a Riemann–Stieltjes integral. In this
connection, we have
ψ(x) = ν

(a, x]

∀x ∈(a, b],
ψ(a) = 0.
Moreover, for each Borel set B ⊆[a, b] we have
ν(B) = inf
 ∞
	
i=1

ψ(bi) −ψ(ai)
  B ⊂
∞

i=1
(ai, bi]
'
.
(5.5)
It follows that the Borel measure ν is concentrated on the Borel set B ⊆[a, b]
if and only if the associated function ψ is constant except for jumps at the
points t ∈B.
Let µ ∈M[a, b] be given. Applying what has just been said about ν to
µ+ and µ−, we obtain nondecreasing right continuous functions ϕ+ and ϕ−
on [a, b]. Then the function ϕ := ϕ+ −ϕ−is right continuous and of bounded
variation on [a, b], and we have

[a,b]
x(t) dµ(t) =

[a,b]
x(t) dϕ(t)
∀x ∈C[a, b].
Recall that T(¯x) := {t ∈T | |¯x(t) −z(t)| = ∥¯x −z∥∞}. Now we can establish
the following:
Proposition 5.3.6 (Classical Chebyshev Approximation) Let
A
de-
note the set of (the restrictions to [a, b] of) all polynomials of degree at most
n, where n ∈N. Further let z ∈C[a, b] \ A. If ¯x ∈A is a best approximation
of z with respect to A, then the set T(¯x) contains at least n + 2 points.
Proof. According to Propositions 4.6.4 and 5.2.5, and by what has been said
above, there exists a right continuous function ϕ of bounded variation on [a, b]
that is constant except for jumps on T(¯x) (Fig. 5.3) and satisﬁes

5.4 Existence of Minimum Points and the Ritz Method
99
∥¯x −z∥∞
−∥¯x −z∥∞
a
t1
t2
t
ϕ
¯x −z
b
Fig. 5.3

[a,b]
x(t) dϕ(t) = 0
∀x ∈A.
(5.6)
The latter result follows from the fact that ⟨x∗, ¯x⟩= minx∈A⟨x∗, x⟩is
equivalent to ⟨x∗, ¯x⟩= 0 since in the present case A is a linear subspace of
C[a, b]. Now suppose that T(¯x) contains only m elements t1, . . . , tm, where
m < n + 2. We may assume that a < t1 < t2 < · · · < tm ≤b. For k ∈
{1, . . . , m} deﬁne
x(t) :=
m
+
i=1
i̸=k
(t −ti), t ∈[a, b].
Then x is (the restriction to [a, b] of) a polynomial of degree m −1 and so
belongs to A. In view of (5.6), we obtain
0 =

[a,b]
x(t) dϕ(t) =
m
	
i=1
x(ti)

ϕ(ti) −ϕ(ti −0)

= x(tk)

ϕ(tk) −ϕ(tk −0)

.
As x(tk) ̸= 0, it follows that ϕ is continuous at tk, which is a contradiction.
⊓⊔
5.4 Existence of Minimum Points and the Ritz Method
In this section and in Sect. 5.5 we digress from the main road of these lectures,
brieﬂy discussing the existence of minimizers of
f : M →R,
where M is a nonempty subset of a normed vector space E. We start with a
deﬁnition.
Deﬁnition 5.4.1 A sequence (xn) in M is said to be a minimizing sequence
for f if limn→∞f(xn) = infx∈M f(x).

100
5 Optimality Conditions for Convex Problems
It is clear that a minimizing sequence for f always exists but it need not be
convergent. If it happens to be convergent, the limit may fail to be a minimizer
of f. The starting point for existence results is a generalization of a well-known
Weierstrass theorem.
Proposition 5.4.2 Let M ⊆E be (weakly) sequentially compact and f :
M →R (weakly) sequentially lower semicontinuous. Then:
(a) There exists ¯x ∈M satisfying f(¯x) = minx∈M f(x).
(b) Every minimizing sequence for f contains a subsequence that (weakly) con-
verges to a minimizer of f on M.
Proof. Let (xn) be a minimizing sequence for f. Since M is (weakly) sequen-
tially compact, some subsequence (xnj) of (xn) is (weakly) convergent to some
¯x ∈M. Since f is (weakly) sequentially l.s.c., it follows that
f(¯x) ≤lim inf
j→∞f(xnj) = lim
n→∞f(xn) = inf
x∈M f(x).
⊓⊔
Concerning the assumptions of Proposition 5.4.2, observe that sequential
compactness of M is too restrictive for most applications. In general, even
weak sequential compactness is not appropriate. We tackle this problem in
the following way:
1. We assume that E is a reﬂexive Banach space. Then by the Eberlein–
Šmulian Theorem (Theorem 1.6.7), each bounded, sequentially closed sub-
set M is weakly sequentially compact.
2. In order to get rid of boundedness which is still too restrictive, we replace
this hypothesis on M by an hypothesis on f to be deﬁned now.
Deﬁnition 5.4.3 The functional f
:
M
→
R is said to be coercive
if for any sequence (xn) in M satisfying limn→∞∥xn∥= +∞one has
lim supn→∞f(xn) = +∞.
We consider the following assumptions:
(A1) E is a reﬂexive Banach space,
M is a nonempty, weakly sequentially closed subset of E,
f : M →R is weakly sequentially l.s.c.,
either M is bounded or f is coercive.
Theorem 5.4.4 Under the assumptions (A1), the following holds:
(a) There exists ¯x ∈M such that f(¯x) = minx∈M f(x).
(b) Each minimizing sequence for f contains a subsequence that weakly con-
verges to a minimizer of f on M.
Proof. (I) As discussed above, if M is bounded, the assertion is a consequence
of Proposition 5.4.2 and the Eberlein–Šmulian Theorem.

5.4 Existence of Minimum Points and the Ritz Method
101
(II) Assume now that M is unbounded and f is coercive. Choose some x0 ∈M
and set M0 := {x ∈M | f(x) ≤f(x0)}. Notice that
inf
x∈M f(x) = inf
x∈M0 f(x).
(5.7)
Since M is weakly sequentially closed and f is weakly sequentially l.s.c. on
M, the set M0 is weakly sequentially closed. Moreover, since f is coercive,
M0 is bounded. By Proposition 5.4.2(a), f has a minimizer on M0 which
by (5.7) is also a minimizer of f on M. This proves (a). Concerning (b),
notice that each minimizing sequence for f in M is eventually in M0 so
that Proposition 5.4.2(b) applies with M replaced by M0.
⊓⊔
The example f(x) = ex, x ∈R, shows that a minimizer may fail to exist
if M is unbounded and f is not coercive.
Corollary 5.4.5 Let E be a ﬁnite-dimensional Banach space and M a non-
empty closed subset of E. Then projM(z) is nonempty for any z ∈E.
Proof. This follows immediately by applying Theorem 5.4.4 to f(x) := ∥x−z∥,
x ∈E.
⊓⊔
Now we pass from (A1) to assumptions that are easier to verify:
(A2) E is a reﬂexive Banach space,
M is a nonempty, convex, and closed subset of E,
f : D →R (where D ⊆E is open and contains M) is strictly convex
and G-diﬀerentiable on M,
either M is bounded or f is coercive on M.
Theorem 5.4.6 Under the assumptions (A2), the functional f has precisely
one minimizer ¯x on M, and each minimizing sequence for f on M is weakly
convergent to ¯x.
Proof. (I) First we show that the strict convexity of f entails that f has at
most one minimizer on M. Suppose, to the contrary, that x1 and x2 are
minimizers of f on M with x1 ̸= x2 and f(x1) = f(x2) =: a. Then
f
 1
2x1 + 1
2x2

< 1
2f(x1) + 1
2f(x2) = a,
which is a contradiction.
(II) By Corollary 1.6.6, M is weakly sequentially closed. By Propositions 1.7.3
and 4.1.9, f is weakly sequentially l.s.c. Hence the assumptions (A1) are
satisﬁed so that Theorem 5.4.4 applies. By statement (b) of that theorem,
all weakly convergent subsequences of a minimizing sequence (xn) for f
have the same limit ¯x; hence the entire sequence (xn) is weakly convergent
to ¯x.
⊓⊔

102
5 Optimality Conditions for Convex Problems
With a given b∗∈E∗, we now consider the following statements:
f(¯x) −⟨b∗, ¯x⟩= min
x∈E

f(x) −⟨b∗, x⟩

(minimum problem),
(5.8)
⟨f ′(¯x) −b∗, y⟩= 0
∀y ∈E
(variational equation),
(5.9)
f ′(¯x) = b∗
(operator equation).
(5.10)
We specify the assumptions:
(A3) E is a reﬂexive Banach space, f : E →R is G-diﬀerentiable,
f ′ is uniformly monotone (with constants c > 0 and γ > 1).
Theorem 5.4.7 If (A3) is satisﬁed, then for each b∗∈E∗the following
holds:
(a) The problems (5.8)–(5.10) are mutually equivalent and have precisely one
solution ¯x ∈E.
(b) Each minimizing sequence (xn) for f −b∗is convergent to ¯x, and one has
the error estimate
c
γ ∥xn −¯x∥γ ≤(f −b∗)(xn) −(f −b∗)(¯x).
(5.11)
Proof. (a) Set g := f −b∗. Then g is G-diﬀerentiable with g′(x) = f ′(x) −b∗
for any x ∈E and so g′ is also uniformly monotone with constants c and γ.
(I) The equivalence of (5.8) and (5.9) follows from Corollary 5.1.2. The
equivalence of (5.9) and (5.10) is obvious.
(II) Existence and uniqueness. By Proposition 4.3.9, g is strictly convex
and
g(y) −g(x) ≥⟨g′(x), y −x⟩+ c
γ ∥y −x∥γ
∀x, y ∈E.
(5.12)
We deduce that
g(y) −g(o) ≥∥y∥

−∥g′(x)∥+ c
γ ∥y∥γ−1
.
The term in parentheses is positive if ∥y∥is large enough, hence g is
coercive. By Theorem 5.4.6, g has precisely one minimizer ¯x ∈E.
(b) We have g′(¯x) = o. If (xn) is any minimizing sequence for g, then (5.12)
with x := ¯x gives
c
γ ∥xn −¯x∥γ ≤g(xn) −g(¯x) →0
as n →∞.
⊓⊔
Remark 5.4.8 Theorem 5.4.7, in particular, shows that under the assump-
tions (A3) the G-derivative f ′ is a bijective mapping of E onto E∗. This
observation closes the gap in the proof of Proposition 4.4.3.

5.4 Existence of Minimum Points and the Ritz Method
103
The Ritz Method
We now describe a method for constructing a minimizing sequence and so for
approximately calculating a minimizer. The basic idea is to replace the original
problem, which is placed in an inﬁnite-dimensional space, by a sequence of
ﬁnite-dimensional problems.
Suppose that E is an inﬁnite-dimensional normed vector space. A count-
able subset {zk | k ∈N} of E is called basis of E if ﬁnitely many zk are always
linearly independent and one has
E = cl

n∈N
En,
where
En := span{z1, . . . , zn}.
Using transﬁnite induction, it is easy to prove:
Lemma 5.4.9 If E is separable, then E possesses a basis.
The Ritz method consists in replacing, for each n ∈N, the problems (5.8)
and (5.9) by the following n-dimensional problems:
f(¯xn) −⟨b∗, ¯xn⟩= min
xn∈En

f(xn) −⟨b∗, xn⟩

(Ritz minimum problem),
(5.8a)
⟨f ′(¯xn) −b∗, zk⟩= 0
∀k = 1, . . . , n
(Ritz equations).
(5.9a)
For a given basis {zk | k ∈N} of E, each ¯xn ∈En is representable as
¯xn = n
j=1 ξjzj, where ξj ∈R. Hence, (5.9a) is a system of n equations (in
general nonlinear) for (ξ1, . . . , ξn) ∈Rn and so can be solved by numerical
methods. This yields a numerical approximation of ¯xn. We shall not pursue
the numerical aspect. Rather we assume that the exact ¯xn is known and ask
how it is related to a solution ¯x of the original problems (5.8) and (5.9).
We shall give a convergence proof for the special case that f is a quadratic
functional of the form
f(x) := 1
2 a(x, x),
x ∈E.
(5.13)
In this connection, we make the following assumptions:
(A4) E is an inﬁnite-dimensional separable reﬂexive Banach space with basis
{zk | k ∈N}, a : E × E →R is bilinear, symmetric, bounded, and
strongly positive, b∗∈E∗.
Recall that a is said to be bounded if with some constant κ > 0,
|a(x, y)| ≤κ ∥x∥∥y∥
∀x, y ∈E,
(5.14)

104
5 Optimality Conditions for Convex Problems
and a is said to be strongly positive if with some constant c > 0,
a(x, x) ≥c ∥x∥2
∀x ∈E.
(5.15)
If (A4) holds, then by Example 4.3.6 the functional f deﬁned by (5.13) is
continuously diﬀerentiable, the derivative is given by ⟨f ′(x), y⟩= a(x, y) for
all x, y ∈E, and f ′ is strongly monotone with constant c. The problems (5.8)
and (5.9) now pass, respectively, into
1
2 a(¯x, ¯x) −⟨b∗, ¯x⟩= min
x∈E
 1
2 a(x, x) −⟨b∗, x⟩

,
(5.16)
a(¯x, y) −⟨b∗, y⟩= 0
∀y ∈E.
(5.17)
The associated Ritz problems are
1
2 a(¯xn, ¯xn) −⟨b∗, ¯xn⟩= min
xn∈En
 1
2 a(xn, xn) −⟨b∗, xn⟩

,
(5.16a)
a(¯xn, zk) −⟨b∗, zk⟩= 0
∀k = 1, . . . , n.
(5.17a)
Notice that the minimum problems (5.16) and (5.16a) are quadratic, the
variational equations (5.17) and (5.17a) are linear.
Theorem 5.4.10 If (A4) holds, then:
(a) The problems (5.16) and (5.17) are equivalent and possess precisely one
solution ¯x ∈E.
(b) For each n ∈N, (5.16a) and (5.17a) are equivalent and possess precisely
one solution ¯xn ∈En.
(c) The sequence (¯xn) is minimizing for f −b∗, converges to ¯x as n →∞, and
satisﬁes
∥¯xn −¯x∥≤κ
c d(¯x, En)
∀n ∈N.
Here, f, κ, and c are as in (5.13), (5.14), and (5.15), respectively.
Proof. (I) Example 4.3.6 shows that, with f according to (5.13), the
assumptions (A3) are satisﬁed. Therefore assertion (a) is a consequence
of Theorem 5.4.7. Analogously, applying Theorem 5.4.7 with E replaced
by En yields (b).
(II) Convergence. From (5.17) with y = yn and (5.17a) we see that
a(¯x −¯xn, yn) = 0
∀yn ∈En
(5.18)
and, in particular, a(¯x −¯xn, ¯xn) = 0. This and (5.18) yield
a(¯x −¯xn, ¯x −¯xn) = a(¯x −¯xn, ¯x −yn)
∀yn ∈En.
Since a is strongly positive and bounded, we deduce
c ∥¯x −¯xn∥2 ≤κ ∥¯x −¯xn∥∥¯x −yn∥
∀yn ∈En

5.5 Application to Boundary Value Problems
105
and so
∥¯x −¯xn∥≤κ
c
inf
yn∈En ∥¯x −yn∥= κ
c d(¯x, En).
Since En ⊆En+1 for all n and 
n En is dense in E, we have d(¯x, En) →0
as n →∞. Hence ¯xn →¯x as n →∞. This also shows that the sequence
(¯xn) is minimizing for f −b∗as the latter functional is continuous.
⊓⊔
5.5 Application to Boundary Value Problems
Our aim in this section is to apply Theorems 5.4.7 and 5.4.10 to a boundary
value problem. We start by introducing some notation. Let G be a bounded
region in RN, with boundary ∂G and closure G = G∪∂G. Recall that a region
is a nonempty open connected set. We set
Ck(G) := set of all continuous functions u : G →R with continuous
partial derivatives up to and including order k on G such that
the partial derivatives can be continuously extended to G.
C∞
c (G) := set of all continuous functions u : G →R having continuous
partial derivatives of arbitrary order on G and vanishing
outside a compact subset of G (that depends on u).
In particular, C(G) := C0(G) denotes the set of all continuous functions
on G. We write x = (x1, . . . , xN) for the independent variable ranging over G
and we denote by Di diﬀerentiation with respect to the ith coordinate, where
i = 1, . . . , N. Let p ∈(1, +∞) be ﬁxed. We consider the Lebesgue space Lp(G)
with norm
∥u∥p :=

G
|u|p dx
1/p
and the Sobolev spaces
W1,p(G) :=

u ∈Lp(G)
 Diu exists in Lp(G) for i = 1, . . . , N

,
W1,p
0 (G) := closure of C∞
c (G) in W1,p(G).
In this connection, Diu now denotes the generalized derivative of u with
respect to the ith coordinate. By deﬁnition, Diu is an element of Lp(G) that
satisﬁes the integration-by-parts formula

G

Diu

v dx = −

G
u

Div

dx
∀v ∈C∞
c (G).
(5.19)
The norm in W1,p(G) is given by
∥u∥1,p :=


G

|u|p +
N
	
i=1
|Diu|p
dx
1/p
.

106
5 Optimality Conditions for Convex Problems
On W1,p
0 (G), the following norm ∥· ∥1,p,0 is equivalent to ∥· ∥1,p :
∥u∥1,p,0 :=


G
N
	
i=1
|Diu|p dx
1/p
.
W1,p(G) and W1,p
0 (G) are separable reﬂexive Banach spaces. In particular,
W1,2(G) and W1,2
0 (G) are Hilbert spaces with respect to the inner product
(u | v)1,2 :=

G

uv +
N
	
i=1
Diu Div

dx.
We start with the following classical boundary value problem. Given g ∈
C(G), ﬁnd u ∈C2(G) satisfying
−
N
	
i=1
Di

|Diu|p−2Diu

= g on G,
u = 0 on ∂G.
(5.20)
For p = 2 this is the famous Dirichlet problem or the ﬁrst boundary value
problem for the Poisson equation. Observe that for p > 2 the problem is
nonlinear. Since the problem may fail to have a solution unless the function
g and the boundary ∂G are suﬃciently smooth, we pass to a generalized
problem. This is obtained heuristically by multiplying the diﬀerential equation
in (5.20) by v ∈C∞
c (G) and applying the integration-by-parts formula (5.19):

G
N
	
i=1
|Diu|p−2Diu Div dx =

G
gv dx
∀v ∈C∞
c (G).
(5.21)
Conversely, if u ∈C2(G) satisﬁes (5.21) and u = 0 on ∂G, then u is also a
solution of (5.20).
The generalized boundary value problem associated with (5.20) now reads
as follows. Given g ∈Lq(G), where 1
p + 1
q = 1, ﬁnd u ∈W1,p
0 (G) such that

G
N
	
i=1
|Diu|p−2Diu Div dx =

G
gv dx
∀v ∈W1,p
0 (G).
(5.22)
In this connection, recall that C∞
c (G) is dense in W1,p
0 (G) and that the
elements of W1,p
0 (G) have vanishing generalized boundary values. In view of
the above discussion, it is reasonable to say that a solution of (5.22) is a
generalized solution of (5.20).
Parallel to (5.22) we also consider the variational problem

5.5 Application to Boundary Value Problems
107

G

1
p
N
	
i=1
|Diu|p −gu

dx −→min,
u ∈W1,p
0 (G).
(5.23)
The following result ensures, in particular, that under weak assumptions
problem (5.20) has a generalized solution.
Proposition 5.5.1 Let G be a bounded region in RN and let p ∈[2, +∞).
Then for any g ∈Lq(G), where 1
p + 1
q = 1, the problems (5.22) and (5.23) are
equivalent and have precisely one solution u ∈W1,p
0 (G).
Before verifying this result, we establish two inequalities.
Lemma 5.5.2 Let N ∈N, p ≥2, and r > 0 be given.
(a) There exists c1 > 0 (depending on N and r) such that

 N
	
i=1
|xi|
r
≤c1
N
	
i=1
|xi|r
∀(x1, . . . , xN) ∈RN.
(5.24)
(b) There exists c2 > 0 (depending on p) such that
(|α|p−2α −|β|p−2β)(α −β) ≥c2|α −β|p
∀α, β ∈R.
(5.25)
Proof. (a) First let r ≥1. Then ∥x∥r :=
N
i=1 |xi|r1/r deﬁnes a norm on
RN. Since all norms on RN are equivalent, there exists c1 > 0 such that
∥x∥1 ≤c1/r
1
∥x∥r for each x ∈RN. This proves (5.24) if r ≥1. If 0 < r < 1,
then argue similarly with ∥· ∥s, where s := 1/r.
(b) First assume that 0 ≤β ≤α. Then
αp−1−βp−1 = (p−1)
 α−β
0
(t+β)p−2 dt ≥(p−1)
 α−β
0
tp−2 dt=(α−β)p−1,
which implies (5.25) in this case. Now let β ≤0 ≤α. Then (5.24) shows
that αp−1+|β|p−1 ≥c(α+|β|)p−1 and again (5.25) follows. The remaining
cases can be reduced to the two considered.
⊓⊔
Proof of Proposition 5.5.1. Our aim is to show that Theorem 5.4.7 applies to
E := W1,p
0 (G),
f(u) :=

G
1
p
N
	
i=1
|Diu|p dx,
b∗(u) :=

G
gu dx,
u ∈E.
(I) First observe that the Sobolev space E is a reﬂexive Banach space.
(II) It is clear that the integral deﬁning f(u) exists for any u ∈E.

108
5 Optimality Conditions for Convex Problems
(III) We show that f is G-diﬀerentiable on E. Recall that
fG(u, v) = ∂
∂τ f(u + τv)

τ=0.
We show that partial diﬀerentiation by τ and integration over G can be
exchanged. For ﬁxed u, v ∈E, consider the function
γ(x, τ) := 1
p
N
	
i=1
|Diu + τDiv|p,
x ∈G,
τ ∈(−1, 1).
Notice that
∂
∂τ γ(x, τ) = 1
p
N
	
i=1
|Diu + τDiv|p−2(Diu + τDiv) · Div
and so
 ∂
∂τ γ(x, τ)
 ≤1
p
N
	
i=1
|Diu + τDiv|p−1 · |Div|
≤
(5.24)
c
N
	
i=1

|Diu|p−1 + |Div|p−1
· |Div|.
(5.26)
Under the last sum sign, the ﬁrst factor is in Lq(G) (notice that (p−1)q =
p) and the second factor is in Lp(G). Hence the H¨older inequality shows
that the right-hand side of (5.26) is integrable over G and so is the
left-hand side. Therefore, measure theory tells us that we may write
fG(u, v) =

G
∂
∂τ γ(x, τ)

τ=0dx =

G
N
	
i=1
|Diu|p−2Diu · Div dx.
(5.27)
The function v →fG(u, v) is linear, and the following estimate using
the H¨older inequality shows that it is also continuous
|fG(u, v)| ≤
N
	
i=1

G
|Diu|(p−1)qdx
1/q
·

G
|Div|pdx
1/p
≤c ∥v∥E;
here, c is independent of v. Hence f is G-diﬀerentiable on E, the G-
derivative being given by (5.27).
(IV) We show that f ′ is uniformly monotone. Let u, *u ∈E be given. Then

f ′(u) −f ′(*u), u −*u
 
=

G
N
	
i=1

|Diu|p−2Diu −|Di*u|p−2Di*u
 
Diu −Di*u

dx
≥c

G
N
	
i=1
|Diu −Di*u|p dx = c ∥u −*u∥p
1,p,0 ≥˜c ∥u −*u∥p
1,p.

5.5 Application to Boundary Value Problems
109
In this connection, the ﬁrst inequality holds by Lemma 5.5.2(b) and the
second follows from the equivalence of the two norms on E.
(V) In view of the above, the generalized boundary value problem (5.22) is
equivalent to the variational equation ⟨f ′(u) −b∗, v⟩= 0 for all v ∈E.
Hence the assertion is a consequence of Theorem 5.4.7.
⊓⊔
In the special case p = 2 we now apply the Ritz method to the problems
(5.22) and (5.23). In other words, setting
E := W1,2
0 (G),
a(u, v) :=

G
N
	
i=1
Diu Div dx,
⟨b∗, v⟩:=

G
gv dx,
(5.28)
we consider the problems (cf. (5.16) and (5.17))
1
2 a(¯u, ¯u) −⟨b∗, ¯u⟩= min
u∈E
 1
2 a(u, u) −⟨b∗, u⟩

,
(5.29)
a(¯u, v) −⟨b∗, v⟩= 0
∀v ∈E,
(5.30)
as well as the associated Ritz problems corresponding to a basis {zk | k ∈N}
of E (cf. (5.16a) and (5.17a)),
1
2 a(¯un, ¯un) −⟨b∗, ¯un⟩= min
un∈En
 1
2 a(un, un) −⟨b∗, un⟩

,
(5.29a)
a(¯un, zk) −⟨b∗, zk⟩= 0
∀k = 1, . . . , n.
(5.30a)
For all u, v ∈E we have the following estimates:
|a(u, v)| ≤
N
	
i=1

G
|Diu Div| dx ≤
N
	
i=1
∥Diu∥2 · ∥Div∥2 ≤N∥u∥1,2 · ∥v∥1,2,
|⟨b∗, v⟩| ≤∥g∥2 · ∥v∥2 ≤∥g∥2 · ∥v∥1,2,
a(u, u) = ∥u∥2
1,2,0 ≥c ∥u∥2
1,2.
In the ﬁrst two lines, we applied the H¨older (or Cauchy–Schwarz) inequality.
The inequality in the third line is the Poincaré–Friedrichs inequality (which
leads to the equivalence of the norms ∥· ∥1,2,0 and ∥· ∥1,2 on E). The above
estimates show that the assumptions (A4) of Sect. 5.4 are satisﬁed. As a con-
sequence of Theorem 5.4.10 we therefore obtain:
Proposition 5.5.3 With the notation of (5.28), the following holds:
(a) The problems (5.29) and (5.30) are equivalent and possess precisely one
solution ¯u ∈E.
(b) For each n ∈N, (5.29a) and (5.30a) are equivalent and possess precisely
one solution ¯un ∈En.
(c) The sequence (¯un) satisﬁes
∥¯un −¯u∥1,2 ≤N
c d(¯u, En)
∀n ∈N.
In particular, (¯un) converges to ¯u as n →∞.

110
5 Optimality Conditions for Convex Problems
5.6 Bibliographical Notes and Exercises
Concerning the subject of this chapter, we refer to the Bibliographical Notes
at the end of Chap. 4. The optimality conditions for convex optimization prob-
lems are due to John [105], and Kuhn and Tucker [114], with Karush [109] as
an early (rather late perceived) predecessor.
The presentation in Sect. 5.5 was strongly inﬂuenced by Zeidler [221]. More
results on the approximation problem in function spaces oﬀer, among others,
Braess [27], Holmes [91], Krabs [112], and Laurent [118].
A result analogous to Theorem 5.4.10 holds under the more general as-
sumptions (A3) (if, in addition, E is inﬁnite dimensional and separable); see,
for instance, Zeidler [221] or Schirotzek [196]. The theory of monotone oper-
ators provides an important generalization concerning both the solvability of
variational equations (or inequalities) and the convergence of an approxima-
tion method, the Galerkin method. For this and many substantial applications
we recommend the comprehensive monograph by Zeidler [223,224]. Concern-
ing the numerical analysis of the Ritz and Galerkin methods we refer to
Atkinson and Han [4], and Großmann and Roos [81].
Standard references on the theory of Sobolev spaces are Adams [1] and
Ziemer [228].
Exercise 5.6.1 Prove the implications (SP) ⇐⇒(L) =⇒(Min 2) of Theo-
rem 5.2.1(a).
Exercise 5.6.2 Verify Theorem 5.2.3.
Hint: To see that (Min 2) implies (J), consider the functional p : E →R
deﬁned by
p(x) :=
*L(x; ¯λ, ¯µ1, . . . , ¯µm) + δA(x)
if x ∈D,
+∞
if x ∈E \ D
Exercise 5.6.3 Prove Proposition 5.3.1.
Exercise 5.6.4 UsingProposition5.2.5(a)⇔(b),formulateandverifyacharac-
terization of best approximation in C(T), where T is a compact Hausdorﬀspace.
Exercise 5.6.5 Let E be a Hilbert space and T : E →E be a continuous
linear self-adjoint operator. Deﬁne f(x) :=
1
2(Tx | x) for all x ∈E. Show
that any local maximizer or minimizer ¯x of f over {x ∈E | ∥x∥= 1} is an
eigenvector of T with associated eigenvalue λ = 2f(¯x).
Exercise 5.6.6 Let A be a convex subset of an n-dimensional subspace of E
and let f : E →R be continuous at ¯x ∈A. Show that ¯x minimizes f over
A if and only if for any i = 1, . . . , n + 1 there exist x∗
i ∈∂f(¯x) and λi ≥0
satisfying
n+1
	
i=1
λi = 1
and
n+1
	
i=1
λi⟨x∗
i , ¯x⟩= min
x∈A
n+1
	
i=1
λi⟨x∗
i , x⟩.
Hint: Recall Exercise 4.8.10.

6
Duality of Convex Problems
The idea of duality in convex optimization theory is, roughly speaking, the
following. With a given optimization problem, called primal problem in this
context, one associates another problem, called dual problem, in such a way
that there is a close relationship between the two problems. The motivation
is that the dual problem may be easier to solve than the primal one (which is
sometimes really the case) or that at least the dual problem furnishes addi-
tional information about the primal one.
6.1 Duality in Terms of a Lagrange Function
Assume that
A ⊆E is a nonempty convex set,
f, g1, . . . , gm : A →R are convex functionals,
M := {x ∈A | gi(x) ≤0 (i = 1, . . . , m)}, ¯x ∈M.
We continue studying the minimization of f on M (cf. Sect. 5.2). We set
α := inf
x∈M f(x).
(6.1)
Further we deﬁne the Lagrange functional L : A × Rm
+ →R by
L(x, q) := f(x) +
m
	
i=1
qi gi(x)
∀x ∈A ∀q = (q1, . . . , qm) ∈Rm
+.
(6.2)
We then have
sup
q∈Rm
+
L(x, q) =

f(x)
if x ∈M,
+∞
if x ∈A \ M

112
6 Duality of Convex Problems
and so we obtain
α = inf
x∈A
sup
q∈Rm
+
L(x, q).
(6.3)
Parallel to (6.3) we now consider
β := sup
q∈Rm
+
inf
x∈A
L(x, q).
(6.4)
The original minimization problem, which is described by (6.1) and so by
(6.3), is called primal problem. The associated problem described by (6.4) is
called dual problem. We say that ¯x ∈A is a solution of the primal problem
(6.3) if ¯x ∈M and f(¯x) = α, thus if
sup
q∈Rm
+
L(¯x, q) = inf
x∈A
sup
q∈Rm
+
L(x, q).
Analogously, ¯q ∈Rm
+ is said to be a solution of the dual problem (6.4) if
inf
x∈A L(x, ¯q) = sup
q∈Rm
+
inf
x∈A
L(x, q).
Theorem 6.1.1 establishes relationships between the two problems. In this
connection, we again need the Slater condition (cf. (5.2))
∃x0 ∈A : gi(x0) < 0 for i = 1, . . . , m.
(6.5)
Theorem 6.1.1 (Lagrange Duality) Assume that the space E is reﬂexive,
the subset A is nonempty, closed, and convex, and the functionals f, g1, . . . , gm
are l.s.c. and convex. Assume further that the Slater condition (6.5) is satis-
ﬁed. Then:
(i)
One has α = β, and the dual problem (6.4) has a solution ¯q ∈Rm
+.
(ii) For ¯x ∈M, the following statements are equivalent:
(a) ¯x is a solution of the primal problem (6.3).
(b) The Lagrange function L has a saddle point (¯x, ¯q) with respect to
A × Rm
+.
(iii) If (b) holds, then ¯q is a solution of the dual problem (6.4), and one has
¯qi gi(¯x) = 0 for i = 1, . . . , m.
Theorem 6.1.1 will follow from Theorem 6.1.3 below.
Remark 6.1.2
(a) Comparing Theorem 6.1.1 with Theorem 5.2.1, we see that the “dual vari-
able” q is nothing else than the Lagrange multiplier vector, i.e., we have
qi = µi for i = 1, . . . , m.
(b) If the Slater condition is not satisﬁed, a duality gap may occur which
means that we have α > β. A trivial example is E = R, A = [−1, +∞),
f(x) = −x, g(x) = 1, where we have α = +∞and β = −∞. An example

6.1 Duality in Terms of a Lagrange Function
113
with ﬁnite and diﬀerent optimal values will be given below in a somewhat
diﬀerent context (Example 6.1.7).
Now we replace the Lagrange functional L of (6.2) by an arbitrary func-
tional L : A × B →R and consider
α := inf
x∈A
sup
q∈B
L(x, q)
(primal problem),
(6.6)
β := sup
q∈B
inf
x∈A
L(x, q)
(dual problem).
(6.7)
Theorem 6.1.3 (General Duality Theorem) Assume that E, F are ref-
lexive Banach spaces, that A ⊆E and B ⊆F are nonempty, closed, and
convex, and that L : A × B →R satisﬁes
x →L(x, q) is l.s.c. and convex on A for each q ∈B,
q →−L(x, q) is l.s.c. and convex on B for each x ∈A.
Then:
(i)
One has α ≥β (weak duality).
(ii) For (¯x, ¯q) ∈A × B, the following statements are equivalent:
(a) ¯x is a solution of (6.6), ¯q is a solution of (6.7), and one has α = β
(strong duality).
(b) (¯x, ¯q) is a saddle point of L with respect to A × B.
(iii) Assume, in addition, that either A is bounded or L(x, q0) →+∞as
∥x∥→+∞, x ∈A, for some q0 ∈B. Assume further that α < +∞.
Then the primal problem (6.6) has a solution ¯x ∈A and one has α = β.
(iv) Assume, in addition, that either B is bounded or −L(x0, q) →+∞as
∥q∥→+∞, q ∈B, for some x0 ∈A. Assume further that β > −∞.
Then the dual problem (6.7) has a solution ¯q ∈B and one has α = β.
Remarks on the Proof of Theorem 6.1.3. The proof consists of two main
steps. First, the result is veriﬁed under the additional assumption that A and
B are bounded. In this case, Neumann’s minimax theorem can be applied,
which in turn is proved with the aid of Brouwer’s ﬁxed point theorem. Sec-
ond, the general case is reduced to the ﬁrst one. If, say, A is unbounded, then
replace A by An := {x ∈A | ∥x∥≤n} and L by Ln(x, q) := L(x, q) + 1
n∥x∥2.
The proof can be found, e.g., in Zeidler [221].
⊓⊔
Proof of Theorem 6.1.1. Set F := Rm, B := Rm
+, and notice that the Slater
condition (6.5) implies
L(x0, q) = f(x0)+
m
	
i=1
qi gi(x0) →−∞as ∥q∥→+∞, q ∈Rm
+.
⊓⊔
In view of Theorem 6.1.3, we can set up a general dualization principle.

114
6 Duality of Convex Problems
General Dualization Principle
Given the minimum problem f(x) →min, x ∈M, ﬁnd sets A, B and a func-
tion L : A × B →R such that
inf
x∈M f(x) = inf
x∈A
sup
q∈B
L(x, q)
and consider the following dual problem:
sup
q∈B
inf
x∈A
L(x, q).
Special Case
Here, we apply the dualization principle to problems of the form
α := inf
x∈E

f(x) + h(Tx −a)

.
(6.8)
Below we shall see that the problem of linear optimization is of this form.
In connection with problem (6.8) we make the following assumptions:
(A) E and F are reﬂexive Banach spaces,
f : E →R and h : F →R are proper, convex, and l.s.c.,
T : E →F is linear and continuous, a ∈F.
We set
A := dom f, B := dom h∗,
L(x, q) := f(x) + ⟨q, Tx −a⟩−h∗(q)
∀x ∈A ∀q ∈B.
(6.9)
It will turn out that
α = inf
x∈A
sup
q∈B
L(x, q).
(6.10)
By the general dualization principle, the dual to (6.10) and so to (6.8) is
β := sup
q∈B
inf
x∈A
L(x, q).
(6.11)
This will be shown to coincide with
β = sup
q∈B

−f ∗(−T ∗q) −h∗(q) −⟨q, a⟩

.
(6.12)
Notice that h∗denotes the conjugate of the functional h while T ∗denotes the
adjoint of the operator T.
Proposition 6.1.4 Under the assumptions (A), the problem dual to (6.8) is
(6.12). Hence all statements of Theorem 6.1.3 hold for (6.8) and (6.12).

6.1 Duality in Terms of a Lagrange Function
115
Proof.
(I) By Theorem 2.2.4, we have h = h∗∗and so
h(Tx −a) = h∗∗(Tx −a) = sup
q∈F ∗

⟨q, Tx −a⟩−h∗(q)

,
which entails
α = inf
x∈E
sup
q∈F ∗

f(x) + ⟨q, Tx −a⟩−h∗(q)

= inf
x∈A
sup
q∈B

. . .

,
and the latter term equals (6.10).
(II) We obtain
inf
x∈A L(x, q) = −sup
x∈A

−⟨T ∗q, x⟩−f(x) + h∗(q) + ⟨q, a⟩

= −f ∗(−T ∗q) −h∗(q) −⟨q, a⟩,
which shows that (6.11) coincides with (6.12).
⊓⊔
Example 6.1.5 We now apply Proposition 6.1.4 to the problem of linear
optimization which is
α := inf{⟨c, x⟩| x ∈PE, Tx −a ∈PF }.
(6.13)
We make the following assumptions:
(˜A) E and F are reﬂexive Banach spaces,
PE and PF are closed convex cones in E and F, respectively,
T : E →F is linear and continuous, c ∈E∗, a ∈F.
Setting
f(x) :=

⟨c, x⟩
if x ∈PE,
+∞
otherwise, h(b) :=

0
if b ∈PF ,
+∞
otherwise,
(6.14)
we see that problem (6.13) is of the form (6.8). Hence the dual problem is
(6.12), with f and h according to (6.14). In Exercise 6.5.1 it is shown that
this dual problem is equivalent to
β = sup{⟨q, a⟩| q ∈−P ◦
F , c −T ∗q ∈−P ◦
E}.
(6.15)
Recall that P ◦
E denotes the negative polar cone to PE. By Proposition 6.1.4
we have the following result.
Corollary 6.1.6 Under the assumptions (˜A), all assertions of Theorem 6.1.3
apply to the problems (6.13) and (6.15).

116
6 Duality of Convex Problems
Example 6.1.7 We show that, in the situation of Corollary 6.1.6, a duality
gap with ﬁnite optimal values may occur (cf. Remark 6.1.2). Let E = F := R3,
Tx := (0, x3, x1)⊤for x = (x1, x2, x3)⊤∈R3, c := (0, 0, 1)⊤, and a :=
(0, −1, 0)⊤. Equip R3 with the Euclidean norm ∥· ∥2. Further let PE = PF :=
K, where
K := {(x1, x2, x3)⊤∈R3 | x1 ≥0, x2 ≥0, 2x1x2 ≥x2
3}.
It is easy to see that with z0 := (1, 1, 0)⊤, we have
K = {x ∈R3 | z⊤
0 x ≥∥z0∥2 ∥x∥2 cos(π/4)}.
Hence K consists of all vectors x whose angle with the vector z0 is not greater
than π/4. Observe that K is a closed convex cone (“ice cream cone”) and that
K◦= −K. Further we have T ∗q = (q3, 0, q2)⊤for q = (q1, q2, q3)⊤∈R3. Thus
the problems (6.13) and (6.15) read, respectively,
α = inf{x3 | x ∈K, (0, x3 −1, x1)⊤∈K},
β = sup{−q2 | q ∈K, (−q3, 0, 1 −q2)⊤∈K}.
It follows that α = 0 and β = −1. Notice that the primal problem and the
dual problem have inﬁnitely many solutions.
Exercise 6.5.5 presents an example where the optimal values of the primal
and the dual problem coincide but the primal problem has no solution.
6.2 Lagrange Duality and Gâteaux Diﬀerentiable
Functionals
Let w ∈E∗. With f(x) := −⟨w, x⟩, x ∈E, and a := o, the primal problem
(6.8) and the dual problem (6.12), respectively, read as follows:
α := inf
x∈E

h(Tx) −⟨w, x⟩

,
(6.16)
β := sup
q∈B

−f ∗(−T ∗q) −h∗(q)

.
We have
f ∗(−T ∗q) = sup
x∈E

⟨−T ∗q, x⟩+ ⟨w, x⟩

=

0
if w = T ∗q,
+∞
otherwise.
The assumptions in Proposition 6.2.1 will entail that B := dom h∗= F ∗.
Setting
K := {q ∈F ∗| w = T ∗q},
(6.17)
we thus see that the problem dual to (6.16) is
β = sup
q∈K

−h∗(q)

.
(6.18)

6.2 Lagrange Duality and Gâteaux Diﬀerentiable Functionals
117
Proposition 6.2.1 Assume that:
E and F are reﬂexive Banach spaces, h : F →R is G-diﬀerentiable,
h′ : F →F ∗is uniformly monotone with constants c > 0 and γ > 1,
T : E →F is linear and isometric (i.e., ∥Tx∥= ∥x∥∀x ∈E).
Then:
(a) Problem (6.16) has precisely one solution ¯x ∈E, problem (6.18) has pre-
cisely one solution ¯q ∈K, and one has α = β.
(b) x = ¯x is also the unique solution of

h′(Tx), Ty
 
= ⟨w, y⟩
∀y ∈E,
(6.19)
and q = ¯q is also the unique solution of

(h′)−1(q), p −q
 
≥0
∀p ∈K.
(6.20)
(c) One has ¯q = h′(T ¯x).
(d) The following error estimates hold for α and ¯x:
−h∗(q) ≤α ≤h(Tx) −⟨w, x⟩
∀x ∈E ∀q ∈K,
(6.21)
c
γ ∥x −¯x∥γ ≤h(Tx) −⟨w, x⟩+ h∗(q)
∀x ∈E ∀q ∈K.
(6.22)
Proof.
(I) Setting g(x) := h(Tx), x ∈E, we obtain g′(x) = T ∗h′(Tx), x ∈E, and

g′(y) −g′(x), y −x
 
=

h′(Ty) −h′(Tx), Ty −Tx
 
≥c∥Ty −Tx∥γ = c∥y −x∥γ.
(6.23)
Hence by Theorem 5.4.7, the problem g(x) −⟨w, x⟩→min, x ∈E, and
so (6.16) has precisely one solution ¯x ∈E; this is also the unique solution
of

g′(¯x) −w, y
 
= 0 for any y ∈E and so of (6.19).
(II) We show that ¯q := h′(T ¯x) is the unique solution of (6.18). By (6.19), we
obtain ⟨¯q, Ty⟩= ⟨w, y⟩for all y ∈E and so T ∗¯q = w which means that
¯q ∈K. The Young inequality implies
h(Tx) + h∗(q) ≥⟨q, Tx⟩= ⟨T ∗q, x⟩= ⟨w, x⟩
∀(x, q) ∈E × K,
and it follows that α ≥β. Since {¯q} = ∂h(T ¯x), we further obtain by
Proposition 4.4.1,
h(T ¯x) + h∗(¯q) = ⟨¯q, T ¯x⟩= ⟨w, ¯x⟩.
We thus conclude that α = β and ¯q is a solution of (6.18).

118
6 Duality of Convex Problems
(III) The element ¯q is the only solution of (6.18) because K is a convex set
and h∗is a strictly convex functional (cf. Theorem 5.4.6). Concerning
the latter, recall that (h∗)′ = (h′)−1 by Proposition 4.4.3, notice that
(h′)−1 is strictly monotone and apply Proposition 4.3.5 to h∗.
(IV) By Remark 5.2.4(c) (cf. also Proposition 5.2.5), q ∈K is a solution of
(6.18) if and only if

(h∗)′(q), p−q
 
≥0 for all p ∈K which is equivalent
to (6.20).
(V) It is left as Exercise 6.5.2 to verify (d).
⊓⊔
6.3 Duality of Boundary Value Problems
We adopt the notation introduced at the beginning of Sect. 5.5. Consider the
classical boundary value problem
Au(x) = g(x) ∀x ∈G,
u(x) = 0 ∀x ∈∂G,
(6.24)
where A denotes the linear second-order diﬀerential operator deﬁned by
Au(x) := −
N
	
i,j=1
Di

aij(x) Dju(x)

.
Recall that A is said to be strongly elliptic if there exists a constant c > 0
such that
N
	
i,j=1
aij(x) yiyj ≥c
N
	
i=1
y2
i
∀x ∈G
∀(y1, . . . , yN) ∈RN.
Set
E := W1,2
0 (G).
Then the generalized problem associated with (6.24) reads as follows. Find
u ∈E satisfying

G
N
	
i,j=1
aij(x)Dju(x) Div(x) dx =

G
g(x) v(x) dx
∀v ∈E.
(6.25)
Heuristically, this is obtained from the classical problem by multiplying the
diﬀerential equation of (6.24) by v ∈C∞
c (G) and partial integration (cf.
Sect. 5.5). Parallel to (6.25) we consider the following minimum problem:
α := inf
u∈E

G
⎛
⎝1
2
N
	
i,j=1
aij(x)Diu(x) Dju(x) −g(x) u(x)
⎞
⎠dx.
(6.26)

6.3 Duality of Boundary Value Problems
119
Our aim is to apply Proposition 6.2.1. In this connection, notice that we now
denote the “primal variable” by u instead of x, while we go on denoting the
“dual variable” by q. The assumptions in Proposition 6.3.1 will ensure that
(6.26) is a convex problem of the form f(u) →min, u ∈E, and (6.25) is the
equivalent variational equation

f ′(u), v
 
= 0 for all v ∈E (Corollary 5.1.2).
Moreover, below we shall show that the problem dual to (6.26) is
β := sup
q∈K
⎛
⎝−

G
1
2
N
	
i,j=1
a(−1)
ij
(x) qi(x) qj(x) dx
⎞
⎠.
(6.27)
Here,

a(−1)
ij
(x)

denotes the inverse of the matrix

aij(x)

. Further, we set
F := L2
N(G) := L2(G) × · · · × L2(G)



N-times
,
∥q∥2 :=
 N
	
i=1

G
qi(x)
2 dx
 1
2
∀q = (q1, . . . , qN) ∈F,
K :=
0
q ∈F ∗

G
N
	
i=1
qi(x) Div(x) dx =

G
g(x) v(x) dx
∀v ∈E
1
,
Tu(x) :=

D1u(x), . . . , DNu(x)

∀x ∈G ∀u ∈E,
⟨w, u⟩:=

G
g(x) u(x) dx
∀u ∈E,
h(v) := 1
2

G
N
	
i,j=1
aij(x) vi(x) vj(x) dx
∀v ∈F.
Proposition 6.3.1 Assumethat,for i, j = 1, . . . , N,thefunctions aij : G →R
are continuous, bounded, and symmetric (i.e., aij = aji). Further assume
that the diﬀerential operator A is strongly elliptic, with the constant c > 0.
Let g ∈L2(G) be given. Then:
(a) The problem (6.26) has precisely one solution ¯u ∈E, the problem (6.27)
has precisely one solution ¯q ∈K, and one has α = β.
(b) The problems (6.25) and (6.26) are equivalent and so ¯u is also the unique
solution of (6.25).
(c) For i = 1, . . . , N, one has ¯qj = N
i=1 aij Di¯u.
(d) The following error estimates hold for α and ¯u:
−h∗(q) ≤α ≤h(Tu) −⟨w, u⟩
∀u ∈E ∀q ∈K,
c
2∥u −¯u∥2
1,2,0 ≤h(Tu) −⟨w, u⟩+ h∗(q)
∀u ∈E ∀q ∈K.

120
6 Duality of Convex Problems
Proof. We show that Proposition 6.2.1 applies.
(I) Notice that T : E →F is linear and isometric. The H¨older inequality
shows that w ∈E∗. Moreover, we obtain

h′(v), r
 
= ∂
∂τ h(v + τr)

τ=0 =

G
N
	
i,j=1
aij vi rj dx
∀v, r ∈F,
(6.28)
which implies that h′ is strongly monotone (as A is strongly elliptic).
(II) By Proposition 4.4.3 we have
h∗(q) = h∗(o) +
 1
0

q, (h′)−1(τq)
 
dτ
∀q ∈F ∗,
(6.29)
h∗(o) = −h

(h′)−1(o)

.
Since h′(o) = o, it follows that h∗(o) = −h(o) = 0. Let τ ∈[0, 1] and
q ∈F ∗be given. By the bijectivity of h′ there exists v ∈F satisfying
v = (h′)−1(τq). In view of (6.28), we conclude that
τ qj(x) = (τq)j(x) =
N
	
i=1
aij(x) vi(x)
for almost all x ∈G
and so
vi(x) =
N
	
j=1
a(−1)
ij
(x)τ qj(x)
for almost all x ∈G and i = 1, . . . , N.
Inserting this for the ith coordinate of (h′)−1(τq) into (6.29), we obtain
h∗(q) =
 1
0
⎛
⎝

G
N
	
i,j=1
qi a(−1)
ij
τ qj dx
⎞
⎠dτ =

G
1
2
N
	
i,j=1
a(−1)
ij
qi qj dx.
(6.30)
Finally we have
K = {q ∈F ∗| ⟨q, Tv⟩F = ⟨w, v⟩E ∀v ∈E} = {q ∈F ∗| T ∗q = w}.
The assertions now follow from Proposition 6.2.1.
⊓⊔
Remark 6.3.2 [Smooth Data] If the boundary ∂G as well as the functions
aij and g are suﬃciently smooth, then the solution ¯u of (6.25) and (6.26) is
an element of C2(G) and so is also a classical solution of (6.24). Set
R := {u ∈C2(G)
 u = o on ∂G},
S := {v ∈C2(G)
 Av = g on G}.

6.3 Duality of Boundary Value Problems
121
Since R ⊆E and ¯u ∈R, we have α = infu∈R
"
G

· · ·

dx (cf. (6.26)) and so
α = inf
u∈R

h(Tu) −⟨w, u⟩

.
(6.31)
Deﬁne
Q :=
0
(q1, . . . , qN) ∈F ∗ qi =
N
	
j=1
aijDjv for i = 1, . . . , N, v ∈S
1
.
If q ∈Q, then
−
N
	
i=1
Diqi = Av = g
(6.32)
and so q ∈K; the latter follows by multiplying (6.32) by ˜v ∈C∞
c (G) and
partial integration. Moreover, we have
¯q = h′(T ¯u) =
N
	
i,j=1
aijDi¯u ∈Q;
here, the second equality follows by Proposition 6.3.1(c). In view of (6.27), we
thus obtain β = sup
q∈Q

−h∗(q)

. From (6.30) we deduce that for q ∈Q we have
h∗(q) = h(Tv) with some v ∈S so that we ﬁnally obtain
β = sup
v∈S

−h(Tv)

= −inf
v∈S h(Tv).
(6.33)
Hence for smooth data, the statements of Proposition 6.3.1 hold with α and
β according to (6.31) and (6.33), respectively. In this connection, we have the
error estimates
−h(Tv) ≤α ≤h(Tu) −⟨w, u⟩
∀u ∈R ∀v ∈S,
(6.34)
c
2∥u −¯u∥2
1,2,0 ≤h(Tu) −⟨w, u⟩+ h(Tv)
∀u ∈R ∀v ∈S.
(6.35)
By applying the Ritz method to (6.33), a sequence (v(n)) in S is obtained
which can be used in (6.34) to successively improve the lower bound for α
according to α ≥−h

Tv(n)
. This is the Treﬀtz method. Notice that the
elements u ∈R and v ∈S only need to satisfy the boundary condition or the
diﬀerential equation.
Example 6.3.3 Consider the diﬀerential operator A = −∆= −N
i=1 DiDi.
Then for u ∈C2(G), we have the boundary value problem
−∆u = g on G,
u = o on ∂G
According to (6.31), the associated minimum problem is

122
6 Duality of Convex Problems
α = inf

G
1
2
n
	
i=1

Diu
2 −gu

dx
 u = o on ∂G
'
and according to (6.34), the dual problem is
β = sup

−

G
1
2
N
	
i=1

Div
2 dx
 −∆v = g on G
'
.
6.4 Duality in Terms of Conjugate Functions
In this section we present another approach to duality, which we ﬁrst explain
in a special case.
Example 6.4.1 As in Example 6.1.5 and with the same notation, we consider
the problem of linear optimization
α := inf{⟨c, x⟩| x ∈PE , Tx −a ∈PF }.
We now perturb the constraint Tx −a ∈PF by a linear parameter b, i.e., we
pass to the perturbed problem
S(b) := inf{⟨c, x⟩| x ∈PE , Tx −a −b ∈PF }.
The original problem is α = S(o). Again we formalize the above procedure.
Setting
˜f(x) :=

⟨c, x⟩
if x ∈PE ,
+∞
if x ∈E \ PE ,
h(ˆb) :=

0
if ˆb ∈PF ,
+∞
if ˆb ∈F \ PF ,
f(x) := ˜f(x) + h(Tx −a),
x ∈E,
M(x, b) := ˜f(x) + h(Tx −a −b)
∀x ∈E ∀b ∈F,
we have
S(b) = inf
x∈E M(x, b)
∀b ∈F,
f(x) = M(x, o)
∀x ∈E,
α = S(o) = inf
x∈E f(x).
The functional M : E × F →R can be interpreted as a perturbation of f.

6.4 Duality in Terms of Conjugate Functions
123
Now we consider a more general setting. Let the following problem be
given
α := inf
x∈E f(x),
(6.36)
where f : E →R. Choose another normed vector space F and a functional
M : E × F →R such that f(x) = M(x, o) for each x ∈E and consider the
following problems:
S(b) := inf
x∈E M(x, b), b ∈F
(perturbed problem),
(6.37)
−ˆS(v) := sup
q∈F ∗

−M ∗(v, q)

, v ∈E∗
(problem dual to (6.37)),
(6.38)
β := −ˆS(o) = sup
q∈F ∗

−M ∗(o, q)

(problem dual to (6.36)).
(6.39)
Deﬁnition 6.4.2 The functional S : F →R deﬁned by (6.37) is called value
functional or marginal functional. The problems (6.36) and (6.39) are said to
be stable if ∂S(o) ̸= ∅and ∂ˆS(o) ̸= ∅, respectively.
We make the following assumptions:
(A1) E and F are normed vector spaces, f : E →R is proper, convex, and
l.s.c., M : E × F →R is proper, convex, and l.s.c., M(x, o) = f(x) ∀
x ∈E,
there exist x0 ∈E and q0 ∈F ∗satisfying f(x0) < +∞and M ∗(o, q0) <
+∞.
It turns out that, under the above assumptions, the duality between the
problems (6.36) and (6.39) can be completely characterized by means of the
value functional S and the perturbation M. Theorem 6.4.3 is one of the central
results of duality theory.
Theorem 6.4.3 Under the assumptions (A1), the following holds:
(i)
One has −∞< β ≤α < +∞.
(ii)
The following statements are equivalent:
(a) Problem (6.36) has a solution and α = β.
(b) Problem (6.39) is stable.
(iii) The following statements are equivalent:
(a′) Problem (6.39) has a solution and α = β.
(b′) Problem (6.36) is stable.
(iv) If α = β, then
∂ˆS(o) = solution set of (6.36),
∂S(o) = solution set of (6.39).
(v)
The following statements are equivalent:
(a′′) x ∈E is a solution of (6.36), q ∈F ∗is a solution of (6.39), and
α = β.

124
6 Duality of Convex Problems
(b′′) M(x, o) + M ∗(o, q) = 0.
(c′′) (o, q) ∈∂M(x, o).
Proof.
(I) First recall that (E × F)∗can and will be identiﬁed with E∗× F ∗ac-
cording to

(v, q), (x, b)
 
= ⟨v, x⟩+ ⟨q, b⟩
∀(x, b) ∈E × F ∀(v, q) ∈E∗× F ∗.
Using this, we have
M ∗(v, q) = sup
x∈E
b∈F

⟨v, x⟩+ ⟨q, b⟩−M(x, b)

.
(6.40)
Furthermore, we obtain
S∗(q) = sup
b∈F

⟨q, b⟩−S(b)

= sup
b∈F
sup
x∈E

⟨q, b⟩−M(x, b)

= sup
x∈E
b∈F

⟨q, b⟩−M(x, b)

= M ∗(o, q)
(6.41)
and so
S∗∗(o) = sup
q∈F ∗

o −S∗(q)

= sup
q∈F ∗

−M ∗(o, q)

= β.
(6.42)
(II) From (6.39) and (6.38) we see that
−β = inf
q∈F ∗M ∗(o, q),
(6.43)
ˆS(v) = inf
q∈F ∗M ∗(v, q),
v ∈E∗.
(6.44)
Recalling that the dual of F ∗[σ(F ∗, F)] and E∗[σ(E∗, E)] can be identi-
ﬁed with F and E, respectively, and comparing the relationship between
(6.37) and (6.38), we conclude that the problem dual to (6.44) is
−ˆˆS(b) := sup
x∈E

−M ∗∗(x, b)

= sup
x∈E

−M(x, b)

,
b ∈F.
Therefore, the problem dual to (6.40) and so to (6.39) is
−ˆˆS(o) = sup
x∈E

−M(x, o)

= inf
x∈E M(x, o) = α,
which is the primal problem.
(III) It is left as an exercise to show that S is convex.
(IV) Ad (i). The hypotheses imply that α < +∞and β > −∞. Applying the
Young inequality to M, we obtain
M(x, o) + M ∗(o, q) ≥⟨o, x⟩+ ⟨q, o⟩= 0

6.4 Duality in Terms of Conjugate Functions
125
which, by passing to the inﬁmum over all (x, q) ∈E×F ∗, yields α−β ≥0.
Ad (v). This follows by applying Proposition 4.4.1 to M.
Ad (iv). Assume that α = β. Then it follows that
q is a solution of (6.39) ⇐⇒−S∗(q)
=
(6.41) −M ∗(o, q)
=
(6.39) β = α = S(o)
⇐⇒q ∈∂S(o);
here, the last equivalence holds by Proposition 4.4.1. According to
step (II), the problem dual to (6.39) is just the original problem (6.36).
Therefore, in analogy to the above, we have
x is a solution of (6.36) ⇐⇒x ∈∂ˆS(o).
Ad (iii). (a′) =⇒(b′): By (iv), (a′) implies that ∂S(o) ̸= ∅and so (6.36)
is stable.
(b′) =⇒(a′): Let v ∈∂S(o). It follows from Proposition 4.4.1 that
S(o) = ⟨v, o⟩−S∗(v) ≤S∗∗(o).
On the other hand, we have S∗∗≤S. Hence α = S(o) = S∗∗(o) = β; here
the last equation is a consequence of (6.42). Moreover, v is a solution of
(6.39) by (iv).
Ad (ii). This follows from (iii) and step (II).
⊓⊔
Theorem 6.4.3 reveals the importance of the stability concept. Lemma 6.4.4
provides a suﬃcient condition for stability.
Lemma 6.4.4 Let the assumptions (A1) be fulﬁlled.
(a) If b →M(x1, b) is continuous at b = o for some x1 ∈E, then the primal
problem (6.36) is stable.
(b) If v →M ∗(v, q1) is continuous at v = o for some q1 ∈F ∗, then the dual
problem (6.39) is stable.
Proof.
(a) By assumption, there exist a number k > 0 and a neighborhood U of o in
F such that
S(b) = inf
x∈E M(x, b) ≤M(x1, b) ≤k
∀b ∈U.
Since the functional S is also convex (cf. the remark in step (III) of the
proof of Theorem 6.4.3), it is continuous at o by Theorem 1.4.1, therefore
∂S(o) ̸= ∅by Proposition 4.1.6.
(b) This is proved analogously.
⊓⊔

126
6 Duality of Convex Problems
Special Case
Now we make the following assumptions:
(A2) f : E →R and h : F →R are proper, convex, and l.s.c.,
T : E →F is linear and continuous, a ∈F,
there exist x0 ∈E and q0 ∈F ∗such that f(x0), h(Tx0 −a), f ∗(T ∗q0),
and h∗(−q0) are all < +∞.
As in (6.8) we consider the problem
α := inf
x∈E

f(x) + h(Tx −a)

.
(6.45)
We set (cf. Example 6.4.1 with f instead of ˜f)
M(x, b) := f(x) + h(Tx −a −b)
(6.46)
to obtain α = infx∈E M(x, o). This gives the following associated problems:
S(b) := inf
x∈E M(x, b)
(perturbed problem),
(6.47)
−ˆS(v) := sup
q∈F ∗

−M ∗(v, q)

(problem dual to (6.47)),
(6.48)
β := −ˆS(o) = sup
q∈F ∗

−M ∗(o, q)

(problem dual to (6.45)).
(6.49)
A simple calculation shows that
−M ∗(v, q) = ⟨q, a⟩−f ∗(T ∗q + v) −h∗(−q)
and so
β = sup
q∈F ∗

⟨q, a⟩−f ∗(T ∗q) −h∗(−q)

.
(6.50)
We associate with (6.45) the Lagrange functional
L1(x, q) := f(x) −⟨q, Tx −a⟩−h∗(−q),
x ∈A, q ∈B,
where
A := dom f, B := {q ∈F ∗| h∗(−q) < +∞}.
Notice that L1(x, q) = L(x, −q), where L denotes the corresponding Lagrange
functional in (6.9).
Theorem 6.4.5 Let the assumptions (A2) be fulﬁlled:
(i) With (6.36) replaced by (6.45), with (6.39) replaced by (6.50) and with M
according to (6.46), the statements (i)–(iv) of Theorem 6.4.3 hold.

6.4 Duality in Terms of Conjugate Functions
127
(ii) [Modiﬁcation of Theorem 6.4.3(v)] The following statements are equiva-
lent:
(a′′′) x ∈E is a solution of (6.45), q ∈F ∗is a solution of (6.50), and
α = β.
(b′′′) (x, q) is a saddle point of L1 with respect to A × B.
(c′′′) T ∗q ∈∂f(x) and −q ∈∂h(Tx −a).
Proof. See Exercise 6.5.3.
⊓⊔
Lemma 6.4.4 immediately implies the following result.
Lemma 6.4.6 Let the assumptions (A2) be fulﬁlled:
(a) If h is continuous at Tx0 −a, then the problem (6.45) is stable.
(b) If f ∗is continuous at T ∗q0, then the problem (6.50) is stable.
Corollary 6.4.7 Let the assumptions (A2) be fulﬁlled. In addition, assume
that h is continuous at Tx0 −a. Then one has
inf
x∈E

f(x) + h(Tx −a)

= max
q∈F ∗

⟨q, a⟩−f ∗(T ∗q) −h∗(−q)

.
(6.51)
Proof. By Lemma 6.4.6, the problem (6.45) is stable. Hence the assertion
follows from Theorem 6.4.5 (cf. Theorem 6.4.3(iii)).
⊓⊔
We further specialize the setting. Let A be a nonempty convex subset
of E. Set f := δA and so f ∗(q) = supx∈A⟨q, x⟩. Moreover, let F :=E, T := idE,
and a := o. Applying Corollary 6.4.7 to these data, we obtain:
Corollary 6.4.8 Assume that A is a nonempty convex subset of E, h is
proper, convex, l.s.c., and continuous at a point of A. Then one has
inf
x∈A h(x) = max
q∈E∗

inf
x∈A⟨q, x⟩−h∗(q)

.
(6.52)
Application
Let E be a Hilbert space with scalar product (v|u). We identify E∗with E.
Moreover, let S : E →Rn be linear and continuous, and let c ∈Rn. We
consider the problem
h(u) := 1
2∥u∥2 →min,
u ∈E,
Su = c.
(6.53)
Assume that the set
A := {u ∈E | Su = c}
is nonempty. By Corollary 6.4.8 we have
inf
u∈A
1
2∥u∥2 = max
v∈E

inf
u∈A(v|u) −h∗(v)

.
(6.54)

128
6 Duality of Convex Problems
We evaluate the dual problem, i.e., the right-hand side of (6.54):
Ad infu∈A(v|u). For Q := {o} ⊆Rn we have Q◦= Rn, and S∗(Rn), as a ﬁnite-
dimensional linear subspace of E(= E∗), is σ(E∗, E)-closed. By Lemma 2.4.1
we therefore obtain
S∗(Rn) =

S−1{o}
◦= {v ∈E | (v|u) = 0 ∀u ∈ker S} =:

ker S
⊥.
(6.55)
(I) If v ̸∈

ker S
⊥, then there exists u0 ∈E such that Su0 =o and (v|u0)=1.
Let u1 ∈A. Since S is linear, we have u := αu0 + u1 ∈A for each α ∈R.
It follows that
(v|u) = α + (v|u1) →−∞
as α →−∞
and so infu∈A(v|u) = −∞.
(II) If v ∈

ker S
⊥, then by (6.55), there exists a ∈Rn satisfying S∗a = v,
and we obtain
inf
u∈A(v|u) = inf
u∈A(S∗a|u) = inf
u∈A(a|Su) = (a|c),
(6.56)
and this holds for each a ∈Rn.
Ad h∗(v). We immediately obtain
h∗(v) = sup
u∈E

(v|u) −1
2(u|u)

= 1
2(v|v) = 1
2∥v∥2;
concerning the second equality, notice that
0 ≤1
2(v −u|v −u) = 1
2(v|v) −(v|u) + 1
2(u|u)
∀u, v ∈E.
With the above, (6.54) passes into
inf
u∈A
1
2∥u∥2 = max
a∈Rn

(a|c) −1
2∥S∗a∥2



=:ϕ(a)

.
(6.57)
Since ϕ : Rn →R is concave and diﬀerentiable, we have
ϕ(a0) = max
a∈Rn ϕ(a)
⇐⇒
ϕ′(a0) = o
⇐⇒
(h|c) −(h|SS∗a0) = 0
∀h ∈Rn
⇐⇒
SS∗a0 = c.
Hence we have deduced the following result: If a0 ∈Rn is a solution of
SS∗a0 = c (which is a linear equation in Rn), then v0 := S∗a0 is a solution
of the right-hand side of (6.54).
We leave it as Exercise 6.5.6 to show that u0 := v0 is a solution of the primal
problem infu∈A 1
2∥u∥2.

6.5 Bibliographical Notes and Exercises
129
Example 6.4.9 Consider a dynamical system described by
˙x(t) = Fx(t) + bu(t),
t ∈[0, 1].
(6.58)
In this connection, x : [0, 1] →Rn is the phase function and u : [0, 1] →R is
the control function. The (n, n)-matrix F and the vector b ∈Rn are given. We
search a control function u that moves the system from x(0) = o to x(1) = c
(where c ∈Rn is given) under minimal consumption of energy. We assume
that the energy needed for any control function u is
h(u) := 1
2
 1
0
u2(t)dt.
We solve the problem in the Hilbert space E := L2[0, 1] so that we have
h(u) =
1
2∥u∥2. Each solution x ∈L2[0, 1] of (6.58) satisfying x(0) = o is
representable as
x(t) =
 t
0
φ(t −τ)bu(τ) dτ,
t ∈[0, 1];
here, φ denotes the fundamental matrix associated with (6.58). The operator
S : L2[0, 1] →Rn deﬁned by
Su :=
 1
0
φ(1 −τ)bu(τ) dτ,
is linear and continuous, and the end condition x(1) = c is equivalent to
Su = c. Hence, according to what has been said above, the solution of the
problem is u0 = S∗a0, where a0 ∈Rn is the solution of SS∗a0 = c.
6.5 Bibliographical Notes and Exercises
Principal contributions to duality theory were obtained by Fenchel [65],
Moreau [147], Brøndsted [28], and Rockafellar [178, 180]. In particular,
Theorem 6.4.3 is due to Fenchel [66] and Rockafellar [179]. Example 6.1.7 is
adapted from Ky Fan [64]. The presentation in Sect. 6.3 essentially follows
Zeidler [221]. The application at the end of Sect. 6.4 is taken from Luen-
berger [127]. In addition to the references in the Bibliographical Notes at the
end of Chap. 4, we recommend Stoer and Witzgall [201] (ﬁnite-dimensional
spaces) and G¨opfert [76] (applications in locally convex spaces).
Exercise 6.5.1 Show that, with the notation and the assumptions of
Example 6.1.5, the problem dual to (6.8) can be written as (6.15).
Exercise 6.5.2 Verify assertion (d) of Proposition 6.2.1.
Exercise 6.5.3 Prove Theorem 6.4.5.

130
6 Duality of Convex Problems
Exercise 6.5.4 Consider Problem (6.13) with E = PE := Rn and F :=
C[a, b] with the maximum norm. Further let PF be the cone of nonnegative
functions in C[a, b]. Then (6.13) is a linear semi-inﬁnite optimization problem.
It is placed in a ﬁnite-dimensional space but has inﬁnitely many side conditions
of the form Tx(t) ≥a(t) for all t ∈[a, b]. In this case, E is reﬂexive but F
is not. Check which assertions of the theory developed above still hold (cf.
Krabs [112]).
Exercise 6.5.5 Consider the following linear semi-inﬁnite problem (cf.
Exercise 6.5.4):
Minimize f(x1, x2) := x2
subject to (x1, x2) ∈R2,
t2x1 + x2 ≥t
∀t ∈[0, 1].
Show that the values of the primal problem and the dual problem coincide,
the dual problem has a solution, but the primal problem has no solution.
Exercise 6.5.6 Verify that u0 := v0 = S∗a0, where a0 ∈Rn solves SS∗a0 =c,
is a solution of the primal problem (6.53).

7
Derivatives and Subdiﬀerentials of Lipschitz
Functionals
7.1 Preview: Derivatives and Approximating Cones
The aim of this section is to give, in an informal discussion, the motivation
for the following sections.
Let f : E →R be proper, let A ⊆E, and let ¯x ∈A. We consider the
following statement:
(Min) ¯x is a local minimizer of f on A.
There are two basic approaches to necessary conditions for (Min), which
we call method of tangent directions and method of penalty functions.
Method of Tangent Directions
(I) Suppose that f and A are convex. Then (Min) can be characterized by a
variational inequality (see Proposition 5.1.1):
(Min)
⇐⇒
fG(¯x, y) ≥0
∀y ∈A −¯x.
(7.1)
(II) Suppose now that f and/or A is not convex. In order to be able to argue
similarly as in the convex case, we have to identify “admissible” directions,
i.e., directions y ∈E that appropriately approximate the set A locally at ¯x.
The set
Tr(A, ¯x) := {y ∈E | ∃τk ↓0 ∀k ∈N : ¯x + τky ∈A},
which turns out to be a cone, is called cone of radial directions to A at ¯x
(Fig. 7.1). If (Min) holds and if y ∈Tr(A, ¯x), then for some sequence τk ↓0,
we have
1
τk

f(¯x + τky) −f(¯x)

≥0
∀k ∈N.

132
7 Derivatives and Subdiﬀerentials of Lipschitz Functionals
¯x
¯x + τky
A
y ∈Tr(A, ¯x)
Fig. 7.1
We therefore consider the upper directional G-derivative
f G(¯x, y) := lim sup
τ↓0
1
τ

f(¯x + τy) −f(¯x)

.
Using this, we conclude that
(Min)
=⇒
f G(¯x, y) ≥0
∀y ∈Tr(M, ¯x).
(7.2)
In other words, as a necessary optimality condition we again obtain a varia-
tional inequality. This condition is useful as long as Tr(A, ¯x) contains “enough”
elements. However, if for example M is the kernel of a mapping h : D →F,
i.e., if
A := ker h := {x ∈D | h(x) = o},
(7.3)
then in general we will have Tr(A, ¯x) = {o}. Since there always holds
f G(¯x, o) = 0, the optimality condition in (7.2) is trivially satisﬁed for each
¯x ∈A and so is not suitable for identifying possible solutions of (Min). There-
fore we look for ﬁner local approximations of A at ¯x.
Let again A be an arbitrary subset of E and ¯x ∈A. The set
T(A, ¯x) := {y ∈E | ∃τk ↓0 ∃yk →y ∀k ∈N : ¯x + τkyk ∈A},
which is also a cone, is called contingent cone to A at ¯x (Fig. 7.2). In analogy
to (7.2), we obtain
(Min)
=⇒
f H(¯x, y) ≥0
∀y ∈T(A, ¯x),
(7.4)
where now the upper directional H-derivative
f H(¯x, y) := lim sup
τ↓0, z→y
1
τ

f(¯x + τz) −f(¯x)

is the adequate local approximation of f at ¯x. Since Tr(A, ¯x) ⊆T(A, ¯x), the
optimality condition in (7.4) is stronger than that in (7.2).

7.1 Preview: Derivatives and Approximating Cones
133
 
 
y ∈T(A, ¯x)
yk
¯x + τkyk
¯x
A
Fig. 7.2
So far, we have not imposed any diﬀerentiability hypotheses on the functional
f. From (7.2) and (7.4) we immediately deduce the following conditions:
(a) If f is G-diﬀerentiable at ¯x, then
(Min)
=⇒
⟨f ′(¯x), y⟩≥0
∀y ∈Tr(A, ¯x).
(7.5)
If, in addition, A is convex, then A −¯x ⊂Tr(A, ¯x) and we obtain (cf. (7.1))
(Min)
=⇒
⟨f ′(¯x), y⟩≥0
∀y ∈A −¯x.
(7.6)
(b) If f is H-diﬀerentiable at ¯x, then
(Min)
=⇒
⟨f ′(¯x), y⟩≥0
∀y ∈T(A, ¯x).
(7.7)
The above shows that necessary conditions for (Min) can be obtained by
choosing local approximations of the functional f by a (directional) deriva-
tive and of the set A by a cone provided these approximations “ﬁt together.”
(III) Let A be as in (7.3), with a mapping h : D →F. Our aim now is to
derive a necessary condition for (Min) in terms of h. If h is F-diﬀerentiable
in a neighborhood of ¯x, h′ is continuous at ¯x, and h′(¯x) is surjective, then a
well-known theorem of Lyusternik says that
T(ker h, ¯x) = ker h′(¯x),
(7.8)
i.e., y ∈T(ker h, ¯x) if and only if h′(¯x)y = o (see Fig. 7.3, where E = Rn).
This will follow below from a more general result (see Theorem 11.4.2).
If, in addition, the functional f is H-diﬀerentiable at ¯x, then we obtain
from (7.7) and (7.8) the following condition:
(Min)
=⇒
#
∀y ∈E : h′(¯x)y = o =⇒

−f ′(¯x), y
 
≤0.
$
Applying the generalized Farkas lemma of Proposition 2.4.2 to [· · · ], where
T := h′(¯x), u := −f ′(¯x), and Q := {o}, we see that (Min) implies the existence

134
7 Derivatives and Subdiﬀerentials of Lipschitz Functionals
∇h(¯x)
y
ker h
¯x
Fig. 7.3
of v ∈F ∗satisfying T ∗v = u, i.e.,

v, h′(¯x)y
 
=

−f ′(¯x), y
 
for all y ∈E
and so
f ′(¯x) + v ◦h′(¯x) = o.
(7.9)
Hence as a necessary condition for (Min), we obtain a Lagrange multiplier
rule, the Lagrange “multiplier” being the functional v ∈F ∗.
(IV) We again consider (Min), where now A is of the form
A = {x ∈E | gi(x) ≤0, i = 1, . . . , m}
(7.10)
with certain functionals g1, . . . , gm. In this case we want to obtain optimality
conditions in terms of f and these functionals. Therefore, in view of say (7.4),
we want to characterize (a suﬃciently large subset of) T(A, ¯x) in terms of
g1, . . . , gm. Similarly to (III) this will be achieved under appropriate diﬀer-
entiability assumptions. A multiplier rule is then obtained with the aid of a
suitable nonlinear substitute for the generalized Farkas lemma.
Method of Penalty Functions
The idea of this method is to replace the constrained minimum problem
f(x) →min,
x ∈A,
by a free minimum problem
f(x) + p(x) →min,
x ∈E,
where the penalty function p is such that p(x) > 0 if x ∈E \ A, i.e., leaving
the set A is “penalized.”
(I) Let A be a convex set and f a convex functional that is continuous at
some point of A. Then the indicator functional δA is an appropriate penalty
function. In fact, we have
(Min) ⇐⇒(f + δA)(¯x) = min
x∈E(f + δA)(x) ⇐⇒o ∈∂(f + δA)(¯x),

7.2 Upper Convex Approximations and Locally Convex Functionals
135
and the sum rule (Proposition 4.5.1) implies
(Min) ⇐⇒o ∈∂f(¯x) + ∂δA(¯x) ⇐⇒o ∈∂f(¯x) + (A −¯x)◦.
The cone N(A, ¯x) := T(A, ¯x)◦is called normal cone to A at ¯x. Since A is
convex, we have T(A, ¯x) = R+(A −¯x) and so N(A, ¯x) = (A −¯x)◦. Thus the
above equivalence can be written as
(Min) ⇐⇒o ∈∂f(¯x) + N(A, ¯x).
(7.11)
Assume now that A is given by (7.10). Then for a further exploitation of
(7.11) we need a representation of N(A, ¯x) in terms of gi.
(II) In a theory involving locally L-continuous (nonconvex) functionals, the
indicator functional is not suitable as a penalty function. In this case, the L-
continuous functional p := λ dA, where λ > 0 is suﬃciently large, will turn out
to serve this purpose. Here, as in the convex case, a possible subdiﬀerential
mapping ∂∗f : E ⇒E∗should at least have the following properties:
If ¯x is a local minimizer of f on E, then o ∈∂∗f(¯x),
∂∗(f + g)(¯x) ⊆∂∗f(¯x) + ∂∗g(¯x).
Then it follows that
(Min) =⇒o ∈∂∗f(¯x) + ∂∗(λdA)(¯x) ⊆∂∗f(¯x) + N∗(A, ¯x),
where N∗(A, ¯x) denotes the σ(E∗, E)-closure of 
λ≥0 ∂∗(λdA)(¯x).
(III) If A is given by (7.10), then we wish to describe N∗(A, ¯x) in terms of
the functionals g1, . . . , gm.
(IV) Finally, analogous investigations are to be done for nonconvex non-
Lipschitz functionals.
7.2 Upper Convex Approximations and Locally
Convex Functionals
We start carrying out the program indicated in Sect. 7.1.
Deﬁnition 7.2.1 Let f : E →R be proper and let ¯x ∈dom f.
(a) The functional ϕ : E →R is called radial upper convex approximation of
f at ¯x if ϕ is proper, sublinear, and satisﬁes
f G(¯x, y) ≤ϕ(y)
∀y ∈E.
(b) The functional ϕ : E →R is called upper convex approximation of f at ¯x
if ϕ is proper, sublinear, and satisﬁes
f H(¯x, y) ≤ϕ(y)
∀y ∈E \ {o}.

136
7 Derivatives and Subdiﬀerentials of Lipschitz Functionals
We write
UCr(f, ¯x) := set of all radial upper convex approximations of f at ¯x,
UC(f, ¯x) := set of all upper convex approximations of f at ¯x.
Since f G(¯x, ·) ≤f H(¯x, ·), we always have UC(f, ¯x) ⊆UCr(f, ¯x) (notice
that f G(¯x, o) = o = ϕ(o)).
Proposition 7.2.2 If f : E →R is proper and locally L-continuous at ¯x ∈
dom f, then f H(¯x, y) = f G(¯x, y) for any y ∈E and so UC(f, ¯x) = UCr(f, ¯x).
Proof. See Exercise 7.5.1.
⊓⊔
Remark 7.2.3 There is a close relationship to quasidiﬀerentiable functionals.
The proper functional f : E →R is said to be quasidiﬀerentiable at ¯x ∈dom f
if fG(¯x, ·) exists on E and there exist nonempty convex σ(E∗, E)-compact
subsets ∂f(¯x) and ∂f(¯x) of E∗such that
fG(¯x, y) =
min
u∈∂f(¯x)
⟨u, y⟩+ max
v∈∂f(¯x)⟨v, y⟩
∀y ∈E.
Now let f : E →R be quasidiﬀerentiable at ¯x ∈dom f and set
ϕu(y) := max{⟨u + v, y⟩| v ∈∂f(¯x)}
∀y ∈E,
ψv(y) := max{⟨u −v, y⟩| u ∈−∂f(¯x)}
∀y ∈E.
Then obviously
ϕu ∈UCr(f, ¯x)
∀u ∈∂f(¯x)
and
ψv ∈UCr(−f, ¯x)
∀v ∈∂f(¯x).
Deﬁnition 7.2.4 describes a special class of functionals admitting (radial)
upper convex approximations.
Deﬁnition 7.2.4 Let f : E →R be proper and let ¯x ∈dom f. The functional
f is said to be
– locally convex at ¯x if fG(¯x, ·) exists and is sublinear as a mapping of E to
R,
– regularly locally convex at ¯x if fH(¯x, ·) exists and is sublinear as a mapping
of E to R.
See Exercise 7.5.2 for an example of a functional that is locally convex but
not regularly locally convex.
Proposition 7.2.5 Let f1, f2 : E →R be proper and set f := f1+f2. Further
let ¯x ∈(int domf1) ∩(int domf2) and assume that f1 is continuous at ¯x and
convex:
(a) If f2 is G-diﬀerentiable at ¯x, then f is locally convex at ¯x and fG(¯x, ·) =
f1,H(¯x, ·) + f ′
2(¯x) ∈UCr(f, ¯x).

7.2 Upper Convex Approximations and Locally Convex Functionals
137
(b) If f2 is H-diﬀerentiable at ¯x, then f is regularly locally convex at ¯x and
fH(¯x, ·) = f1,H(¯x, ·) + f ′
2(¯x) ∈UC(f, ¯x).
Proof. By Theorem 4.1.3 we have f1,H(¯x, ·) ∈UC(f1, ¯x), and by Remark 3.2.3
it follows that f ′
2(¯x) ∈UCr(f2, ¯x) or f ′
2(¯x) ∈UC(f2, ¯x), respectively. This
veriﬁes the assertions.
⊓⊔
Remark 7.2.6 By Proposition 7.2.5, each functional that is G-diﬀerentiable
at ¯x is locally convex there. Moreover, each continuous convex functional
as well as each functional that is H-diﬀerentiable at ¯x is regularly locally
convex. Notice that the proposition also describes regularly locally convex
functionals that are neither convex nor G-diﬀerentiable; consider, e.g., f(x) :=
|x| + x3, x ∈R, at ¯x = 0.
We want to derive a maximum rule for the directional G-derivative. For
i = 1, . . . , m let fi : E →R and set
f(x) :=
max
i=1....,m fi(x),
x ∈E.
(7.12)
Let ¯x ∈E, I := {1, . . . , m}, and I(¯x) := {i ∈I | fi(¯x) = f(¯x)}.
Proposition 7.2.7 (Maximum Rule) Assume that ¯x ∈
i∈I int(dom fi),
that fi is continuous at ¯x for each i ∈I, and that fi,G(¯x, ·) exists for each
i ∈I(¯x). Then, with f as in (7.12), the directional G-derivative fG(¯x, ·) exists
and one has
fG(¯x, y) = max
i∈I(¯x) fi,G(¯x, y),
y ∈E.
(7.13)
An analogous result holds with fG, fi,G replaced by fH, fi,H, respectively.
Proof.
(I) First we show that the directional G-derivative fG(¯x, ·), whenever it
exists, depends on the functions fi for i ∈I(¯x) only. Let y ∈E be
given. If i ∈I \ I(¯x), then the continuity of fi and f imply that there
exists τi > 0 such that fi(¯x + τy) < f(¯x + τy) for each τ ∈[0, τi]. Let
τ0 := min{τi | i ∈I \ I(¯x)}. For any τ ∈(0, τ0) we have
τ −1
f(¯x + τy) −f(¯x)

= max
i∈I(¯x) τ −1
fi(¯x + τy) −f(¯x)

= max
i∈I(¯x) τ −1
fi(¯x + τy) −fi(¯x)

.
(7.14)
Hence we may assume that I(¯x) = I.
(II) For each i ∈I

= I(¯x)

we obtain
lim inf
τ↓0
τ −1
f(¯x + τy) −f(¯x)

≥lim
τ↓0 τ −1
fi(¯x + τy) −fi(¯x)

= (fi)G(¯x, y).
(7.15)

138
7 Derivatives and Subdiﬀerentials of Lipschitz Functionals
We now show that
lim sup
τ↓0
τ −1
f(¯x + τy) −f(¯x)

≤max
i∈I fi,G(¯x, y).
This and (7.15) verify (7.13). Assume that
lim sup
τ↓0
τ −1
f(¯x + τy) −f(¯x)

> max
i∈I fi,G(¯x, y).
Then we ﬁnd ϵ > 0 and a sequence τk ↓0 such that
τ −1
k

f(¯x + τky) −f(¯x)

≥max
i∈I fi,G(¯x, y) + ϵ
∀k ∈N .
For a subsequence (τkν) of (τk) we have f(¯x + τkνy) = fj(¯x + τkνy) with
a ﬁxed index j. It follows that
fj,G(¯x, y) = lim
ν→∞τ −1
kν

fj(¯x + τkνy) −fj(¯x)

≥max
i∈I fi,G(¯x, y) + ϵ,
which is a contradiction.
(III) For fH(¯x, ·) see Exercise 7.5.3.
⊓⊔
Proposition 7.2.8 Assume that ¯x ∈
i∈I int(dom fi), each fi is continuous
at ¯x, and fi is (regularly) locally convex at ¯x for each i ∈I(¯x). Then the
functional f deﬁned by (7.12) is (regularly) locally convex at ¯x.
Proof. This follows immediately from Proposition 7.2.7.
⊓⊔
Proposition 7.2.8 applies, in particular, to the maximum of a ﬁnite number of
continuous Gâteaux diﬀerentiable (resp. Hadamard diﬀerentiable) functionals.
Notice that such a maximum functional in general is not Gâteaux diﬀeren-
tiable (resp. Hadamard diﬀerentiable).
Proposition 4.1.6 stimulates us to deﬁne a subdiﬀerential for locally convex
functionals.
Deﬁnition 7.2.9 If f : E →R is locally convex at ¯x ∈dom f, then
∂∗f(¯x) := {x∗∈E∗| ⟨x∗, y⟩≤fG(¯x, y) ∀y ∈E}
is called locally convex subdiﬀerential of f at ¯x.
If f is convex, then by Proposition 4.1.6 we have ∂∗f(¯x) = ∂f(¯x). Notice
that if fG(¯x, y) = −∞for some y ∈E, then ∂∗f(¯x) is empty.
Proposition 7.2.10 If f : E →R is locally convex at ¯x ∈dom f, then the
following assertions are equivalent:
(a) ∂∗f(¯x) is nonempty.
(b) fG(¯x, ·) is lower semicontinuous at y = o.

7.3 The Subdiﬀerentials of Clarke and Michel–Penot
139
Proof.
(a) =⇒(b): Let x∗∈∂∗f(¯x). Further let k < fG(¯x, o) = 0. Since x∗is
continuous, there exists a neighborhood W of zero in E such that k < ⟨x∗, y⟩≤
fG(¯x, y) for each y ∈W.
(b) =⇒(a): By assumption there exists a neighborhood V of zero in E such
that −1 ≤fG(¯x, y) for each y ∈V . Now let z ∈E be given. Then ηz ∈V
for some η > 0. Since p := fG(¯x, ·) is positively homogeneous, it follows that
−∞< −1
η ≤fG(¯x, z) = p(z). Hence p is proper and sublinear. Moreover, let
q(y) := 1 for y ∈V and q(y) := +∞for y ∈E \ V . Then q is proper, convex,
and continuous at zero. We further have −q(y) ≤p(y) for each y ∈E. The
sandwich theorem (Theorem 1.5.2) thus implies that there exists x∗∈∂∗f(¯x).
⊓⊔
The locally convex subdiﬀerential is an appropriate tool for detecting min-
imizers as is the convex subdiﬀerential (cf. Remark 4.1.2). The following result
is an immediate consequence of the deﬁnitions.
Proposition 7.2.11 If f : E →R is locally convex at ¯x ∈dom f and ¯x is a
local minimizer of f, then o ∈∂∗f(¯x).
7.3 The Subdiﬀerentials of Clarke and Michel–Penot
Convention. Throughout this section, we assume that D ⊆E is open, ¯x ∈D
and f : D →R.
Here, we present two intrinsic constructions for upper convex approxima-
tions. For comparison, recall that
f H(¯x, y) := lim sup
τ↓0
z→y
1
τ

f(¯x + τz) −f(¯x)

.
Deﬁnition 7.3.1 If y ∈E, then
f ◦(¯x, y) := lim sup
τ↓0
x→¯x
1
τ

f(x + τy) −f(x)

(7.16)
is called Clarke directional derivative of f at ¯x in the direction y and
f ♦(¯x, y) := sup
z∈E
lim sup
τ↓0
1
τ

f(¯x + τy + τz) −f(¯x + τz)

(7.17)
is called Michel–Penot directional derivative of f at ¯x in the direction y.
Theorem 7.3.2 Let f be locally L-continuous around ¯x with constant λ > 0.
Then:
(a) f ◦(¯x, ·) and f ♦(¯x, ·) are sublinear and (globally) L-continuous with con-
stant λ on E and satisfy
f H(¯x, y) ≤f ♦(¯x, y) ≤f ◦(¯x, y) ≤λ∥y∥
∀y ∈E.
(7.18)
In particular, f ◦(¯x, ·) and f ♦(¯x, ·) are ﬁnite upper convex approximations
of f at ¯x.

140
7 Derivatives and Subdiﬀerentials of Lipschitz Functionals
(b) For any y ∈E one has
f ◦(¯x, −y) = (−f)◦(¯x, y),
f ♦(¯x, −y) = (−f)♦(¯x, y).
Proof.
(a)(Ia) The third inequality of (7.18) holds. Let y ∈E be ﬁxed. By assump-
tion, we have
1
τ

f(x + τy) −f(x)

≤1
τ λ∥τy∥= λ∥y∥
whenever ∥x −¯x∥and τ > 0 are small. Hence f ◦(¯x, y) ≤λ∥y∥.
(Ib) The second inequality of (7.18) holds. Fix y ∈E. Further let ϵ > 0
be given. For each z ∈E there exists δ(z) > 0 such that (consider
x := ¯x + τz)
1
τ

f(¯x + τy + τz) −f(¯x + τz)

< f ◦(¯x, y) + ϵ
∀τ ∈(0, δ(z)).
This implies
lim sup
τ↓0
1
τ

f(¯x + τy + τz) −f(¯x + τz

≤f ◦(¯x, y) + ϵ,
which holds for each z ∈E. We conclude that f ♦(¯x, y) ≤f ◦(¯x, y) + ϵ.
Letting ϵ ↓0, the assertion follows.
(Ic) The ﬁrst inequality of (7.18) holds. Let y ∈E be ﬁxed. Further let
ϵ > 0 be given. For all suﬃciently small τ > 0 and all z ∈E such that
∥y −z∥is suﬃciently small, we have
1
τ

f(¯x + τz) −f(¯x)

= 1
τ

f

¯x + τy + τ(z −y)

−f

¯x + τ(z −y)

+ 1
τ

f

¯x + τ(z −y)

−f(¯x)

≤1
τ

f

¯x + τy + τ(z −y)

−f

¯x + τ(z −y)

+ λ∥z −y∥
≤f ♦(¯x, y) + ϵ + λ∥z −y∥.
Letting τ ↓0, z →y, and ﬁnally ϵ ↓0, the ﬁrst inequality follows.
(IIa) f ◦(¯x, ·) is sublinear. It is obvious that f ◦(¯x, ·) is positively homoge-
neous. We show that it is subadditive. Let y1, y2 ∈E. We have
1
τ
&
f

x + τ(y1 + y2)

−f(x)

= 1
τ
&
f

(x + τy2
  
=:ˆx→¯x
) + τy1

−f(x + τy2
  
ˆx→¯x
)

+ 1
τ
&
f(x + τy2) −f(x)

.
Passing on both sides to the limit superior for τ ↓0 and x →¯x, we
obtain
f ◦(¯x, y1 + y2) ≤f ◦(¯x, y1) + f ◦(¯x, y2).

7.3 The Subdiﬀerentials of Clarke and Michel–Penot
141
(IIb) f ♦(¯x, ·) is sublinear. Again we can restrict ourselves to showing sub-
additivity. Let y1, y2 ∈E. Let ϵ > 0 be given. For all τ > suﬃciently
small we obtain
1
τ

f

¯x + τ(y1 + y2) + τz

−f

¯x + τ(y2 + z)

≤f ♦(¯x, y1) + ϵ
2
∀z ∈E,
1
τ

f

¯x + τy2 + τz

−f

¯x + τz)

≤f ♦(¯x, y2) + ϵ
2
∀z ∈E.
Adding these inequalities, we get
1
τ

f
¯x+τ(y1+y2)+τz
−f
¯x+τz
≤f ♦(¯x, y1)+f ♦(¯x, y2)+ϵ
∀z ∈E,
and ﬁnally f ♦(¯x, y1 + y2) ≤f ♦(¯x, y1) + f ♦(¯x, y2).
(IIIa) f ◦(¯x, ·) is L-continuous. Let y1, y2 ∈E. If τ > 0 is small and x is close
to ¯x, we obtain
f(x + τy1) −f(x) =
&
f(x + τy2) −f(x)

+
&
f(x + τy1) −f(x + τy2)

≤
&
f(x + τy2) −f(x)

+ τλ∥y1 −y2∥
and so
f ◦(¯x, y1) ≤f ◦(¯x, y2) + λ∥y1 −y2∥.
By an analogous estimate with y1 and y2 interchanged, we see that
|f ◦(¯x, y1) −f ◦(¯x, y2)| ≤λ∥y1 −y2∥.
(IIIb) Analogously, the L-continuity of f ♦(¯x, ·) is veriﬁed.
(b)(IVa) We immediately obtain
f ◦(¯x, −y) = lim sup
τ↓0
x→¯x
1
τ
&
f(x −τy) −f(x)

= lim sup
τ↓0
ˆx→¯x
1
τ
&
(−f)(ˆx + τy) −(−f)(ˆx)

= (−f)◦(¯x, y);
in this connection, ˆx stands for x −τy.
(IVb) For any z ∈E we have
lim sup
τ↓0
1
τ
&
f(¯x −τy + τz) −f(¯x + τz)

= lim sup
τ↓0
&
(−f)(¯x + τy + τ(z −y)) −(−f)(¯x + τ(z −y)

.
Taking the supremum over z and z −y, respectively, gives the second
statement of (b).
⊓⊔

142
7 Derivatives and Subdiﬀerentials of Lipschitz Functionals
f
π
x
f ♦(π, ·)
= f ◦(π, ·)
f H(π, ·)
y
Fig. 7.4
Example 7.3.3 Let E := R, f(x) := |x| −| sin x|, and ¯x := π. Then we have
f H(π, y) =

2y
if y < 0,
0
if y ≥0,
f ♦(π, y) = f ◦(π, y) =

0
if y < 0,
2y
if y ≥0.
We see that of the three directional derivatives, the functional f H(π, ·) is the
best local approximation of f at π but it is not convex (Fig. 7.4).
Recall (see Proposition 4.1.6) that if f is convex, then
∂f(¯x) = {x∗∈E∗ ⟨x∗, y⟩≤fG(¯x, y) ∀y ∈E}.
In the nonconvex case, we now give the following:
Deﬁnition 7.3.4 If f is locally L-continuous around ¯x, then
∂◦f(¯x) := {x∗∈E∗| ⟨x∗, y⟩≤f ◦(¯x, y) ∀y ∈E}
is called Clarke subdiﬀerential, or Clarke generalized gradient, of f at ¯x and
∂♦f(¯x) := {x∗∈E∗| ⟨x∗, y⟩≤f ♦(¯x, y) ∀y ∈E}
is called Michel–Penot subdiﬀerential of f at ¯x.
Proposition 7.3.5 If f is locally L-continuous around ¯x, then for any σ ∈R
one has
∂◦(σf)(¯x) = σ∂◦f(¯x)
and
∂♦(σf)(¯x) = σ∂♦f(¯x).

7.3 The Subdiﬀerentials of Clarke and Michel–Penot
143
Proof. We consider ∂◦f; for ∂♦f the proof is analogous. If σ ≥0, the formula
follows immediately from (σf)◦(¯x, ·) = σf ◦(¯x, ·). Thus it remains to verify it
for σ = −1. We have
∂◦(−f)(¯x) = {x∗∈E∗| ⟨x∗, y⟩≤(−f)◦(¯x, y) ∀y ∈E}
= {x∗∈E∗| ⟨x∗, −z⟩≤f ◦(¯x, z) ∀z ∈E}
= −∂◦f(¯x).
Here the second equation holds by Theorem 7.3.2(b) and with z := −y.
⊓⊔
The importance of the subdiﬀerentials introduced above reveals:
Proposition 7.3.6 If f is locally L-continuous around ¯x and ¯x is a local
minimizer or a local maximizer of f, then o ∈∂◦f(¯x) and o ∈∂♦f(¯x).
Proof. If ¯x is a local minimizer of f, then for any y ∈E we obtain
0 ≤lim inf
τ↓0
1
τ

f(¯x + τy) −f(¯x)

≤lim sup
τ↓0
1
τ

f(¯x + τy) −f(¯x)

≤f ◦(¯x, y).
(7.19)
The deﬁnition of ∂◦f(¯x) now shows that o ∈∂◦f(¯x). If ¯x is a local maximizer
of f, then ¯x is a local minimizer of −f and so o ∈∂◦(−f)(¯x) = −∂◦f(¯x) (the
latter by Proposition 7.3.5). The proof for ∂♦f is analogous.
⊓⊔
We establish further properties of the subdiﬀerentials.
Proposition 7.3.7 Let f be locally L-continuous around ¯x with constant λ > 0.
Then:
(a) The subdiﬀerentials ∂◦f(¯x) and ∂♦f(¯x) are nonempty, convex, and
σ(E∗, E)-compact, and satisfy
∂♦f(¯x) ⊆∂◦f(¯x) ⊆BE∗(o, λ).
(b) One has
f ◦(¯x, y) = max{⟨x∗, y⟩| x∗∈∂◦f(¯x)}
∀y ∈E,
f ♦(¯x, y) = max{⟨x∗, y⟩| x∗∈∂♦f(¯x)}
∀y ∈E.
Proof. Taking Theorem 7.3.2(a) into consideration, the assertions follow as
those of Proposition 4.1.6(b).
⊓⊔
Observe that, beside the lower semicontinuity, it is the sublinearity of
f ◦(¯x, ·) and f ♦(x, ·) that ensures the nonemptyness of the respective subdif-
ferential. If we choose, say, f H(¯x, ·) instead, we obtain for the function f of
Example 7.3.3,
{x∗∈E∗| ⟨x∗, y⟩≤f H(π, y)
∀y ∈E} = ∅.

144
7 Derivatives and Subdiﬀerentials of Lipschitz Functionals
Proposition 7.3.8 If f : E →R is locally L-continuous on E, then:
(a) The functional (x, y) →f ◦(x, y) is upper semicontinuous on E × E.
(b) Let (xk) and (x∗
k) be sequences in E and E∗, respectively, such that x∗
k ∈
∂◦f(xk) for all k ∈N. Assume that (xk) converges to ¯x ∈E as k →∞
and that x∗∈E∗is a σ(E∗, E)-cluster point of (x∗
k). Then one has x∗∈
∂◦f(¯x). (That is, graph(∂◦f) is a norm–weak∗closed subset of E × E∗.)
(c) The subdiﬀerential mapping ∂◦f : E ⇒E∗is norm-to-weak∗upper semi-
continuous.
Proof.
(a) Let (xk) and (yk) be sequences converging to ¯x ∈E and ¯y ∈E, respec-
tively. By deﬁnition of f ◦, for each k there exist zk ∈E and τk > 0 such
that ∥zk −xk∥+ τk < 1
k and
f ◦(xk, yk) −1
k ≤f(zk + τkyk) −f(zk)
τk
= f(zk + τk¯y) −f(zk)
τk
+ f(zk + τkyk) −f(zk + τk¯y)
τk
≤f(zk + τk¯y) −f(zk)
τk
+ λ∥yk −¯y∥;
in the last term, λ > 0 denotes a Lipschitz constant of f near ¯x. By letting
k →∞, the deﬁnition of the upper limit gives lim supk→∞f ◦(xk, yk) ≤
f ◦(¯x, ¯y). Hence f ◦is u.s.c. at (¯x, ¯y).
(b) Let y ∈E be given. Some subsequence of (⟨x∗
k, y⟩), again denoted (⟨x∗
k, y⟩),
satisﬁes ⟨x∗
k, y⟩→⟨x∗, y⟩as k →∞. By the deﬁnition of ∂◦f we have
⟨x∗
k, y⟩≤f ◦(xk, y) for all k. Letting k →∞, we conclude from (a) that
⟨x∗, y⟩≤f ◦(¯x, y). Since y ∈E was arbitrary, we obtain x∗∈∂◦f(¯x).
(c) The proof is analogous to that of Proposition 4.3.2(a). (Notice that by
Proposition 7.3.7(a), the multifunction ∂◦f is locally bounded at any
¯x ∈E.)
⊓⊔
Statement (b) of Proposition 7.3.8 will be crucial for deriving a chain rule
in Sect. 7.4 as well as a multiplier rule in Sect. 12.4. Now we establish rela-
tionships between the various notions. Recall the convention at the beginning
of this section.
Proposition 7.3.9
(a) If fG(¯x, ·) exists and is sublinear on E, then f ♦(¯x, y) = fG(¯x, y) for each
y ∈E. In particular, if f is G-diﬀerentiable at ¯x, then ∂♦f(¯x) = {f ′(¯x)}.
(b) If f is locally L-continuous around ¯x and G-diﬀerentiable at ¯x, then
f ′(¯x) ∈∂◦f(¯x).

7.3 The Subdiﬀerentials of Clarke and Michel–Penot
145
(c) If f is strictly H-diﬀerentiable at ¯x, then f is locally L-continuous around ¯x
and f ◦(¯x, y) = ⟨f ′(¯x), y⟩for each y ∈E and ∂♦f(¯x) = ∂◦f(¯x) = {f ′(¯x)}.
(d) If D is convex and f is convex and locally L-continuous around ¯x, then
f ♦(¯x, y) = f ◦(¯x, y) = fH(¯x, y) for each y ∈E and ∂♦f(¯x) = ∂◦f(¯x) =
∂f(¯x).
Proof.
(a) It is clear that fG(¯x, ·) ≤f ♦(¯x, ·). We show the reverse inequality. For
each y ∈E we have
f ♦(¯x, y)
≤sup
z∈E

lim sup
τ↓0
1
τ

f(¯x + τy + τz) −f(¯x)

+lim sup
τ↓0
1
τ

f(¯x) −f(¯x + τz)

= sup
z∈E

fG(¯x, y + z) −fG(¯x, z)

≤fG(¯x, y);
here, the last inequality holds because fG(¯x, ·) is subadditive. The second
statement follows immediately from the deﬁnition of ∂♦f(¯x).
(b) If y ∈E, then
⟨f ′(¯x), y⟩= lim
τ↓0
1
τ
&
f(¯x+τy)−f(¯x)

≤lim sup
τ↓0
x→¯x
1
τ
&
f(x+τy)−f(x)

=f ◦(¯x, y)
and so f ′(¯x) ∈∂◦f(¯x).
(c) By Proposition 3.2.4, f is locally L-continuous around ¯x and strictly G-
diﬀerentiable at ¯x. We therefore have
⟨f ′(¯x), y⟩= lim
τ→0
x→¯x
1
τ
&
f(x + τy) −f(x)

= f ◦(¯x, y)
∀y ∈E
and so ∂◦f(¯x) = {f ′(¯x)} = ∂♦f(¯x).
(d) Let δ > 0. Then
f ◦(¯x, y) =
inf
ϵ∈(0,ϵ0)
sup
τ∈(0,ϵ)
x∈B(¯x,δϵ)
1
τ
&
f(x + τy) −f(x)

=
inf
ϵ∈(0,ϵ0)
sup
x∈B(¯x,δϵ)
1
ϵ
&
f(x + ϵy) −f(x)

;
(7.20)
here the ﬁrst equation is a consequence of the deﬁnition of the limit su-
perior, and the second holds by Theorem 4.1.3(a) because f is convex.
Denoting the Lipschitz constant of f around ¯x by λ, we further obtain
1
ϵ
&
f(x + ϵy) −f(x)

−
&
f(¯x + ϵy) −f(¯x)

≤1
ϵ
f(x + ϵy) −f(¯x + ϵy)
 +
f(¯x) −f(x)

≤2δλ,

146
7 Derivatives and Subdiﬀerentials of Lipschitz Functionals
provided ∥x−¯x∥< δϵ and ϵ is suﬃciently small. With this estimate, (7.20)
passes into
f ◦(¯x, y) ≤
inf
ϵ∈(0,ϵ0)
1
ϵ
&
f(¯x + ϵy) −f(¯x)

+ 2δλ
= fG(¯x, y) + 2δλ = fH(¯x, y) + 2δλ;
here the second equation holds by Proposition 4.1.8. Since δ > 0 was
arbitrary, it follows that f ◦(¯x, y) ≤fH(¯x, y). Since the reverse inequality
always holds, we obtain f ◦(¯x, y) = fH(¯x, y) and so ∂◦f(¯x) = ∂f(¯x). The
assertion concerning f ♦(¯x, ·) and ∂♦f(¯x) follows from this and (a) since
by Theorem 4.1.3(d), fH(¯x, ·) and so fG(¯x, ·) exists and is sublinear.
⊓⊔
Remark 7.3.10
(a) Proposition 7.3.9 shows that the Michel–Penot subdiﬀerential is a gener-
alization of the G-derivative while the Clarke subdiﬀerential generalizes
the strict H-derivative.
(b) Since we always have ∂♦f(¯x) ⊆∂◦f(¯x) (Proposition 7.3.7) and the in-
clusion may be proper (see Example 7.3.11), the necessary optimality
condition o ∈∂♦f(¯x) (Proposition 7.3.6) is in general stronger than the
condition o ∈∂◦f(¯x).
Example 7.3.11 Let E := R and f(x) := x2 sin 1
x for x ̸= 0, f(0) := 0.
Then f is locally L-continuous and diﬀerentiable at 0, with f ′(0) = 0. By
Proposition 7.3.9 we have f ♦(0, y) = 0 for each y ∈R and ∂♦f(0) = {0}. On
the other hand, we obtain f ◦(0, y) = |y| for each y ∈R and so ∂◦f(0) = [−1, 1].
Notice that f is not strictly diﬀerentiable at 0.
Recall that a locally L-continuous function f : Rn →R is diﬀerentiable
almost everywhere, i.e., outside a set Ωf of n-dimensional Lebesgue measure
zero (Theorem of Rademacher, see, for instance, Evans and Gariepy [63]).
Theorem 7.3.12 If f : Rn →R is locally L-continuous around ¯x and S ⊆Rn
has n-dimensional Lebesgue measure zero, then one has
∂◦f(¯x) = co

lim
k→∞f ′(xk)
 xk →¯x, xk /∈Ωf ∪S}.
For a proof of Theorem 7.3.12 we refer to Clarke [36].
7.4 Subdiﬀerential Calculus
The following notion will serve to reﬁne certain computation rules for the
subdiﬀerentials.
Deﬁnition 7.4.1 The functional f : D →R is called regular (in the sense of
Clarke) at ¯x if fG(¯x, ·) and f ◦(¯x, ·) both exist and coincide.

7.4 Subdiﬀerential Calculus
147
Remark 7.4.2
(a) If f is regular at ¯x, then together with f ◦(¯x, ·) the functional fG(¯x, ·)
is sublinear and so the two functionals also coincide with f ♦(¯x, ·)
(Proposition 7.3.9).
(b) Let the functional f : D →R be locally L-continuous around ¯x. Then it
is regular at ¯x if it is strictly H-diﬀerentiable or if D and f are convex
(Proposition 7.3.9).
Concerning the following computation rules, compare Proposition 4.5.1.
Proposition 7.4.3 (Sum Rule) Let f0, f1, . . . , fn : D →R be locally L-
continuous around ¯x:
(a) One has
∂◦
 n
	
i=0
fi

(¯x) ⊆
n
	
i=0
∂◦fi(¯x)
and
∂♦
 n
	
i=0
fi

(¯x) ⊆
n
	
i=0
∂♦fi(¯x).
(7.21)
(b) If f1, . . . , fn are strictly H-diﬀerentiable at ¯x, then (7.21) holds with equal-
ity in both cases.
(c) If f0, f1, . . . , fn are regular at ¯x, then
n
i=0
fi is regular at ¯x and (7.21)
holds with equality in both cases.
Proof.
(a) We verify the statement for the Clarke subdiﬀerential, leaving the veri-
ﬁcation for the Michel–Penot subdiﬀerential as Exercise 7.5.4. Moreover,
we conﬁne ourselves to the case n = 1; the general case then follows by
induction. Since by Proposition 7.3.7, we have f ◦
i (¯x, y) = max{⟨v, y⟩| v ∈
∂◦fi(¯x)} for i = 0, 1, we conclude that:
– The support functional of ∂◦(f0 + f1)(¯x) is (f0 + f1)◦(¯x, ·).
– The support functional of ∂◦f0(¯x) + ∂◦f1(¯x) is f ◦
0 (¯x, ·) + f ◦
1 (¯x, ·).
From the deﬁnition of the Clarke directional derivative we easily obtain
(f0 + f1)◦(¯x, y) ≤f ◦
0 (¯x, y) + f ◦
1 (¯x, y)
∀y ∈E.
(7.22)
Hence the assertion follows by the H¨ormander theorem (Theorem 2.3.1(c)).
(b) The assumption implies that the functional f1 + · · · + fn is also strictly
H-diﬀerentiable. Therefore it suﬃces to consider the case n = 1. It is easy
to show that
(f0 + f1)◦(¯x, y) = f ◦
0 (¯x, y) + ⟨f ′
1(¯x), y⟩= f ◦
0 (¯x, y) + f ◦
1 (¯x, y)
∀y ∈E.
This together with (a) yields the assertion for the Clarke subdiﬀerential.
Again the proof is analogous for the Michel–Penot subdiﬀerential.

148
7 Derivatives and Subdiﬀerentials of Lipschitz Functionals
(c) By assumption we obtain
(f0 + f1)G(¯x, y)
= f0,G(¯x, y) + f1,G(¯x, y) = f ◦
0 (¯x, y) + f ◦
1 (¯x, y)
≥
(7.22)
(f0 + f1)◦(¯x, y).
On the other hand, we always have (f0 + f1)◦(¯x, y) ≥(f0 + f1)G(¯x, y).
Therefore f0 + f1 is regular at ¯x. Moreover, by what has just been shown
we see that
(f0 + f1)◦(¯x, y) = f ◦
0 (¯x, y) + f ◦
1 (¯x, y)
∀y ∈E.
From this, the assertion again follows by the H¨ormander theorem since
the left-hand side is the support functional of ∂◦(f0+f1)(¯x) and the right-
hand side is the support functional of ∂◦f0(¯x) + ∂◦f1(¯x). Remark 7.4.2(a)
completes the proof.
⊓⊔
Next we establish a mean value theorem. If x, y ∈E and A ⊆E∗, we write
[x, y] := {(1 −τ)x + τy | τ ∈[0, 1]},
(x, y) := {(1 −τ)x + τy | τ ∈(0, 1)},
⟨A, x⟩:= {⟨x∗, x⟩| x∗∈A}.
Theorem 7.4.4 (Mean Value Theorem) Assume that f : D →R is loc-
ally L-continuous and [x, y] ⊆D. Then there exists z ∈(x, y) satisfying
f(y) −f(x) ∈⟨∂◦f(z), y −x⟩.
(7.23)
Proof.
(I) For λ ∈[0, 1] let xλ := x + λ(y −x). Deﬁne ϕ, ψ : [0, 1] →R by
ϕ(λ) := ψ(λ) + λ

f(x) −f(y)

,
ψ(λ) := f(xλ).
Since ϕ(0) = ϕ(1) = f(x), the continuous function ϕ attains a local
minimum or a local maximum at some λ0 ∈(0, 1). Therefore 0 ∈∂◦ϕ(λ0)
(Proposition 7.3.6). By Propositions 7.3.5 and 7.4.3 we obtain
0 ∈∂◦ψ(λ0) +

f(x) −f(y)

.
(7.24)
(II) We show that
∂◦ψ(λ) ⊆⟨∂◦f(xλ), y −x⟩
∀λ ∈(0, 1).
(7.25)
Observe that ψ is L-continuous on (0, 1) so that ∂◦ψ makes sense. Also
notice that the two sets in (7.25) are closed convex subsets of R and so
are intervals. Hence it suﬃces to prove that
max

a∂◦ψ(λ)

≤max

a⟨∂◦f(xλ), y −x⟩

for a = ±1.

7.4 Subdiﬀerential Calculus
149
This is veriﬁed as follows:
max

a∂◦ψ(λ)

= ψ◦(λ, a) = lim sup
τ↓0
λ′→λ
1
τ

ψ(λ′ + τa) −ψ(λ′)

= lim sup
τ↓0
λ′→λ
1
τ
&
f

x + (λ′ + τa)(y −x)

−f

x + τ(y −x)

≤lim sup
τ↓0
z→xλ
1
τ
&
f

z + τa(y −x)

−f(z)

= f ◦(xλ, a(y −x)) = max⟨∂◦f(xλ), a(y −x)⟩.
In view of (7.24) and (7.25) the proof is complete on setting z := xλ0.
⊓⊔
Finally we establish a chain rule. We consider the composite function
g ◦h : E →R, where
h : E →Rn,
g : Rn →R,
(g ◦h)(x) := g

h(x)

,
x ∈E.
(7.26)
We identify

Rn∗with Rn, put h = (h1, . . . , hn) with hi : E →R, and deﬁne
for any a ∈Rn,
ha(x) := ⟨a, h(x)⟩Rn,
x ∈E.
(7.27)
Recall that co∗A denotes the σ(E∗, E)-closed convex hull of the set A ⊆E∗.
Theorem 7.4.5 (Chain Rule) Let g and h be as in (7.26). Assume that h
is locally L-continuous around ¯x ∈E and g is locally L-continuous around
h(¯x). Then:
(a) The composite function g ◦h is locally L-continuous around ¯x, and there
holds
∂◦(g ◦h)(¯x) ⊆co∗{∂◦ha(¯x) | a ∈∂◦g

h(¯x)

}.
(7.28)
(b) If, in addition, g is regular at h(¯x), any hi is regular at ¯x, and any a ∈
∂◦g

h(¯x)

has nonnegative components, then (7.28) holds as equality and
g ◦h is regular at ¯x.
Proof.
(I) Set f := g ◦h. It is easy to see that f is locally L-continuous around ¯x.
(II) Denote the set on the right-hand side of the inclusion (7.28) by M.
The sets ∂◦f(¯x) and M are nonempty, convex, and σ(E∗.E)-compact.
Therefore (7.28) holds if and only if the associated support functions
satisfy σ∂◦f(¯x) ≤σM. By Proposition 7.3.7, we have σ∂◦f(¯x) = f ◦(¯x, ·).
Hence the theorem is veriﬁed if we can show that
f ◦(¯x, y) ≤σM(y)
∀y ∈E.
(7.29)

150
7 Derivatives and Subdiﬀerentials of Lipschitz Functionals
(III) To verify (7.29), let y ∈E be given. We shall construct elements a ∈
∂◦g

h(¯x)

and y∗∈∂◦ha(¯x) satisfying
f ◦(¯x, y) ≤⟨y∗, y⟩.
(7.30)
Choose sequences τk ↓0 and xk →¯x such that
lim
k→∞
1
τk

f(xk + τky) −f(xk)

= f ◦(¯x, y).
By the mean value theorem (Theorem 7.4.4) there exist zk ∈[h(xk),
h(xk + τky)] and ak ∈∂◦g(zk) satisfying
1
τk

f(xk + τky) −f(xk)

= 1
τk
#
g

h(xk + τky)

−g

h(xk)
$
=
2
ak, 1
τk

h(xk + τky) −h(xk)
3
Rn.
(7.31)
Let λ be a local Lipschitz constant of g at h(¯x). Since zk →h(¯x) as
k →∞, we conclude that for k suﬃciently large, λ is also a Lipschitz
constant of g at zk and so ∥ak∥≤λ (Proposition 7.3.7(a)). A subse-
quence of the sequence (ak), again denoted (ak), is thus convergent to
some a ∈Rn. Proposition 7.3.7(c) shows that a ∈∂◦g

h(¯x)

.
(IV) Again by the mean value theorem there exist yk ∈[xk, xk + τky] and
y∗
k ∈∂◦ha(yk) such that
2
a, 1
τk

h(xk + τky) −h(xk)
3
Rn = ⟨y∗
k, y⟩.
(7.32)
As above it follows that the sequences (y∗
k) and (⟨y∗
k, y⟩) are bounded
in E∗and R, respectively. Let again denote (⟨y∗
k, y⟩) a convergent sub-
sequence and let y∗∈E∗be a σ(E∗, E)-cluster point of (y∗
k). Then
⟨y∗
k, y⟩→⟨y∗, y⟩as k →∞and y∗∈∂◦ha(¯x) by Proposition 7.3.7(c).
(V) Combining (7.31) and (7.32) we obtain
1
τk

f(xk + τky) −f(xk)

=
2
ak −a, 1
τ

h(xk + τky) −h(xk)
3
Rn + ⟨y∗
k, y⟩.
Since h is locally L-continuous around ¯x and xk
→
¯x, the term
τ −1
k

h(xk +τky)−h(xk)

is bounded. Moreover, we have ak →a. There-
fore we obtain
f ◦(¯x, y) = lim
k→∞
1
τk

f(xk + τky) −f(xk)

= ⟨y∗, y⟩,
which proves (a). The veriﬁcation of (b) is left as Exercise 7.5.5.
⊓⊔

7.4 Subdiﬀerential Calculus
151
We consider the special case that g is strictly H-diﬀerentiable at h(¯x).
Recall that Dig, where i = 1, . . . , n, denotes the partial derivative of g with
respect to the ith variable.
Corollary 7.4.6 Let g and h be as in (7.26). Assume that h is locally L-
continuous around ¯x ∈E and g is strictly H-diﬀerentiable at h(¯x). Then the
composite function g ◦h is locally L-continuous around ¯x, and there holds
∂◦(g ◦h)(¯x) ⊆
n
	
i=1
Dig

h(¯x)

∂◦hi(¯x).
(7.33)
In particular, if n = 1, then
∂◦(g ◦h)(¯x) = g′
h(¯x)

∂◦h(¯x).
(7.34)
Proof.
(I) By Proposition 7.3.9(c) we have ∂◦g

h(¯x)

= {g′
h(¯x)

} and so, with
a = g′
h(¯x)

,
ha(x) =
n
	
i=1
Dig

h(¯x)

hi(x),
x ∈E.
The inclusion (7.33) now follows by applying Theorem 7.4.5 and
Propositions 7.3.5 and 7.4.3. The co∗operation is superﬂuous here
since with each ∂◦hi(¯x) the set on the right-hand side of (7.33) is
σ(E∗, E)-compact and convex.
(II) Now let n = 1. Deﬁne γ : E →R by
γ(y) := max{g′
h(¯x)

⟨x∗, y⟩| x∗∈∂◦h(¯x)}.
For any y ∈E we have
γ(y) = g′
h(¯x)

h◦(¯x, y) = lim sup
τ↓0
x→¯x
1
τ g′
h(¯x)

h(x + τy) −h(x)

= lim sup
τ↓0
x→¯x
1
τ
#
g

h(x + τy)

−g

h(x)
$
= (g ◦h)◦(¯x, y).
Here, the ﬁrst equation holds by Proposition 7.3.7(b) and the third
is a consequence of the strict H-diﬀerentiability of g. The assertion
(7.34) follows because γ is the support function of g′
h(¯x)

∂◦h(¯x) and
(g ◦h)◦(¯x, ·) is the support function of ∂◦(g ◦h)(¯x).
⊓⊔
Given a ﬁnite family of functionals fi : D →R, i ∈I, we consider the
maximum functional f : D →R deﬁned by
f(x) := max{fi(x) | i ∈I},
x ∈D.
(7.35)

152
7 Derivatives and Subdiﬀerentials of Lipschitz Functionals
Let ¯x ∈D. As in Sect. 7.2 we set
I(¯x) := {i ∈I | fi(¯x) = f(¯x)}.
Proposition 7.4.7 (Maximum Rule) Let I be a ﬁnite set and for all i ∈I
let fi : D →R be locally L-continuous around ¯x. Then the functional f deﬁned
by (7.35) satisﬁes
∂◦f(¯x) ⊆co{∂◦fi(¯x) | i ∈I(¯x)}
and
∂♦f(¯x) ⊆co{∂♦fi(¯x) | i ∈I(¯x)}.
(7.36)
If, in addition, fi is regular at ¯x for any i ∈I(¯x), then the ﬁrst inclusion in
(7.36) holds with equality and f is regular at ¯x.
Proof. We verify (7.36) for the Michel–Penot subdiﬀerential, leaving the proof
for the Clarke subdiﬀerential as Exercise 7.5.6.
(I)
As in the proof of Proposition 7.2.7 it can be shown that for i ∈I \ I(¯x)
the functional fi does not contribute to f ♦(¯x, ·).
(II) Let y ∈E be given. Choose sequences (zn) in E and (τn) in (0, +∞) such
that τn ↓0 and
1
τn

f(¯x + τny + τnzn) −f(¯x + τnzn)

→f ♦(¯x, y)
as n →∞.
Without loss of generality we may assume that for suitable subsequences,
again denoted (zn) and (τn), we have for some i ∈I(¯x),
f(¯x + τny + τnzn) = fi(¯x + τny + τnzn).
It follows that
f ♦
i (¯x, y) ≥lim sup
n→∞
1
τn

fi(¯x + τny + τnzn) −fi(¯x + τnzn)

≥lim sup
n→∞
1
τn

f(¯x + τny + τnzn) −f(¯x + τnzn)

= f ♦(¯x, y)
and so f ♦(¯x, ·)
≤
f ♦
i (¯x, ·)
≤
maxi∈I(¯x) f ♦
i (¯x, ·). Since f ♦(¯x, ·) is the
support functional of ∂♦f(¯x) (Proposition 7.3.7) and so equals δ∗
∂♦f(¯x)
(Example 2.2.5), we conclude that, setting M := co{∂♦fi(¯x) | i ∈I(¯x)},
we have
δ∗
∂♦f(¯x) ≤max
i∈I(¯x) δ∗
∂♦fi(¯x) = δ∗
M;
here the equality sign is easily veriﬁed. By Proposition 7.3.7 the set M is
nonempty, convex, and σ(E∗, E)-compact and so δM is proper, convex, and
l.s.c. Hence Theorem 2.2.4 gives δM = δ∗∗
M ≤δ∗∗
∂♦f(¯x)) = δ∂♦f(¯x), and we
conclude that ∂♦f(¯x) ⊆M.
⊓⊔

7.5 Bibliographical Notes and Exercises
153
7.5 Bibliographical Notes and Exercises
(Radial) upper convex approximations were introduced and studied by
Neustadt [150] and Pshenichnyi [168] (see also Scheﬄer [190] and Scheﬄer
and Schirotzek [192]). (Regularly) locally convex functionals are considered
by Ioﬀe and Tikhomirov [101]. Demyanov and Rubinov [47, 48] studied qua-
sidiﬀerentiable functionals in detail (see also Luderer et al. [126] and the
literature cited therein).
Clarke’s doctoral thesis [33] marks a breakthrough in that it gives, for
Lipschitz functions on Rn, the ﬁrst intrinsic (nonaxiomatic) approach to
generalized directional derivatives. The characterization of ∂◦f(¯x) given in
Theorem 7.3.12 is Clarke’s original deﬁnition in the ﬁnite-dimensional case.
A remarkable generalization of this characterization to Banach spaces with a
β-smooth norm is due to Preiss [166].
Clarke [36] systematically elaborated his concept in normed vector spaces.
The mean value theorem (Theorem 7.4.4) is due to Lebourg [119]. For further
results of this kind see Hiriart-Urruty [86], Penot [163], and Studniarski [202,
203]. A mean value theorem in terms of radial upper convex approximations
that encompasses Lebourg’s mean value theorem is due to Scheﬄer [191]. For
applications of Clarke’s directional derivative and subdiﬀerential to various
problems we refer to Clarke [36], Clarke et al. [39], Loewen [123], M¨akel¨a and
Neittaanm¨aki [149], Panagiotopoulos [157], Papageorgiou and Gasinski [158],
and the references in these books. The Michel–Penot directional derivative
and subdiﬀerential (see [129,130]) are considered, among others, by Borwein
and Lewis [18] and Ioﬀe [99].
Exercise 7.5.1 Prove Proposition 7.2.2.
Hint: Compare the proof of Lemma 3.1.2.
Exercise 7.5.2 Deﬁne f : R2 →R by f(x1, x2) := 0 if x1 ≥0 and
f(x1, x2) := 1 otherwise. Show that f is locally convex but not regularly
locally convex at ¯x := (0, 0).
Exercise 7.5.3 Prove Proposition 7.2.7 for the directional H-derivative.
Exercise 7.5.4 Verify Proposition 7.4.3 for the Michel–Penot subdiﬀerential.
Exercise 7.5.5 Verify assertion (b) of Theorem 7.4.5.
Exercise 7.5.6 Prove Proposition 7.4.7 for the Clarke subdiﬀerential.
Hint: Deﬁne g : Rn →R and h : E →Rn by
g(z1, . . . , zn) := max{z1, . . . , zn},
h(x) :=

f1(x), . . . , fn(x)

.
Observe that f = g ◦h and apply Theorem 7.4.5.

8
Variational Principles
8.1 Introduction
Convention. In this chapter, unless otherwise speciﬁed, assume that E is a
Banach space and f : E →R is proper, l.s.c., and bounded below.
The theory of generalized directional derivatives and subdiﬀerentials con-
sidered so far for both convex and nonconvex functionals is essentially based on
separation and so on convexity arguments; consider, e.g., the proofs of the sum
rules (Propositions 4.5.1 and 7.4.3) and the maximum rule (Proposition 7.4.7),
where the crucial tool is the sandwich theorem, the H¨ormander theorem, and
the biconjugation theorem, respectively. These tools were applicable since the
derivative-like objects constructed are convex. It turns out that a correspond-
ing theory not enforcing convexity and working beyond the Lipschitz case
requires quite diﬀerent tools. In the following we establish variational prin-
ciples as well as extremal principles, which have proved to be adequate for
treating lower semicontinuous functionals. (To be precise, Clarke’s multiplier
rule for Lipschitz functionals to be derived in Sect. 12.4 also hinges on a vari-
ational principle.)
First we explain the idea of variational principles. It is clear that a func-
tional f as above may fail to have a global minimizer. However, since f is
bounded below, there are points that “almost” minimize f, i.e., for each ϵ > 0
there exists ¯x ∈E satisfying
f(¯x) ≤inf
x∈E f(x) + ϵ.
Ekeland [56] showed that for each such ¯x and each λ > 0 there exists a
point z ∈E that actually minimizes the slightly perturbed functional
ϕ(y) := f(y) + ϵ
λ∥z −y∥,
y ∈E,
and is such that ∥z −¯x∥≤λ. This ﬁrst variational principle has remarkable
applications in quite diﬀerent areas of nonlinear analysis (see the references
at the end of this chapter).

156
8 Variational Principles
A drawback of Ekeland’s variational principle is that the perturbed func-
tional ϕ is not diﬀerentiable at y = z even if the original functional f
is diﬀerentiable on all of E. The ﬁrst to overcome this drawback were
Borwein and Preiss [19] who established a smooth variational principle. Mean-
while several smooth variational principles have been derived. We present
below a smooth variational principle due to Loewen and Wang [125] from
which the mentioned variational principles will then be deduced in a uni-
ﬁed way.
8.2 The Loewen–Wang Variational Principle
We write infE f for infx∈E f(x). Recall the notion of a minimizing sequence.
Deﬁnition 8.2.1
(a) A point ¯x ∈E is said to be a strict minimizer of f if f(¯x) < f(x) for
each x ∈E, x ̸= ¯x.
(b) A point ¯x ∈E is said to be a strong minimizer of f if f(¯x) = infE f and
each minimizing sequence for f is convergent to ¯x.
It is clear that each strong minimizer of f is also a strict minimizer. But
the converse is false. For example, the point ¯x = 0 is a strict but not a strong
minimizer of the function f(x) := x2e−x on R; notice that each sequence (xn)
tending to +∞as n →∞is a minimizing sequence for f.
Recall that diam(A) := sup{∥x −y∥| x, y ∈A} denotes the diameter of
the set A ⊆E.
Remark 8.2.2 For ϵ > 0 let
Σϵ(f) := {x ∈E | f(x) ≤inf
E f + ϵ}.
It is left as Exercise 8.5.1 to show that the functional f has a strong minimizer
on E if and only if
inf {diam

Σϵ(f)
  ϵ > 0} = 0.
Now we construct a perturbation ρ∞of f. The data involved will be spec-
iﬁed in Theorem 8.2.3. Let ρ : E →[0, +∞) be such that
ρ(o) = 0,
η := sup{∥x∥| x ∈E, ρ(x) < 1} < +∞
(8.1)
and set
ρ∞(x) :=
∞
	
n=0
µn ρ

(n + 1)(x −zn)

.
(8.2)

8.2 The Loewen–Wang Variational Principle
157
Theorem 8.2.3 (Loewen–Wang) Let ϵ > 0 and let ¯x ∈E be such that
f(¯x) < infE f + ϵ. Assume further that ρ : E →[0, +∞) is a continuous
function satisfying (8.1) and that (µn) is a decreasing sequence in (0, 1) with
∞
n=0 µn < +∞. Then there exists a sequence (zn) in E converging to some
z ∈E such that, with ρ∞according to (8.2), the following holds:
(a) ρ(¯x −z) < 1.
(b) f(z) + ϵρ∞(z) ≤f(¯x).
(c) z is a strong minimizer of f + ϵρ∞on E. In particular,
f(z) + ϵρ∞(z) < f(x) + ϵρ∞(x)
∀x ∈E \ {z}.
(8.3)
Proof.
(I) Set z0 := ¯x, f0 := f. By induction, zn+1 can be chosen (see below) and
fn+1, Dn can be deﬁned for n = 0, 1, . . . in the following way:
fn+1(x) := fn(x) + ϵµn ρ

(n + 1)(x −zn)

,
x ∈E,
(8.4)
fn+1(zn+1) ≤µn+1
2
fn(zn) +

1 −µn+1
2

inf
E fn+1 ≤fn(zn),
(8.5)
Dn :=
0
x ∈E
 fn+1(x) ≤fn+1(zn+1) + µnϵ
2
1
.
(8.6)
We show that zn+1 can be chosen according to (8.5). Note that
infE fn+1 ≤fn+1(zn) = fn(zn). If this inequality is strict, then by
the deﬁnition of the inﬁmum there exists zn+1 ∈E such that
fn+1(zn+1) < inf
E fn+1 + µn+1
2

fn(zn) −inf
E fn+1

.
If equality holds, then choose zn+1 := zn. In either case, (8.5) is satis-
ﬁed.
(II) Since fn+1 is l.s.c., the set Dn is closed. Moreover Dn is nonempty as
zn+1 ∈Dn. Since µn ∈(0, 1) and fn+1 ≥fn, (8.5) implies
fn+1(zn+1) −inf
E fn+1 ≤µn+1
2

fn(zn) −inf
E fn+1

≤fn(zn) −inf
E fn.
(8.7)
(III) We have Dn ⊆Dn−1 for n = 1, 2 . . . In fact, if x ∈Dn, then µn−1 > µn
and (8.5) yield
fn(x) ≤fn+1(x) ≤fn+1(zn+1) + µnϵ
2
≤fn(zn) + µn−1ϵ
2
and so x ∈Dn−1.
(IV) We show that diam(Dn) →0 as n →∞. Since fn−1 ≤fn, (8.5) with
n replaced by n −1 implies
fn(zn) −inf
E fn ≤µn
2

fn−1(zn−1) −inf
E fn

≤µn
2

fn−1(zn−1) −inf
E fn−1

< µnϵ
2 .
(8.8)

158
8 Variational Principles
The last < follows from (8.7) and f0(z0)−infE f0 = f(¯x)−infE f < ϵ.
Now let x ∈Dn. By the deﬁnitions of Dn and fn+1 we obtain
µnϵ ρ

(n + 1)(x −zn)

≤fn+1(zn+1) −fn(x) + µnϵ
2
≤fn+1(zn+1) −inf
E fn + µnϵ
2 .
This inequality together with fn+1(zn+1) ≤fn(zn) (see (8.5)) and (8.8)
shows that
ρ

(n + 1)(x −zn)

< 1
∀n = 0, 1, . . .
(8.9)
The hypothesis (8.1) therefore implies
(n + 1)∥x −zn∥≤η
(8.10)
and so diam(Dn) ≤
2η
n+1 →0 as n →∞.
(V) In view of (III) and (IV), Cantor’s intersection theorem applies to (Dn)
ensuring that ∞
n=0 Dn contains exactly one point, say z. For each n
we have zn+1 ∈Dn and z ∈Dn. Hence ∥zn+1 −z∥→0 as n →∞.
Moreover, setting x = z and n = 0 in (8.9), we see that ρ(z −¯x) < 1.
This veriﬁes (a).
(VI) Next we show that f(z) + ϵρ∞(z) ≤fn(zn) for each n. Let
%Dn := {x ∈E | fn+1(x) ≤fn+1(zn+1)}
for n = 1, 2, . . .
Since fn+1 ≥fn but fn+1(zn+1) ≤fn(zn) (see (8.5)), we have %Dn ⊆
%Dn−1. Moreover, each %Dn is a nonempty closed subset of Dn. Therefore
∞
n=1 %Dn = {z}. This together with fn+1(zn+1) ≤fn(zn) implies
fk(z) ≤fk(zk) ≤fn(zn) ≤f0(z0) = f(¯x)
∀k > n.
From (8.4) we get
fk(x) = f(x) + ϵ
k−1
	
j=0
µjρ

(j + 1)(x −zj)

,
x ∈E.
(8.11)
Recalling (8.2), we conclude that
f(z) + ϵρ∞(z) = lim
k→∞fk(z) ≤fn(zn) ≤f(¯x).
(8.12)
This was claimed above and this also veriﬁes (b).
(VII) Let ˜f := f + ϵρ∞. We show that Σµnϵ/2( ˜f) ⊆Dn for each n. Thus let
x ∈Σµnϵ/2( ˜f). Then
fn+1(x)
≤
(8.11)
˜f(x) ≤˜f(z) + µnϵ
2
≤
(8.12)
fn+1(zn+1) + µnϵ
2
and so indeed x ∈Dn.

8.2 The Loewen–Wang Variational Principle
159
(VIII) Since the sequence (µn) is decreasing, the sequence of the closed sets
Σµnϵ/2( ˜f) is decreasing with respect to inclusion and so (V) and (VII)
give ∞
n=0 Σµnϵ/2( ˜f) = {z}. Hence z is a minimizer of ˜f. By (IV) and
(VII) we have
lim
n→∞diam

Σµnϵ/2( ˜f)

= 0.
Hence Remark 8.2.2 ﬁnally tells us that z is even a strong minimizer
of ˜f.
⊓⊔
As a ﬁrst corollary to Theorem 8.2.3 we derive a Banach space variant of
Ekeland’s variational principle, with the additional property that the mini-
mizer of the perturbed functional is strong.
Theorem 8.2.4 (Ekeland) Let ϵ > 0 and let ¯x ∈E be such that f(¯x) <
infE f + ϵ. Then for any λ > 0 there exists z ∈E such that:
(a) ∥¯x −z∥< λ.
(b) z is a strong minimizer of the functional x →f(x) + ϵ
λ∥x −z∥on E.
In particular,
f(z) < f(x) + ϵ
λ∥x −z∥
∀x ∈E \ {z}.
(8.13)
Proof. Set
ρ(x) := ∥x∥
λ ,
µn :=
1
2n+1(n + 1).
By Theorem 8.2.3 there exist a sequence (zn) and a point z in E such that,
in particular, (8.3) holds true, i.e., for each x ̸= z we have
f(z) < f(x) + ϵ

ρ∞(x) −ρ∞(z)

= f(x) + ϵ
λ
∞
	
n=0
1
2n+1 (∥x −zn∥−∥z −zn∥)
≤f(x) + ϵ
λ
∞
	
n=0
1
2n+1 ∥x −z∥= f(x) + ϵ
λ∥x −z∥.
(8.14)
This veriﬁes (8.13). Now let (xn) be a minimizing sequence for ϕ(x) := f(x)+
ϵ
λ∥x −z∥, i.e., ϕ(xn) →infE ϕ = f(z) as n →∞. Then (8.14) shows that
(xn) is a minimizing sequence for f + ϵρ∞. By Theorem 8.2.3(c) we conclude
that xn →z. Hence z is a strong minimizer of ϕ.
⊓⊔
Corollary 8.2.5 Let ϵ > 0 and let ¯x ∈E be such that f(¯x) < infE f + ϵ.
Assume that f is G-diﬀerentiable. Then there exists z ∈B(¯x, √ϵ) satisfying
f(z) < inf
E f + ϵ
and
∥f ′(z)∥< √ϵ.
Proof. See Exercise 8.5.2.
⊓⊔

160
8 Variational Principles
The corollary states that near an “almost minimum” point of f we can ﬁnd
an “almost critical” point. In particular, there exists a minimizing sequence
(xk) of f such that the sequence (f ′(xk)) converges to zero.
Corollary 8.2.6 Let A be a closed subset of E, let f : A →R be l.s.c. and
bounded below. Let ϵ > 0 and let ¯x ∈A be such that f(¯x) < infA f + ϵ. Then
for any λ > 0 there exists z ∈A such that:
(a) ∥¯x −z∥< λ.
(b) z is a strong minimizer of the functional x →f(x) + ϵ
λ∥x −z∥on A.
In particular,
f(z) < f(x) + ϵ
λ∥x −z∥
∀x ∈A \ {z}.
(8.15)
Proof. See Exercise 8.5.3.
⊓⊔
Here, we give a geometric application of Ekeland’s variational principle.
In view of this, recall that by Corollary 1.5.5, every boundary point of a closed
convex set M ⊆E is a support point provided M has interior points. Without
the latter condition, the existence of support points cannot be guaranteed.
However, the following result due to Bishop and Phelps [15] ensures that M
contains support points with respect to certain Bishop–Phelps cones. In this
connection, M is not assumed to be convex or to have interior points. In
Fig. 8.1, the point y is a support point of M ⊆R2 with respect to the Bishop–
Phelps cone K(x∗, α) while z is not.
Proposition 8.2.7 Let E be a Banach space and M be a closed subset of E.
Suppose that x∗∈E∗\ {o} is bounded on M. Then for every α > 0 there
exists y ∈M such that
M ∩

y + K(x∗, α)

= {y}.
Proof. See Exercise 8.5.4.
⊓⊔
y
z
y + K(x∗, α)
z + K(x∗, α)
M
Fig. 8.1

8.3 The Borwein–Preiss Variational Principle
161
8.3 The Borwein–Preiss Variational Principle
Now we deduce the smooth variational principle of Borwein and Preiss, again
with a strong minimizer.
Theorem 8.3.1 (Borwein–Preiss) Let ϵ > 0 and let ¯x ∈E be such that
f(¯x) < infE f + ϵ. Further let λ > 0 and p ≥1. Then there exist a sequence
(νn) in (0, 1) with ∞
n=0 νn = 1 and a sequence (zn) in E converging to some
z ∈E such that the following holds:
(a) ∥z −¯x∥< λ.
(b) f(z) ≤infE f + ϵ.
(c) z is a strong minimizer of f + ϵρ∞on E, where
ρ∞(x) := 1
λp
∞
	
n=0
νn∥x −zn∥p.
(8.16)
Proof. We set
ρ(x) := ∥x∥p
λp ,
µn :=
1
2n+1(n + 1)σ ,
where σ :=
∞
	
n=0
(n + 1)p−1
2n+1
.
(8.17)
Then there exists a sequence (zn) converging to some z as in Theorem 8.2.3.
The perturbation functional according to (8.2) here is given by (8.16), where
νn := (n + 1)p−1
2n+1σ
.
It is left as Exercise 8.5.5 to show that these data meet the assertions.
⊓⊔
Remark 8.3.2 If, under the assumptions of Theorem 8.3.1 and with p > 1,
the norm functional ω(x) := ∥x∥, x ∈E, is β-diﬀerentiable on E \ {o} for
some bornology β, then the perturbation functional ρ∞deﬁned by (8.16) is
β-diﬀerentiable on all of E and satisﬁes
ρ′
∞(x) = p
λσ
∞
	
n=0
(n + 1)p−1
2n+1

x −zn
λ

p−1
ω′(x −zn)
∀x ̸= zn, n ∈N,
ρ′
∞(zn) = 0
∀n ∈N,
∥ρ′
∞(x)∥≤p
λσ
∞
	
n=0
(n + 1)p−1
2n+1
1
(n + 1)p−1 = p
λσ
∀x ∈E.
The estimation follows with the aid of (8.10), where by (8.17) we have η = λ
and ∥ω′(z −zn)∥= 1 (Proposition 4.7.1).
If E is a Hilbert space, the perturbation functional ρ∞in Theorem 8.3.1
can be simpliﬁed.

162
8 Variational Principles
Theorem 8.3.3 Assume that E is a Hilbert space. Let ϵ > 0 and let ¯x ∈E
be such that f(¯x) < infE f + ϵ. Then for any λ > 0 there exist y, z ∈E such
that the following holds:
(a) ∥z −¯x∥< λ,
∥z −y∥< λ.
(b) f(z) ≤infE f + ϵ.
(c) z is a strong minimizer of the functional x →f(x) +
ϵ
λ2 ∥x −y∥2 on E.
Proof. We set
ρ(x) := ∥x∥2
λ2 ,
µn :=
1
2n+1(n + 1)2 .
Then there exists a sequence (zn) converging to some z as in Theorem 8.2.3.
The perturbation functional is
ρ∞(x) = 1
λ2
∞
	
n=0
∥x −zn∥2
2n+1
.
Now deﬁne
y :=
∞
	
n=0
zn
2n+1 ,
c :=
∞
	
n=0
∥zn∥2
2n+1 −∥y∥2.
A direct calculation using the inner product shows that for each x ∈E,
ρ∞(x) = 1
λ2
∞
	
n=0
∥x∥2 −2(x | zn) + ∥zn∥2
2n+1
= 1
λ2

∥x∥2 −2(x | y) +
∞
	
n=0
∥zn∥2
2n+1

= 1
λ2 ∥x −y∥2 + c
λ2 .
Noting that c/λ2 is constant, the assertions follow from Theorem 8.2.3, except
for the estimate ∥z −y∥< λ. The latter is obtained as follows (observe that
c is positive). Since
f(z) + ϵ
λ2 ∥z −y∥2 ≤f(z) + ϵρ∞(z) ≤f(¯x) < inf
E f + ϵ,
we have
ϵ
λ2 ∥z −y∥2 < inf
E f −f(z) + ϵ ≤ϵ,
which completes the proof.
⊓⊔
8.4 The Deville–Godefroy–Zizler Variational Principle
We prepare the next result. If g : E →R is bounded, we write
∥g∥∞:= sup{|g(x)| | x ∈E}.
A functional b : E →R is said to be a bump functional if b is bounded and
the set supp(b) := {x ∈E | b(x) ̸= 0} is nonempty and bounded.

8.4 The Deville–Godefroy–Zizler Variational Principle
163
Lemma 8.4.1 Let E be a Fréchet smooth Banach space and ∥·∥be an equiv-
alent norm on E that is F-diﬀerentiable on E \ {o}. Then E admits a bump
functional b : E →R that is L-continuous, continuously diﬀerentiable, and
such that
b(E) ⊆[0, 1],
b(x) = 0 if ∥x∥≥1,
b(o) = 1.
(8.18)
Proof. Let ϕ : R →R be a continuously diﬀerentiable function satisfying
ϕ(R) ⊆[0, 1],
ϕ(t) = 0 if t ≤1 and if t ≥3,
ϕ(2) = 1.
Choose x0 ∈E such that ∥x0∥= 2 and set
b(x) := ϕ(∥5x + x0∥),
x ∈E.
Together with ϕ and ∥· ∥, the functional b is L-continuous. Moreover, by
Corollary 4.3.4 the norm functional is continuously diﬀerentiable on E \ {o}
and so b is continuously diﬀerentiable on E; in this connection notice that
in a neighborhood of the critical point x = −(1/5)x0 the function ϕ is zero.
Obviously (8.18) holds.
⊓⊔
We make the following assumptions:
(A1) E is a Banach space, Y is a Banach space (with norm ∥·∥Y ) of bounded
continuous real-valued functions on E.
(A2) ∥g∥∞≤∥g∥Y for any g ∈Y .
(A3) For any g ∈Y and z ∈E, the function gz : E →R deﬁned by gz(x) :=
g(x + z) satisﬁes gz ∈Y and ∥gz∥Y = ∥g∥Y .
(A4) For any g ∈Y and α ∈R, the function x →g(αx) is an element of Y .
(A5) E admits a bump functional b ∈Y .
Theorem 8.4.2 (Deville–Godefroy–Zizler [49]) If
the
assumptions
(A1)–(A5) are satisﬁed, then the set G of all g ∈Y such that f + g attains a
strong minimum on E is a dense Gδ subset of Y .
Proof. Given g ∈Y , deﬁne
S(g, α) := {x ∈E; | g(x) ≤inf
E g + α},
Uk := {g ∈Y | ∃α > 0 : diam S(f + g, α) < 1
k }.
We will show that each Uk is open and dense in Y and that ∩∞
k=1Uk = G:
(I) We show that each Uk is open. Let g ∈Uk be given and let α be an
associated positive number. Then for any h ∈Y satisfying ∥g −h∥Y <
α/3 we have ∥g −h∥∞< α/3. If x ∈S(f + h, α/3), then
(f + h)(x) ≤inf
E (f + h) + α
3 .

164
8 Variational Principles
It follows that
(f + g)(x) ≤(f + h)(x) + ∥g −h∥∞≤inf
E (f + h) + α
3 + ∥g −h∥∞
≤inf
E (f + g) + α
3 + 2∥g −h∥∞≤inf
E (f + g) + α.
Hence S(f + h, α/3) ⊆S(f + g, α) and so h ∈Uk.
(II) Next we show that each Uk is dense in Y .
(IIa) Let g ∈Y and ϵ > 0 be given. It suﬃces to ﬁnd h ∈Y such that
∥h∥Y < ϵ and diam S(f + g + h, α) < 1/k for some α > 0. We may
assume that the functional b of (A5) satisﬁes ∥b∥Y < ϵ. By (A3) we may
further assume that b(o) > 0 and by (A4) that supp(b) ⊆B(o, 1/(2k)).
Set α := b(o)/2, choose ¯x ∈E such that
(f + g)(¯x) < inf
E (f + g) + b(o)
2
and deﬁne h : E →R by h(x) := −b(x −¯x). Then (A3) implies that
h ∈Y and ∥h∥Y = ∥b∥Y < ϵ.
(IIb) We show that
S(f + g + h, α) ⊆B(¯x, 1/(2k)).
(8.19)
Let ∥x −¯x∥> 1/(2k). Since supp(h) ⊆B(¯x, 1/(2k)), we have h(x) = 0.
It follows that
(f + g + h)(x) = (f + g)(x) ≥inf
E (f + g) > (f + g)(¯x) −α
= (f + g + h)(¯x) + b(o) −b(o)/2 ≥inf
E (f + g + h) + α
and so x /∈S(f + g + h, α). This veriﬁes (8.19). By what has been said
in step (IIa) we can now conclude that Uk is dense in Y .
(IIc) The Baire category theorem now implies that ∩∞
k=1Uk is dense in Y .
(III) Finally we show that ∩∞
k=1Uk = G. It is left as Exercise 8.5.6 to verify
that G ⊆∩∞
k=1Uk. Now let g ∈∩∞
k=1Uk be given. We will show that f +g
attains a strong minimum on E. Given k ∈N choose αk > 0 such that
diam S(f +g, αk) < 1/k. Since each set S(f +g, αk) is closed, the Cantor
intersection theorem shows that ∩∞
k=1S(f + g, αk) consists of exactly
one point ¯x, which obviously is a minimizer of f + g. Now let (xn) be a
sequence in E satisfying limn→∞(f+g)(xn) = infE(f+g). For any k ∈N
there exists k0 such that k ≥k0 implies (f + g)(xn) ≤infE(f + g) + αk
and so xn ∈S(f + g, αk). We conclude that
∥xn −¯x∥≤diam S(f + g, αk) < 1
k
∀n ≥k0.

8.4 The Deville–Godefroy–Zizler Variational Principle
165
Hence xn →¯x as n →∞. Therefore, ¯x is a strong minimizer of f + g
and so g ∈G.
⊓⊔
As a consequence of Theorem 8.4.2 we derive:
Theorem 8.4.3 Let E be a Banach space admitting a continuously diﬀer-
entiable bump functional b such that ∥b∥∞and ∥b′∥∞are ﬁnite. Further let
f : E →R be proper, l.s.c., and bounded below. Then there exits a constant
α > 0 (depending only on E) such that for all ϵ ∈(0, 1) and for any x0 ∈E
satisfying
f(x0) < inf
E f + αϵ2,
(8.20)
there exist a continuously diﬀerentiable function g : E →R and y0 ∈E such
that:
(a) y0 is a strong minimizer of f + g.
(b) max{∥g∥∞, ∥g′∥∞} < ϵ.
(c) ∥y0 −x0∥< ϵ.
Proof. Let Y be the vector space of all continuously diﬀerentiable functions
g : E →R such that ∥g∥∞and ∥g′∥∞are ﬁnite. Equipped with the norm
∥g∥Y := max{∥g∥∞, ∥g∥∞}, Y is a Banach space. A construction analogous
to that in the proof of Lemma 8.4.1 allows us to assume that b satisﬁes (8.18),
in particular ∥b∥∞= 1. Deﬁne
α :=
1
4 max{∥b′∥∞, 1}
and
h(x) := f(x) −2αϵ2b
x −x0
ϵ

, x ∈E.
By Theorem 8.4.2 there exist k ∈Y and y0 ∈E such that h + k attains a
strong minimum at y0 and
∥k∥∞≤αϵ2/2,
∥k′∥∞≤αϵ2/2 ≤ϵ/2.
(8.21)
We have
h(x0) = f(x0) −2αϵ2 < inf
E f −αϵ2,
h(y) ≥inf
E f
whenever ∥y −x0∥≥ϵ.
If (c) would not hold, the above estimate would give
inf
E f + k(y0) ≤(h + k)(y0) ≤(h + k)(x0) < inf
E f −αϵ2 + k(x0)
and so k(y0) < k(x0) −αϵ2, which is a contradiction to (8.21). Hence (c) is
veriﬁed. Finally set
g(x) := k(x) −2αϵ2b
x −x0
ϵ

,
x ∈E.
It is easy to see that (a) and (b) also hold.
⊓⊔

166
8 Variational Principles
8.5 Bibliographical Notes and Exercises
Some references have already been given in the text. For various applications
of Ekeland’s variational principle we refer to Ekeland [57], Figueiredo [69],
Pallaschke [155], and Penot [162]. Vector-valued variants of Ekeland’s vari-
ational principle have been obtained by G¨opfert et al. [78]. Concerning the
smooth variational principle of Deville, Godefroy, and Zizler see also Deville
et al. [50]. The proof given here follows Borwein and Zhu [24]. This book
also contains further variational principles, many applications, and additional
references.
Borwein and Preiss [19] show that a result analogous to Theorem 8.3.3
holds in any reﬂexive Banach space with a Kadec norm and with ρ∞(x) =
1
λp ∥x −y∥p for any given p > 1. Recall that on each reﬂexive Banach
space there exists an equivalent norm that is locally uniformly convex
(Theorem 4.7.12), and each locally uniformly convex norm is a Kadec norm
(Lemma 4.7.9). In particular, on each Hilbert space the norm generated by
the inner product is (locally) uniformly convex (Example 4.7.7) and so is the
initial norm on Lp for 1 < p < +∞(Example 4.7.11).
Exercise 8.5.1 Verify Remark 8.2.2.
Exercise 8.5.2 Prove Corollary 8.2.5.
Exercise 8.5.3 Verify Corollary 8.2.6.
Exercise 8.5.4 Verify Proposition 8.2.7.
Hint: Apply Ekeland’s variational principle to the functional f := −x∗
∥x∗∥+δM
and with appropriate choices of ϵ and λ.
Exercise 8.5.5 Elaborate the details of the proof of Theorem 8.3.1.
Exercise 8.5.6 Show that, with the assumptions and the notation of
Theorem 8.4.2, one has G ⊆∩∞
k=1Uk.

9
Subdiﬀerentials of Lower Semicontinuous
Functionals
9.1 Fréchet Subdiﬀerentials: First Properties
In this section we study another kind of derivative-like concepts.
Deﬁnition 9.1.1 Assume that E is a Banach space, f : E →R is proper
and l.s.c., and ¯x ∈dom f.
(a) The functional f is said to be Fréchet subdiﬀerentiable (F-subdiﬀerenti-
able) at ¯x if there exists x∗∈E∗, the F-subderivative of f at ¯x, such that
lim inf
y→o
f(¯x + y) −f(¯x) −⟨x∗, y⟩
∥y∥
≥0.
(9.1)
(b) The functional f is said to be viscosity subdiﬀerentiable at ¯x if there
exist x∗∈E∗, the viscosity subderivative of f at ¯x, and a C1-function
g : E →R such that g′(¯x) = x∗and f −g attains a local minimum at ¯x.
If, in particular,
g(x) = ⟨x∗, x −¯x⟩−σ∥x −¯x∥2
with some positive constant σ, then x∗is called proximal subgradient of
f at ¯x. The sets
∂F f(¯x) := set of all F-subderivatives of f at ¯x,
∂V f(¯x) := set of all viscosity subderivatives of f at ¯x,
∂P f(¯x) := set of all proximal subgradients of f at ¯x
are called Fréchet subdiﬀerential (F-subdiﬀerential), viscosity subdiﬀeren-
tial, and proximal subdiﬀerential of f at ¯x, respectively.
Remark 9.1.2 Observe that the function g in Deﬁnition 9.1.1(b) can always
be chosen such that (f −g)(¯x) = 0 (cf. Fig. 9.1).
We study the relationship between the diﬀerent notions.

168
9 Subdiﬀerentials of Lower Semicontinuous Functionals
f
g
¯x
x∗
Fig. 9.1
Proposition 9.1.3 Assume that E is a Banach space, f : E →R is proper
and l.s.c., and ¯x ∈dom f. Then ∂V f(¯x) ⊆∂F f(¯x).
Proof. See Exercise 9.8.1.
⊓⊔
Remark 9.1.4 Notice that ∂F f(¯x) and ∂V f(¯x) can be deﬁned as above for
any proper, not necessarily l.s.c. functional f. However, if ∂F f(¯x) (in parti-
cular, ∂V f(¯x)) is nonempty, then in fact f is l.s.c. at ¯x (see Exercise 9.8.2).
The next result is an immediate consequence of the deﬁnition of the vis-
cosity F-subdiﬀerential and Proposition 9.1.3.
Proposition 9.1.5 (Generalized Fermat Rule) If the proper l.s.c. func-
tional f : E →R attains a local minimum at ¯x, then o ∈∂V f(¯x) and in
particular o ∈∂F f(¯x).
We shall now show that we even have ∂V f(¯x) = ∂F f(¯x) provided E is a
Fréchet smooth Banach space. We start with an auxiliary result.
Lemma 9.1.6 Let E be a Fréchet smooth Banach space and ∥·∥be an equiva-
lent norm on E that is F-diﬀerentiable on E\{o}. Then there exist a functional
d : E →R+ and a number α > 1 such that:
(a) d is bounded, L-continuous on E and continuously diﬀerentiable on E\{o}.
(b) ∥x∥≤d(x) ≤α∥x∥if ∥x∥≤1 and d(x) = 2 if ∥x∥≥1.
Proof. Let b : E →R be the bump functional of Lemma 8.4.1. Deﬁne d : E →
R+ by d(o) := 0 and
d(x) :=
2
s(x),
where
s(x) :=
∞
	
n=0
b(nx)
for x ̸= o.

9.1 Fréchet Subdiﬀerentials: First Properties
169
We show that d has the stated properties:
Ad (b). First notice that the series deﬁning s is locally a ﬁnite sum. In fact,
if ¯x ̸= o, then we have
b(nx) = 0
∀x ∈B(¯x, ∥¯x∥/2)
∀n ≥2∥¯x∥.
(9.2)
Moreover, s(x) ≥b(o) = 1 for any x ̸= o. Hence d is well deﬁned. We have
d(E) ⊆[0, 2]
and
d(x) = 2 whenever ∥x∥≥1.
Further it is clear that
[x ̸= o and b(nx) ̸= 0]
=⇒
n < 1/∥x∥
(9.3)
and so, since 0 ≤b ≤1, we conclude that s(x) ≤1 + 1/∥x∥. Hence d(x) ≥
2∥x∥/(1+∥x∥), which shows that d(x) ≥∥x∥whenever ∥x∥≤1. Since b(o) = 1
and b is continuous at o, there exists η > 0 such that b(x) ≥1/2 whenever
∥x∥≤η. Let x ∈E and m ≥1 be such that η/(m + 1) < ∥x∥≤η/m.
It follows that
s(x) ≥
m
	
n=1
b(nx) ≥m + 1
2
>
η
2∥x∥
and so d(x) < (4/η)∥x∥whenever ∥x∥≤η. This and the boundedness of d
imply that d(x)/∥x∥is bounded on E \ {o}. This veriﬁes (b).
Ad (a). Since by (9.2) the sum deﬁning s is locally ﬁnite, the functional d is
continuously diﬀerentiable on E \ {o}. For any x ̸= o we have
d′(x) = −2

 ∞
	
n=0
nb′(nx)
 
 ∞
	
n=0
b(nx)
−2
= −(d(x))2
2
∞
	
n=0
nb′(nx).
Since b is L-continuous, λ := sup{∥b′(x)∥| x ∈E} is ﬁnite and we obtain for
any x ̸= o,

∞
	
n=0
nb′(nx)
 ≤λ
[∥x∥−1]
	
n=0
n ≤λ

1 +
1
∥x∥
2
;
here the ﬁrst inequality holds by (9.3). This estimate together with (b) yields
∥d′(x)∥≤λ max{α, 2}2(∥x∥+ 1)2,
showing that d′ is bounded on B(o, 1) \ {o}. Since d′ is zero outside B(o, 1),
it follows that d′ is bounded on E \ {o}. Hence d is L-continuous on E. This
veriﬁes (a).
⊓⊔
Now we can supplement Proposition 9.1.3.
Theorem 9.1.7 Let E be a Fréchet smooth Banach space, f : E →R be a
proper l.s.c. functional, and ¯x ∈dom f. Then ∂V f(¯x) = ∂F f(¯x).

170
9 Subdiﬀerentials of Lower Semicontinuous Functionals
Proof. In view of Proposition 9.1.3 it remains to show that ∂F f(¯x) ⊆∂V f(¯x).
Thus let x∗∈∂F f(¯x). Replacing f with the functional ˜f : E →R deﬁned by
˜f(y) := sup{f(¯x + y) −f(¯x) −⟨x∗, y⟩, −1},
y ∈E,
we have o ∈∂F ˜f(o). We show that o ∈∂V ˜f(o). Notice that ˜f(¯x) = 0 and ˜f is
bounded below. By (9.1) we obtain
lim inf
y→o
˜f(y)
∥y∥≥0.
(9.4)
Deﬁne ρ : R+ →R by ρ(t) := inf{ ˜f(y) | ∥y∥≤t}. Then ρ is nonincreasing,
ρ(0) = 0 and ρ ≤0. This and (9.4) give
lim
t→0
ρ(t)
t
= 0.
(9.5)
Deﬁne ρ1 and ρ2 on (0, +∞) by
ρ1(t) :=
 et
t
ρ(s)
s ds,
ρ2(t) :=
 et
t
ρ1(s)
s
ds.
Since ρ is nonincreasing, we have
ρ1(et) =
 e2t
et
ρ(s)
s ds ≥ρ(e2t)
 e2t
et
1
sds = ρ(e2t).
(9.6)
Since ρ1 is also nonincreasing, we obtain analogously ρ1(et) ≤ρ2(t) ≤0. This
and (9.5) yield
lim
t↓0
ρ2(t)
t
= lim
t↓0
ρ1(t)
t
= lim
t↓0
ρ(t)
t
= 0.
(9.7)
Now deﬁne ˜g : E →R by ˜g(x) := ρ2(d(x)) for x ̸= o and ˜g(o) := 0, where d
denotes the functional in Lemma 9.1.6. Recall that d(x) ̸= 0 whenever x ̸= o.
Since ρ1 is continuous on (0, +∞) and so ρ2 is continuously diﬀerentiable on
(0, +∞), the chain rule implies that ˜g is continuously diﬀerentiable on E \{o}
with derivative
˜g′(x) = ρ1

ed(x)

−ρ1

d(x)

d(x)
· d′(x),
x ̸= o.
The properties of d and (9.7) further imply that limx→o ∥˜g′(x)∥= 0. There-
fore it follows as a consequence of the mean value theorem that ˜g is also
F-diﬀerentiable at o with ˜g′(o) = o, and ˜g′ is continuous at o. Since ρ is non-
increasing, we have ρ2(t) ≤ρ1(t) ≤ρ(t); here, the second inequality follows
analogously as (9.6) and the ﬁrst is a consequence of the second. Let ∥x∥≤1.
Then ∥x∥≤d(x), and since ρ2 is nonincreasing (as ρ1 is nonincreasing), we
obtain

9.1 Fréchet Subdiﬀerentials: First Properties
171
( ˜f −˜g)(x) = ˜f(x) −ρ2(d(x)) ≥˜f(x) −ρ2(∥x∥) ≥˜f(x) −ρ(∥x∥) ≥0.
Since 0 = ( ˜f −˜g)(o), we see that ˜f −˜g attains a local minimum at o. Hence
o ∈∂V ˜f(o) and so x∗∈∂V f(¯x).
⊓⊔
Remark 9.1.8 Let E, f, and ¯x be as in Theorem 9.1.7. Further let x∗∈
∂V f(¯x), which by Theorem 9.1.7 is equivalent to x∗∈∂F f(¯x). Then there
exists a concave C1 function g : E →R such that g′(¯x) = x∗and f −g attains
a local minimum at ¯x (cf. Fig. 9.1); see Exercise 9.8.4.
In order to have both the limit deﬁnition and the viscosity deﬁnition of
F-subderivatives at our disposal, we shall in view of Theorem 9.1.7 assume
that E is a Fréchet smooth Banach space and we denote the common F-
subdiﬀerential of f at ¯x by ∂F f(¯x).
The relationship to classical concepts is established in Proposition 9.1.9.
In this connection recall that
∂P f(¯x) ⊆∂F f(¯x).
(9.8)
Proposition 9.1.9 Assume that E is a Fréchet smooth Banach space and
f : E →R is proper and l.s.c.
(a) If the directional G-derivative fG(¯x, ·) of f at ¯x ∈dom f exists on E, then
for any x∗∈∂F f(¯x) (provided there exists one),
⟨x∗, y⟩≤fG(¯x, y)
∀y ∈E.
If, in particular, f is G-diﬀerentiable at ¯x ∈dom f, then ∂F f(¯x) ⊆
{f ′(¯x)}.
(b) If f ∈C1(U), where U ⊆E is nonempty and open, then ∂F f(x) = {f ′(x)}
for any x ∈U.
(c) If f ∈C2(U), where U ⊆E is nonempty and open, then ∂P f(x) =
∂F f(x) = {f ′(x)} for any x ∈U.
(d) If f is convex, then ∂P f(x) = ∂F f(x) = ∂f(x) for any x ∈dom f.
(e) If f is locally L-continuous on E, then ∂F f(x) ⊆∂◦f(x) for any x ∈E.
Proof.
(a) Let x∗∈∂F f(¯x) be given. Then there exist a C1 function g and a number
ϵ > 0 such that g′(¯x) = x∗and for each x ∈B(¯x, ϵ) we have
(f −g)(x) ≥(f −g)(¯x)
∀x ∈B(¯x, ϵ).
(9.9)
Now let y ∈E. Then for each τ > 0 suﬃciently small we have ¯x + τy ∈
B(¯x, ϵ) and so
1
τ

f(¯x + τy) −f(¯x)

≥1
τ

g(¯x + τy) −g(¯x)

.
Letting τ ↓0 it follows that fG(¯x, y) ≥⟨g′(¯x), y⟩= ⟨x∗, y⟩. If f is
G-diﬀerentiable at ¯x, then by linearity the latter inequality passes into
f ′(¯x) = x∗.

172
9 Subdiﬀerentials of Lower Semicontinuous Functionals
(b) It is obvious that f ′(x) ∈∂F f(x) for each x ∈U. This and (a) imply
∂F f(x) = {f ′(x)} for each x ∈U.
(c) By Proposition 3.5.1 we have f ′(x) ∈∂P f(x), which together with (a)
and (9.8) veriﬁes the assertion.
(d) It is evident that ∂f(¯x) ⊆∂P f(¯x) ⊆∂F f(¯x) for each ¯x ∈dom f. Now
let x∗∈∂F f(¯x) be given. As in the proof of (a) let g and ϵ be such that
(9.9) holds. Further let x ∈E. If τ ∈(0, 1) is suﬃciently small, then
(1 −τ)¯x + τx ∈B(¯x, ϵ) and we obtain using the convexity of f,
(1−τ)f(¯x)+τf(x) ≥f

(1−τ)¯x+τx

≥
(9.9)
f(¯x)+g

(1−τ)¯x+τx

−g(¯x).
It follows that
f(x) −f(¯x) ≥g

¯x + τ(x −¯x)

−g(¯x)
τ
.
Letting τ ↓0, we see that f(x) −f(¯x) ≥⟨g′(¯x), x −¯x⟩= ⟨x∗, x −¯x⟩. Since
x ∈E was arbitrary, we conclude that x∗∈∂f(¯x).
(e) See Exercise 9.8.5.
⊓⊔
In Sect. 9.5 we shall establish the relationship between the Fréchet subdif-
ferential and the Clarke subdiﬀerential.
9.2 Approximate Sum and Chain Rules
Convention. Throughout this section, we assume that E is a Fréchet smooth
Banach space, and ∥· ∥is a norm on E that is F-diﬀerentiable on E \ {o}.
Recall that we write ω¯x(x) := ∥x −¯x∥, and in particular ω(x) := ∥x∥,
x ∈E.
One way to develop subdiﬀerential analysis for l.s.c. functionals is to
start with sum rules. It is an easy consequence of the deﬁnition of the
F-subdiﬀerential that we have
∂F f1(¯x) + ∂F f2(¯x) ⊆∂F (f1 + f2)(¯x).
But the reverse inclusion
∂F (f1 + f2)(¯x) ⊆∂F f1(¯x) + ∂F f2(¯x)
(9.10)
does not hold in general.

9.2 Approximate Sum and Chain Rules
173
Example 9.2.1 Let f1(x) := |x| and f2(x) := −|x| for x ∈R. Then ∂F (f1 +
f2)(0) = {0} but since ∂F f2(0) = ∅(see Exercise 9.8.3), we have ∂F f1(0) +
∂F f2(0) = ∅.
Yet what we usually need is just (9.10). For instance, if ¯x is a local mini-
mizer of the proper l.s.c. function f on the closed subset M of E, then ¯x is a
local minimizer of f + δM on all of E, which implies
o ∈∂F (f + δM)(¯x).
(9.11)
Now we would like to conclude that o ∈∂F f(¯x)+∂F δM(¯x) which (9.10) would
ensure. In a special case we do obtain an exact sum rule.
Proposition 9.2.2 Let f1, f2 : E →R be proper and l.s.c. If f1 is F-
diﬀerentiable at ¯x, then
∂F (f1 + f2)(¯x) = f ′
1(¯x) + ∂F f2(¯x).
Proof. See Exercise 9.8.6.
⊓⊔
In the general case we at least obtain, among others, an approximate, or
fuzzy, sum rule of the following form. If x∗∈∂F (f1 + f2)(¯x), then for each
σ(E∗, E)-neighborhood V of zero in E∗there exist x1 and x2 close to ¯x such
that fi(xi) is close to fi(¯x) for i = 1, 2 and
x∗∈∂F f1(x1) + ∂F f2(x2) + V.
We establish several approximate sum rules, which are then applied to
derive a general mean value theorem as well as multiplier rules for constrained
optimization problems involving lower semicontinuous data. The ﬁrst result
is nonlocal, meaning that there is no reference point ¯x.
Theorem 9.2.3 (Nonlocal Approximate Sum Rule) Let f1, . . . ,fn :E→
R be proper, l.s.c., bounded below, and such that
lim
ρ↓0 inf
0 n
	
i=1
fi(yi)
 diam{y1, . . . , yn} ≤ρ
1
< +∞.
Then for any ϵ > 0 there exist xi ∈E and x∗
i ∈∂F fi(xi), i = 1, . . . , n,
satisfying
diam{x1, . . . , xn} · max{1, ∥x∗
1∥, . . . , ∥x∗
n∥} < ϵ,
(9.12)
n
	
i=1
fi(xi) < lim
ρ↓0 inf
0 n
	
i=1
fi(yi)
 diam{y1, . . . , yn} ≤ρ
1
+ ϵ,
(9.13)

n
	
i=1
x∗
i
 ≤ϵ.
(9.14)

174
9 Subdiﬀerentials of Lower Semicontinuous Functionals
Proof.
(I) For each positive real number κ let
ϕκ(y1, . . . , yn) :=
n
	
i=1
fi(yi) + κ
n
	
i,j=1
∥yi −yj∥2
and
ακ := inf
En ϕκ.
We show that
ακ ≤β := lim
ρ↓0 inf
0 n
	
i=1
fi(yi)
 diam{y1, . . . , yn} ≤ρ
1
∀κ > 0.
Assume, to the contrary, that for some κ we had
β < ακ ≤
n
	
i=1
fi(yi) + κ
n
	
i,j=1
∥yi −yj∥2
∀(y1, . . . , yn) ∈En.
By the deﬁnition of β, for each suﬃciently large ν
∈N we ﬁnd
(z1, . . . , zn) ∈En satisfying
n
	
i=1
fi(zi) < ακ
and
diam{z1, . . . , zn} ≤1
ν
and so
n
	
i=1
fi(zi) + κ
n
	
i,j=1
∥zi −zj∥2 ≤
n
	
i=1
fi(zi) + κn(n −1)
2ν2
.
If ν is large enough, the right-hand side, and so the left-hand side, of
the last inequality is smaller than ακ, but this contradicts the deﬁnition
of ακ. Thus we have shown that the generalized sequence (ακ)κ>0 is
bounded (above). Since it is also increasing, the limit α := limκ→∞ακ
exists.
(II) Observe that En with the Euclidean product norm is also a Fréchet
smooth Banach space. By the Borwein–Preiss variational principle
(Theorem 8.3.1 and Remark 8.3.2) applied to ϕκ for κ = 1, . . . , n (with
p = 2 and λ > 0 suﬃciently large), there exist a C1-function ψκ and a
point (z1,κ, . . . , zn,κ) ∈En such that ϕκ + ψκ attains a local minimum
at (z1,κ, . . . , zn,κ) and that
∥ψ′(z1,κ, . . . , zn,κ)∥< ϵ
n,
ϕk(z1,κ, . . . , zn,κ) < inf
En ϕκ + 1
κ ≤α + 1
κ.
(9.15)

9.2 Approximate Sum and Chain Rules
175
For each κ > 0 deﬁne γκ : E →R by
γκ(y1, . . . , yn) := −ψκ(y1, . . . , yn) −κ
n
	
i,j=1
∥yi −yj∥2.
Then γκ is a C1-function satisfying
n
	
i=1
fi(yi) −γκ(y1, . . . , yn) = ϕκ(y1, . . . , yn) + ψκ(y1, . . . , yn).
(9.16)
Since for each i = 1, . . . , n the function
y →ϕκ(z1,κ, . . . , zi−1, κ, y, zi+1, κ, . . . , zn,κ)
+ ψκ(z1,κ, . . . , zi−1, κ, y, zi+1, κ, . . . , zn,κ)
attains a local minimum at y = zi,κ, we conclude from (9.16) that
x∗
i,κ := Di γk(z1,κ, . . . , zn,κ) ∈∂F fi(zi,κ)
for i = 1, . . . , n.
Summing over i and recalling the deﬁnition of γκ gives
n
	
i=1
x∗
i,κ = −
n
	
i=1
Di ψκ(z1,κ, . . . , zn,κ) −2κ
n
	
i,j=1
(ω2)′(zi,κ −zj,κ).
For symmetry reasons the double sum over i, j vanishes. Moreover, by
(9.15) we have ∥−n
i=1 Di ψκ(z1,κ, . . . , zn,κ)∥≤ϵ. It follows that

n
	
i=1
x∗
i,κ
 ≤ϵ.
(9.17)
(III) By the deﬁnition of ακ and ϕκ we conclude that
ακ/2 ≤ϕκ/2(z1,κ, . . . , zn,κ)
= ϕκ(z1,κ, . . . , zn,κ) −κ
2
n
	
i=1
∥zi,κ −zj,κ∥2
≤
(9.15)
ακ + 1
κ −κ
2
n
	
i,j=1
∥zi,κ −zj,κ∥2.
(9.18)
Rearranging we obtain
κ
n
	
i,j=1
∥zi,κ −zj,κ∥2 ≤2(ακ −ακ/2 + 1
κ)
and so limκ→∞κ n
i,j=1 ∥zi,κ −zj,κ∥2
=
0. Hence limκ→∞diam
{z1,κ, . . . , zn,κ} = 0 and, recalling (9.17), we conclude that
lim
κ→∞diam{z1,κ, . . . , zn,κ} · max{∥x∗
1,κ, . . . , ∥x∗
n,κ∥} = 0.

176
9 Subdiﬀerentials of Lower Semicontinuous Functionals
(IV) We now obtain
α ≤β ≤lim inf
κ→∞
n
	
i=1
fi(zi,κ) = lim inf
κ→∞ϕκ(z1,κ, . . . , zn,κ)
≤
(9.15)
α.
Therefore we have α = β. In view of (9.15), the assertion follows by
setting xi := zi,κ and x∗
i := x∗
i,κ for i = 1, . . . , n, with κ suﬃciently
large.
⊓⊔
As an immediate application of Theorem 9.2.3 we obtain a remarkable
density result.
Proposition 9.2.4 Let f : E →R be proper and l.s.c. Then Dom(∂F f) is
dense in dom f.
Proof. Let ¯x ∈dom f and η > 0 be given. Since f is l.s.c. at ¯x, there exists
ϵ > 0 such that f(x) > f(¯x) −1 for all x ∈B(¯x, ϵ). We may assume that
ϵ < η. The functionals f1, f2 deﬁned by
f1(x) :=

f(x)
if x ∈B(¯x, ϵ),
+∞
otherwise,
f2(x) :=

0
if x = ¯x,
+∞
otherwise
satisfy the hypotheses of Theorem 9.2.3. Hence for i = 1, 2 there exist xi ∈E
and x∗
i ∈∂F fi(xi) such that
∥x1 −x2∥< ϵ,
o ∈x∗
1 + x∗
2 + BE∗(o, ϵ),
f1(x1) + f2(x2) < f1(¯x) + f2(¯x) + ϵ = f(¯x) + ϵ.
The last inequality shows that x2 = ¯x. Hence x1 ∈˚B(¯x, ϵ), and since
f1 coincides with f on B(¯x, ϵ), we obtain ∂F f1(x1) = ∂F f(x1). Moreover,
∂F f2(¯x) = {o}. Therefore x∗
1 ∈∂F f(x1) and we have ∥x1 −¯x∥< η.
⊓⊔
Now we turn to local approximate sum rules. In this connection, we shall
assume that, for some η > 0, the reference point ¯x has the following property:
n
	
i=1
fi(¯x) ≤lim
ρ↓0 inf
0 n
	
i=1
fi(yi)
 ∥y0 −¯x∥≤η, diam{y0, y1, . . . , yn} ≤ρ
1
.
(9.19)
We ﬁrst give a suﬃcient condition for (9.19).
Lemma 9.2.5 Let fi : E →R be proper and l.s.c. Assume that ¯x ∈
∩n
i=1dom fi is a local minimizer of n
i=1 fi and that one of the following con-
ditions (a) and (b) is satisﬁed:
(a) All but one of fi are uniformly continuous in a neighborhood of ¯x.
(b) The restriction of at least one fi to a neighborhood of ¯x has compact level
sets.
Then (9.19) holds.
Proof. See Exercise 9.8.7
⊓⊔

9.2 Approximate Sum and Chain Rules
177
Theorem 9.2.6 (Strong Local Approximate Sum Rule) Assume that
f1, . . . , fn : E →R are proper and l.s.c., let ¯x ∈∩n
i=1dom fi, and assume
that there exists η > 0 such that (9.19) holds. Then for any ϵ > 0 there exist
xi ∈B(¯x, ϵ) and x∗
i ∈∂F fi(xi), i = 1, . . . , n, satisfying
|fi(xi) −fi(¯x)| < ϵ,
i = 1, . . . , n,
(9.20)
diam{x1, . . . , xn} · max{∥x∗
1∥, . . . , ∥x∗
n∥} < ϵ,
(9.21)

n
	
i=1
x∗
i
 < ϵ.
(9.22)
Proof. Obviously we may assume that η < min{ϵ, 1}. Since each fi is l.s.c.,
we may further assume that
fi(x) > fi(¯x) −ϵ/n
∀x ∈B(¯x, η), i = 1, . . . , n.
(9.23)
In view of (9.19), for ϵ1 := η2/(32n2) there exists ρ ∈(0, η) such that
n
	
i=1
fi(¯x) ≤inf
0 n
	
i=1
fi(yi)+δB(¯x,η)(y0)
 ∥yi−yj∥≤ρ ∀i, j = 0, 1, . . . , n
1
+ϵ1.
(9.24)
For i = 1, . . . , n let
˜fi(x) := fi(x) + ∥x −¯x∥2 + δB(¯x,η)(x),
x ∈E.
Then ˜fi is l.s.c., bounded below, and satisﬁes
r := lim
ρ↓0 inf
0 n
	
i=1
˜fi(yi)
 diam{y1, . . . , yn} ≤ρ
1
≤
n
	
i=1
fi(¯x) < +∞.
Applying Theorem 9.2.3 to ˜fi and ϵ2 ∈(0, min{ρ, ϵ1}), we obtain xi and
y∗
i ∈∂F ˜fi(xi), i = 1, . . . , n, such that
n
	
i=1
˜fi(xi) < r + ϵ2,
(9.25)
diam{x1, . . . , xn} · {∥y∗
1∥, . . . , ∥y∗
n∥} < ϵ2,
(9.26)

n
	
i=1
y∗
i
 < ϵ2.
(9.27)
Observe that (9.25) implies xi ∈B(¯x, η). Moreover, from (9.24) and (9.26) we
deduce that

178
9 Subdiﬀerentials of Lower Semicontinuous Functionals
n
	
i=1

fi(¯x) + ∥xi −¯x∥2
−ϵ1 ≤
n
	
i=1
˜fi(xi) < r + ϵ2
≤
n
	
i=1
˜fi(¯x) + ϵ2 =
n
	
i=1
fi(¯x) + ϵ2
and so
n
	
i=1
∥xi −¯x∥2 ≤ϵ1 + ϵ2 < 2ϵ1.
(9.28)
Deﬁne x∗
i := y∗
i −(ω2
¯x)′(xi). It follows that
x∗
i ∈∂F ˜f(xi) −∂F ω2
¯x(xi) ⊆∂F
 ˜f −ω2
¯x

(xi)
= ∂F

fi + δB(¯x,η)

(xi) = ∂F fi(xi);
here the latter equation holds because by (9.28) the point xi is in the interior
of B(¯x, η). From (9.25), (9.27), and
(ω2
¯x)′(xi)
 ≤ϵ/(2n) we obtain (9.21) and
(9.22). Finally, the estimate
fi(xi)
≤
(9.25)
fi(¯x) +
	
j̸=i

fj(¯x) −fj(xj)

+ ϵ2
<
(9.23) fi(¯x) + (n −1)ϵ
n
+ ϵ2 < fi(¯x) + ϵ
together with (9.23) veriﬁes (9.20).
⊓⊔
Theorem 9.2.6 in conjunction with Lemma 9.2.5 is a necessary optimality
condition. It can also be interpreted as a strong approximate sum rule in that
it relates a local minimizer of n
i=1 fi to F-subderivatives x∗
i of fi whose sum
is close to zero in the norm topology of E∗. The following weak rule relates
an F-subderivative x∗of n
i=1 fi to F-subderivatives x∗
i of fi whose sum is
close to x∗in the weak* topology of E∗. Notice that in this result, condition
(9.19) can be omitted.
Theorem 9.2.7 (Weak Local Approximate Sum Rule) Assume
that
f1, . . . , fn : E →R are proper and l.s.c., let ¯x ∈∩n
i=1dom fi, and let
x∗∈∂F
n
i=1 fi

(¯x). Then for any ϵ > 0 and any σ(E∗, E)-neighborhood
V of zero in E∗there exist xi ∈B(¯x, ϵ) and x∗
i ∈∂F fi(xi), i = 1, . . . , n,
satisfying
|fi(xi) −fi(¯x)| < ϵ,
i = 1, . . . , n,
diam{x1, . . . , xn} · max{∥x∗
1∥, . . . , ∥x∗
n∥} < ϵ,
x∗∈
n
	
i=1
x∗
i + V.

9.2 Approximate Sum and Chain Rules
179
Proof. Let ϵ and V be given. Then there exist y1, . . . , ym ∈E such that
{x∗∈E∗ |⟨x∗, yk⟩| ≤1, k = 1, . . . , m} ⊆V.
Let L := span{¯x, y1, . . . , ym} and ρ :=

2 max{∥y1∥, . . . ∥ym∥}
−1. Then we
have
L⊥+ B(o, 2ρ) ⊆V.
For x∗there exists a C1-function g such that g′(¯x) = x∗and
n
i=1 fi

−g
attains a local minimum at ¯x. Choose ϵ′ > 0 such that
∥x −¯x∥< ϵ′
=⇒
∥g′(x) −g′(¯x)∥< ρ.
(9.29)
We may assume that ϵ′ < min{ϵ, ρ}. The functional
n
i=1 fi

−g+δL attains
a local minimum at ¯x and δL has locally compact lower level sets. Hence by
Lemma 9.2.5 the (n + 2)-tuple (f1, . . . , fn, −g, δL) satisﬁes condition (9.19).
By Theorem 9.2.6 there exist xi ∈B(¯x, ϵ′) for i = 1, . . . , n + 2 and x∗
i ∈
∂F fi(¯x) for i = 1, . . . , n as well as x∗
n+1 := −g′(xn+1) and x∗
n+2 ∈∂F δL(xn+2)
satisfying
|fi(xi) −fi(¯x)| < ϵ′,
i = 1, . . . , n,
|δL(xn+2) −δL(¯x)| < ϵ′,
diam{x1, . . . , xn+2} · max{∥x∗
1∥, . . . , ∥x∗
n+2∥} < ϵ′,

n
	
i=1
x∗
i −g′(xn+1) + x∗
n+2
 < ϵ′.
The inequality involving δL shows that x∗
n+2 ∈L. Moreover, it is easy to see
that ∂F δL(xn+2) = L⊥. Since ∥xn+1−¯x∥< ϵ′, (9.29) gives ∥g′(xn+1)−x∗∥<ρ.
We conclude that

 n
	
i=1
x∗
i + x∗
n+2

−x∗
≤∥g′(xn+1) −x∗∥+

n
	
i=1
x∗
i −g′(xn+1) + x∗
n+2
 < ρ + ϵ′ ≤2ρ,
which implies
x∗∈
n
	
i=1
x∗
i + L⊥+ B(o, 2ρ) ⊂
n
	
i=1
x∗
i + V.
⊓⊔
Finally we establish an approximate chain rule. For this, we need the
following concepts.

180
9 Subdiﬀerentials of Lower Semicontinuous Functionals
Deﬁnition 9.2.8 Let T : E →F be a mapping between Banach spaces E
and F.
(a) T is said to be locally compact at ¯x ∈E if there is a neighborhood U of ¯x
such that T(C) is compact for any closed set C ⊆U.
(b) For any y∗∈F ∗, the scalarization ⟨y∗, T⟩: E →R of T is deﬁned by
⟨y∗, T⟩(x) := ⟨y∗, T(x)⟩,
x ∈E.
Recall that if g : F →R and T : E →F, then g ◦T : E →R denotes the
composition of g and T.
Theorem 9.2.9 (Approximate Chain Rule) Assume that E and F are
Fréchet smooth Banach spaces, g : F →R is proper and l.s.c., and T : E →F
is locally L-continuous and locally compact at ¯x ∈dom f. Suppose that x∗∈
∂F (g ◦T)(¯x). Then for any ϵ > 0 there exist x ∈BE(¯x, ϵ), y ∈BF (T(¯x), ϵ),
y∗∈∂F g(y), z∗∈˚
BF ∗(y∗, ϵ), and ˜x∗∈∂F ⟨z∗, T⟩(x) such that
|g(y) −g(T(¯x))| < ϵ,
∥y −T(x)∥max{∥˜x∗∥, ∥y∗∥, ∥z∗∥} < ϵ,
∥x∗−˜x∗∥< ϵ.
(9.30)
Proof. Let h : E →R be a C1 function such that h′(¯x) = x∗and g ◦T −h
attains a local minimum at ¯x. Deﬁne
f1(u, y) := g(y) −h(u),
f2(u, y) := δgraph T (u, y)
∀(u, y) ∈E × F (9.31)
and put f := f1 +f2. Then f attains a local minimum at (¯x, T(¯x)). Moreover,
since T is locally compact, condition (b) of Lemma 9.2.5 also holds. By that
lemma the hypothesis (9.19) of the approximate sum rule of Theorem 9.2.6
is satisﬁed. Applying the latter theorem, we ﬁnd x, u ∈BE(¯x, ϵ) such that
∥h′(u) −x∗∥< ϵ/2 as well as y ∈BF (T(¯x), ϵ) with |f(y) −f(T(¯x))| < ϵ,
y∗∈∂F g(y) and
(˜x∗, −z∗) ∈∂F δgraph T (x, T(x))
(9.32)
satisfying (9.30) and
∥(−h′(u), y∗) + (˜x∗, −z∗)∥< ϵ/2.
(9.33)
From (9.32) we conclude that there is a C1 function ˜h : E × F →R such that
˜h′(x, T(x)) = (˜x∗, −z∗) and ˜h attains a local minimum 0 at (x, T(x)). The
latter means that for any u in a neighborhood of x we have
0 ≥˜h(u, T(u)) −˜h(x, T(x)) = ⟨˜x∗, u −x⟩−⟨z∗, T(u) −T(x)⟩+ o(∥u −x∥).
This shows that ˜x∗∈∂F ⟨z∗, T⟩(x). Applying (9.33) we obtain
∥x∗−˜x∗∥≤∥x∗−h′(u)∥+ ∥h′(u) −˜x∗∥< ϵ,
which completes the proof.
⊓⊔

9.3 Application to Hamilton–Jacobi Equations
181
9.3 Application to Hamilton–Jacobi Equations
Convention. Throughout this section, assume that E is a Hilbert space.
An equation of the form
f(x) + H

x, f ′(x)

= 0
∀x ∈E,
(9.34)
where H : E × E∗→R is given, is called Hamilton–Jacobi equation for f.
Equations of this (and a more general) type play a fundamental role in the
calculus of variations and in optimal control theory. In this context, (9.34) may
fail to have a classical, i.e., continuously diﬀerentiable, solution f : E →R.
It turns out that F-subdiﬀerentials can be used to introduce an adequate
concept of generalized solutions. First, parallel to the F-subdiﬀerential ∂F (¯x),
we now consider the F-superdiﬀerential of f at ¯x deﬁned by
∂Ff(¯x) := −∂F (−f)(¯x).
Deﬁnition 9.3.1
(a) A function f : E →R is said to be a viscosity supersolution of (9.34) if f
is lower semicontinuous and for any x ∈E and any x∗∈∂F f(x) one has
f(x) + H(x, x∗) ≥0.
(b) A function f : E →R is said to be a viscosity subsolution of (9.34) if f is
upper semicontinuous and for any x ∈E and any x∗∈∂Ff(x) one has
f(x) + H(x, x∗) ≤0.
(c) If f : E →R is both a viscosity supersolution and a viscosity subsolution
of (9.34), then f is said to be a viscosity solution of (9.34).
If f : E →R is continuously diﬀerentiable, then ∂F f(x) = ∂Ff(x) =
{f ′(x)} for every x ∈E (Proposition 9.1.9). Hence any classical solution of
(9.34) is also a viscosity solution, and any viscosity solution of (9.34) that is
continuously diﬀerentiable is also a classical solution.
We consider the following condition on the function H:
|H(y, y∗)−H(x, x∗)| ≤ϕ(y −x, y∗−x∗)+c max{∥x∗∥, ∥y∗∥} ∥y −x∥. (9.35)
Theorem 9.3.2 (Comparison Theorem) Let H : E × E∗→R be such
that, with some constant c > 0 and some continuous function ϕ : E ×E∗→R
satisfying ϕ(o, o) = 0, the condition (9.35) holds for any x, y ∈E and any
x∗, y∗∈E∗. If f is a viscosity subsolution of (9.34) and bounded above and
g is a viscosity supersolution of (9.34) and bounded below, then f ≤g.

182
9 Subdiﬀerentials of Lower Semicontinuous Functionals
Proof. Let ϵ > 0 be given. By Theorem 9.2.3 applied to f1 := g and f2 := −f,
there exist x, y ∈E and x∗∈∂F g(x), y∗∈∂Ff(y) satisfying
∥x −y∥< ϵ,
∥x∗∥∥x −y∥< ϵ,
∥y∗∥∥x −y∥< ϵ,
g(x) −f(y) < inf
E (g −f) + ϵ,
∥x∗−y∗∥≤ϵ.
From the properties of f and g we deduce
g(x) + H(x, x∗) ≥0,
f(y) + H(y, y∗) ≤0.
Combining the above inequalities as well as (9.35), we obtain
inf
E (g −f) > g(x) −f(y) −ϵ ≥

H(y, y∗) −H(x, x∗)

−ϵ
≥−

ϕ(y −x, y∗−x∗) + c max{∥x∗∥, y∗∥} ∥y −x∥

−ϵ.
By the assumptions on ϕ, the right-hand side of the last inequality converges
to 0 as ϵ →0. Therefore infE(g −f) ≥0.
⊓⊔
As an immediate consequence of Theorem 9.3.2 we have:
Corollary 9.3.3 Under the assumptions of Theorem 9.3.2, (9.34) has at most
one continuous bounded viscosity solution.
9.4 An Approximate Mean Value Theorem
Convention. Throughout this section, assume that E is a Fréchet smooth
Banach space.
Theorem 9.4.1 (Approximate Mean Value Theorem) Let f : E →R
be proper and l.s.c. Further let a, b ∈E and ρ ∈R be such that a ̸= b,
f(a) ∈R, and ρ ≤f(b) −f(a). Then there exist a point c ∈[a, b) as well as
sequences (xn) in E and (x∗
n) in E∗satisfying
(xn, f(xn)) →(c, f(c)) as n →∞,
x∗
n ∈∂F f(xn) ∀n ∈N,
lim inf
n→∞⟨x∗
n, c −xn⟩≥0,
(9.36)
lim inf
n→∞⟨x∗
n, b −a⟩≥ρ,
(9.37)
f(c) ≤f(a) + |ρ|.
(9.38)
Proof.
(I) Let z∗∈E∗be such that ⟨z∗, a −b⟩= ρ and set
g(x) := f(x) + ⟨z∗, x⟩+ δ[a,b](x),
x ∈E.
Then g attains its minimum on the compact set [a,b] at some c, and
we may assume that c ∈[a, b) because g(b) ≥g(a). By the strong local

9.4 An Approximate Mean Value Theorem
183
approximate sum rule (Theorem 9.2.6) there exist sequences (xn), (yn),
(x∗
n), and (y∗
n) satisfying
(xn, f(xn)) →(c, f(c))
as n →∞,
yn ∈[a, b]
∀n,
yn →c
as n →∞,
x∗
n ∈∂F f(xn),
y∗
n ∈∂F δ[a,b](yn)
∀n,
∥x∗
n∥· ∥xn −yn∥< 1/n,
∥y∗
n∥· ∥xn −yn∥< 1/n
∀n,
∥x∗
n + z∗+ y∗
n∥< 1/n
∀n.
Since yn →c, we have yn ∈[a, b) if n is suﬃciently large which we now
assume. Since δ[a,b] is convex, Proposition 9.1.9 gives
∂F δ[a,b](yn) = ∂δ[a,b](yn) = {y∗∈E∗| ⟨y∗, x −yn⟩≤0
∀x ∈[a, b]}.
(9.39)
Since y∗
n ∈∂F δ[a,b](yn) and c ∈[a, b), we see that lim supn→∞(y∗
n | c −
yn) ≤0. Using this, we obtain
lim inf
n→∞(x∗
n | c −xn) = lim inf
n→∞(x∗
n + u | c −xn)
= lim inf
n→∞(−y∗
n | c −yn) = −lim sup
n→∞(y∗
n | c −yn) ≥0,
which veriﬁes (9.36).
(II) We turn to (9.37). As yn ∈[a, b) for all suﬃciently large n, we have for
these n,
b −a = λn(b −yn),
where λn := ∥b −a∥
∥b −yn∥.
It follows that
lim inf
n→∞⟨x∗
n + z∗, b −a⟩= lim inf
n→∞
&
λn⟨x∗
n + z∗, b −yn⟩

= ∥b −a∥
∥b −c∥lim inf
n→∞⟨−y∗
n, b −yn⟩≥0
(9.39)
,
which immediately implies (9.37).
(III) To verify (9.38), notice that g(c) ≤g(a) and so f(c) ≤f(a) + (u | a −c).
With some λ ∈(0, 1] we have c = λa + (1 −λ)b and it follows that
f(c) ≤f(a) + (1 −λ)(u | a −b) ≤f(a) + |ρ|.
⊓⊔
As an application we show:
Proposition 9.4.2 Let f : E →R be proper and l.s.c., let U be an open
convex subset of E such that U ∩dom f ̸= ∅. Then for any λ > 0 the following
assertions are equivalent:

184
9 Subdiﬀerentials of Lower Semicontinuous Functionals
(a) f is L-continuous on U with Lipschitz constant λ.
(b) sup{∥x∗∥| x∗∈∂F f(x)} ≤λ for any x ∈U.
Proof. (a) =⇒(b): This is straightforward.
(b) =⇒(a): Let a, b ∈U and ρ ∈R be such that a ∈dom f, a ̸= b, and
ρ ≤f(b) −f(a). Further let ϵ > 0 be given. By Theorem 9.4.1 there exist
x ∈U and x∗∈∂F f(x) such that (see (9.37))
ρ ≤⟨x∗, b −a⟩+ ϵ ≤λ∥b −a∥+ ϵ.
Since ρ ≤f(b) −f(a) and ϵ > 0 are arbitrary, it follows that f(b) −f(a) ≤
λ∥b −a∥and so, in particular, f(b) < +∞. Exchanging the roles of a and b,
we thus obtain |f(b) −f(a)| ≤λ∥b −a∥.
⊓⊔
9.5 Fréchet Subdiﬀerential vs. Clarke Subdiﬀerential
For a locally L-continuous functional we now deduce a representation of the
Clarke subdiﬀerential in terms of Fréchet subdiﬀerentials.
Proposition 9.5.1 Let E be a Fréchet smooth Banach space and let f : E →
R be locally L-continuous on E. Then for any ¯x ∈E one has
∂◦f(¯x) = co∗{x∗∈E∗| ∃xk ∈E ∃x∗
k ∈∂F f(xk) : xk →¯x, x∗
k
w∗
−−→x∗}.
(9.40)
Proof. For convenience we write x∗=∗limk→∞x∗
k if x∗
k
w∗
−−→x∗. In view of
Theorem 2.3.1, it suﬃces to show that the support functionals of the two sets
in (9.40) coincide, i.e.,
f ◦(¯x, y) = sup{⟨x∗, y⟩| x∗=∗lim
k→∞x∗
k, x∗
k ∈∂F f(xk), xk →¯x}
∀y ∈E.
Since ∂F f(xk) ⊆∂◦f(xk) by Proposition 9.1.9(e) and ∂◦f is norm-to-weak∗
u.s.c. by Proposition 7.3.8(c), we have
f ◦(¯x, y) ≥sup{⟨x∗, y⟩| x∗=∗lim
k→∞x∗
k, x∗
k ∈∂F f(xk), xk →¯x}
∀y ∈E.
It remains to verify that
f ◦(¯x, y) ≤sup{⟨x∗, y⟩| x∗=∗lim
k→∞x∗
k, x∗
k ∈∂F f(xk), xk →¯x}
∀y ∈E.
(9.41)
Let y ∈E be ﬁxed. Choose sequences zk →¯x and τk ↓0 satisfying
f ◦(¯x, y) = lim
k→∞
f(zk + τky) −f(zk)
τk
.
Now let ϵ > 0. By Theorem 9.4.1, for each k there exist ˜zk ∈[zk, zk + τky),
xk ∈B(˜zk, ϵτk), and x∗
k ∈∂F f(xk) such that

9.6 Multidirectional Mean Value Theorems
185
⟨x∗
k, y⟩≥f(zk + τky) −f(zk)
τk
−ϵ.
(9.42)
If λ > 0 denotes a Lipschitz constant of f around ¯x, then x∗
k ∈BE∗(o, λ) for
each k (Proposition 7.3.7). Since BE∗(o, λ) is weak∗compact, we may assume
that (x∗
k) is weak∗convergent to some x∗∈BE∗(o, λ). By letting k →∞, we
conclude from (9.42) that
sup{⟨x∗, y⟩| x∗=∗lim
k→∞x∗
k, x∗
k ∈∂F f(xk), xk →¯x} ≥f ◦(¯x, y) −ϵ.
Since ϵ > 0 and y ∈E are arbitrary, (9.41) follows.
⊓⊔
Remark 9.5.2 Proposition 9.5.1 may be considered as an inﬁnite-dimensional
analogue of Clarke’s Theorem 7.3.12. It shows that the Clarke subdiﬀerential
is the convexiﬁcation of weak∗limits of Fréchet subdiﬀerentials. In many ins-
tances, convexity is a very convenient property as it allows to use techniques of
convex analysis (cf. the remarks at the beginning of this chapter). However, as
already observed above, the Clarke subdiﬀerential may be too coarse to detect
minimizers and so may be the smaller Michel–Penot subdiﬀerential (cf. Re-
mark 7.3.10, Example 7.3.11, and Exercise 9.8.3). The Fréchet subdiﬀerential
is qualiﬁed as an appropriate derivative-like object not only by its “smallness,”
but also, in particular, by the rich calculus it admits. This will also allow to
derive multiplier rules in terms of Fréchet subdiﬀerentials in Chap. 12. But we
already know that the results are of an approximate nature. In Chap. 13 we
shall study derivative-like objects that admit exact results.
9.6 Multidirectional Mean Value Theorems
Convention. Throughout this section, E denotes a Fréchet smooth Banach
space.
Let f : E →R be a G-diﬀerentiable l.s.c. functional. As a special case of
the mean value inequality of Proposition 3.3.4 we obtain that for any x, y ∈E
there exists z ∈(x, y) such that
f(y) −f(x) ≤⟨f ′(z), y −x⟩.
Given a compact convex set S ⊆E, we pass to the inequality
min
˜y∈S f(˜y) −f(x) ≤⟨f ′(z), y −x⟩
∀y ∈S.
(9.43)
We ﬁrst establish a multidirectional version of this inequality by showing that
for ﬁxed x the same element z can be chosen in (9.43) while the direction y
varies over S, provided E is ﬁnite dimensional.
If x ∈E and S ⊆E, we write [x, S] := co({x} ∪S).

186
9 Subdiﬀerentials of Lower Semicontinuous Functionals
Proposition 9.6.1 Assume that S is a nonempty, bounded, closed, convex
subset of RN, x ∈RN, and f : RN →R is l.s.c. on RN and G-diﬀerentiable
on a neighborhood of [x, S]. Then there exists z ∈[x, S] satisfying (9.43).
Proof. Let U be an open neighborhood of [x, S] on which f is G-diﬀerentiable.
Set
r := min
˜y∈S f(˜y) −f(x)
and deﬁne g : U × [0, 1] →R by
g(y, τ) := f(x + τ(y −x)) −rτ.
Since g is l.s.c. and [x, S] is compact, g attains its inﬁmum on S × [0, 1] at
some (ˆy, ˆτ) ∈S × [0, 1]. We show that (9.43) holds with
z :=

x + ˆτ(ˆy −x)
if ˆτ ∈[0, 1),
x
if ˆτ = 1.
Now we distinguish three cases:
(I) Assume ﬁrst that ˆτ ∈(0, 1). Then the function τ →g(ˆy, τ) attains its
inﬁmum on the interval [0, 1] at the interior point ˆτ. It follows that
0 = ∂
∂tg(ˆy, τ)

τ=ˆτ= ⟨f ′(z), ˆy −x⟩−r.
(9.44)
Analogously, the function y →g(y, ˆτ) attains its inﬁmum over the set
S at ˆy. Since the function is G-diﬀerentiable, the necessary optimality
condition (7.6) in Sect. 7.1 implies that
0 ≤
( ∂
∂y g(y, ˆτ)

y=ˆy, y −ˆy
)
=

ˆτf ′(z), y −ˆy
 
∀y ∈S
and so
⟨f ′(z), y −ˆy⟩≥0
∀y ∈S.
(9.45)
Combining (9.44) and (9.45), we obtain
r ≤⟨f ′(z), ˆy −x⟩+ ⟨f ′(z), y −ˆy⟩= ⟨f ′(z), y −x⟩;
here y ∈S is arbitrary. Hence (9.43) is veriﬁed in case ˆτ ∈(0, 1).
(II) Now assume that ˆτ = 0 so that (ˆy, 0) is a minimizer of g on S × [0, 1].
It follows directly that
f(x) = g(ˆy, 0) ≤g(y, τ) = f(x + τ(y −x)) −rτ
∀(y, τ) ∈S × (0, 1]
and so
r ≤lim
τ↓0
f(x + τ(y −x)) −f(x)
τ
= ⟨f ′(z), y −x⟩
∀y ∈S,
which is equivalent to (9.43).

9.6 Multidirectional Mean Value Theorems
187
(III) Finally assume that ˆτ = 1. Then, in particular, we have g(ˆy, 1) ≤
g(ˆy, 0) = f(x) and on the other hand,
g(ˆy, 1) = f(ˆy) −r = f(ˆy) −min
˜y∈S f(˜y) + f(x) ≥f(x).
Therefore, f(x) = g(ˆy, 1) which means that f(x) is the minimum of g
on S × [0, 1]. Since f(x) = g(y, 0) for any y ∈S, we see that any (y, 0) is
also a minimizer of g. Hence we can replace ˆτ = 1 with ˆτ = 0 and refer
to case (II).
⊓⊔
Now we establish a multidirectional mean value theorem in terms of F-
subdiﬀerentials in arbitrary Fréchet smooth Banach spaces.
Theorem 9.6.2 (Multidirectional Mean Value Theorem) Assume that
E is a Fréchet smooth Banach space, S is a nonempty closed convex subset
of E, f : E →R is a l.s.c. functional, and x ∈dom f. Suppose that for some
ρ > 0, f is bounded below on [x, S] + B(o, ρ). Let r be such that
r < lim
η↓0 inf{f(y) | y ∈S + B(o, η)} −f(x).
(9.46)
Then for any ϵ > 0 there exist z ∈[x, S] + B(o, ϵ) and z∗∈∂F f(z) such that
f(z) < lim
η↓0 inf{f(y) | y ∈[x, S] + B(o, η)} + |r| + ϵ,
(9.47)
r < ⟨z∗, y −x⟩+ ϵ∥y −x∥
∀y ∈S.
(9.48)
Proof.
(I) First we assume that (9.46) holds for r = 0 and we consider the case
r = 0. The functional ˜f := f + δ[x,S]+B(o,ρ) is bounded below on all
of E. By (9.46) there exists η ∈(0, ρ/2) such that
f(x) < inf{f(y) | y ∈S + B(o, 2η)}.
Without loss of generality we may assume that ϵ satisﬁes
0 < ϵ < inf{f(y) | y ∈S + B(o, 2η)} −f(x)
and ϵ < η.
(9.49)
By the nonlocal approximate sum rule (Theorem 9.2.3), applied to
f1 := ˜f and f2 := δ[x,S], there exist z ∈dom f ∩([x, S] + B(o, ρ)) and
u ∈[x, S] such that
∥z −u∥< ϵ,
z∗∈∂F f1(z) = ∂F f(z)
as well as u∗∈∂F δ[x,S](u) satisfying
max{∥z∗∥, ∥u∗∥} · ∥z −u∥< ϵ,
(9.50)
f(z) < lim
η↓0 inf{f(y) | y ∈[x, S] + B(o, η)} + ϵ ≤f(x) + ϵ,
(9.51)
∥z∗+ u∗∥< ϵ.
(9.52)

188
9 Subdiﬀerentials of Lower Semicontinuous Functionals
Since [x, S] is a convex set, we have
u∗∈∂F δ[x,S](u) = NF ([x, S], u) = N([x, S], u)
and so
⟨u∗, w −u⟩≤0
∀w ∈[x, S].
(9.53)
From (9.52) and (9.53) we obtain
⟨z∗, w −u⟩= ⟨z∗+ u∗, w −u⟩−⟨u∗, w −u⟩
≥⟨z∗+ u∗, w −u⟩> −ϵ∥w −u∥
∀w ∈[x, S], w ̸= u.
(9.54)
We show that d(S, u) ≥η. If we had d(S, u) < η, it would follow that
∥˜y −u∥< η for some ˜y ∈S, thus
∥˜y −z∥≤∥˜y −u∥+ ∥u −z∥
<
(9.50) η + ϵ < 2η
and so d(S, z) < 2η. But then
f(z) ≥inf{f(y) | y ∈S + B(o, 2η)}
>
(9.49) f(x) + ϵ,
which contradicts (9.51). Hence d(S, u) ≥η. Let u := x + ˆτ(ˆy −x) with
some ˆτ ∈[0, 1] and ˆy ∈S. Then
0 < η ≤∥ˆy −u∥= (1 −ˆτ)∥ˆy −x∥
and so ˆτ < 1. Consider any y ∈S and set w := y + ˆτ(ˆy −y). Then
w ̸= u, otherwise it would follow that y = x which is contradictory
because x /∈S (see (9.46)). Inserting this w into (9.54), we ﬁnally obtain
(9.48) with r = 0.
(II) Now we consider the general case (9.46). Equip E×R with the Euclidean
product norm. Choose ϵ′ ∈(0, ϵ/2) such that
r + ϵ′ < lim
η↓0 inf{f(y) | y ∈S + B(o, η)} −f(x).
Deﬁne F : E × R →R by F(y, τ) := f(y) −(r + ϵ′)τ. Then F is l.s.c. on
E ×R and bounded below on [(x, 0), S ×{1}]+BE×R(o, ρ). Furthermore
we have
0 < lim
η↓0 inf{f(y) | y ∈S + B(o, η)} −(r + ϵ′) −f(x)
= lim
η↓0 inf{F(y, 1) | (y, 1) ∈(S × {1}) + BE×R(o, η)} −F(x, 0).
Hence the special case (I) applies with f, x, and S replaced by F,
(x, 0), and S ×{1}, respectively. Consequently there exist (z, τ) ∈[(x, 0),

9.6 Multidirectional Mean Value Theorems
189
S × {1}] + BE×R(o, ϵ) and (z∗, τ ∗) ∈∂F F(z, τ) ⊆∂F f(z) × {−(r + ϵ′)}
such that
f(z) = F(z, τ) + (r + ϵ′)τ
< lim
η↓0 inf{F(y, τ) | (y, τ) ∈[(x, 0), S × {1}]+BE×R(o, η)}+ϵ′+(r + ϵ′)τ
≤lim
η↓0 inf{f(y) | y ∈[x, S] + B(o, η)} + |r| + ϵ,
and for any (y, 1) ∈S × {1} we have
0 <

(z∗, τ ∗), (y, 1) −(x, 0)
 
+ ϵ′∥(y −x, 1)∥
≤⟨z∗, y −x⟩−(r + ϵ′) + ϵ′(∥y −x∥+ 1)
= ⟨z∗, y −x⟩−r + ϵ′∥y −x∥≤⟨z∗, y −x⟩−r + ϵ∥y −x∥.
The proof is thus complete.
⊓⊔
Notice that the set S in Theorem 9.6.2 is not assumed to be bounded
(in this context, see Exercise 9.8.8).
To
prepare
the
next
result,
consider
a
G-diﬀerentiable
functional
f : E →R such that f ′(¯x) ̸= o for some ¯x ∈E. Then ¯x is not a local
minimizer of f. Hence for some r > 0 we have
inf
x∈B(¯x,r) f(x) < f(¯x).
Theorem 9.6.3 generalizes this fact to the nondiﬀerentiable case and at the
same time quantiﬁes the inequality.
Theorem 9.6.3 (Decrease Principle) Assume that f : E →R is l.s.c.
and bounded below, and ¯x ∈E. Assume further that for some r > 0 and
σ > 0, one has
&
x ∈B(¯x, r) and x∗∈∂F f(x)

=⇒∥x∗∥> σ.
(9.55)
Then
inf
x∈B(¯x,r) f(x) ≤f(¯x) −rσ.
(9.56)
Proof. Obviously we may suppose that ¯x ∈dom f. Let r′ ∈(0, r). Observe
that
inf
x∈B(¯x,r) f(x) ≤lim
η↓0
inf
y∈B(¯x,η) f(y).
(9.57)
Let ϵ ∈(0, r −r′) and set
˜r := lim
η↓0
inf
y∈B(¯x,η) f(y) −f(¯x) −ϵ.

190
9 Subdiﬀerentials of Lower Semicontinuous Functionals
Applying Theorem 9.6.2 with S := B(¯x, r′) and x, r replaced by ¯x, ˜r, res-
pectively, we conclude that there exist z ∈B(¯x, r′) + B(o, ϵ) ⊆B(¯x, r) and
z∗∈∂F f(z) such that
˜r < ⟨z∗, y −¯x⟩+ ϵ∥y −¯x∥
∀y ∈B(¯x, r′).
(9.58)
By hypothesis (9.55) we have ∥z∗∥> σ. Hence there exists z0 ∈E satisfying
∥z0∥= 1 and ⟨z∗, z0⟩> σ. Inserting y := −r′z0 + ¯x into (9.58) yields
˜r < −r′⟨z∗, z0⟩+ r′ϵ < −r′σ + r′ϵ.
Recalling (9.57) and the deﬁnition of ˜r, we further obtain
inf
B(¯x,r) f(x) < f(¯x) −r′σ + (r′ + 1)ϵ.
Letting r′ ↑r and so ϵ ↓0 gives (9.56).
⊓⊔
Corollary 9.6.4 is a counterpart of Corollary 8.2.5 for a nondiﬀerentiable
functional f.
Corollary 9.6.4 Let f : E →R be l.s.c. and bounded below. Assume that
¯x ∈E and ϵ > 0 are such that f(¯x) < infE f + ϵ. Then for any λ > 0 there
exist z ∈B(¯x, λ) and z∗∈∂F f(z) satisfying
f(z) < inf
E f + ϵ
and
∥z∗∥< ϵ
λ.
Proof. See Exercise 9.8.9.
⊓⊔
9.7 The Fréchet Subdiﬀerential of Marginal Functions
We now establish representations of the F-subdiﬀerential of a marginal func-
tional of the form
f(x) := inf
y∈F ϕ(x, y),
x ∈E.
(9.59)
The ﬁrst result will be crucial for deriving an implicit multifunction
theorem in Sect. 13.10. Recall that f(x) := lim infy→x f(y) denotes the
lower semicontinuous closure of f
(see Exercise 1.8.11). Notice that
∂F f(x) ⊆∂F f(x).
Proposition 9.7.1 Assume that E and F are Fréchet smooth Banach spaces,
ϕ : E×F →R is l.s.c., and f is deﬁned by (9.59). Let x ∈E and x∗∈∂F f(x).
Then for any suﬃciently small ϵ > 0 there exist (xϵ, yϵ) ∈E×F and (x∗
ϵ, y∗
ϵ ) ∈
∂F ϕ(xϵ, yϵ) such that
∥x −xϵ∥< ϵ,
|f(x) −f(xϵ)| < ϵ,
(9.60)
ϕ(xϵ, yϵ) < f(xϵ) + ϵ < f(xϵ) + ϵ,
(9.61)
∥x∗
ϵ −x∗∥< ϵ,
∥y∗
ϵ ∥< ϵ.
(9.62)

9.7 The Fréchet Subdiﬀerential of Marginal Functions
191
Proof. Let g : E →R be a C1 function such that g′(x) = x∗and for some
ρ ∈(0, 1) one has
(f −g)(u) ≥(f −g)(x) = 0
∀u ∈B(x, ρ).
Let ϵ ∈(0, ρ) and let α > 0 be the constant associated with E in the
smooth variational principle of Theorem 8.4.3. Choose a positive number η <
min{ϵ/5,
!
ϵ/(5α) such that the following holds:
f(u) ≥f(x) −ϵ/5
∀u ∈B(x, η),
|g(u) −g(ˆu)| < ϵ/5
whenever ∥u −ˆu∥< η,
∥g′(u) −g′(x)∥< ϵ/2
∀u ∈B(x, η).
Now choose ¯u ∈B(x, η/2) close enough to x so that f(¯u) −g(¯u) < f(x) −
g(x) + αη2/8. Then there exists ¯v ∈F satisfying
ϕ(¯u, ¯v) −g(¯u) < f(¯u) −g(¯u) + αη2/8 < f(x) −g(x) + αη2/4
≤
inf
u∈B(x,ρ)
v∈F

ϕ(u, v) −g(u)

+ αη2/4.
Applying Theorem 8.4.3 to the functional (u, v) →ϕ(u, v) −g(u), we ﬁnd
(xϵ, yϵ) ∈B((¯u, ¯v), η/2) ⊆B((x, ¯v), η) and a C1 function h : E × F →R such
that max{∥h∥∞, ∥h′∥∞} < η and the functional
(u, v) →ϕ(u, v) −g(u) + h(u, v),
(u, v) ∈E × F,
attains its minimum at (xϵ, yϵ). It follows that

g′(xϵ) −h 1(xϵ, yϵ), −h 2(xϵ, yϵ)

∈∂F ϕ(xϵ, yϵ).
Setting x∗
ϵ := g′(xϵ) −h 1(xϵ, yϵ) and y∗
ϵ := −h 2(xϵ, yϵ), we see that (9.62)
holds. We further have
ϕ(xϵ, yϵ) ≤ϕ(¯u, ¯v) +

g(xϵ) −g(¯u)

+ h(¯u, ¯v) −h(xϵ, yϵ)
≤f(x) + αη2 + |g(xϵ) −g(¯u)| + 2∥h∥∞
< f(xϵ) + ϵ/5 + αη2 + |g(xϵ) −g(¯u)| + 2∥h∥∞
≤f(xϵ) + ϵ ≤f(xϵ) + ϵ,
which veriﬁes (9.61). This inequality together with f(xϵ) ≤f(xϵ) ≤ϕ(xϵ, yϵ)
shows that (9.60) also holds.
⊓⊔
The following result strengthens Proposition 9.7.1; it states that each x∗∈
∂F f(x) (in particular, each x∗∈∂F f(x)) can be approximated by some u∗∈
∂F,1ϕ(u, y), where u is close to x, for all y such that ϕ(x, y) is close to f(x).
Here, ∂F,1ϕ(u, y) denotes the F-subdiﬀerential of u →ϕ(u, y).

192
9 Subdiﬀerentials of Lower Semicontinuous Functionals
Proposition 9.7.2 Assume that E is a Fréchet smooth Banach space and F
is an arbitrary nonempty set. For each y ∈F let u →ϕ(u, y), u ∈E, be proper
and l.s.c. Let f : E →R be deﬁned by (9.59), let x ∈E, and x∗∈∂F f(x).
Then there exist a nonnegative continuous function γ : [0, +∞) →R with
γ(0) = 0 and a constant c > 0 such that for any suﬃciently small ϵ > 0,
any y ∈F, and any ˆx ∈B(x, ϵ) satisfying ϕ(ˆx, y) < f(x) + ϵ, there exist
u ∈B(x, c√ϵ) and u∗∈∂F,1ϕ(u, y) such that
ϕ(u, y) < f(x) + c√ϵ
and
∥u∗−x∗∥≤γ(ϵ).
Proof. Since x∗∈∂F f(x), there exist δ ∈(0, 1) and a C1 functional g : E →R
such that g′(x) = x∗and one has
0 = (f −g)(x) ≤(f −g)(u)
∀u ∈B(x, 2δ).
(9.63)
Moreover we may assume that δ is so small that g is L-continuous on B(x, 2δ)
with Lipschitz constant λ > 0 (cf. Propositions 3.2.4 and 3.4.2). Now let
ϵ ∈(0, δ2) be given. Further let ˆx be as in the theorem. It follows that
ϕ(ˆx, y) −g(ˆx) =

ϕ(ˆx, y) −f(x)

+

f(x) −g(ˆx)

< ϵ +

g(x) −g(ˆx)

≤ϵ + λ∥x −ˆx∥≤(1 + λ)ϵ.
For any u ∈B(x, 2√ϵ) we have ϕ(u, y)−g(u) ≥0 (which follows from (9.63)).
This and the foregoing estimate imply

ϕ(u, y) −g(u)

−

ϕ(ˆx, y) −g(ˆx)

≥−(1 + λ)ϵ
∀u ∈B(x, 2√ϵ).
Applying Theorem 9.6.2 with S, x, and f replaced by B(x, √ϵ), ˆx, and
u →ϕ(u, y) −g(u), respectively, we conclude that there exist u ∈B(x, √ϵ) +
B(o, √ϵ) ⊆B(x, 2√ϵ) and u∗∈∂F,1ϕ(u, y) such that
ϕ(u,y)) < ϕ(ˆx, y) +

g(u) −g(ˆx)

+ ϵ < f(x) + λ∥u −ˆx∥+ 2ϵ
<f(x) + λ(∥u −x∥+ ∥x −ˆx∥) + 2ϵ ≤f(x) + (3λ + 2)√ϵ
and
⟨u∗−g′(u), v −ˆx⟩≥−(1 + λ)ϵ
∀v ∈B(ˆx, √ϵ);
(9.64)
in this connection notice that ∂F,1

ϕ(u, y)−g(u)

= ∂F,1ϕ(u, y)−{g′(u)} and
employ Exercise 9.8.8. From (9.64) we conclude that ∥u∗−g′(u)∥≤(1+λ)√ϵ
and so
∥u∗−x∗∥≤∥u∗−g′(u)∥+∥g′(u)−g′(x)∥≤(1+λ)√ϵ+∥g′(u)−g′(x)∥≤γ(ϵ),
where
γ(ϵ) := (1 + λ)√ϵ + sup{∥g′(u) −g′(x)∥| u ∈B(x, 2√ϵ)}
∀ϵ ≥0.
Obviously, γ has the required properties. It remains to set c := 3λ + 2.
⊓⊔

9.8 Bibliographical Notes and Exercises
193
9.8 Bibliographical Notes and Exercises
The concept of the Fréchet subdiﬀerential can be traced back to Bazaraa and
Goode [10]. It was developed by Kruger and Mordukhovich [113], Borwein
and Strójwas [20], Schirotzek [194], and others. Crucial progress in the study
of the Fréchet subdiﬀerential was possible after Deville et al. [50] had shown
that it coincides with the viscosity subdiﬀerential in any Fréchet smooth
Banach space and so in particular with the proximal subdiﬀerential (see
Lemma 9.1.6 and Theorem 9.1.7). The concept of proximal subgradients is
due to Rockafellar [185].
The presentation of Chap. 9 owes much to Borwein and Zhu [23,
24].
As
these
authors,
we
took
the
nonlocal
approximate
sum
rule
(Theorem 9.2.3), which is due to Zhu [225], as starting point for the theory
of the F-subdiﬀerential. Local approximate sum rules go back to Ioﬀe [95].
Generalizations were obtained among others by Borwein and Ioﬀe [17] and
Borwein and Zhu [22].
The approximate mean value inequality is originally due to Zagrodny [220],
its version in terms of F-subdiﬀerentials was established by Loewen [124].
The simple proof of Theorem 9.4.1 via the nonlocal approximate sum rule is
adapted from Borwein and Zhu [23]. Zagrodny [220] also shows that Lebourg’s
mean value theorem (Theorem 7.4.4) can be derived from Theorem 9.4.1.
The multidirectional mean value theorem is due to Clarke and Ledyaev [38].
It is a cornerstone in the subdiﬀerential theory of Clarke et al. [39]. The
F-subdiﬀerential version of Theorem 9.6.2 appeared in Zhu’s paper [225],
the ﬁnite-dimensional version of Proposition 9.6.1 was taken from Clarke
et al. [39]. For further substantial results and applications in this direction
we also recommend [39] (inﬁnite-dimensional spaces) and Rockafellar and
Wets [189] (ﬁnite-dimensional spaces).
Proposition
9.7.1
is
due
to
Ledyaev
and
Zhu
[120, 121],
while
Proposition 9.7.2 is taken from Borwein and Zhu [24] who attribute it to
Ledyaev and Treiman.
Crandall and Lions [42] introduced the concept of a viscosity solution of the
Hamilton–Jacobi equation. Viscosity subsolutions and viscosity supersolutions
were ﬁrst studied by Crandall et al. [41]. Theorem 9.3.2 and its proof are due
to Borwein and Zhu [22]. For related comparison results as well as existence
theorems in terms of viscosity solutions see also Clarke et al. [39], Deville et
al. [50], and Subbotin [204].
Exercise 9.8.1 Verify Proposition 9.1.3.
Exercise 9.8.2 Verify Remark 9.1.4.

194
9 Subdiﬀerentials of Lower Semicontinuous Functionals
Exercise 9.8.3
(a) Let f(x) := −|x|, x ∈R. Show that ∂F f(0) = ∅but ∂♦f(0) = ∂◦f(0) =
[−1, 1].
(b) Let f(x) := −|x|3/2, x ∈R. Show that ∂P f(0) = ∅but ∂F f(0) = {f ′(0)}.
(Hence the inclusion in (9.8) can be proper.)
Exercise 9.8.4 Verify Remark 9.1.8.
Hint (cf. Borwein and Zhu [23]): Let η(t) := −ρ2(αt) for t > 0 and η(0) := 0;
here α is as in Lemma 9.1.6 and ρ2 is as in the proof of Theorem 9.1.7. Notice
that η is diﬀerentiable and put
γ(t) :=
 t
0
β(s) ds, t ≥0,
where β(s) := sup
0≤σ≤s
η′(σ), s ≥0.
Show that the function g : E →R deﬁned by
g(x) := f(¯x) + ⟨x∗, x −¯x⟩−γ(∥x −¯x∥),
x ∈E,
meets the requirement.
Exercise 9.8.5 Prove statement (e) of Proposition 9.1.9.
Exercise 9.8.6 Prove Proposition 9.2.2.
Exercise 9.8.7 Verify Lemma 9.2.5.
Exercise 9.8.8 We refer to Theorem 9.6.2:
(a) Show that in (9.48) the term ϵ∥y −x∥can be omitted if the set S is
bounded.
(b) Consider the example E = S := R and f(y) := ey to see that in general
the conclusion of Theorem 9.6.2 is false if the term ϵ∥y −x∥is omitted
from (9.48).
Exercise 9.8.9 Verify Corollary 9.6.4.

10
Multifunctions
10.1 The Generalized Open Mapping Theorem
In this section, let E and F be Banach spaces.
Given a multifunction Φ : E ⇒F (cf. Sect. 4.3), we write
Dom Φ := {x ∈E | Φ(x) ̸= ∅},
domain of Φ,
ker Φ
:= {x ∈E | o ∈Φ(x)},
kernel of Φ,
range Φ:= 
x∈E Φ(x),
range of Φ,
graph Φ:= {(x, y) ∈E × F | x ∈E, y ∈Φ(x)}, graph of Φ,
Φ−1(y):= {x ∈E | y ∈Φ(x)},
y ∈F,
inverse of Φ.
The multifunction Φ is said to be closed or convex if graph Φ is closed or
convex, respectively. We call Φ closed-valued or bounded-valued if Φ(x) is,
respectively, a closed or a bounded subset of F for any x ∈E. Notice that a
closed multifunction is closed-valued but the converse is not true.
Our aim in this section is to generalize the open mapping theorem from
continuous linear mappings to multifunctions. We prepare this with an aux-
iliary result. Let pE : E × F →E denote the projection onto E deﬁned by
pE(x, y) := x for each (x, y) ∈E × F. Analogously deﬁne pF : E × F →F.
Lemma 10.1.1 If C is a closed convex subset of E × F such that pE(C) is
bounded, then
int cl

pF (C)

= int

pF (C)

.
Proof. We may assume that C is nonempty. The assertion is veriﬁed when we
have shown that int cl

pF (C)

⊆pF (C). Thus let y ∈int cl

pF (C)

be given.
We shall show that there exists x ∈C satisfying (x, y) ∈C. Let ϵ > 0 be
such that B(y, 2ϵ) ⊆cl

pF (C)

. Choose (x0, y0) ∈C and deﬁne a sequence

(xk, yk)

in C recursively in the following way. Assume that (xk, yk) is already

196
10 Multifunctions
deﬁned. If yk = y, then set xk+1 := xk and yk+1 := yk. In this case, the element
x := xk meets the requirement. If yk ̸= y, then set
αk :=
ϵ
∥yk −y∥,
zk := y + αk(y −yk).
Then zk ∈B(y, ϵ) ⊆cl

pF (C)

. Hence there exists (˜x, ˜y) ∈C satisfying
∥˜y −zk∥≤1
2∥yk −y∥. Now let
(xk+1, yk+1) :=
αk
1 + αk
(xk, yk) +
1
1 + αk
(˜x, ˜y).
Since C is convex, we have (xk+1, yk+1) ∈C. It follows that
∥xk+1 −xk∥= ∥˜x −xk∥
1 + αk
≤diam pE(C)
ϵ
∥yk −y∥,
(10.1)
∥yk+1 −y∥= ∥˜y −zk∥
1 + αk
≤1
2∥yk −y∥.
(10.2)
From (10.2) we conclude that ∥yk −y∥≤2−k∥y0 −y∥. Hence yk →y as
k →∞. This together with (10.1) shows that (xk) is a Cauchy sequence and
so is convergent to some x ∈E. Since C is closed, we have (x, y) ∈C.
⊓⊔
Now we can establish the announced result.
Theorem 10.1.2 (Generalized Open Mapping Theorem) Let E and F
be Banach spaces and Φ : E ⇒F be a closed convex multifunction. If
y ∈int range(Φ), then y ∈int Φ
˚B(x, ρ)

for each x ∈Φ−1(y) and each ρ > 0.
Remark 10.1.3 Recall that a mapping T : E →F is said to be open if it
maps open subsets of E onto open subsets of F. The classical open mapping
theorem of Banach states that if T is continuous, linear, and surjective, then
T is open. We show that this follows from Theorem 10.1.2. Since T is contin-
uous and linear, the multifunction %T deﬁned by %T(x) := {T(x)}, x ∈E, has
a closed and convex graph. Moreover, the surjectivity of T is equivalent to
o ∈int T(E) and so to o ∈int range %T. Hence applying Theorem 10.1.2 with
x = o and y = o, we conclude that o ∈int T(˚BE) which is equivalent to T
being open. (Recall that ˚BE denotes the open unit ball of E.)
Proof of Theorem 10.1.2. We may and do assume that x = o, y = o (replace
Φ with ˜x →Φ(x −˜x) −y if necessary) and that ρ = 1. Set M := cl Φ( 1
2˚BE).
Then M is nonempty closed and convex. Let z ∈F. Since by assumption
range Φ is a neighborhood of zero, we have λz ∈range Φ for some λ > 0 and
so λz ∈Φ(x′) for some x′ ∈E. Furthermore, for each α ∈(0, 1) we obtain
αλz = αλz + (1 −α)o
∈αΦ(x′) + (1 −α)Φ(o) ⊆Φ

αx′ + (1 −α)o

= Φ(αx′);

10.2 Systems of Convex Inequalities
197
here the inclusion ⊆holds since graph Φ is convex. We conclude that αλz ∈
Φ( 1
2˚BE) for suﬃciently small α > 0. Since this holds for each z ∈F, it
follows that Φ( 1
2˚BE), and so M, is absorbing. Thus by Proposition 1.2.1, M
is a neighborhood of zero. Therefore, ρ˚BF ⊆int M for some ρ > 0. Now let
C := graph(Φ)∩
 1
2BE ×F

. Then C is closed and convex and pE(C) ⊆1
2BE.
Hence Lemma 10.1.1 implies that int cl pF (C) = int pF (C). Noting this and
pF (C) = Φ
 1
2BE

, we ﬁnally obtain
ρ˚BF ⊆int M ⊆int cl Φ( 1
2BE) = int pF (C) = int Φ( 1
2BE) ⊆int Φ(˚BE).
⊓⊔
10.2 Systems of Convex Inequalities
Let G be a normed vector space and P be a convex cone in G. Recall that we
denote by ≤P the preorder generated by P, i.e., for all u, v ∈G we set (see
Sect. 1.5)
u ≤P v
:⇐⇒
v ∈u + P.
Now let E be another normed vector space, let K be a convex subset of E,
and let S : K →G. Generalizing the notion of a convex functional, we say
that the mapping S is P-convex if for all x, y ∈K and all λ ∈(0, 1) we have
S

λx + (1 −λ)y

≤P λS(x) + (1 −λ)S(y),
in other words, if we have
λS(x) + (1 −λ)S(y) ∈S

λx + (1 −λ)y

+ P.
Consider the following assumptions:
(A) E, G, and H are normed vector spaces, K ⊆E is nonempty and convex.
P ⊆G is a convex cone with int(P) ̸= ∅, Q ⊆H is a closed convex cone.
S : K →G is P-convex, T : K →H is Q-convex.
Furthermore let
C := {(y, z) ∈G × H | ∃x ∈K : y −Sx ∈int P, z −Tx ∈Q}.
We shall utilize the condition
∃¯y ∈G : (¯y, o) ∈int C.
(10.3)
We establish a theorem of the alternative for convex mappings.
Proposition 10.2.1 If (A) and (10.3) are satisﬁed, then precisely one of the
following statements is true:
(a) ∃x ∈K :
Sx ∈−int P, Tx ∈−Q.
(b) ∃u ∈P ◦\ {o}
∃v ∈Q◦
∀x ∈K :
⟨u, Sx⟩+ ⟨v, Tx⟩≤0.

198
10 Multifunctions
Proof. It is obvious that (a) and (b) cannot hold simultaneously. Assuming
now that (a) is not satisﬁed, we have to show that (b) holds. It is easy to see
that the set C is convex. Moreover, (10.3) implies int C ̸= ∅, and since (a)
does not hold, we have (o, o) /∈C. Hence (o, o) and C can be separated by a
closed hyperplane, i.e., there exists (u, v) ∈G∗× H∗such that ⟨u, v⟩̸= o and
⟨u, y⟩+ ⟨v, z⟩≤0
∀(y, z) ∈C.
(10.4)
Now let x ∈K, p ∈int P, q ∈Q, α > 0, and β > 0. It follows that (Sx +
αp, Tx + βq) ∈C and so by (10.4),
⟨u, Sx⟩+ α⟨u, p⟩+ ⟨v, Tx⟩+ β⟨v, q⟩≤0.
(10.5)
Letting α ↓0 and β ↓0, we obtain ⟨u, Sx⟩+ ⟨v, Tx⟩≤0. Moreover, letting
α →+∞and β →+∞in (10.5), we get ⟨u, p⟩≤0 and ⟨v, q⟩≤0, respectively.
Since this holds for all p ∈int P and all q ∈Q, it follows that u ∈(int P)◦= P ◦
and v ∈Q◦. Assume that u = o. Then (10.4) implies ⟨v, z⟩≤0 for each
(y, z) ∈C. By virtue of (10.3), there exists a neighborhood W of zero in F
such that {¯y} × W ⊆C. Hence we obtain ⟨v, z⟩≤0 for each z ∈W and so
v = o. This is a contradiction to (u, v) ̸= o.
⊓⊔
To make Proposition 10.2.1 applicable, we need conditions suﬃcient for (10.3).
A simple condition is available if int Q is nonempty.
Lemma 10.2.2 Let (A) be satisﬁed. If Tx0 ∈−int Q for some x0 ∈K, then
(10.3) holds.
Proof. Choose p0 ∈int P and set ¯y := Sx0+p0. By assumption there exist zero
neighborhoods V in G and W in H such that p0+V ⊆int P and −Tx0+W ⊆
Q. For each y ∈V and each z ∈W we thus obtain
(¯y + y) −Sx0 = p0 + y ∈int P
and
z −Tx0 ∈Q.
We conclude that (¯y + V ) × W ⊆C and so (¯y, o) ∈int C.
⊓⊔
Now we drop the assumption that Q has interior points. With a subset A
of K we formulate the following conditions:
∃x0 ∈A :
S is continuous at x0 and Tx0 ∈−Q ∩int

T(A) + Q

.
(10.3a)
∃x0 ∈int A :
S is continuous at x0 and Tx0 ∈−Q ∩int

T(E) + Q

.
(10.3b)
Proposition 10.2.3 Let (A) be satisﬁed. Further let E and H be Banach
spaces and A be a closed convex subset of E such that A ⊆K.
(a) If T : K →H is continuous on A and Q-convex, then (10.3a) implies
(10.3).

10.2 Systems of Convex Inequalities
199
(b) If T is deﬁned, continuous, and Q-convex on all of E, then (10.3b) implies
(10.3a) and so (10.3).
Proof.
(a) Choose p0 ∈int P and a neighborhood V of zero in G such that p0 + V +
V ⊆int P. Further set ¯y := Sx0 + p0. Since S is continuous at x0, there
exists a neighborhood U of zero in E such that Sx0 −Sx ∈V for each
x ∈K ∩(x0 + U). Deﬁne Φ : E ⇒H by
Φ(x) :=

Tx + Q
if x ∈A,
∅
if x ∈E \ A.
(10.6)
It is easy to see that graph Φ is closed and convex. Hence Theorem 10.1.2
applies to Φ. Therefore, since Tx0 ∈int Φ(A) = int range Φ, we obtain
Tx0 ∈int

T(˚B(x, ρ)) + Q

for each x ∈E satisfying Tx −Tx0 ∈−Q and
any ρ > 0. Hence there exists a neighborhood W of zero in H satisfying
Tx0 + W ⊆T
˚B(x0, 1)

+ Q.
(10.7)
We show that
(¯y + V ) × W ⊆C.
(10.8)
Thus let y ∈V and z ∈W be given. By (10.7) there exists x ∈˚B(x0, 1)
such that Tx0 + z ∈Tx + Q and so z −Tx ∈−Tx0 + Q ⊆Q + Q = Q.
Moreover, we also have
(¯y + y) −Sx = p0 + (Sx0 −Sx) + y ∈p0 + V + V ⊆int P.
This shows that (¯y + y, z) ∈C. Hence (10.8) is veriﬁed and it follows that
(¯y, o) ∈int C.
(b) Let U be a neighborhood of zero in E with x0+U ⊆A. The multifunction
Φ deﬁned by (10.6) again satisﬁes the assumptions of Theorem 10.1.2.
Hence there exists a neighborhood W of zero in H such that Tx0 + W ⊆
T(x0 + U) + Q. Since x0 + U ⊆A, we obtain Tx0 ∈int

T(A) + Q

.
⊓⊔
For later use we want to reformulate the special case Q = {o} of Propo-
sition 10.2.1, incorporating Proposition 10.2.3(a) with A := K. We therefore
consider the following assumptions:
(ˆA) E, G, and H are normed vector spaces, with E and H complete.
K ⊆E is nonempty, convex, and closed, P ⊆G is a convex cone with
int(P) ̸= ∅.
S : K →G is P-convex and continuous, T : E →H is linear and
continuous.

200
10 Multifunctions
Proposition 10.2.4 Let (ˆA) be satisﬁed and assume that T(R+K) = H.
Then precisely one of the following statements is true:
(a) ∃x ∈K :
Sx ∈−int P, Tx = o.
(b) ∃u ∈P ◦\ {o}
∃v ∈H∗
∀x ∈K :
⟨u, Sx⟩+ ⟨v, Tx⟩≤0.
Notice that in the case considered in Proposition 10.2.4, the hypothesis
T(R+K) = H implies (and in fact is equivalent to) the second condition of
(10.3a).
10.3 Metric Regularity and Linear Openness
Convention. Throughout this section, let E and F denote Banach spaces.
In order to motivate the following, we consider a generalized equation of
the form
h(x) ∈Q,
x ∈E,
(10.9)
where the mapping h : E →F and the nonempty subset Q of F are given.
We seek x ∈E that satisﬁes (10.9). It turns out that much information on
the solvability and the solutions of (10.9) can be obtained by studying the
perturbed generalized equation
h(x) ∈Q + y,
x ∈E
(10.10)
that depends on the parameter y ∈F. This leads us to considering the mul-
tifunction Φh : E ⇒F deﬁned by
Φh(x) := h(x) −Q,
x ∈E.
(10.11)
Notice that (10.10) is equivalent to y ∈Φh(x). In other words, for a given
y ∈F the solution set of (10.10) is Φ−1
h (y).
The idea of stability is the following. Given (x, y) ∈E × F, the distance
d

x, Φ−1
h (y)

should be small whenever the distance d

y, Φh(x)

is small. For
an arbitrary multifunction Φ, not necessarily of the form (10.11), the following
deﬁnition quantiﬁes this idea.
Deﬁnition 10.3.1 The multifunction Φ : E ⇒F is said to be metrically
regular around (¯x, ¯y) ∈graph(Φ) if there exist a neighborhood W of (¯x, ¯y)
and a constant κ > 0 such that
d(x, Φ−1(y)) ≤κ d(y, Φ(x))
∀(x, y) ∈W.
(10.12)
The constant κ is called constant of metric regularity.
Parallel to metric regularity we consider the following concept.

10.3 Metric Regularity and Linear Openness
201
Deﬁnition 10.3.2 The multifunction Φ : E ⇒F is said to be open at a
linear rate around (¯x, ¯y) ∈graph(Φ) if there exist a neighborhood W of (¯x, ¯y)
and constants ρ > 0 and τ0 > 0 such that
y + ρτ BF ⊆Φ(x + τ BE)
∀(x, y) ∈graph(Φ) ∩W
∀τ ∈[0, τ0].
(10.13)
The constant ρ is called linear rate of openness.
To elucidate this concept we consider a mapping T : E →F. Observe that
T is an open mapping if and only if for any x ∈E and any τ > 0 there exists
σ(x, τ) > 0 such that
T(x) + σ(x, τ)BF ⊆T(x + τBE).
In contrast to this, T is open at a linear rate around (¯x, T(¯x)) if for any
(x, T(x)) ∈W and any τ ∈[0, τ0], we have
T(x) + ρτBF ⊆T(x + τBE).
The latter means that in a neighborhood of (¯x, T(¯x)) and for τ > 0 suﬃciently
small, σ(x, τ) can be chosen to be of the form ρτ, i.e., independent of x and
linear in τ. Instead of “openness at a linear rate” we shall sometimes brieﬂy
speak of “linear openness.”
Our strategy is as follows. We show that metric regularity and linear open-
ness are equivalent (Theorem 10.3.3). If Φ is convex, linear openness can be
characterized, using the generalized open mapping theorem, by the condition
¯y ∈int range Φ,
(10.14)
see Theorem 10.3.5. We then proceed to show that metric regularity is stable
under Lipschitz continuous perturbations (Theorem 10.3.6). The latter result
will be applied below to characterize tangential approximations of sets of the
form h−1(Q), which in turn will be crucial for deriving multiplier rules.
Theorem 10.3.3 If Φ : E ⇒F is a multifunction and (¯x, ¯y) ∈graph(Φ),
then the following assertions are equivalent:
(a) Φ is metrically regular around (¯x, ¯y) with constant κ > 0.
(b) Φ is open around (¯x, ¯y) at the linear rate ρ = κ−1.
Proof. First observe that Φ is metrically regular around (¯x, ¯y) with constant
κ if and only if the multifunction Ψ : E ⇒F deﬁned by Ψ(x) := Φ(x + ¯x) −¯y
is metrically regular around (o, o) with the same constant κ. An analogous
remark applies to linear openness. Therefore we may and do assume that
(¯x, ¯y) = (o, o).

202
10 Multifunctions
(a) =⇒(b): Let (x, y) ∈graph Φ be suﬃciently close to (o, o) and let τ > 0 be
suﬃciently small. Then for each y′ ∈F satisfying ∥y′ −y∥< κ−1τ we obtain
by (a) that
d(x, Φ−1(y′)) ≤κ d(y′, Φ(x)) ≤κ∥y′ −y∥< τ.
Hence there exists x′ ∈Φ−1(y′) such that ∥x −x′∥< τ. This implies y′ ∈
Φ(x′) ⊆Φ(x + τ BE). Since y′ ∈y + κ−1τ BF was arbitrary, we see that (b)
holds.
(b) =⇒(a): We may assume that W, ρ, and τ0 in Deﬁnition 10.3.2 are such
that
W = δE BE × δF BF ,
τ0ρ ≤1
2δF ,
(10.15)
where δE and δF are positive constants. Further let ϵE and ϵF be positive
constants satisfying
ϵE ≤δE,
ρϵE + ϵF ≤τ0ρ.
(10.16)
We show now that (a) holds with κ = ρ−1. Let x ∈ϵEBE and y ∈ϵF BF be
given. Applying (10.13) with (o, o) instead of (x, y) and with τ := ρ−1∥y∥, we
conclude that there exists x′ ∈Φ−1(y) such that ∥x′∥≤ρ−1∥y∥. It follows
that
d(x, Φ−1(y)) ≤∥x −x′∥≤∥x∥+ ρ−1∥y∥≤ϵE + ρ−1ϵF .
Hence, if d(y, Φ(x)) ≥ρ(ϵE +ρ−1ϵF ) = ρϵE +ϵF , then the assertion is veriﬁed.
Assume now that d(y, Φ(x)) < ρ(ϵE +ρ−1ϵF ). Then for each suﬃciently small
α > 0 there exists yα ∈Φ(x) satisfying
∥y −yα∥≤d(y, Φ(x)) + α < ρϵE + ϵF
≤
(10.16)
τ0ρ.
(10.17)
It follows that
∥yα∥≤∥yα −y∥+ ∥y∥< τ0ρ + ϵF
≤
(10.16)
τ0ρ + τ0ρ
≤
(10.15)
δF
(10.18)
and so (x, yα) ∈graph(Φ) ∩W. In view of (b) there exists x′ ∈Φ−1(y) such
that ∥x −x′∥≤ρ−1∥y −yα∥. We thus obtain
d(x, Φ−1(y)) ≤∥x −x′∥≤ρ−1∥y −yα∥
≤
(10.17)
ρ−1 d(y, Φ(x)) + ρ−1α.
Letting α ↓0 we see that (a) holds with κ = ρ−1.
⊓⊔
Under additional assumptions on the multifunction we obtain reﬁned
results.
Convex Multifunctions
Proposition 10.3.4 If the multifunction Φ : E ⇒F is convex, then for each
(¯x, ¯y) ∈graph Φ the following assertions are equivalent:

10.3 Metric Regularity and Linear Openness
203
(a) Φ is open at a linear rate around (¯x, ¯y).
(b) There exist constants µ > 0 and ν > 0 such that
¯y + ν BF ⊆Φ(¯x + µ BE).
(10.19)
More precisely, if (b) holds, then (10.13) holds with the following data:
W = µ BE × 1
2ν BF ,
ρ = ν
4µ,
τ0 = 2µ.
(10.20)
Proof.
(a) =⇒(b): Set µ = τ0 and ν = ρτ0.
(b) =⇒(a): We may assume that ¯x = o and ¯y = o. Deﬁne W as in (10.20).
Now let (x, y) ∈graph(Φ) ∩W. For each ˜τ ∈[0, 1] we obtain
y + 1
2ν˜τ BF = (1 −˜τ)y + ˜τ(y + 1
2ν BF )
⊆(1 −˜τ)y + ˜τν BF
⊆(1 −˜τ)Φ(x) + ˜τΦ(µ BE)
(by (10.19))
⊆Φ

(1 −˜τ)x + µ˜τ BE

(since Φ is convex)
⊆Φ(x + 2µ˜τ BE).
Hence setting τ := 2µ˜τ we see that with ρ and τ0 as in (10.20), condi-
tion (10.13) is satisﬁed.
⊓⊔
Now we can establish an important result in the theory of generalized
equations.
Theorem 10.3.5 (Stability Theorem) If Φ : E ⇒F is a closed convex
multifunction, then for each (¯x, ¯y) ∈graph Φ the following assertions are
equivalent:
(a) Φ is metrically regular around (¯x, ¯y).
(b) Φ is open at a linear rate around (¯x, ¯y).
(c) There exist constants µ > 0 and ν > 0 such that ¯y + ν BF ⊆Φ(¯x + µ BE).
(d) ¯y ∈int range Φ.
In particular, assume that (c) holds and that (x, y) ∈E × F satisﬁes
∥x −¯x∥< µ
2 ,
∥y −¯y∥< ν
8.
(10.21)
Then one has
d(x, Φ−1(y)) ≤4µν−1 d(y, Φ(x)).
(10.22)
Proof. Concerning (a) ⇐⇒(b) and (b) ⇐⇒(c), see Theorem 10.3.3 and
Proposition 10.3.4, respectively.
(c) =⇒(d): This is obvious.
(d) =⇒(c): This follows from Theorem 10.1.2.

204
10 Multifunctions
Now assume that (c) and (10.21) hold. By Proposition 10.3.4, the multifunc-
tion Φ is open at a linear rate, the data according to (10.13) being
W = δE BE × δF BF ,
δE := µ,
δF := 1
2ν,
ρ = ν
4µ,
τ0 = 2µ.
Passing from τ0 = 2µ to τ0 = µ, we obtain τ0ρ = ν/4 = δF /2 and so (10.15)
holds. Moreover, setting ϵE := µ/2 and ϵF := ν/8, we see that (10.16) is
also satisﬁed. The proof of Theorem 10.3.3 therefore shows that we have
d(x, Φ−1(y)) ≤κ d(y, Φ(x)), where κ = ρ−1 = 4µν−1.
⊓⊔
Multifunctions of the Form x →h(x) −Q
Recall that given a mapping h : E →F and a nonempty subset Q of F, we de-
note by Φh : E ⇒F the multifunction deﬁned by Φh(x) := h(x)−Q,
x ∈E.
For multifunctions of this type, we now show that metric regularity is stable
under small locally Lipschitz continuous perturbations. More precisely, we
pass from Φh to Φ*h, where the Lipschitz constant of h−*h is suﬃciently small.
Theorem 10.3.6 (Perturbation Theorem) Assume that
h,*h : E →F are continuous, Q ⊆F is closed and convex,
Φh is metrically regular around (¯x, ¯y) ∈graph Φh with constant κ > 0,
h −*h is locally L-continuous around ¯x with Lipschitz constant λ < κ−1.
Then the multifunction Φ*h is metrically regular around (¯x, ¯y −h(¯x) + *h(¯x))
with constant κ(λ) := κ(1 −κλ)−1.
Proof.
(I) Deﬁne g(x) := h(x) −*h(x) for any x ∈E. By assumption on Φh and g
there exist positive constants δE and δF such that
d(x, Φ−1
h (y)) ≤κ d(y, Φh(x))
whenever x ∈B(¯x, δE), y ∈B(¯y, δF ),
(10.23)
∥g(x) −g(x′)∥≤λ∥x −x′∥
whenever x, x′ ∈B(¯x, δE).
(10.24)
We shall show that there exist positive constants ϵE and ϵF such that
d(x, Φ−1
*h (y)) ≤κ(λ) d(y, Φ*h(x))
(10.25)
whenever
∥x −¯x∥< ϵE,
∥y −(¯y −g(¯x))∥< ϵF .
(10.26)
(II) Without loss of generality we may assume that g(¯x) = o. Choose β, ϵ > 0
such that
κλ < β < 1,
(1 + ϵ)κλ < β
(10.27)

10.3 Metric Regularity and Linear Openness
205
and ϵE, ϵF > 0 such that
ϵE < δE,
ϵF + λϵE < δF .
(10.28)
Now let (x, y) ∈E × F satisfy (10.26). We construct recursively a seq-
uence (xk) in E with the following properties:
x1 := x,
xk+1 ∈Φ−1
h (y + g(xk)),
k = 1, 2, . . . ,
(10.29)
∥xk+1 −xk∥≤(1 + ϵ) d

xk, Φ−1
h (y + g(xk))

,
k = 1, 2, . . .
(10.30)
We have
∥x−¯x∥< δE,
∥y+g(x)−¯y∥≤∥y−¯y∥+∥g(x)∥
<
(10.24),(10.28) δF (10.31)
and so (10.23) gives
d

x, Φ−1
h (y + g(x))

≤κ d

h(x) −y −g(x), P

= κ d

y, Φ*h(x)

.
Hence there exists x2 ∈Φ−1
h (y + g(x)) satisfying
∥x2 −x1∥≤(1 + ϵ)κ d(y, Φ*h(x))
<
(10.27) λ−1β d(y, Φ*h(x)).
(10.32)
For ρ > 0 let α(ρ) denote the modulus of continuity of h at ¯x, i.e.,
α(ρ) := sup{∥h(x) −h(¯x)∥| x ∈B(¯x, ρ)}.
It follows that
d(y, Φ*h(x)) = d(h(x) −y −g(x), Q) ≤∥

h(x) −y −g(x)

−

h(¯x) −¯y

∥
≤∥h(x) −h(¯x)∥+ ∥y −¯y∥+ ∥g(x)∥≤α(ϵE) + ϵF + λϵE.
(10.33)
Concerning the ﬁrst inequality, notice that (¯x, ¯y) ∈graph(Φh) and so
h(¯x) −¯y ∈Q. In view of (10.33), the estimate (10.32) gives
∥x2 −x1∥< λ−1β

α(ϵE) + λϵE + ϵF

.
(10.34)
Hence, if ϵE and ϵF (beside satisfying (10.28)) are small enough, then
∥x2 −¯x∥≤∥x2 −x1∥+ ∥x −¯x∥< δE,
∥

y + g(x2)

−¯y∥≤∥

y + g(x)

−¯y∥+ ∥g(x2) −g(x)∥< δF ;
(10.35)
here the last inequality follows from (10.24) and (10.31).

206
10 Multifunctions
(III) We now show by induction that ϵE and ϵF can be made so small that
for each k ∈N we have
∥xk −¯x∥< δE,
∥

y + g(xk)

−¯y∥< δF .
(10.36)
By (10.26) and (10.35) we know that (10.36) holds for k < k0 if k0 = 3.
Suppose now that (10.36) holds for all k < k0, where k0 ≥3. We have
to show that it also holds for k0. For each k ∈{2, . . . , k0 −1} we have
∥xk+1 −xk∥
<
(10.30) κ−1λ−1β d

xk, Φ−1
h (y + g(xk)

.
(10.37)
We further obtain
d

xk, Φ−1
h (y + g(xk))

≤κ d

y + g(xk), Φh(xk)

≤κ ∥

y + g(xk)

−

y + g(xk−1)

∥≤κλ∥xk −xk−1∥;
(10.38)
here the second inequality holds since xk ∈Φ−1
h (y+g(xk−1)) (see (10.29))
and so y+g(xk−1) ∈Φh(xk). Inserting (10.38) into (10.37) yields ∥xk+1−
xk∥< β∥xk −xk−1∥and so
∥xk+1 −xk∥< βk−1∥x2 −x1∥.
(10.39)
From this we get
∥xk0 −x1∥≤∥xk0 −xk0−1∥+ · · · + ∥x2 −x1∥≤
1
1 −β ∥x2 −x1∥
≤
(10.32)
β
λ(1 −β) d(y, Φ*h(x)),
(10.40)
which implies
∥xk0 −¯x∥≤∥xk0 −x1∥+ ∥x1 −¯x∥<
β
λ(1 −β) d(y, Φ*h(x)) + ϵE .
(10.41)
Moreover, we have
∥y + g(xk0) −¯y∥≤∥y −¯y∥+ ∥g(xk0) −g(¯x)∥
≤∥y −¯y∥+ λ∥xk0 −¯x∥≤ϵF + λϵE + β(1 −β)−1 d(y, Φ*h(x)). (10.42)
The inequalities (10.41) and (10.42) together with (10.33) show that
there exists δ > 0, independent of k, such that (cf. (10.36))
xk ∈˚B(¯x, δ),
y + g(xk) ∈˚B(¯y, δ)
for k = 1, 2, . . .
(10.43)

10.3 Metric Regularity and Linear Openness
207
(IV) From (10.39) and 0 < β < 1 we conclude that (xk) is a Cauchy sequence
and so, since E is complete, is convergent to some x′ ∈B(¯x, δ). Since g
is continuous, we have g(xk) →g(x′) as k →∞. This, (10.29), and the
closedness of graph Φh imply (x′, y + g(x′)) ∈graph Φh. Since Φ−1
h (y +
g(x′)) = Φ−1
*h (y), it follows that x′ ∈Φ−1
*h (y). We thus obtain
d

x, Φ−1
*h (y)

≤∥x1 −x′∥
≤
(10.40)
λ−1(1 −β)−1β d(y, Φ*h(x)).
Letting β ↓κλ (notice (10.27)), we ﬁnally see that (10.25) holds for all
x ∈˚B(¯x, δ) and all y ∈˚B(¯y −g(¯x), δ).
⊓⊔
Now assume that, in addition,
h : E →F is continuously diﬀerentiable at ¯x ∈h−1(Q).
Then h is F-diﬀerentiable on a nonempty open subset U of E containing ¯x. Let
ρ > 0 be such that B(¯x, ρ) ⊆U. Moreover, let *h : E →F be the linearization
of h at ¯x, i.e.,
*h(x) := h(¯x) + h′(¯x)(x −¯x),
x ∈E.
Parallel to
Φh(x) := h(x) −Q,
x ∈E,
(10.44)
we consider the linearized multifunction
Φ*h(x) := *h(x) −Q = h(¯x) + h′(¯x)(x −¯x) −Q,
x ∈E.
(10.45)
Since the function *h is continuous and aﬃne, the linearized multifunction Φ*h
is closed and convex. Hence by Theorem 10.3.5, Φ*h is metrically regular at
(¯x, o) if and only if o ∈int range Φ*h which is equivalent to
o ∈int

h(¯x) + h′(¯x)(E) −Q

.
(10.46)
By the mean value theorem (Proposition 3.3.4), we have
∥

h(x) −*h(x)

−

h(x′) −*h(x′)

∥= ∥

h(x) −h(x′)

−h′(¯x)(x −x′)∥
≤λ∥x −¯x∥
for all x, x′ ∈B(¯x, ρ),
where
λ := max{∥h′(x) −h′(¯x)∥| x ∈B(¯x, ρ)}.
Hence the function h −*h is locally Lipschitz continuous at ¯x, where the
Lipschitz constant can be made suﬃciently small by making ρ small enough.
Therefore Theorem 10.3.6 shows that Φh is also metrically regular. Conversely,
if Φh is metrically regular at (¯x, o), then by Theorem 10.3.6 the perturbed mul-
tifunction Φ*h is also metrically regular at (¯x, o), which in turn is equivalent
to (10.46) by Theorem 10.3.5. Thus we have proved the following.

208
10 Multifunctions
Proposition 10.3.7 Let Q ⊆F be closed and convex, assume that h : E →F
is continuous on E and continuously diﬀerentiable at ¯x ∈h−1(Q). Then the
following assertions are equivalent:
(a) Φh (see (10.44)) is metrically regular at (¯x, o).
(b) Φ*h (see (10.45)) is metrically regular at (¯x, o).
(c) The condition (10.46) holds.
We want to establish conditions that are at least suﬃcient for (10.46) or,
in view of later applications, for a slightly more general condition. Recall that
cr M denotes the core of the set M ⊆F.
Let A be a nonempty subset of E. We consider the Robinson condition
(see [176])
o ∈int

h(¯x) + h′(¯x)(A −¯x) −Q

,
(10.47)
the core condition
o ∈cr

h(¯x) + h′(¯x)(A −¯x) −Q

,
(10.48)
and the Zowe–Kurcyusz condition (see [229])
h′(¯x)

R+(A −¯x)

−R+

Q −h(¯x)

= F.
(10.49)
Proposition 10.3.8 Assume that h, Q, and ¯x are as in Proposition 10.3.7.
Assume further that A is a nonempty closed convex subset of E. Then
the Robinson condition (10.47), the core condition (10.48), and the Zowe–
Kurcyusz condition (10.49) are mutually equivalent.
Proof. The implication (10.47) =⇒(10.48) is obvious and the implica-
tion (10.48) =⇒(10.49) is immediately veriﬁed.
(10.49) =⇒(10.47): Deﬁne Ψ : E × R × R ⇒F by
Ψ(x, σ, τ) :=

h′(¯x)

σ(x −¯x)

−τ(Q −h(¯x))
if σ ≥0, τ ≥0, x ∈A,
∅
otherwise.
Then the multifunction Ψ is closed and convex and
range Ψ = h′(¯x)

R+(A −¯x)

−R+(Q −h(¯x)).
The condition (10.49), therefore, implies o ∈int range Ψ. By the generalized
open mapping theorem (Theorem 10.1.2) we see that o ∈int Ψ

(R+(A −¯x) ∩
BE) × [0, 1] × [0, 1]

and so (10.47) is satisﬁed.
⊓⊔

10.4 Openness Bounds of Multifunctions
209
10.4 Openness Bounds of Multifunctions
The following concept will turn out to be a suitable tool for the further study
of multifunctions.
Deﬁnition 10.4.1 Let the multifunction Φ : E ⇒F be open at a linear rate
around (¯x, ¯y) ∈graph Φ. Then
ope(Φ)(¯x, ¯y) := supremum of all linear rates of openness of Φ around (¯x, ¯y)
is called openness bound of Φ around (¯x, ¯y).
We shall consider two classes of multifunctions for which the openness
bound can easily be computed.
Processes
A multifunction Φ : E ⇒F is called (convex) process if graph(Φ) is a (convex)
cone. Notice that if Φ is a process, so is Φ−1. A process is said to be bounded
if it maps bounded sets into bounded sets. If Φ is a bounded convex process,
then the (ﬁnite) expression
∥Φ∥:=
sup
x∈B∩Dom Φ
inf
y∈Φ(x)
∥y∥
(10.50)
is called norm of Φ.
Proposition 10.4.2 Let Φ : E ⇒F be a bounded convex process. If Φ is
open at a linear rate around (o, o), then 0 < ∥Φ−1∥< +∞and
ope(Φ)(o, o) =
1
∥Φ−1∥.
(10.51)
Proof.
(I) We verify ∥Φ−1∥< +∞. Let ρ > 0 and τ0 be openness parameters of
Φ around (o, o). Then it follows that ρτBF ⊆Φ(τBE) for all τ ∈[0, τ0].
Since Φ is a process, we have Φ(τBE) = τΦ(BE). Therefore
ρBF ⊆Φ(BE).
(10.52)
We conclude that ∥Φ−1∥≤1/ρ.
(II) Next we show that ∥Φ−1∥> 0. Assume ∥Φ−1∥= 0. Choose some y0 ∈
BF ∩Dom(Φ−1) such that y0 ̸= o (which exists by (10.52)). For each
n ∈N there exists xn ∈Φ−1(y0) such that ∥xn∥< 1/n. It follows
that nxn ∈BE and ny0 ∈Φ(nxn). Hence Φ(BE) is not bounded, which
contradicts the hypothesis on Φ.
(III) Now we verify (10.51). As shown in step (I), if ρ is a linear rate of
openness, then (10.52) holds. Conversely, if (10.52) holds with some
ρ > 0, then
y + ρτBF ⊆Φ(x) + Φ(τBE) ⊆Φ(x + τBE)
∀(x, y) ∈graph Φ ∀τ ≥0.

210
10 Multifunctions
Hence we obtain
ope(Φ)(o, o) = sup{ρ > 0 | ρBF ⊆Φ(BE)}.
(10.53)
It is evident that (10.52) is equivalent to infx∈Φ−1(y) ∥x∥≤1
ρ for any y ∈BF .
From this and (10.53) we deduce (10.51).
⊓⊔
Single-Valued Multifunctions
Recall that a functional f : E →R is identiﬁed with the single-valued mul-
tifunction ˜f : E ⇒R deﬁned by ˜f(x) := {f(x)}, x ∈E. In the following we
shall say that f is open at a linear rate around (¯x, f(¯x)) if ˜f has this property,
and we write ope(f)(¯x) instead of ope( ˜f)(¯x, ˜f(¯x)).
Proposition 10.4.3 Let f : E →R be locally L-continuous around ¯x ∈E
and assume that o /∈∂◦f(¯x). Then f is open at a linear rate around (¯x, f(¯x))
and
ope(f)(¯x) = −inf
∥y∥=1 f ◦(¯x, y).
(10.54)
Proof.
(I) First notice that p := −inf∥y∥=1 f ◦(¯x, y) is a positive real number.
In fact, since o /∈∂◦f(¯x), we have f ◦(¯x, y0) < 0 for some y0 ∈E, where
we may assume that ∥y0∥= 1. Hence p > 0. Since f ◦(¯x, ·) is globally
L-continuous (Theorem 7.3.2), we have in particular f ◦(¯x, y) ≥−λ∥y∥
for each y ∈E, where λ > 0 is a local Lipschitz constant of f at ¯x.
Therefore p ≤λ < +∞.
(II) We show that ope(f)(¯x) ≥p. Let ϵ ∈(0, p/4] be given. Then there
exists yϵ ∈E such that ∥yϵ∥= 1 and f ◦(¯x, yϵ) ≤−p + ϵ
2. Moreover,
by the deﬁnition of f ◦(¯x, yϵ), there exists τ1 ∈(0, 1] such that for all
x ∈¯x + τ1BE and all τ ∈(0, τ1],
f(x + τyϵ) −f(x)
τ
≤−p + ϵ,
and so f(x + τyϵ) ≤f(x) −τ(p −ϵ) < f(x). Applying the intermediate
value theorem to the restriction of f to x + τBE, we obtain
[f(x) −τ(p −ϵ), f(x)] ⊆f(x + τBE).
(10.55)
Recall that (−f)◦(¯x, −yϵ) = f ◦(¯x, yϵ) (Theorem 7.3.2). Therefore, a sim-
ilar argument with f and yϵ replaced by −f and −yϵ, respectively, shows
that there exists τ2 ∈(0, 1] such that for all x ∈¯x + τ2BE and all
τ ∈(0, τ2],
[f(x), f(x) + τ(p −ϵ)] ⊆f(x + τBE).
(10.56)
Set τ0 := min{τ1, τ2}. Combining (10.55) and (10.56), we obtain

10.5 Weak Metric Regularity and Pseudo-Lipschitz Continuity
211
f(x) + (p −ϵ) · τBE ⊆f(x + τBE)
∀x ∈¯x + τ0BE
∀τ ∈(0, τ0],
which shows that p−ϵ is an openness rate of f around (¯x, f(¯x)). Letting
ϵ ↓0, we conclude that ope(f)(¯x) ≥p. In particular, we see that f is
open with a linear rate around (¯x, f(¯x)).
(III) Now we show that ope(f)(¯x) ≤p. This together with step (II) veriﬁes
(10.54). Let ρ > 0 be a linear rate of openness of f around (¯x, f(¯x)).
Then there exist a neighborhood W of (¯x, f(¯x)) and τ0 > 0 such that
f(x) + ρτη ∈f(x + τBE)
∀(x, f(x)) ∈W
∀τ ∈[0, τ0]
∀η ∈[−1, 1].
In particular, there exists y1 ∈BE such that
f(x) −ρτ = f(x + τy1)
∀(x, f(x)) ∈W
∀τ ∈[0, τ0].
It is clear that y1 ̸= o. By adjusting τ0 if necessary, we may assume that
∥y1∥= 1. It follows that −ρ = f ◦(¯x, y1) ≥−p and so ope(f)(¯x) ≤p.
⊓⊔
10.5 Weak Metric Regularity and Pseudo-Lipschitz
Continuity
We introduce and study two concepts that are closely related to metric regu-
larity and linear openness.
Deﬁnition 10.5.1
(a) The multifunction Φ : E ⇒F is said to be weakly metrically regular
around (¯x, ¯y) ∈graph Φ, if there exist a neighborhood U of ¯x, a neigh-
borhood V of ¯y, and a constant κ > 0 such that for all x ∈U with
Φ(x) ∩V ̸= ∅and all y ∈V one has
d(x, Φ−1(y)) ≤κ d(y, Φ(x)).
(10.57)
(b) The multifunction Ψ : F ⇒E is said to be pseudo-Lipschitz (or to have
the Aubin property) around (¯y, ¯x) ∈graph Ψ, if there exist a neighborhood
U of ¯x, a neighborhood V of ¯y, and a (Lipschitz) constant λ > 0 such that
Ψ(y) ∩U ̸= ∅
∀y ∈V
and
(10.58)
Ψ(y) ∩U ⊆Ψ(y′) + λ∥y −y′∥BE
∀y, y′ ∈V.
(10.59)
It is obvious that a metrically regular multifunction is weakly metrically
regular. A mapping T : F →E which is pseudo-Lipschitz around (¯y, T(¯y)),
where U can be chosen to be E, is locally Lipschitz continuous around ¯y.
Theorem 10.5.2 If Φ : E ⇒F is a closed-valued multifunction and (¯x, ¯y) ∈
graph Φ, then the following assertions are equivalent:

212
10 Multifunctions
(a) Φ is weakly metrically regular around (¯x, ¯y).
(b) Φ−1 is pseudo-Lipschitz around (¯y, ¯x).
Proof. (a) =⇒(b): Let the condition of Deﬁnition 10.5.1(a) be satisﬁed, where
we may assume that U := ¯x+ϵ1BE and V := ¯y+ϵ2BF with ϵ1 > 0 and ϵ2 > 0.
Since ¯x ∈U and ¯y ∈Φ(¯x) ∩V , we have by (10.57) that
d(¯x, Φ−1(y)) ≤κ d(y, Φ(¯x)) ≤κ∥y −¯y∥
∀y ∈V.
(10.60)
Choose a positive number ˜ϵ2 < ϵ2 so small that κ˜ϵ2 ≤ϵ1. Set ˜U := ¯x + κϵ2BE
and ˜V := ¯y + ˜ϵ2BF . If y ∈˜V , then y ∈V and (10.60) gives d(¯x, Φ−1(y)) ≤
κ˜ϵ2 < κϵ2. Hence there exists x ∈Φ−1(y) such that ∥x−¯x∥< κϵ2. This shows
that Φ−1(y) ∩˜U ̸= ∅for any y ∈˜V . Now let y, y′ ∈˜V be given. For any
x ∈Φ−1(y) ∩˜U it follows from (10.57) that
d(x, Φ−1(y′)) ≤κ d(y′, Φ(x)).
If λ > κ, we thus ﬁnd some x′ ∈Φ−1(y′) ∩˜U satisfying
∥x −x′∥≤λ d(y′, Φ(x)) ≤λ∥y′ −y∥.
In this connection notice that if d(y′, Φ(x)) = 0, then y′ ∈Φ(x) (as Φ(x) is
closed) and so we may take x′ := x. We have thus shown that (b) holds.
(b) =⇒(a): Let ϵ > 0 be such that U := ¯x + ϵBE and V := ¯y + ϵBF satisfy
the condition of Deﬁnition 10.5.1(b). Set ˜V := ¯y + (ϵ/3)BF . By (10.58) there
exists a neighborhood ˜U of ¯x such that ˜U ⊆U and Φ−1(y) ∩˜U ̸= ∅for all
y ∈˜V . We also have
d(y, Φ(x)) = d(y, Φ(x) ∩˜V )
∀x ∈˜U
∀y ∈˜V .
(10.61)
To verify this equation, let y′ ∈Φ(x) \ ˜V be given. Then
d(y, y′) ≥d(y′, ¯y) −d(¯y, y) > ϵ −ϵ
3 = 2
3ϵ.
On the other hand, for any z ∈Φ(x) ∩˜V we obtain
d(y, z) ≤d(y, ¯y + d(¯y, z) ≤ϵ
3 + ϵ
3 = 2
3ϵ.
Now let x ∈˜U be such that Φ(x) ∩˜V ̸= ∅and let y ∈˜V . By (10.59) we have
d(x, Φ−1(y)) ≤λ d(y, Φ−1(x) ∩U) ≤λ∥y −z∥
∀z ∈Φ(x) ∩˜V
and so
d(x, Φ−1(y)) ≤λ d(y, Φ(x) ∩˜V )
=
(10.61) λ d(y, Φ(x)),
which completes the proof.
⊓⊔

10.6 Linear Semiopenness and Related Properties
213
10.6 Linear Semiopenness and Related Properties
We modify the concepts introduced in the preceding sections. Assume again
that E and F are Banach spaces, Φ : E ⇒F is a multifunction and (¯x, ¯y) ∈
graph Φ.
Deﬁnition 10.6.1
(a) The multifunction Φ is said to be linearly semiopen around (¯x, ¯y) if there
exist numbers ρ > 0 and τ0 > 0 such that for all (x, y) ∈graph Φ satisfy-
ing x ∈¯x + τ0BE and y ∈¯y + τ0BF and all τ ∈[0, τ0] one has
y + ρτ∥x −¯x∥BF ⊆Φ(x + τ∥x −¯x∥BE).
(10.62)
(b) The multifunction Φ is said to be metrically semiregular around (¯x, ¯y) if
there exist numbers κ > 0 and τ1 > 0 such that for all (x, y) ∈E × F
satisfying x ∈¯x + τ1BE, y ∈¯y + τ1BF , and d(y, Φ(x)) ≤τ1∥x −¯x∥one
has
d(x, Φ−1(y)) ≤κ d(y, Φ(x)).
(10.63)
(c) The multifunction Φ is said to be semi-pseudo-Lipschitz around (¯x, ¯y) if
there exist numbers λ > 0 and τ2 > 0 such that for all (x, y) ∈graph Φ
satisfying x ∈¯x + τ2BE and y ∈¯y + τ2BF there is a neighborhood V (y)
of y such that
Φ(x) ∩V (y) ⊆Φ(x′) + λ∥x −x′∥BF
∀x′ ∈x + τ2∥y −¯y∥BE.
(10.64)
The numbers ρ > 0 and τ0 > 0 in Deﬁnition 10.6.1(a) will be referred to
as semiopenness parameters. An analogous terminology will be applied for
the numbers associated with metric semiregularity and semi-pseudo-Lipschitz
continuity.
Remark 10.6.2 It is obvious that linear openness implies linear semiopen-
ness. In fact, if Φ is open around (¯x, ¯y) with the linear rate ρ′ and the parameter
τ ′
0, then Φ is linearly semiopen around (¯x, ¯y) with the semiopenness parameters
ρ = ρ′ and τ0 = min{τ ′
0,
!
τ ′
0}. The norm functional on E, interpreted as a
multifunction from E to R, is not open at a linear rate around (0, 0) (it is not
even an open mapping) but is linearly semiopen around (0, 0). Observe that,
in contrast to openness at a linear rate, linear semiopenness does not impose
a condition on the multifunction at the reference point (¯x, ¯y) ∈graph Φ.
Theorem 10.6.3 If Φ : E ⇒F is a closed-valued multifunction and (¯x, ¯y) ∈
graph Φ, then the following assertions are mutually equivalent:
(a) Φ is linearly semiopen around (¯x, ¯y).
(b) Φ is metrically semiregular around (¯x, ¯y).
(c) Φ−1 is semi-pseudo-Lipschitz around (¯y, ¯x).

214
10 Multifunctions
Proof. As in the proof of Theorem 10.3.3 we may assume that (¯x, ¯y) = (o, o).
The parameters used in the following refer to the respective deﬁnition.
(a) =⇒(b): Choose τ1 > 0 so small that
τ1 < min

τ0
1 + ρτ0
, ρτ0

.
Let (x, y) ∈τ1BE ×τ1BF be such that d(y, Φ(x)) ≤τ1∥x∥. We distinguish two
cases:
Case 1. First assume that d(y, Φ(x)) > 0. Then x ̸= o. Deﬁne τ by
d(y, Φ(x)) = ρτ∥x∥. Then for any δ > 0 there exists y′ ∈Φ(x) such that
∥y −y′∥≤ρ(τ + δ) ∥x∥and so
∥y′∥≤∥y∥+ ∥y −y′∥≤τ1 + ρ(τ + δ)τ1.
Since ρτ ≤τ1 the choice of τ1 shows that τ < τ0. Hence we ﬁnd δ = δ(τ) > 0
such that τ + δ(τ) < τ0. We thus obtain
x ∈τ0BE,
y′ ∈τ0BF ,
y ∈y′ + ρτ0∥x∥BF .
Since (a) holds, we conclude from (10.62), with y replaced by y′, that there
exists x′ ∈x + (τ + δ(τ))∥x∥BE such that y ∈Φ(x′). Consequently,
d(x, Φ−1(y)) ≤∥x −x′∥≤(τ + δ(τ))∥x∥≤τ + δ(τ)
ρτ
d(y, Φ(x)).
Since this holds for all suﬃciently small δ(τ), we conclude that any κ > ρ−1
satisﬁes (10.63).
Case 2. Assume now that d(y, Φ(x)) = 0. Then y ∈Φ(x) as Φ(x) is closed.
Therefore we have d(x, Φ−1(y) = 0 ≤κ d(y, Φ(x)) with the same κ as above.
(b) =⇒(c): Choose τ2 > 0 such that τ2 + τ 2
2 < τ1/2 and take any λ > κ.
Fix any (y, x) ∈graph(Φ−1) with x ∈τ2BE and y ∈τ2BF . Further let y′ ∈
y + τ2∥x∥BF be given. We are going to show that with some neighborhood
U(x) of x, we have
Φ−1(y) ∩U(x) ⊆Φ−1(y′) + λ∥y −y′∥BE.
(10.65)
If x ̸= o, deﬁne U(x) := x + 1
2∥x∥BE. Now let x′ ∈Φ−1(y) ∩U(x) be given.
Then we have the estimates
∥x′∥≤∥x∥+ ∥x −x′∥≤τ2 + 1
2τ2 ≤3
4τ1 < τ1,
∥y′∥≤∥y∥+ τ2∥x∥≤(1 + τ2)τ2 < τ1,
d(y′, Φ(x′)) ≤∥y′ −y∥≤τ2∥x∥≤2τ2∥x′∥≤τ1∥x′∥.

10.6 Linear Semiopenness and Related Properties
215
Since (b) holds, we can apply (10.57) with x replaced by x′ to deduce
d(x′, Φ−1(y′)) ≤κ d(y′, Φ(x′)).
Since λ > κ, there exists x′′ ∈Φ−1(y′) satisfying
∥x′ −x′′∥≤λ d(y′, Φ(x′)) ≤λ ∥y −y′∥.
It follows that x′ ∈Φ−1(y′)+λ ∥y −y′∥BE. If x = o, then y +τ2∥x∥BF = {y},
and (10.65) holds with U(x) := E.
(c) =⇒(a): Set ρ := 1/λ and τ0 := τ2λ. Fix any (x, y) ∈graph Φ with
x ∈τ0BE and y ∈τ0BF . If x = o, there is nothing to prove. Assume now that
x ̸= o. It suﬃces to show that for any τ ∈(0, τ0] the implication
∥y′ −y∥= ρτ∥x∥=⇒y′ ∈Φ(x + τ∥x∥BE)
holds true. From ∥y′ −y∥= ρτ∥x∥we conclude y′ ∈y + τ2∥x∥BF . Now (c)
gives
x ∈Φ−1(y) ∩U(x) ⊆Φ−1(y′) + λ ∥y −y′∥BE.
Hence there exists x′ ∈Φ−1(y′) such that x ∈x′ + λ ∥y −y′∥BE and so
x′ ∈x + λ ∥y −y′∥BE. It follows that
y′ ∈Φ(x+λ ∥y −y′∥BE) = Φ(x+τ∥x∥BE).
⊓⊔
Next we show that linear semiopenness is stable under local Lipschitz
perturbations (cf. Theorem 10.3.6).
Theorem 10.6.4 Assume that Φ : E ⇒F is closed and linearly semiopen
around (¯x, ¯y) ∈graph Φ with semiopenness rate ρ > 0 and that Ψ : E →F
is locally L-continuous around ¯x with constant λ < ρ. Then Φ + Ψ is linearly
semiopen around (¯x, ¯y + Ψ(¯x)) with semiopenness rate ρ −λ.
Proof. Without loss of generality we can again assume that (¯x, ¯y) = (o, o) and
that Ψ(o) = o. Beside ρ let τ0 be a semiopenness parameter of Φ. Then for all
(x, y) ∈graph Φ with x ∈τ0BE, y ∈τ0BF and all τ ∈(0, τ0] we have
y + ρτ∥x∥BF ⊆Φ(x + τ∥x∥BE).
(10.66)
Choose τ1 > 0 such that
τ1 ≤min

2τ0
3(1 + λ), 1
2, τ0
2 ,
1
2(ρ −λ)

and that Ψ is Lipschitz continuous on τ1BE with Lipschitz constant λ. Now
let (x0, y0) ∈graph(Φ + Ψ) with x0 ∈τ1BE and y0 ∈τ1BF be given. We shall
show that for any τ ∈(0, τ1] we have
y0 + (ρ −λ)τ∥x0∥BF ⊆(Φ + Ψ)(x0 + τ∥x0∥BE).
(10.67)

216
10 Multifunctions
This is clear if x = o. Now let x ̸= o. Take any τ ∈(0, τ1] and any y′ ∈F
satisfying
∥y′ −y0∥= (ρ −λ)τ∥x0∥.
We are going to show the existence of x′ ∈E such that
x′ ∈x0 + τ∥x0∥BE
and
y′ ∈(Φ + Ψ)(x′).
(10.68)
By assumption on (x0, y0) we have

x0, y0 −Ψ(x0)

∈graph Φ,
∥x0∥≤τ1 ≤τ0,
∥y0 −Ψ(x0)∥≤∥y0∥+ ∥Ψ(x0)∥≤τ1 + λ∥x0∥≤(1 + λ)τ1 ≤τ0,
∥

y′ −Ψ(x0)

−

y0 −Ψ(x0)

∥≤(ρ −λ)t∥x0∥≤ρτ0|x0∥.
The last line shows that
y′ −Ψ(x0) ∈

y0 −Ψ(x0)

+ (ρ −λ)τ∥x0∥BF .
Hence by (10.66) with y := y0 −Ψ(x0), there exists x1 ∈E satisfying
y′ −Ψ(x0) ∈Φ(x1),
∥x1 −x0∥≤ρ −λ
ρ
τ∥x0∥.
Now we proceed by induction. Suppose that for i = 1, . . . , n we have obtained
xi ∈E such that
y′ −Ψ(xi−1) ∈Φ(xi),
∥xi −xi−1∥≤ρ −λ
ρ
λ
ρ
i−1
τ∥x0∥.
(10.69)
It follows that
∥xn −x0∥≤
n
	
i=1
∥xi −xi−1∥≤ρ −λ
ρ
τ∥x0∥
n
	
i=1
λ
ρ
i−1
≤ρ −λ
ρ
τ∥x0∥
∞
	
i=0
λ
ρ
i
= τ∥x0∥≤1
2∥x0∥.
(10.70)
On the one hand, this implies ∥xn∥≤3
4∥x0∥≤τ0. On the other hand, using
∥xn∥≥∥x0∥−∥xn −x0∥we also obtain ∥xn∥≥
1
2∥x0∥and so xn ̸= o.
Furthermore we have
∥y′ −Ψ(xn−1)∥≤∥y′ −y0∥+ ∥Ψ(xn−1)∥+ ∥y0∥
≤(ρ −λ)τ1∥x0∥+ 3
2λ∥x0∥+ ∥y0∥≤τ1
1
2λ + 3
2λ + 1

≤τ0

10.7 Linearly Semiopen Processes
217
and also
∥

y′ −Ψ(xn)

−

y′ −Ψ(xn−1)

∥≤λ∥xn −xn−1∥
≤(ρ −λ)
λ
ρ
i
τ∥x0∥≤(ρ −λ)
λ
ρ
i
2τ1∥xn∥≤ρτ0∥xn∥.
Hence we can apply (10.66) with x := xn and y := y′ −Ψ(xn−1) to ﬁnd
xn+1 ∈E such that y′ −Ψ(xn) ∈Φ(xn+1) and
∥xn+1 −xn∥≤1
ρ∥

y′ −Ψ(xn)

−

y′ −Ψ(xn−1)

∥
≤λ
ρ ∥xn −xn−1∥≤ρ −λ
ρ
λ
ρ
i
τ∥x0∥.
(10.71)
Since these estimates correspond to (10.69), we conclude that a sequence (xn)
exists in E satisfying (10.71) for all n ∈N. Since (xn) is a Cauchy sequence
in the Banach space E, it is convergent to some x′ ∈E. The continuity of Ψ
gives limn→∞Ψ(xn) = Ψ(x′). Since (xn+1, y′ −Ψ(xn)) ∈graph Φ for all n and
graph Φ is closed, we see that (x′, y′−Ψ(x′)) ∈graph Φ and so y′ ∈(Φ+Ψ)(x′).
Finally, ∥xn −x0∥≤τ∥x0∥for any n implies ∥x′ −x0∥≤τ∥x0∥, which
completes the proof.
⊓⊔
10.7 Linearly Semiopen Processes
For processes there is a close relationship between linear openness and linear
semiopenness. This will be elaborated in this section. We assume that
E and F are Banach spaces and Φ : E ⇒F is a process.
The following notions will be helpful.
Deﬁnition 10.7.1
(a) A set S ⊆E × F is said to be generating for the process Φ if graph Φ =
R+S, i.e., graph Φ is the cone generated by S.
(b) A set S ⊆E × F is said to be bounded in E by r (where r > 0) if ∥x∥≤r
whenever (x, y) ∈S.
Example 10.7.2 Let Φ be such that Φ(o) = {o}. Then the set
S := {(x, y) ∈graph Φ | ∥x∥= 1}
is generating for Φ and is bounded in E by r = 1.
Lemma 10.7.3 Let S be generating for Φ and bounded in E by r > 0. Assume
that Φ is open at a linear rate around each (x, y) ∈S with the openness
parameters ρ and τ0 being independent of (x, y). Then Φ is linearly semiopen
around (o, o) with the openness parameters ρ and ˜τ0 := min{τ0, τ0/r}.

218
10 Multifunctions
Proof. Let (x, y) ∈graph Φ, (x, y) ̸= (o, o), where x ∈˜τ0BE and y ∈˜τ0BF .
Then (λx, λy) ∈S for some λ > 0. By assumption we have λy + ρτBF ⊆
Φ(λx + τBE) for any τ ∈(0, τ0]. Since ∥λx∥≤r, it follows that
λy + ρτλ∥x∥BF ⊆Φ(λx + τλ∥x∥BE)
∀τ ∈(0, ˜τ0]
and so since Φ is a process,
λ

y + ρτ∥x∥BF

⊆λ Φ(x + τ∥x∥BE)
∀τ ∈(0, ˜τ0].
Dividing by λ results in the assertion.
⊓⊔
Lemma 10.7.4 Let Φ be open at a linear rate around (¯x, ¯y) ∈graph Φ. Then
there are neighborhoods U of ¯x and V of ¯y as well as positive numbers ρ and
τ0 such that Φ is open at a linear rate around each (x, y) ∈graph(Φ)∩(U ×V )
with the openness parameters ρ and τ0.
Proof. Let ¯ρ and ¯τ0 be openness parameters of Φ around (¯x, ¯y). Then
y′ + ¯ρτBF ⊆Φ(x′ + τBE)
(10.72)
whenever (x′, y′) ∈graph Φ, x′ ∈¯x + ¯τ0BE, y′ ∈¯y + ¯τ0BF , and τ ∈(0, ¯τ0].
Deﬁne
ρ := ¯ρ,
τ0 := ¯τ0/2,
U := ¯x + τ0BE,
V := ¯y + τ0BF .
Now let any (x, y) ∈graph(Φ) ∩(U × V ) be given. Choose (x′, y′) ∈graph Φ
such that x′ ∈x + τ0BE and y′ ∈y + τ0BF . Then x′ ∈¯x + ¯τ0BE and
y′ ∈¯y + ¯τ0BF . In view of (10.72) we obtain y′ + ρτBF ⊆Φ(x′ + τBE) for any
τ ∈(0, τ0], and the proof is complete.
⊓⊔
Proposition 10.7.5 Let S ⊆E × F be a generating set for Φ and assume
that one of the following conditions is satisﬁed:
(a) S is compact.
(b) E is ﬁnite dimensional, Φ : E →F is single-valued and locally L-
continuous around o, and S = {(x, Φ(x)) | ∥x∥= 1}.
If Φ is open at a linear rate around each point of S, then Φ is linearly semiopen
around (o, o).
Proof.
(I) First notice that in either case, S is bounded in E.
(II) By Lemma 10.7.4 we can assign to each (x, y) ∈S an open neighbor-
hood U(x) × V (y) as well as positive numbers ρ(x, y) and τ0(x, y) such
that Φ is open at a linear rate around each (x′, y′) ∈U(x) × V (y) with
the openness parameters ρ(x, y) and τ0(x, y).

10.8 Maximal Monotone Multifunctions
219
(IIIa) If condition (a) is satisﬁed, then the open covering

U(x)×V (y)

(x,y)∈S
of S contains a ﬁnite subcovering

U(xi) × V (yi)

i=1,...,n. Deﬁne
ρ := min{ρ(xi, yi) | i = 1, . . . , n},
τ0 := min{τ0(xi, yi) | i = 1, . . . , n}
and apply Lemma 10.7.3 to see that the assertion is true.
(IIIb) Now let condition (b) be satisﬁed. Since Φ is positively homoge-
neous and locally L-continuous around o in particular, Φ is (glob-
ally) L-continuous. Hence for each x ∈E satisfying ∥x∥= 1 we can
ﬁnd an open neighborhood U ′(x) ⊆U(x) such that x′ ∈U ′(x) im-
plies Φ(x′) ∈V (Φ(x)). Thus Φ is open at a linear rate around each
(x′, Φ(x′)), where x′ ∈U ′(x), with openness parameters ρ(x) and τ0(x).
The open covering

U ′(x)

∥x∥=1 of the compact set {x ∈E | ∥x∥= 1}
contains a ﬁnite subcovering

U ′(xi)

i=1,...,n. Setting
ρ := min{ρ(xi) | i = 1, . . . , n},
τ0 := min{τ0(xi) | i = 1, . . . , n}
and applying Lemma 10.7.3 concludes the proof.
⊓⊔
10.8 Maximal Monotone Multifunctions
The aim of this section is to establish conditions ensuring that a multifunction
Φ : E ⇒E∗satisﬁes range Φ = E∗, which means that for any x∗∈E∗the
generalized equation x∗∈Φ(x) has a solution x ∈E. In this connection, the
following concept is crucial.
Deﬁnition 10.8.1 The multifunction Φ : E ⇒E∗is said to be maximal
monotone if Φ is monotone and graph Φ is not properly contained in the
graph of any other monotone multifunction.
Maximal monotone multifunctions play a prominent role in treating para-
bolic diﬀerential equations as evolution equations in Sobolev spaces of Banach
space-valued functions. For instance, the generalized time derivative in the
time-periodic quasilinear parabolic problem turns out to be a (single-valued)
maximal monotone multifunction. A technical remark will be useful.
Remark 10.8.2 The monotone multifunction Φ : E ⇒E∗is maximal
monotone if and only if the following holds:
&
(y, y∗) ∈E × E∗and ⟨y∗−x∗, y −x⟩≥0
∀(x, x∗) ∈graph Φ

=⇒
(y, y∗) ∈graph Φ.
We show the maximal monotonicity of the subdiﬀerential mapping ∂F f.
Theorem 10.8.3 Let E be a Fréchet smooth Banach space, let f : E →R be
proper and l.s.c. If the multifunction ∂F f : E ⇒E∗is monotone, then it is
maximal monotone.

220
10 Multifunctions
Proof. Let (b, b∗) ∈E×E∗be such that b∗/∈∂F f(b). In view of Remark 10.8.2,
we have to show that there exist x ∈E and x∗∈∂F f(x) satisfying (b∗−
x∗, b −x) < 0. Since o /∈∂F (f −b∗)(b), the point b is not a minimizer of
f −b∗. Hence there exists a ∈E such that (f −b∗)(a) < (f −b∗)(b) := ρ. By
Zagrodny’s approximate mean value theorem (Theorem 9.4.1), there exist a
point c ∈[a, b) as well as sequences (xn) in E and (x∗
n) in E∗such that
lim
n→∞xn = c,
y∗
n := x∗
n −b∗∈∂F (f −b∗)(xn)
∀n,
lim inf
n→∞⟨y∗
n, c −xn⟩≥0,
lim inf
n→∞⟨y∗
n, b −a⟩> 0.
Noting that b −c = λ(b −a) with some λ ∈(0, 1], we conclude that
lim inf
n→∞⟨x∗
n −b∗, b −xn⟩≥lim inf
n→∞⟨y∗
n, b −c⟩+ lim inf
n→∞⟨y∗
n, c −xn⟩
≥∥b −c∥
∥b −a∥lim inf
n→∞⟨y∗
n, b −a⟩+ lim inf
n→∞⟨y∗
n, c −xn⟩> 0.
Since we obviously have x∗
n ∈∂F f(xn) for any n, it suﬃces to set x := xn and
x∗:= x∗
n for n suﬃciently large.
⊓⊔
Corollary 10.8.4 Let E be a Fréchet smooth Banach space. If f : E →R
is proper, convex, and l.s.c., then the subdiﬀerential mapping ∂f (of convex
analysis) is maximal monotone.
Proof. The subdiﬀerential mapping ∂f is monotone (Proposition 4.3.7) and
coincides with ∂F f (Proposition 9.1.9). Hence the assertion follows from
Theorem 10.8.3.
⊓⊔
To describe a class of single-valued maximal monotone multifunctions, we
need the following notion. The mapping T : E →E∗is said to be hemicon-
tinuous if for all x, y, z ∈E the real function τ →⟨T(x + τy), z⟩is continuous
on [0, 1]. Notice that each hemicontinuous mapping is radially continuous.
Proposition 10.8.5 If T : E →E∗is monotone and hemicontinuous, then
T is maximal monotone.
Proof. See Exercise 10.10.3.
⊓⊔
Before we can establish the announced surjectivity statement, we derive
an auxiliary result that is a distinguished relative of the sandwich theorem.
Lemma 10.8.6 Let E and F be Banach spaces, let f : E →R and g : F →R
be convex functionals and let A : E →F be a continuous linear mapping.
Assume further that:
(C1) f and g are l.s.c. and o ∈cr (dom g −A(dom f) or
(C2) g is continuous at some point of A(dom f).

10.8 Maximal Monotone Multifunctions
221
Then there exists y∗∈F ∗such that for any x ∈E and y ∈F, one has
inf
x∈E

f(x) + g(Ax)

≤

f(x) −⟨y∗, Ax⟩

+

g(y) + ⟨y∗, y⟩

.
(10.73)
Proof.
(I) We deﬁne the value functional h : F →R by
h(u) := inf
x∈E

f(x) + g(Ax + u)

,
u ∈F.
The functional h is convex and satisﬁes dom h = dom g −A(dom f). We
now show that o ∈int dom h.
(II) First we assume that condition (C1) is satisﬁed. Passing to suitable
translations of f and g if necessary, we may assume that f(o) = g(o) = 0.
Let
M :=

x∈BE
{u ∈F | f(x) + g(Ax + u) ≤1}.
Obviously M is convex.
(IIa) We show that M is absorbing. Let y ∈F be given. By (C1) there
exists τ0 > 0 such that τy ∈dom g −A(dom f) whenever |τ| ≤τ0.
For each such τ let x ∈dom f be such that Ax + τy ∈dom g. Then
f(x) + g(Ax + τy) =: r < +∞. Let s ≥max{∥x∥, |r|, 1}. Since f and g
are convex and f(o) = g(o) = 0, we deduce that
f
1
sx

+ g

A
1
sx

+ τ
s y

≤1
and so (τ/s)y ∈M. Hence M is absorbing, i.e., o ∈cr M.
(IIb) Next we show that M is cs-closed. Assume that λi ≥0, ∞
i=1 λi = 1,
yi ∈M and y := ∞
i=1 λiyi ∈F. Then for each i there is an xi ∈BE
satisfying
f(xi) + g(Axi + yi) ≤1.
(10.74)
Let ϵ > 0 be given. Then there exists i0 such that n
i=m λi < ϵ whenever
n > m ≥i0. It follows that

n
	
i=m
λixi
 ≤
n
	
i=m
λi∥xi∥< ϵ
whenever n > m ≥i0.
Hence ∞
i=1 λixi is convergent to some x in the Banach space E. The se-
quence (xi) is contained in the ball BE which is cs-closed (Lemma 1.2.2),
therefore x ∈BE. Since f and g are convex and l.s.c. and A is linear
and continuous, we deduce from (10.74) that
f(x) + g(Ax + y) = f
 ∞
	
i=1
λixi

+ g
 ∞
	
i=1
λi(Axi + yi)

≤
∞
	
i=1
λif(xi) +
∞
	
i=1
λig(Axi + yi) ≤1
and so y ∈M. Thus M is cs-closed.

222
10 Multifunctions
(IIc) Now Proposition 1.2.3 shows that cr M = int M. This together with
step (IIa) yields o ∈int M.
(IId) Since h is convex and bounded above on M and o ∈int M, the functional
h is continuous at o.
(III) Now we assume that condition (C2) is satisﬁed. Let ¯y ∈A(dom f) be
such that g is continuous at ¯y. Then there exists r > 0 such that g(¯y +
u) ≤g(¯y + 1 for any u ∈BF (o, r). Let ¯x ∈dom f be such that ¯y = A¯x.
Then we obtain
h(u) ≤f(¯x) + g(A¯x + u) ≤f(¯x) + g(¯y) + 1
∀u ∈BF (o, r).
As in step (IId) it follows that h is continuous at o.
(IV) Since h is convex and continuous at o, Proposition 4.1.6 implies that
there exists −y∗∈∂h(o). We thus have
inf
x∈E

f(x) + g(Ax)

= h(o) ≤h(u) + ⟨y∗, u⟩
≤f(x) + g(Ax + u) + ⟨y∗, u⟩
∀x ∈E ∀u ∈F.
(10.75)
Now, if x ∈E and y ∈F are given, then inserting u := y −Ax in
(10.75), we obtain (10.73).
⊓⊔
Recall that the duality mapping J : E ⇒E∗is deﬁned by J = ∂j, where
j(z) := 1
2∥z∥2. By Remark 4.6.3, J can be written as
J(z) = {z∗∈E∗| ∥z∗∥= ∥z∥, ⟨z∗, z⟩= ∥z∥2},
z ∈E.
(10.76)
If E is reﬂexive, then on identifying E∗∗with E, the duality mapping
J : E∗⇒E is deﬁned analogously.
Theorem 10.8.7 Let E be a reﬂexive Banach space. If Φ : E ⇒E∗is max-
imal monotone, then range (Φ + λJ) = E∗for any λ > 0.
Proof.
(I) Suppose for the moment we had already veriﬁed the existence of z ∈E
satisfying o ∈(Φ + J)(z). Now let λ > 0 and z∗∈E∗be given. Since
λ−1(Φ−z∗) inherits the maximal monotonicity from Φ, we can conclude
that there exists z ∈E satisfying o ∈(λ−1(Φ −z∗) + J)(z). It follows
that z∗∈(Φ + λJ)(z). Hence it remains to show that the generalized
equation o ∈(Φ + J)(z) has a solution.
(II) Deﬁne fΦ : E × E∗→R by
fΦ(x, x∗) :=
sup
y∗∈Φ(y)

⟨y∗, x⟩+ ⟨x∗, y⟩−⟨y∗, y⟩

= ⟨x∗, x⟩+
sup
y∗∈Φ(y)
⟨x∗−y∗, y −x⟩.

10.8 Maximal Monotone Multifunctions
223
The function fΦ is proper, convex, and l.s.c. Since Φ is maximal
monotone, it follows that
fΦ(x, x∗) ≥⟨x∗, x⟩,
(10.77)
and by Remark 10.8.2 equality holds if and only if x∗∈Φ(x).
(III) For any x ∈E and x∗∈E∗we have
0 ≤1
2

∥x∥2 + ∥x∗∥2
−∥x∥· ∥x∗∥≤1
2

∥x∥2 + ∥x∗∥2
+ ⟨x∗, x⟩(10.78)
and so (10.77) passes into
0 ≤fΦ(x, x∗) + 1
2

∥x∥2 + ∥x∗∥2
.
(10.79)
Lemma 10.8.6 (with E and F replaced by E × E∗) now ensures the existence
of (z, z∗) ∈E × E∗such that for all (y, y∗) ∈E × E∗,
0 ≤fΦ(x, x∗) −⟨z∗, x⟩−⟨x∗, z⟩+ 1
2

∥y∥2 + ∥y∗∥2
+ ⟨z∗, y⟩+ ⟨y∗, z⟩.
Choose y∗∈−J(z) and apply (10.76), analogously choose y ∈−J(z∗). Then
(10.79) gives
fΦ(x, x∗) −⟨z∗, x⟩−⟨x∗, z⟩≥1
2

∥z∥2 + ∥z∗∥2
.
(10.80)
Let x∗∈Φ(x). Then fΦ(x, x∗) = ⟨x∗, x⟩(cf. step (II)). Hence (10.80) can be
written as
⟨x∗−z∗, x −z⟩≥1
2

∥z∥2 + ∥z∗∥2
+ ⟨z∗, z⟩≥0,
(10.81)
where the last inequality follows from (10.78). Since (10.81) holds for any
x, x∗satisfying x∗∈Φ(x) and Φ is maximal monotone, we can conclude that
z∗∈Φ(z). Setting x := z and x∗:= z∗in (10.81), we obtain 1
2

∥z∥2+∥z∗∥2
+
⟨z∗, z⟩= 0, which by (10.76) implies −z∗∈J(z) and so o ∈(Φ + J)(z).
⊓⊔
With the aid of Theorem 10.8.7 we shall establish a result on the surjec-
tivity of Φ. For this, we need the following notion.
The multifunction Φ : E ⇒E∗is said to be coercive if Dom Φ is bounded,
or Dom Φ is unbounded and
inf{⟨x∗, x⟩| x∗∈Φ(x)}
∥x∥
→+∞
as x ∈Dom Φ, ∥x∥→+∞.
Theorem 10.8.8 (Surjectivity Theorem) Let E be a reﬂexive Banach
space. If Φ : E ⇒E∗is maximal monotone and coercive, then range Φ = E∗.

224
10 Multifunctions
Proof.
(I) By Proposition 4.7.14, E admits an equivalent norm that is F-
diﬀerentiable on E \ {o} and so the duality mapping J with respect to
this norm is single-valued. Notice that Φ is also coercive with respect to
the equivalent norm.
(II) Let z∗∈E∗be given. Choose a sequence (λk) of positive numbers
tending to zero. By Theorem 10.8.7, for each k there exists xk ∈Dom Φ
such that z∗∈(Φ + λkJ)(xk) and so there exists x∗
k ∈Φ(xk) satisfying
z∗= x∗
k + λkJ(xk).
(10.82)
(III) If Dom Φ is bounded, then the sequence (xk) is also bounded. Assume
now that Dom Φ is unbounded. Since Φ is coercive, there exists ρ > 0
such that
⟨x∗, x⟩
∥x∥
> ∥z∗∥
whenever x ∈Dom Φ, ∥x∥> ρ, x∗∈Φ(x).
For these x we obtain
⟨x∗−z∗, x⟩= ⟨x∗, x⟩−⟨z∗, x⟩> ∥x∥· ∥z∗∥−⟨z∗, x⟩≥0.
On the other hand, in view of (10.76) and (10.82) we have
⟨x∗
k −z∗, xk⟩= −λk⟨J(xk), xk⟩= −λk∥xk∥2 ≤0.
Therefore we must conclude that ∥xk∥≤ρ for any k. This further implies
∥x∗
k −z∗∥= λk∥J(xk)∥= λk∥xk∥≤λkρ →0
as k →∞.
(IV) Since E is reﬂexive, the bounded sequence (xk) contains a subsequence
(zk) that is weakly convergent to some z ∈E. We show that z sat-
isﬁes z∗∈Φ(z). Since Φ is monotone, we obtain for any y ∈Dom Φ
and y∗∈Φ(y) that ⟨z∗
k −y∗, zk −y⟩≥0 for any k. In this context, (z∗
k)
denotes the corresponding subsequence of (x∗
k). Since by step (III) the se-
quence (z∗
k) is norm convergent to z∗, the last inequality implies ⟨z∗−y∗,
z−y⟩≥0 (Exercise 10.10.1). Since Φ is maximal monotone, we conclude
that z ∈Dom Φ and z∗∈Φ(z).
⊓⊔
As an immediate consequence of Theorem 10.8.8 and Proposition 10.8.5
we obtain:
Corollary 10.8.9 If E is a reﬂexive Banach space and T : E →E∗is
monotone, hemicontinuous, and coercive, then range T = E∗.

10.9 Convergence of Sets
225
10.9 Convergence of Sets
Convention. Throughout this section, unless otherwise speciﬁed, E is a
normed vector space and F is a locally convex (not necessarily normed)
vector space.
Here we consider this more general setting because we will later apply the
following concepts to multifunctions of the form Φ : E ⇒E∗, where E∗is
equipped with the weak∗topology σ(E∗, E).
Deﬁnition 10.9.1 Let (Sα)α∈A, where A is a directed set, be a generalized
sequence of subsets of F.
(a) The Painlevé–Kuratowski upper limit Lim supα∈A Sα is the set of cluster
points of generalized sequences (vα)α∈A, where vα ∈Sα for any α ∈A.
(b) The Painlevé–Kuratowski lower limit Lim infα∈A Sα is the set of limits of
generalized sequences (vα)α∈A, where vα ∈Sα for any α ∈A.
The deﬁnition applies in particular to a sequence (Sk)k∈N in F, in which
case we write Lim supk→∞, Sk and Lim infk→∞, Sk, respectively.
Now let Φ : E ⇒F be a multifunction and ¯x ∈Dom Φ. We consider Φ as
a generalized sequence (Φ(x))x∈E in F, where E is directed by the preorder
y ⪰x if and only if ∥y −¯x∥≤∥x −¯x∥. The resulting Painlevé–Kuratowski
upper (lower) limit is then written
Lim sup
x→¯x
Φ(x)
and
Lim inf
x→¯x
Φ(x),
respectively. Lemma 10.9.2 gives the explicit characterization of these limits.
Lemma 10.9.2 If Φ : E ⇒F is a multifunction and ¯x ∈Dom Φ, then:
(a) Lim supx→¯x Φ(x) is the set of cluster points of generalized sequences
(vα)α∈A, where vα ∈Φ(xα) for any α in the directed set A and (xα)α∈A
is convergent in E to ¯x.
(b) Lim infx→¯x Φ(x) is the set of limits of generalized sequences (vα)α∈A,
where vα ∈Φ(xα) for any α ∈A and (xα)α∈A is convergent in E to ¯x.
Proof. See Exercise 10.10.4.
⊓⊔
The following result is also easily veriﬁed.
Lemma 10.9.3 One always has
Lim inf
x→¯x
Φ(x) ⊆cl Φ(¯x) ⊆Lim sup
x→¯x
Φ(x).
Proof. See Exercise 10.10.5.
⊓⊔

226
10 Multifunctions
If, in addition, F is a normed vector space, we have a simple characteriza-
tion of these concepts. We write x →Φ ¯x if x ∈Dom Φ and x →¯x.
Lemma 10.9.4 If E and F are normed vector spaces and Φ : E ⇒F is a
multifunction, then
Lim sup
x→¯x
Φ(x) =

v ∈F
 lim inf
x→Φ¯x d(Φ(x), v) = 0

,
Lim inf
x→¯x
Φ(x) =

v ∈F
 lim
x→Φ¯x d(Φ(x), v) = 0

,
and these limits are closed sets.
Proof. See Exercise 10.10.6.
⊓⊔
We shall also make use of a sequential variant of the above concepts.
Deﬁnition 10.9.5 Let E be a normed vector space, Φ : E ⇒E∗be a mul-
tifunction, and ¯x ∈Dom Φ. The sequential Painlevé–Kuratowski upper limit
sLim supx→¯xΦ(x) of Φ is deﬁned to be the set of all x∗∈E∗for which there
exist a sequence (xk) in Dom Φ that is norm convergent to ¯x and a sequence
(x∗
k) in E∗that is σ(E∗, E) convergent to x∗such that x∗
k ∈Φ(xk) for all
k ∈N.
Lemma 10.9.6 is an immediate consequence of the deﬁnitions.
Lemma 10.9.6 Let E be a normed vector space and equip E∗with the topol-
ogy σ(E∗, E). Further let Φ : E ⇒E∗. Then
sLim sup
x→¯x
Φ(x) ⊆Lim sup
x→¯x
Φ(x).
Now we introduce a convergence concept for a generalized sequence of
functions.
Deﬁnition 10.9.7 Let (ϕα)α∈A be a generalized sequence of functions ϕα :
F →R:
(a) The upper epi-limit of (ϕα)α∈A is the function eLim supα∈Aϕα whose
epigraph is the Painlevé–Kuratowski lower limit of epi ϕα:
epi

eLim sup
α∈A
ϕα

:= Lim inf
α∈A (epi ϕα).
(10.83)
(b) The lower epi-limit of (ϕα)α∈A is the function eLim infα∈Aϕα whose epi-
graph is the Painlevé–Kuratowski upper limit of epi ϕα:
epi

eLim inf
α∈A
ϕα

:= Lim sup
α∈A
(epi ϕα).
(10.84)
(c) If the upper and the lower epi-limit of (ϕα)α∈A coincide, then this function
is called epi-limit of (ϕα)α∈A and is denoted eLimα∈Aϕα.

10.10 Bibliographical Notes and Exercises
227
It is left as Exercise 10.10.7 to show that the right-hand sides of (10.83)
and (10.84) in fact are the epigraphs of functions. If, in particular, (ϕk) is a
sequence of functions, then the corresponding epi-limit functions are deﬁned,
respectively, by
epi

eLim sup
k→∞
ϕk

:= Lim inf
k→∞(epi ϕk),
epi

eLim inf
k→∞
ϕk

:= Lim sup
k→∞
(epi ϕk),
epi

eLim
k→∞ϕk

:= epi

eLim sup
k→∞
ϕk

= epi

eLim inf
k→∞
ϕk

.
In a normed vector space we have a simple characterization of the epi-limit.
Lemma 10.9.8 Let F be a normed vector space and ϕk : F →R for all
k ∈N. Then ϕ = eLim
k→∞ϕk if and only if for each x ∈F one has
ϕ(x) ≤lim inf
k→∞ϕk(xk)
for any sequence xk →x
and
ϕ(x) ≥lim sup
k→∞
ϕk(xk)
for some sequence xk →x.
Proof. See Exercise 10.10.8.
⊓⊔
10.10 Bibliographical Notes and Exercises
The presentation of Sects. 10.1–10.5 was strongly inﬂuenced by Bonnans
and Shapiro [16]. Lemma 10.1.1 is due to Robinson [176]. The general-
ized open mapping theorem (Theorem 10.1.2) is due, independently, to
Robinson [176] and Ursescu [211]. Proposition 10.2.1 is a result of Tuy [210],
Proposition 10.2.3 appears in this context in [196].
The concept of openness at a linear rate is inherent in Lyusternik’s orig-
inal proof (of 1934) of the tangent space theorem (see Theorem 11.4.2). The
concept was developed for single-valued mappings, under diﬀerent names, by
Dmitruk et al. [54], Dolecki [55], Warga [214], and others.
Ioﬀe [94] obtained Theorem 10.3.3, the proof given here follows Bonnans
and Shapiro [16]. The stability theorem (Theorem 10.3.5) is due, indepen-
dently, to Robinson [175] and Ursescu [211]. The perturbation theorem
(Theorem 10.3.6) can be traced back to Lyusternik [128] and Graves [79]. For
the estimate in the theorem see Ioﬀe [93].
Proposition 10.4.3 is a result of P¨uhl [172]. Jourani and Thibault [107]
have established a corresponding suﬃcient condition for linear openness of
certain classes of multifunctions but without a representation of the openness
bound. P¨uhl [171] gives a nice geometric proof for the fact that a continu-
ous convex functional f is open at a linear rate around ¯x if and only if ¯x

228
10 Multifunctions
is not a minimizer of f. This paper also contains suﬃcient conditions for
cone-convex mappings to be open at a linear rate. Theorem 10.5.2 and its
proof are taken from Borwein and Zhuang [25]. Penot [164] showed that the
assumption that Φ be closed-valued can be dropped; see also Mordukhovich
and Shao [139].
Concerning the results of Sects. 10.6 and 10.7 we refer to P¨uhl and Schi-
rotzek [173], see also the doctoral thesis of Heidrun P¨uhl [172].
The elegant proof of Theorem 10.8.3 is taken from Borwein and Zhu [24].
In this connection, we had to assume that E be a Fréchet smooth Banach space
so that we could apply Theorem 10.8.3 which in turn was deduced with the aid
of Theorem 9.4.1. By a quite diﬀerent proof, Rockafellar [181] showed that the
conclusion of Corollary 10.8.4 holds in any Banach space E. A substantially
simpler proof of Rockafellar’s result is due to Simons [198] (cf. Phelps [165]).
Groh [80] considers monotone operators via certain scalarizations called forms.
Also see Exercise 10.10.2.
Theorem 10.8.7 is due to Rockafellar [182]. Lemma 10.8.6 and the astound-
ingly easy proof of Theorem 10.8.7 are taken from Borwein and Zhu [24].
In this context, the function fΦ is called Fitzpatrick function by Borwein and
Zhu. Theorem 10.8.8 together with results on the maximal monotonicity of the
sum of two multifunctions admits various important applications. For read-
ers interested in this subject, we recommend the comprehensive two-volume
monograph by Zeidler [223,224].
As standard references to multifunction theory we recommend Aubin and
Frankowska [8] (inﬁnite-dimensional spaces) and Rockafellar and Wets [189]
(ﬁnite-dimensional spaces).
Exercise 10.10.1 Assume that E is a Banach space, (xk) is a sequence in E
and (x∗
k) is a sequence in E∗. Show that limk→∞⟨x∗
k, xk⟩= ⟨x∗, x⟩if
(a) (xk) is norm convergent to x and (x∗
k) is weak∗convergent to x∗or
(b) (xk) is weakly convergent to x and (x∗
k) is norm convergent to x∗.
Exercise 10.10.2 Prove the following assertion:
If E is a Banach space and f : E →R is convex and continuous, then ∂f :
E ⇒E∗is maximal monotone.
Hint: Follow the proof of Theorem 10.8.3 but apply the mean value theorem
of Proposition 3.3.1 instead of Theorem 9.4.1 (cf. Phelps [165]).
Exercise 10.10.3 Verify Proposition 10.8.5.
Exercise 10.10.4 Prove Lemma 10.9.2.
Exercise 10.10.5 Verify Lemma 10.9.3.
Exercise 10.10.6 Prove Lemma 10.9.4.

10.10 Bibliographical Notes and Exercises
229
Exercise 10.10.7 Prove that the right-hand sides of (10.83) and (10.84) in
fact are the epigraphs of functions.
Hint: Show that a set S ⊆F × R is the epigraph of a function ϕ : F →R if
and only if it has the following two properties:
(a) (x, t) ∈S and t′ > t imply (x, t′) ∈S and
(b) x ∈F and t∗:= inf{t ∈R | (x, t) ∈S} imply (x, t∗) ∈S.
Exercise 10.10.8 Prove Lemma 10.9.8.

11
Tangent and Normal Cones
11.1 Tangent Cones: First Properties
In this section, unless otherwise speciﬁed, we assume that E is a normed vector
space, A is a nonempty subset of E, and ¯x ∈A. Resuming the discussion
started in Sect. 7.1, we deﬁne various tangent cones as local approximations
of A near ¯x. By x →A ¯x we mean that x ∈A and x →¯x.
Deﬁnition 11.1.1 One deﬁnes
Tr(A, ¯x) := {y ∈E | ∃τk ↓0 ∀k : ¯x + τky ∈A},
cone of radial directions to A at ¯x,
T(A, ¯x) := {y ∈E | ∃τk ↓0 ∃yk →y ∀k : ¯x + τkyk ∈A},
contingent cone to A at ¯x,
TC(A, ¯x) := {y ∈E | ∀xk →A ¯x ∀τk ↓0 ∃yk →y ∀k : xk + τkyk ∈A},
Clarke tangent cone to A at ¯x,
Ir(A, ¯x) := {y ∈E | ∃ϵ > 0 ∀τ ∈(0, ϵ) : ¯x + τy ∈A},
cone of radial inner directions, or
cone of feasible directions, to A at ¯x,
I(A, ¯x) := {y ∈E | ∃ϵ > 0 ∀τ ∈(0, ϵ) ∀z ∈B(y, ϵ) : ¯x + τz ∈A},
cone of inner directions to A at ¯x,
H(A, ¯x) := {y ∈E | ∀xk →A ¯x ∀τk ↓0 ∀yk →y ∀k : xk + τkyk ∈A},
cone of hypertangents to A at ¯x.
Proposition 11.1.2
(a) One has
I(A, ¯x) ⊆Ir(A, ¯x) ⊆Tr(A, ¯x) ⊆T(A, ¯x),
H(A, ¯x) ⊆TC(A, ¯x) ⊆T(A, ¯x).

232
11 Tangent and Normal Cones
Each of the sets is a cone, I(A, ¯x) and H(A, ¯x) may be empty, the other
cones contain the zero element.
(b) T(A, ¯x) and TC(A, ¯x) are closed, TC(A, ¯x) is also convex.
(c) If U is a neighborhood of ¯x, then T(A, ¯x) = T(A ∩U, ¯x), analogously for
the other cones considered in (a).
(d) If A is convex, then
Ir(A, ¯x) = Tr(A, ¯x) = R+(A −¯x),
T(A, ¯x) = cl

R+(A −¯x)

,
I(A, ¯x) = {ρ(x −¯x) | ρ > 0, x ∈int A}.
Proof.
(I) We show that T(A, ¯x) is closed. Let (zn) be a sequence in T(A, ¯x) con-
verging to some y ∈E. For each n ∈N there exist sequences (τ (n)
k
) in
(0, +∞) and (y(n)
k ) in E satisfying
τ (n)
k
↓0,
y(n)
k
→zn as k →∞
and
¯x + τ (n)
k
y(n)
k
∈A ∀k ∈N.
Hence for each n ∈N there exists k(n) such that
τ (n)
k
< 1
n
and
∥y(n)
k
−zn∥< 1
n
∀k ≥k(n).
Setting τn := τ (n)
k(n) and yn := y(n)
k(n), we obtain τn ↓0 and yn →y as
n →∞as well as ¯x + τnyn ∈A for each n. Therefore y ∈T(A, ¯x).
(II) We now verify that TC(A, ¯x) is convex. Let y1, y2 ∈TC(A, ¯x). Since
TC(A, ¯x) is a cone, we only have to show that y1+y2 ∈TC(A, ¯x). Assume
that τk ↓0 and xk →A ¯x as k →∞. Then there exists (y(1)
k ) in E such
that y(1)
k
→y1 as k →∞and x(1)
k
:= xk + τky(1)
k
∈A for each k. Since
x(1)
k
→¯x, there also exists (y(2)
k ) in E satisfying
y(2)
k
→y2
and
xk + τk

y(1)
k
+ y(2)
k

= x(1)
k
+ τky(2)
k
∈A
∀k ∈N.
Since we also have y(1)
k
+ y(2)
k
→y1 + y2, we conclude that y1 + y2 ∈
TC(A, ¯x).
The veriﬁcation of the remaining assertions is left as Exercise 11.7.1.
⊓⊔
Statement (c) of the proposition means that the approximating cones depend
on the local properties of A near ¯x only.
Figure 11.1 supplements the ﬁgures in Sect. 7.1.
Proposition 11.1.3 If A, B ⊆E and ¯x ∈A ∩B, then
Tr(A, ¯x) ∩Ir(B, ¯x) ⊆Tr(A ∩B, ¯x),
(11.1)
T(A, ¯x) ∩I(B, ¯x) ⊆T(A ∩B, ¯x).
(11.2)

11.1 Tangent Cones: First Properties
233
T(A, ¯x) + ¯x
TC(A, ¯x) + ¯x
A
¯x
Fig. 11.1
Proof. We verify (11.2), leaving (11.1) as Exercise 11.7.2. Let y ∈T(A, ¯x) ∩
I(B, ¯x). Then there exist sequences τk ↓0 and yk →y such that ¯x + τkyk ∈A
for any k ∈N. Further there exists ϵ > 0 such that ¯x + τB(y, ϵ) ∈B for any
τ ∈(0, ϵ). For all suﬃciently large k we therefore obtain ¯x + τkyk ∈A ∩B.
Hence y ∈T(A ∩B, ¯x).
⊓⊔
The following example shows that in the above formulas, I(B, ¯x) cannot
be replaced by T(B, ¯x).
Example 11.1.4 In E := R2 consider the sets A := {(x, y) ∈R2 | y ≥x2}
and B := {(x, y) ∈R2 | y ≤−x2}. Then with ¯x := (0, 0) we have
T(A, ¯x) ∩T(B, ¯x) = R × {0}
but
T(A ∩B, ¯x) = {(0, 0)}.
Proposition 11.1.5 There always holds
T(A, ¯x) = {y ∈E | lim inf
τ↓0
τ −1dA(¯x + τy) = 0},
TC(A, ¯x) = {y ∈E | lim inf
τ↓0
x→A ¯x
τ −1dA(x + τy) = 0}.
Proof. See Exercise 11.7.3.
⊓⊔
Now we establish a representation of the Clarke tangent cone in terms of
the Clarke directional derivative. It is easy to see that
dA(x) −dA(y)
 ≤∥x −y∥
∀x, y ∈E,
(11.3)
i.e., the distance functional dA(·) is (globally) L-continuous and so d◦
A(x, y)
exists for all x, y ∈E.
Proposition 11.1.6 One has
TC(A, ¯x) = {y ∈E | d◦
A(¯x, y) = 0}.

234
11 Tangent and Normal Cones
Proof.
(I) Let y ∈E satisfy d◦
A(¯x, y) = 0. Further let sequences τk ↓0 and xk →A ¯x
be given. Then
0 = lim sup
τ↓0
x→¯x
1
τ

dA(x + τy) −dA(x)

≥lim sup
k→∞
1
τk

dA(xk + τky) −dA(xk)
  
=0

.
On the other hand, we have lim infk→∞1
τk dA(xk + τky) ≥0 and so
lim
k→∞
1
τk dA(xk + τky) = 0.
By the deﬁnition of dA, for each k ∈N there exists zk ∈A satisfying
∥zk −(xk + τky)∥≤dA(xk + τky) + τk
k .
Setting yk :=
1
τk (zk −xk), we obtain
∥yk −y∥=
1
τk ∥zk −(xk + τky)∥≤
1
τk dA(xk + τky) + 1
k →0
as k →∞.
Further we have xk + τkyk = zk ∈A for each k. Hence y ∈TC(A, ¯x).
(II) Now let y ∈TC(A, ¯x). By the deﬁnition of d◦
A, there exist τk ↓0 and
x′
k →¯x satisfying
d◦
A(¯x, y) = lim
k→∞
1
τk

dA(x′
k + τky) −dA(x′
k)

.
(11.4)
Notice that the sequence (x′
k) need not belong to A. But since there does
exist a sequence (xk) in A converging to ¯x (set, for example, xk := ¯x for
each k), we have
d◦
A(¯x, y) ≥lim sup
k→∞
1
τk

dA(xk + τky) −dA(xk)

≥0.
Therefore it suﬃces to show that the right-hand side of (11.4) is not
greater than zero. Let zk ∈A be such that
∥zk −x′
k∥≤dA(x′
k) + τk
k .
(11.5)
Since x′
k →¯x as k →∞, it follows that
∥zk −¯x∥≤∥zk −x′
k∥+ ∥x′
k −¯x∥≤dA(x′
k) + τk
k + ∥x′
k −¯x∥→0
and so zk →¯x. Since y ∈TC(A, ¯x), there exists yk →y satisfying zk +
τkyk ∈A for each k ∈N. Moreover, since dA is L-continuous with L-
constant 1 (see (11.3)), we obtain
dA(x′
k + τky) ≤dA(zk + τkyk) + ∥zk −x′
k∥+ τk∥yk −y∥
≤
(11.5)
dA(x′
k) + τk
 1
k + ∥yk −y∥

.
Hence the right-hand side of (11.4) is in fact at most equal to zero.
⊓⊔

11.1 Tangent Cones: First Properties
235
Corollary 11.1.7 If A is convex, then TC(A, ¯x) = T(A, ¯x) = cl R+(A −¯x).
Proof. By Proposition 11.1.2(d) we know that the second equation holds true.
We now show that TC(A, ¯x) = cl R+(A−¯x). Since A is convex, the functional
dA is convex, and it is also L-continuous. Hence dA is regular (Remark 7.4.2)
and so d◦
A(¯x, ·) = dA,G(¯x, ·). By Proposition 11.1.6, u ∈TC(A, ¯x) is equivalent
to dA,G(¯x, u) = 0 and so to limτ↓0 τ −1dA(¯x+τu) = 0. The latter relation holds
if and only if for each k ∈N there exist τk ∈(0, 1
k) and xk ∈A such that
uk := 1
τk

¯x + τku −xk

→0
as k →∞.
Noting that u =
1
τk

xk −¯x

+ uk completes the proof.
⊓⊔
The following “ball characterizations” of the Clarke tangent cone and the
hypertangent cone will be useful in the sequel.
Lemma 11.1.8
(a) One has y ∈TC(A, ¯x) if and only if for any ϵ > 0 there exists δ > 0 such
that
A ∩B(¯x, δ) + τy ⊆A + τB(o, ϵ)
∀τ ∈(0, δ).
(b) One has y ∈H(A, ¯x) if and only if there exists ϵ > 0 such that
u + τv ∈A
whenever u ∈A ∩B(¯x, ϵ), v ∈B(y, ϵ), τ ∈(0, ϵ).
Proof. See Exercise 11.7.4.
⊓⊔
The next result will be applied in Sect. 12.3 to derive a multiplier rule.
Proposition 11.1.9 H(A, ¯x) is always open. If H(A, ¯x) is nonempty, then
int TC(A, ¯x) = H(A, ¯x).
Proof.
(I) It follows easily from Lemma 11.1.8 that the cone H(A, ¯x) is open. Since
it is a subset of TC(A, ¯x), we always have H(A, ¯x) ⊆int TC(A, ¯x).
(IIa) Assuming now that H(A, ¯x) is nonempty, we have to show that
int TC(A, ¯x) ⊆H(A, ¯x).
(11.6)
This will be done when we have veriﬁed the relation
H(A, ¯x) + TC(A, ¯x) ⊆H(A, ¯x).
(11.7)
In fact, let y ∈int TC(A, ¯x) be given. Choose z ∈H(A, ¯x). Then y −
ηz ∈TC(A, ¯x) for some suﬃciently small η > 0. Since we also have
ηz ∈H(A, ¯x), we see that
y = ηz + (y −ηz)
∈
(11.7) H(A, ¯x).

236
11 Tangent and Normal Cones
(IIb) Thus it remains to verify (11.7). Let y1 ∈H(A, ¯x) and y2 ∈TC(A, ¯x) be
given. We have to show that for some ϵ > 0,
A ∩B(¯x, ϵ) + τ B(y1 + y2, ϵ) ⊆A
∀τ ∈(0, ϵ).
(11.8)
Since y1 ∈H(A, ¯x), there exists ϵ1 > 0 such that
A ∩B(¯x, ϵ1) + τ B(y1, ϵ1) ⊆A
∀τ ∈(0, ϵ1).
(11.9)
Furthermore, y2 ∈TC(A, ¯x) implies that for some ϵ2 > 0 we have
A ∩B(¯x, ϵ2) + τ y2 ⊆A + B

o, τ ϵ1
2

∀τ ∈(0, ϵ2).
(11.10)
Now let ϵ be such that
0 < ϵ < min

ϵ2, ϵ1
2 ,
ϵ1
1 + ϵ1 + ∥y2∥

.
Let y be an element of the left-hand side of (11.7). It follows that y =
z + τ(y1 + y2 + ϵz′), where z ∈A ∩B(¯x, ϵ) and z′ ∈B(o, 1). Since ϵ ≤ϵ2,
by (11.10) we see that for some z′′ ∈B(o, 1) we have z+τy2−τ ϵ1
2 z′′ ∈A.
Moreover, we obtain
¯x −

z + τy2 −τ ϵ1
2 z′′ ≤∥¯x −z∥+ τ
y2 −ϵ1
2 z′′
< ϵ + ϵ

∥y2∥+ ϵ1
2

< ϵ1
and so z + τy2 −τ ϵ1
2 z′′ ∈A ∩B(¯x, ϵ1). In view of (11.9), it follows that
z + τy2 −τ ϵ1
2 z′′ + τ B(y1, ϵ1) ⊆A.
(11.11)
Notice that
y = z + τ

y2 −ϵ1
2 z′′
+ τ

y1 + (ϵz′ + ϵ1
2 z′′)

,
where
ϵz′ + ϵ1
2 z′′ ≤ϵ + ϵ1
2 < ϵ1. Hence (11.11) implies y ∈A. We have
thus veriﬁed (11.7) and so (11.6).
⊓⊔
In view of Proposition 11.1.9 we give the following:
Deﬁnition 11.1.10 The set A is said to be epi-Lipschitzian at ¯x if H(A, ¯x)
is nonempty. If H(A, x) is nonempty for all x ∈A, then A is said to be epi-
Lipschitzian.
Remark 11.1.11 Rockafellar [184] showed that if E is ﬁnite dimensional,
then A is epi-Lipschitzian at ¯x if and only if int TC(A, ¯x) is nonempty. He also
gave an example of a convex subset A of an inﬁnite-dimensional normed vector
space such that int TC(A, ¯x) is nonempty but A is not epi-Lipschitzian.

11.2 Normal Cones: First Properties
237
The following result provides an important class of epi-Lipschitzian sets.
Proposition 11.1.12 If A is convex and int A is nonempty, then A is epi-
Lipschitzian.
Proof.
(I) Let x′ ∈int A and choose ϵ > 0 such that B(x′, 2ϵ) ⊆A. Now let ¯x be
any element of A. We show that y := x′ −¯x ∈H(A, ¯x). First notice that
¯x + B(y, 2ϵ) ⊆A.
(11.12)
In fact, if v ∈B(y, 2ϵ) and v′ := ¯x + v, then ∥v′ −x′∥= ∥v −y∥≤2ϵ and
so v′ ∈B(x′, 2ϵ) ⊆A.
(II) Now let u ∈A ∩B(¯x, ϵ) and v ∈B(y, ϵ) be given. We then have
∥(v + u −¯x) −y∥≤∥v −y∥+ ∥u −¯x∥≤2ϵ
and so (by (11.12)) u + v = ¯x + (v + u −¯x) ∈A. Since A is convex, we
obtain u+τv = τ(u+v)+(1−τ)u ∈A for any τ ∈[0, 1]. By Lemma 11.1.8
we conclude that y ∈H(A, ¯x).
⊓⊔
In analogy to Proposition 11.1.3 we have the following intersection result.
Proposition 11.1.13 If A, B ⊆E and ¯x ∈A ∩B, then
TC(A, ¯x) ∩H(B, ¯x) ⊆TC(A ∩B, ¯x).
Proof. See Exercise 11.7.5.
⊓⊔
We formulate without proof a stronger intersection result due to
Rockafellar [183].
Proposition 11.1.14 Let A, B ⊆E, let ¯x ∈A ∩B, and assume that
TC(A, ¯x) ∩H(B, ¯x) is nonempty. Then
TC(A, ¯x) ∩TC(B, ¯x) ⊆TC(A ∩B, ¯x).
11.2 Normal Cones: First Properties
Let again A be a nonempty subset of the normed vector space E and let
¯x ∈A. We now deﬁne several normal cones to A at ¯x.
Deﬁnition 11.2.1 If A is convex, then
N(A, ¯x) := (A −¯x)◦= {v ∈E∗| ⟨v, x −¯x⟩≤0
∀x ∈A}
is called normal cone to A at ¯x in the sense of convex analysis.

238
11 Tangent and Normal Cones
Lemma 11.2.2 If A is convex, then
N(A, ¯x) = T(A, ¯x)◦
and
N(A, ¯x) = ∂δA(¯x).
Proof. The ﬁrst equation follows by Proposition 11.1.2(d) and the second is
an immediate consequence of the deﬁnition of N(A, ¯x).
⊓⊔
In the nonconvex case, the deﬁnition of normal cone is modeled on one or
the other of the preceding equations.
Deﬁnition 11.2.3 The cone NC(A, ¯x) := TC(A, ¯x)◦is called Clarke normal
cone to A at ¯x.
Recall that cl∗M denotes the σ(E∗, E)-closure of M ⊆E∗.
Proposition 11.2.4 One has NC(A, ¯x) = cl∗
R+∂◦dA(¯x)

.
Proof. By Proposition 7.3.7, we have d◦
A(¯x, y) = max{⟨v, y⟩| v ∈∂◦dA(¯x)}.
Using this and Proposition 11.1.6, we obtain
y ∈TC(A, ¯x) ⇐⇒d◦
A(¯x, y) = 0 ⇐⇒⟨v, y⟩≤0 ∀v ∈∂◦dA(¯x)
⇐⇒y ∈

∂◦dA(¯x)
◦,
which
implies
NC(A, ¯x)
=

∂◦dA(¯x)
◦◦.
The
bipolar
theorem
(Proposition 2.3.3) ﬁnally yields the assertion. In this connection, recall
that the Clarke subdiﬀerential is convex.
⊓⊔
Deﬁnition 11.2.5 Let A be a nonempty subset of E and ¯x ∈A. Then we
call
NF (A, ¯x) := ∂F δA(¯x)
Fréchet normal cone to A at ¯x,
NV (A, ¯x) := ∂V δA(¯x)
viscosity normal cone to A at ¯x,
NP (A, ¯x) := ∂P δA(¯x)
proximal normal cone to A at ¯x.
Each u ∈NF (A, ¯x) is said to be a Fréchet normal to A at ¯x, analogously we
use viscosity normal and proximal normal.
We ﬁrst give a simple but useful characterization of Fréchet normal cones.
Proposition 11.2.6 Let A be a nonempty subset of E and ¯x ∈A. Then for
any x∗∈E∗, the following assertions are mutually equivalent:
(a) x∗∈NF (A, ¯x).
(b) For every ϵ > 0 there exists δ > 0 such that
⟨x∗, x −¯x⟩≤ϵ∥x −¯x∥
∀x ∈A ∩B(¯x, δ).
(c) There exists a function ϕ : E →R that is F-diﬀerentiable at ¯x with
ϕ′(¯x) = x∗and attains a maximum over A at ¯x.

11.2 Normal Cones: First Properties
239
Proof.
(a) =⇒(b): This follows immediately from the deﬁnition of NF (A, ¯x).
(b) =⇒(c): It is easy to check that the function ϕ : E →R deﬁned by
ϕ(x) :=

min{0, ⟨x∗, x −¯x⟩}
if x ∈A,
⟨x∗, x −¯x⟩
otherwise
has the required properties.
(c) =⇒(a): According to (c) we have
ϕ(x) = ϕ(¯x) + ⟨x∗, x −¯x⟩+ r(x)
where
r(x)/∥x −¯x∥→0
as x →¯x.
Since ϕ(x) ≤ϕ(¯x) for any x ∈A, statement (a) follows.
⊓⊔
In a Hilbert space, proximal normals can be characterized in various ways.
Proposition 11.2.7 Let A be a nonempty subset of the Hilbert space E and
let ¯x ∈A. Then for any u ∈E, the following assertions are mutually equiva-
lent:
(a) u ∈NP (A, ¯x).
(b) Either u = o or there exist λ > 0 and z ∈E \ A such that u = λ(z −¯x)
and ¯x ∈projA(z).
(c) There exists ρ ≥0 such that (u | x −¯x) ≤ρ∥x −¯x∥2 for any x ∈A.
(d) There exist σ ≥0 and ϵ > 0 such that (u | x −¯x) ≤σ∥x −¯x∥2 for any
x ∈A ∩B(¯x, ϵ).
(e) There exists τ > 0 such that dA(¯x + τu) = τ∥u∥.
Proof. We prepare the proof with two observations. First, we have
¯x ∈projA(z)
⇐⇒
∥z −¯x∥≤∥z −x∥∀x ∈A
⇐⇒
(z −¯x | x −¯x) ≤(z −x | z −x) ∀x ∈A.
Simplifying the inner products in the last inequality leads to
¯x ∈projA(z)
⇐⇒
(z −¯x | x −¯x) ≤1
2∥x −¯x∥2
∀x ∈A.
(11.13)
Second, for any τ > 0 we have
∥x −(¯x + τu)∥2 = ∥x −¯x∥2 −2τ(u | x −¯x) + τ 2∥u∥2.
(11.14)
(a) =⇒(b): This is obvious for u = o. If u ∈∂P δA(¯x) and u ̸= o, then there
exists σ > 0 satisfying
(u | x −¯x) −σ∥x −¯x∥2 ≤0
∀x ∈A.
By (11.13) we obtain ¯x ∈projA(z), where z := ¯x +
1
2σu. Observe that z /∈A
and u = 2σ(z −¯x).

240
11 Tangent and Normal Cones
(b) =⇒(c): Let u be as in (b). In view of (11.13) it follows that (u | x −¯x) ≤
λ
2 ∥x −¯x∥2 for each x ∈A.
(c) =⇒(d) is obvious.
(d) =⇒(e): Assume that (d) holds and choose any τ > 0. Using (11.14), we
obtain
∥x −(¯x + τu)∥2 ≥(1 −2τσ)∥x −¯x∥2 + τ 2∥u∥2
∀x ∈A ∩B(¯x, ϵ).
Since for x := ¯x we have ∥x −(¯x + τu)∥2 = τ 2∥u∥2, we conclude that dA(¯x +
τu) = τ∥u∥.
(e) =⇒(a): The condition (e) implies
∥x −(¯x + τu)∥2 ≥τ 2∥u∥2
∀x ∈A,
(11.15)
which by (11.14) entails
δA(x) −δA(¯x) ≥(u | x −¯x) −1
2τ ∥x −¯x∥2
∀x ∈E
(11.16)
and so u ∈NP (A, ¯x).
⊓⊔
Geometric Interpretation
The equivalence of (a) and (b) means that NP (A, ¯x) collects all points u on
rays emanating from ¯x and meeting some point z ∈E \ A for which ¯x is the
best approximation with respect to A (Fig. 11.2).
It is clear that generally we have NP (A, ¯x) ⊆NF (A, ¯x).
Proposition 11.2.8 Assume that E is a Fréchet smooth Banach space, A is
convex and closed, and ¯x ∈A. Then
NP (A, ¯x) = NF (A, ¯x) = NC(A, ¯x) = N(A, ¯x).
Proof. See Exercise 11.7.6.
⊓⊔
A
NP (A, ¯x)
¯x
z
u
Fig. 11.2

11.3 Tangent and Normal Cones to Epigraphs
241
Observe that the closedness of A is assumed only to ensure that δA is l.s.c.
which enters the deﬁnition of the proximal subdiﬀerential. If A is convex (and
closed), then u ∈NP (A, ¯x) if and only if (b) of Proposition 11.2.7 holds, which
is geometrically interpreted in Remark 5.3.2 and Fig. 5.1.
11.3 Tangent and Normal Cones to Epigraphs
Let f : E →R be proper and let ¯x ∈dom f. Our aim now is to give repre-
sentations of approximating cones to epi f at ¯x. Recall the lower directional
H-derivative
f H(¯x, y) = lim inf
τ↓0
z→y
1
τ

f(¯x + τz) −f(¯x)

,
y ∈E.
Proposition 11.3.1 Let f : E →R be proper and ¯x ∈dom f.
(a) There always holds
T

epi f, (¯x, f(¯x))

= epi f H(¯x, ·).
(b) If f is locally L-continuous around ¯x, then
TC

epi f, (¯x, f(¯x))

= epi f ◦(¯x, ·).
Proof.
(a) (I) Let (y, ρ) ∈T

epi f, (¯x, f(¯x))

be given. Then there exist sequences
(τk) in (0, +∞) and (zk, ρk) in E × R satisfying τk ↓0, zk →y, and
ρk →ρ as k →∞such that (¯x, f(¯x)) + τk(zk, ρk) ∈epi f for any
k ∈N. It follows that
1
τk

f(¯x + τkzk) −f(¯x)

≤ρk
∀k ∈N
and so f +
H(¯x, y) ≤ρ which means (y, ρ) ∈epi f +
H(¯x, ·).
(II) Now let (y, ρ) ∈epi f +
H(¯x, ·) be given. We then have
inf
0<τ<ϵ
∥z−y∥<ϵ
1
τ

f(¯x + τz) −f(¯x)

≤ρ
∀ϵ > 0.
Hence for any k ∈N there exists τk ∈(0, 1
k) and zk ∈B(y, 1
k) such that
1
τk

f(¯x + τkzk) −f(¯x)

< ρ + 1
k
∀k ∈N.
We thus see that τk ↓0, (zk, ρ+ 1
k) →(y, ρ), and (¯x, f(¯x))+τk(zk, ρ+ 1
k) ∈
epi f. Hence (y, ρ) ∈T

epi f, (¯x, f(¯x))

.
(b) This is veriﬁed analogously.
⊓⊔

242
11 Tangent and Normal Cones
Corollary 11.3.2 If f : E →R is locally L-continuous around ¯x ∈dom f,
then for any x∗∈E∗one has
x∗∈∂◦f(¯x)
⇐⇒
(x∗, −1) ∈NC

epi f, (¯x, f(¯x))

.
Proof. By Proposition 7.3.7 we have x∗∈∂◦f(¯x) if and only if f ◦(¯x, y) ≥
⟨x∗, y⟩for any y ∈E. Hence using Proposition 11.3.1 and the deﬁnition of the
Clarke normal cone, we obtain
x∗∈∂◦f(¯x)
⇐⇒
(y, ρ) ∈epi f ◦(¯x, ·)
∀y ∈E
∀ρ ≥f ◦(¯x, y)
⇐⇒
⟨(x∗, −1), (y, ρ)⟩= ⟨x∗, y⟩−ρ ≤0
∀(y, ρ) ∈epif ◦(¯x, ·)
⇐⇒
(x∗, −1) ∈TC

epi f, (¯x, , f(¯x))
◦= NC

epi f, (¯x, f(¯x))

.
⊓⊔
If f is strictly H-diﬀerentiable at ¯x, then by Proposition 7.3.9 the assertion
of the corollary reduces to (f ′(¯x), −1) ∈NC

epi f, (¯x, f(¯x))

. In the language
of diﬀerential geometry in the plane this means that (f ′(¯x), −1) is a normal
vector to graph f at the point (¯x, f(¯x)).
Remark 11.3.3 By Proposition 11.3.1 we have
f H(¯x, y) = inf{ρ ∈R | (y, ρ) ∈T

epi f, (¯x, f(¯x))

}
∀y ∈E,
f ◦(¯x, y) = inf{ρ ∈R | (y, ρ) ∈TC

epi f, (¯x, f(¯x))

}
∀y ∈E.
This shows that directional derivatives can also be deﬁned with the aid of
approximating cones. Furthermore, Corollary 11.3.2 and Proposition 11.3.4
(which is the proximal subdiﬀerential analogue to Corollary 11.3.2) indicate
that subdiﬀerentials can be deﬁned via normal cones.
Proposition 11.3.4 Let E be a Hilbert space, let f : E →R be proper and
l.s.c., and let ¯x ∈dom f. Then for each x∗∈E one has
x∗∈∂P f(¯x)
⇐⇒
(x∗, −1) ∈NP

epif, (¯x, f(¯x))

.
Proof. =⇒: Let x∗∈∂P f(¯x) be given. By the deﬁnition of the proximal
subdiﬀerential there exist σ > 0 and δ > 0 such that for all x ∈B(¯x, δ) and
all α ≥f(x) we have
α −f(¯x) + σ
&
∥x −¯x∥2 +

α −f(¯x)
2
≥(x∗| x −¯x).
(11.17)
In other words, if x ∈B(¯x, δ) and (x, α) ∈epif, then

(x∗, −1)
 (x, α) −(¯x, f(¯x))

=

(x∗, −1)
 (x −¯x, α −f(¯x))

= (x∗| x −¯x) −α + f(¯x)
≤
(11.17)
σ∥(x, α) −(¯x, f(¯x))∥2.

11.3 Tangent and Normal Cones to Epigraphs
243
By Proposition 11.2.7 we conclude that (x∗, −1) ∈NP

epi f, (x, f(x))

.
⇐=: Assume now that (x∗, −1) ∈NP

epi f, (¯x, f(¯x))

. By Proposition 11.2.7
there exists η > 0 such that for all (x, α) ∈epi f we have

η(x∗, −1) | (x −¯x, α −f(¯x))

≤1
2∥(x −¯x, α −f(¯x))∥2,
which in view of (11.13) implies that
(¯x, f(¯x)) ∈projepif(p),
where p := (¯x, f(¯x)) + η(x∗, −1).
(11.18)
The deﬁnition of the projection now shows (cf. Fig. 11.3, where δ′ :=
∥η(x∗, −1)∥) that
∥η(x∗, −1)∥2 ≤∥p −(x, α)∥2
∀(x, α) ∈epi f.
In particular, choosing α = f(x) we obtain
δ2∥x∗∥2 + δ2 ≤∥¯x −y + δx∗∥2
f(¯x) −f(x) −δ
2.
Evaluating ∥· ∥2 via the inner product, the latter inequality passes into
δ2 + 2δ (x∗| x −¯x) −∥x −¯x∥2 ≤

f(x) −f(¯x) + δ
2.
(11.19)
Now choose ϵ > 0 so small that for each x ∈B(¯x, ϵ) the left-hand side of
(11.19) is positive and at the same time f(x) > f(¯x) −δ (the latter being
possible since f is l.s.c. at ¯x). For each such x we obtain from (11.19) that
f(x) ≥g(x), where
g(x) := f(¯x) −δ +

δ2 + 2δ (x∗| x −¯x) −∥x −¯x∥21/2.
p
(¯x, f(¯x))
epi f
B(p, δ′)
Fig. 11.3

244
11 Tangent and Normal Cones
By Example 3.6.2 the function g is twice continuously diﬀerentiable on B(¯x, ϵ)
(upon diminishing ϵ if necessary) and g′(¯x) = x∗. Now Proposition 3.5.1
implies that with some σ > 0 we have
g(x) ≥g(¯x) + (x∗| x −¯x) −σ∥x −¯x∥2
∀x ∈B(¯x, ϵ).
This together with f(x) ≥g(x) and f(¯x) = g(¯x) gives
f(x) ≥f(¯x) + (x∗| x −¯x) −σ|x −¯x∥2
∀x ∈B(¯x, ϵ)
and so x∗∈∂P f(¯x).
⊓⊔
Now we derive a result analogous to Proposition 11.3.4 for the viscosity
(Fréchet) subdiﬀerential and the viscosity (Fréchet) normal cone.
Proposition 11.3.5 Let f : E →R be proper and l.s.c., and let ¯x ∈dom f.
Then for each x∗∈E one has
x∗∈∂V f(¯x)
⇐⇒
(x∗, −1) ∈NV

epif, (¯x, f(¯x))

.
(11.20)
If, in addition, E is a Fréchet smooth Banach space, then
x∗∈∂F f(¯x)
⇐⇒
(x∗, −1) ∈NF

epif, (¯x, f(¯x))

.
(11.21)
Proof.
(I) Let x∗∈∂V f(¯x) be given. By deﬁnition there exists a C1 function g
such that g′(¯x) = x∗and f −g attains a local minimum at ¯x. Deﬁne
h(y, r) := g(y) −r for y near ¯x and r ∈R. Then h is a C1 function
satisfying h′(¯x, f(¯x)) = (x∗, −1) and
δepi f(y, r) −h(y, r) ≥δepi f(¯x, f(¯x)) −h(¯x, f(¯x)).
It follows that (x∗, −1) ∈∂V δepi f(¯x, f(¯x)) = NV

epi f, (¯x, f(¯x))

.
(II) Now let (x∗, −1) ∈NV

epi f, (¯x, f(¯x))

. Then there exists a C1 func-
tion h : E × R →R such that h′(¯x, f(¯x)) = (x∗, −1) and h(x, t) ≤
h(¯x, f(¯x)) = 0 for any (x, t) ∈epi f that is suﬃciently close to (¯x, f(¯x)).
Concerning the equation h(¯x, f(¯x)) = 0, notice that h can be chosen
in this way. Now the implicit function theorem (Theorem 3.7.2) ensures
the existence of a C1 function g : E →R satisfying h(x, g(x)) = 0 for
any x near ¯x as well as g(¯x) = f(¯x) and
g′(¯x) = −h 2(¯x, g(¯x))−1 ◦h 1(¯x, g(¯x)) = x∗.
Since h is continuously diﬀerentiable and h 2(¯x, g(¯x)) = −1, there exists
ϵ > 0 such that
h(x, t) < h(x, s)
whenever
x ∈B(¯x, ϵ) and f(¯x) −ϵ < s < t < f(¯x) + ϵ.
(11.22)

11.4 Representation of Tangent Cones
245
Since g is continuous at ¯x and f is l.s.c. at ¯x, there exists δ ∈(0, ϵ) such
that
f(¯x) −ϵ ≤g(x) ≤f(¯x) + ϵ
and
f(x) > f(¯x) −ϵ
∀x ∈B(¯x, δ).
Now let x ∈B(¯x, δ). If f(x) ≥f(¯x) + ϵ, then we immediately have
f(x) −g(x) ≥0 = f(¯x) −g(¯x). But the latter inequality also holds if
f(x) < f(¯x) + ϵ because in this case h(x, f(x)) ≤0 = h(x, g(x)) by
(11.22). Thus, we have shown that x∗∈∂V f(¯x).
(III) The
additional
assertion
follows
from
the
above
by
virtue
of
Theorem 9.1.7 and the deﬁnition of the Fréchet normal cone. In this
connection notice that if E is Fréchet smooth, so is E × R.
⊓⊔
Remark 11.3.6 Here we obtained the characterization (11.21) as a by-
product of (11.20). In a more general setting we shall later see that (11.21)
holds without the hypothesis that E be Fréchet smooth.
11.4 Representation of Tangent Cones
Our aim in this section is to characterize (subsets of) approximating cones of
sets given by inequalities and/or equations.
Approximating h−1(Q)
We make the following assumptions:
(A) E and F are Banach spaces, Q is a nonempty closed convex subset of
F, h : E →F is continuous on E and continuously diﬀerentiable at
¯x ∈h−1(Q).
Theorem 11.4.1 Let the assumptions (A) and the Robinson condition
o ∈int

h(¯x) + h′(¯x)(E) −Q

be satisﬁed. Then
T(h−1(Q), ¯x) = h′(¯x)−1
T(Q, h(¯x))

.
(11.23)
Proof.
(I) We show
h′(¯x)−1
T(Q, h(¯x))

⊆T(h−1(Q), ¯x).
(11.24)
Let y ∈h′(¯x)−1
T(Q, h(¯x))

. By Proposition 11.1.5 there exists τk ↓0
such that
lim
k→∞τ −1
k d(Q, h(¯x) + τkh′(¯x)y) = 0.
(11.25)

246
11 Tangent and Normal Cones
Since h is continuously diﬀerentiable at ¯x, we further have
h(¯x + τy) = h(¯x) + τh′(¯x)y + o(τ),
τ ↓0.
(11.26)
Hence τ −1
k d(Q, h(¯x + τky)) →0 as k →∞. By Proposition 10.3.7 there
exists κ > 0 such that d(h−1(Q), ¯x + τy) ≤κ d(Q, h(¯x + τy)). It follows
that
lim
k→∞τ −1
k d(h−1(Q), ¯x + τky) = 0
(11.27)
and so y ∈T(h−1(Q), ¯x).
(II) Now we show the reverse inclusion to (11.24). So let y ∈T(h−1(Q), ¯x) be
given. Then there exists τk ↓0 such that (11.27) holds. Since the mapping
h is continuously diﬀerentiable at ¯x, it is locally Lipschitz continuous
there. Hence there exists λ > 0 such that d(Q, h(x)) ≤λ d(h−1(Q), x)
for any x near ¯x. This and (11.27) imply that τ −1
k d(h(¯x + τky), Q) →0
as k →∞. Using (11.26) again, we see that (11.25) holds and so h′(¯x)y ∈
T(Q, h(¯x)).
⊓⊔
Notice that we veriﬁed the reverse inclusion to (11.24) without making
use of the Robinson condition. However, the crucial inclusion for deriving
multiplier rules in Chap. 12 will be (11.24), and this inclusion has been veriﬁed
with the aid of Proposition 10.3.7 which is bound to the Robinson condition
or one of the equivalent conditions (see Proposition 10.3.8).
As a special case, Theorem 11.4.1 contains the following classical result
(cf. Fig. 7.3).
Theorem 11.4.2 (Tangent Space Theorem) Let the assumptions
(A)
with Q = {o} be satisﬁed. If h′(¯x) is surjective, then
T(ker h, ¯x) = ker h′(¯x).
(11.28)
Example 11.4.3 Let E = F := R2, ¯x := (1, 0), and h = (h1, h2), where
h1(x1, x2) := −x2,
h2(x1, x2) := x2 + (x1 −1)3.
Then T(ker h, ¯x) = {(0, 0)} but ker h′(¯x) = R × {0}, i.e., (11.28) is not valid.
Notice that in this case, h′(¯x)

R2
= {α(−1, 1) | α ∈R} and so h′(¯x) is not
surjective.
Approximating A ∩h−1(Q)
Now we consider sets of the form
A ∩h−1(Q) = {x ∈E | x ∈A, h(x) ∈Q}.

11.4 Representation of Tangent Cones
247
Theorem 11.4.4 In addition to the assumptions (A), let now A be a non-
empty closed convex subset of E and assume that the Robinson condition
o ∈int

h(¯x) + h′(¯x)(A −¯x) −Q

(11.29)
is satisﬁed. Then one has
T(A ∩h−1(Q), ¯x) = T(A, ¯x) ∩h′(¯x)−1
T(Q, h(¯x))

.
(11.30)
Proof. Setting
%F := E × F,
%Q := A × Q,
%h(x) := (x, h(x)),
x ∈E,
we have
%h−1( %Q) = A ∩h−1(Q),
%h′(¯x)y = (y, h′(¯x)y)
for ally ∈E,
T( %Q,%h(¯x)) = T(A, ¯x) × T(Q, h(¯x)).
Hence the assertion follows from Theorem 11.4.1 as soon as we have shown
that the Robinson condition
(o, o) ∈int
˜h(¯x) + ˜h′(¯x)(E) −˜Q

(11.31)
is satisﬁed. According to (11.29) there exists ϵ > 0 such that
ϵ BF ⊆h(¯x) + h′(¯x)(A −¯x) −Q.
(11.32)
Choose δ > 0 such that ∥z−h′(¯x)x1∥< ϵ whenever |x1∥< δ and ∥z∥< δ. Now
let (y, z) ∈δ BE×F be given. Set x1 := y. By (11.32) there exists x2 ∈A −¯x
such that
z −h′(¯x)x1 ∈h(¯x) + h′(¯x)x2 −Q.
Deﬁning x := x1+x2, we have (y, z) ∈˜h(¯x)+˜h′(¯x)x−˜Q. This veriﬁes (11.31),
and the proof is complete.
⊓⊔
Approximating Sublevel Sets
Now we want to approximate the set
M := {x ∈E | x ∈A, gi(x) ≤0 (i = 1, . . . , m), h(x) = o},
(11.33)
where
g1, . . . , gm : E →R,
h : E →F.
Of course, M can be written as A ∩*h −1(Q) by setting
*h := (g1, . . . , gm, h) : E →Rm × F,
Q := −Rm
+ × {o}.

248
11 Tangent and Normal Cones
However, if we want to apply Theorem 11.4.4, we have to assume that beside
the mapping h, the functions g1, . . . , gm are also continuously diﬀerentiable
at ¯x. By a somewhat diﬀerent approach we shall now show that we can do
with weaker diﬀerentiability hypotheses on the functions gi. Therefore we ﬁrst
consider the set
M1 := {x ∈E | x ∈A, gi(x) ≤0 (i = 1, . . . , m)}.
(11.34)
We deﬁne
I := {1, . . . , m},
I(¯x) := {i ∈I | gi(¯x) = 0}.
The set I(¯x) is the index set of the constraint functions that are active or
binding at the point ¯x. In Fig. 11.4 we have 1 ∈I(¯x) and 2 ̸∈I(¯x). It will turn
out that for i /∈I(¯x), the constraint gi(x) ≤0 is not critical provided the
function gi is upper semicontinuous at ¯x.
Figure 11.5 indicates what we can expect in Rn if i ∈I(¯x) and gi is
diﬀerentiable at ¯x. An “admissible” direction y satisﬁes π
2 < α < π and so
⟨∇gi(¯x), y⟩≤0. If gi is not diﬀerentiable at ¯x, then we use a (radial) upper
convex approximation γi. We set
γ := (γi)i∈I(¯x),
L<(γ, ¯x) := {y ∈E | γi(y) < 0 ∀i ∈I(¯x)},
L≤(γ, ¯x) := {y ∈E | γi(y) ≤0 ∀i ∈I(¯x)}.
The sets L<(γ, ¯x) and L≤(γ, ¯x), which are obviously cones, are called lineariz-
ing cones of γ at ¯x.
g2(x) = 0
M1
¯x
g1(x) = 0
Fig. 11.4
α
∇gi(¯x)
gi(x) = 0
¯x
M1
y
Fig. 11.5

11.4 Representation of Tangent Cones
249
Proposition 11.4.5 Let E be a normed vector space, A be a nonempty subset
of E, and gi : E →R for i ∈I. Assume that for i ∈I \ I(¯x) the function gi
is upper semicontinuous at ¯x. Let M1 be deﬁned by (11.34).
(a) If γi ∈UCr(gi, ¯x) for i ∈I(¯x), then
L<(γ, ¯x) ⊆Ir(M1, ¯x),
(11.35)
Tr(A, ¯x) ∩L<(γ, ¯x) ⊆Tr(A ∩M1, ¯x).
(11.36)
If, in addition, Kr ⊆Tr(A, ¯x) is a convex cone satisfying
Kr ∩L<(γ, ¯x) ̸= ∅,
(11.37)
then
Kr ∩L≤(γ, ¯x) ⊆cl Tr(A ∩M1, ¯x).
(11.38)
(b) If γi ∈UC(gi, ¯x) for i ∈I(¯x), then
L<(γ, ¯x) ⊆I(M1, ¯x),
(11.39)
T(A, ¯x) ∩L<(γ, ¯x) ⊆T(A ∩M1, ¯x).
(11.40)
If, in addition, K ⊆T(A, ¯x) is a convex cone satisfying
K ∩L<(γ, ¯x) ̸= ∅,
(11.41)
then
K ∩L≤(γ, ¯x) ⊆T(A ∩M1, ¯x).
(11.42)
Proof. Ad (11.39). Let y ∈L<(γ, ¯x). Then we have ( ¯gi)+
H(¯x, y) ≤γi(y) < 0
for any i ∈I(¯x). Hence for any such i there exists ϵi ∈(0, 1) such that
1
τ
&
gi(¯x + τz) −gi(¯x)
  
=0

< 0
∀τ ∈(0, ϵi) ∀z ∈B(y, ϵi).
(11.43)
Now let i ∈I \ I(¯x). Then gi(¯x) < 0 and gi is upper semicontinuous at ¯x.
Hence there exists δi > 0 such that
gi(x) < 0
∀x ∈B(¯x, δi).
(11.44)
Set
˜ϵ := min{ϵi | i ∈I(¯x)}, δ := min{δi | i ∈I \ I(¯x)}, ϵ := min
0
˜ϵ,
δ
˜ϵ + ∥y∥
1
.
If now τ ∈(0, ϵ) and z ∈B(y, ˜ϵ), then it follows from (11.43) that gi(¯x+τz) < 0
for each i ∈I(¯x). Furthermore we obtain
∥(¯x + τz) −¯x∥= τ∥z∥≤τ(∥z −y∥+ ∥y∥) ≤ϵ(˜ϵ + ∥y∥) ≤δ

250
11 Tangent and Normal Cones
which, by (11.44), implies gi(¯x + τz) < 0 for each i ∈I \ I(¯x). Thus we
conclude that y ∈I(M1, ¯x).
Ad (11.40). This follows from (11.39) and Lemma 11.1.3.
Ad (11.42). Let y0 ∈K ∩L<(γ, ¯x) and y ∈K ∩L≤(γ, ¯x). For λ ∈(0, 1), set
yλ := λy0 + (1 −λ)y. Then we have yλ ∈K ⊆T(A, ¯x) and
γi(yλ) ≤λγi(y0) + (1 −λ)γi(y) < 0
∀i ∈I(¯x)
and so yλ ∈L<(γ¯x). In view of (11.39) and Proposition 11.1.3, we conclude
that
yλ ∈T(A, ¯x) ∩I(M1, ¯x) ⊆T(A ∩M1, ¯x)
and so y = limλ↓0 yλ ∈T(A ∩M1, ¯x) because the latter set is closed
(Proposition 11.1.2). It is left as Exercise 11.7.9 to verify the assertions (11.35),
(11.36), and (11.38).
⊓⊔
Remark 11.4.6
(a) The assumption that gi, for each i ∈I(¯x), admits a (radial) upper convex
approximation γi at ¯x may be interpreted as a “diﬀerentiability” require-
ment. If gi is locally L-continuous around ¯x, then by Theorem 7.3.2, the
Clarke directional derivative g◦
i (¯x, ·) as well as the Michel–Penot direc-
tional derivative g♦
i (¯x, ·) are possible choices for γi ∈UC(gi, ¯x).
(b) The above proof shows that for (11.35) and (11.39) the convexity of γi, i ∈
I(¯x), is dispensable. Hence these statements also hold with γi replaced by
the upper directional G-derivative (or H-derivative) of gi at ¯x.
(c) The conditions (11.37) and (11.41) are called regularity conditions or
constraint qualiﬁcations. Notice that the set L<(γ, ¯x) may be empty. In
Proposition 11.4.5, the set A is not assumed to be convex. However, if
A happens to be convex, then Tr(A, ¯x) and T(A, ¯x) are convex cones
(Proposition 11.1.2) and so we can choose Kr := Tr(A, ¯x), K := Tr(A, ¯x)
or K := T(A, ¯x).
In the preceding results we used the contingent cone for the local approx-
imation of sublevel sets. Now we choose the Clarke tangent cone. We start
with a deﬁnition.
Deﬁnition 11.4.7 The subset M of E is said to be tangentially regular at
¯x ∈M if TC(M, ¯x) = T(M, ¯x).
Now we consider the sublevel set
M := {x ∈E | g(x) ≤g(¯x)}.
(11.45)
Theorem 11.4.8 Let g : E →R be locally L-continuous around ¯x ∈E and
assume that o /∈∂◦g(¯x). Then, with M according to (11.45), one has
{y ∈E | g◦(¯x, y) ≤0} ⊆TC(M, ¯x).
(11.46)
If g is regular at ¯x, then (11.46) holds with equality and M is tangentially
regular at ¯x.

11.4 Representation of Tangent Cones
251
Proof.
(I) By the deﬁnition of ∂◦g(¯x) and since o /∈∂◦g(¯x), there exists y0 ∈E
such that g◦(¯x, y0) < 0. Now let ˜y be any element of the left-hand side
of (11.46). Since g◦(¯x, ·) is sublinear, it follows that g◦(¯x, ˜y + ϵy0) < 0
for each ϵ > 0. In step (II) we shall show that every y ∈E satisfying
g◦(¯x, y) < 0 belongs to TC(M, ¯x). It then follows that ˜y+ϵy0 ∈TC(M, ¯x)
for each ϵ > 0, and since TC(M, ¯x) is closed (Proposition 11.1.2), we
conclude letting ϵ ↓0 that ˜y ∈TC(M, ¯x). This veriﬁes (11.46).
(II) Let y ∈E be such that g◦(¯x, y) < 0. By the deﬁnition of g◦(¯x, y) there
exist ϵ > 0 and δ > 0 such that
g(x + τy) −g(x) ≤−δτ
∀x ∈B(¯x, ϵ)
∀τ ∈(0, ϵ).
(11.47)
Now let (xk) be a sequence in M converging to ¯x and τk ↓0. In view of
(11.47) we obtain for all suﬃciently large k,
g(xk + τky) ≤g(xk) −δτk ≤g(¯x) −δτk
and so xk + τky ∈M. This shows that y ∈TC(M, ¯x).
(III) We verify the regularity statement. Assume that g is regular at ¯x. Since
(11.46) is already veriﬁed and TC(M, ¯x) ⊆T(M, ¯x) always holds, it
suﬃces to show that T(M, ¯x) is a subset of the left-hand side of (11.46).
Thus let y ∈T(M, ¯x) be given. Then Proposition 11.1.5 shows that
lim infτ↓0 τ −1dM(¯x + τy) = 0. Hence for each ϵ > 0 we ﬁnd a sequence
τk ↓0 such that for all suﬃciently large k we have dM(¯x + τky) ≤ϵτk.
Thus there exists xk ∈M satisfying ∥(¯x + τky) −xk∥≤2ϵτk. Let λ
denote a local Lipschitz constant of g around ¯x. Then we obtain, again
for k suﬃciently large,
g(¯x + τky) −g(xk) ≤λ∥(¯x + τky) −xk∥≤2ϵτkλ
and so
1
τk

g(¯x + τky) −g(¯x)

≤1
τk

g(xk) −g(¯x)

+ 2ϵλ ≤2ϵλ.
Letting k →∞and then ϵ ↓0, we conclude that g◦(¯x, y) = gG(¯x, y) ≤0.
⊓⊔
Approximating Level–Sublevel Sets
We return to the contingent cone, now considering the set
A ∩M,
where
M := {x ∈E | gi(x) ≤0 (i = 1, . . . , m), h(x) = o},
¯x ∈A ∩M.

252
11 Tangent and Normal Cones
We again set I := {1, . . . , m} and I(¯x) := {i ∈I | gi(¯x) = 0}. We make the
following hypotheses:
(H) E and F are Banach spaces, A ⊆E is nonempty closed and convex,
gi : E →R for i ∈I, γi ∈UC(gi, ¯x) for i ∈I(¯x),
gi is upper semicontinuous at ¯x for i ∈I \ I(¯x),
h : E →F is continuous on E and continuously diﬀerentiable at ¯x.
Theorem 11.4.9 Assume that the hypotheses (H) hold and that
h′(¯x)

R+(A −¯x)

= F.
(11.48)
Then:
(a) There always holds
R+(A −¯x) ∩L<(γ, ¯x) ∩ker h′(¯x) ⊆T(A ∩M, ¯x).
(b) If
R+(A −¯x) ∩L<(γ, ¯x) ∩ker h′(¯x) ̸= ∅,
(11.49)
then
R+(A −¯x) ∩L≤(γ, ¯x) ∩ker h′(¯x) ⊆T(A ∩M, ¯x).
Proof.
(a) Let y ∈R+(A −¯x) ∩L<(γ, ¯x) ∩ker h′(¯x). By Theorem 11.4.4 (with Q =
{o}) we obtain y ∈T(A ∩ker h, ¯x), and Proposition 11.4.5(b) implies
y ∈I(M1, ¯x). Thus the assertion follows with the aid of Proposition 11.1.3.
(b) This is veriﬁed in analogy to formula (11.42) in Proposition 11.4.5.
⊓⊔
11.5 Contingent Derivatives and a Lyusternik Type
Theorem
We introduce a derivative-like concept for multifunctions. In Sect. 13.2 we
shall study an alternative construction.
Deﬁnition 11.5.1 Let Φ : E ⇒F be a multifunction and (¯x, ¯y) ∈graph Φ.
The multifunction DΦ(¯x, ¯y) : E ⇒F deﬁned by
DΦ(¯x, ¯y)(u) := Lim sup
u′→u, τ↓0
1
τ

Φ(¯x + τu′) −¯y

,
u ∈E,
is called contingent derivative of Φ at (¯x, ¯y).

11.5 Contingent Derivatives and a Lyusternik Type Theorem
253
The deﬁnition implies
graph

DΦ(¯x, ¯y)

= T

graph Φ, (¯x, ¯y)

,
(11.50)
where the right-hand side is the contingent cone to graph Φ at (¯x, ¯y). This
is why DΦ(¯x, ¯y) is called contingent derivative. If Φ : E →F is Hadamard
diﬀerentiable at ¯x, then
DΦ(¯x, Φ(¯x))(u) = {Φ′(¯x)u}
∀u ∈E,
i.e., DΦ(¯x, Φ(¯x)) can be identiﬁed with the Hadamard derivative Φ′(¯x).
The contingent derivative turns out to be an appropriate tool to estab-
lish a tangential approximation of ker Φ, where Φ is a multifunction (cf. the
tangential approximations derived in Sect. 11.4).
Theorem 11.5.2 Let E and F be Banach spaces. If the multifunction Φ :
E ⇒F is linearly semiopen around (¯x, o) ∈graph Φ, then
T(ker Φ, ¯x) = ker

DΦ(¯x, o)

.
(11.51)
Proof.
(I) First let u ∈T(ker Φ, ¯x) be given. Then there exist sequences uk →u and
τk ↓0 such that o ∈Φ(¯x + τkuk) for any k ∈N. It follows that
o ∈lim sup
k→∞
1
τk
Φ(¯x + τkuk) ⊆DΦ(¯x, o)(u).
Hence u ∈ker

DΦ(¯x, o)

.
(II) Now let u ∈ker

DΦ(¯x, o)

be given. If u = o, then u ∈T(ker Φ, ¯x). Thus
assume that u ̸= o. Denote the semiopenness parameters of Φ around
(¯x, o) by ρ and τ0. By deﬁnition of DΦ(¯x, o) there exist sequences uk →u,
τk ↓0, and vk ∈Φ(¯x+τkuk) such that limk→∞vk/τk = o. For suﬃciently
large k, we have ¯x+τkuk ∈¯x+τ0BE and vk ∈τ0BF . Again for suﬃciently
large k, we further have ∥uk∥≥1
2∥u∥and so
τ ′
k :=
∥vk∥
ρτk∥uk∥≤
2
ρ∥u∥· ∥vk∥
τk
→0
as k →∞.
Deﬁne zk := ¯x + τkuk. Then we obtain
o ∈vk + ∥vk∥BF = vk + ρτ ′
k∥zk −¯x∥BF ⊆Φ(zk + τ ′
k∥zk −¯x∥BE);
here the latter inclusion is a consequence of the linear semiopenness of Φ.
Hence there exists z′
k ∈ker(Φ) satisfying ∥z′
k −zk∥≤τ ′
kτ∥uk∥. Deﬁne

254
11 Tangent and Normal Cones
yk :=
1
τk (z′
k −¯x). Then ¯x + τkyk ∈ker Φ. It remains to show that yk →u
as k →∞. This follows from
∥yk −uk∥= 1
τk
∥z′
k −zk∥≤τ ′
k∥uk∥→0
as k →∞
and so
∥yk −u∥≤∥yk −uk∥+ ∥uk −u∥→0
as k →∞.
⊓⊔
Remark 11.5.3 We
show
that
the
classical
tangent
space
theorem
(Theorem 11.4.2) can be regained from Theorem 11.5.2. We use the assump-
tions and the notation of Theorem 11.4.2. Since the continuous linear mapping
h′(¯x) is surjective, it is open by the Banach open mapping theorem. Hence
x →h′(¯x)(x −¯x) is open at a linear rate, say ρ, around ¯x. Furthermore,
since h is continuously diﬀerentiable at ¯x ∈ker(h), there exists a mapping
r : E →F such that
h(x) = h′(¯x)(x −¯x) + r(x),
where lim
x→¯x r(x)/∥x∥= o,
(11.52)
and we have
1
∥x1 −x2∥

r(x1) −r(x2)

=
1
∥x1 −x2∥
#
h(x1) −h(x2)

−h′(¯x)(x1 −x2)
$
→o
as x1, x2 →¯x.
Here the limit relation holds by Proposition 3.2.4(v) because h is strictly
diﬀerentiable (Proposition 3.4.2). Hence for any ϵ > 0 there exists δ > 0 such
that
∥r(x1) −r(x2)∥≤ϵ∥x1 −x2∥
∀x1, x2 ∈BE(¯x, δ).
(11.53)
In particular, we can take ϵ ∈(0, ρ). Then Theorem 10.3.6 shows that the
mapping h is linearly semiopen around ¯x. Therefore Theorem 11.5.2 implies
T(ker h, ¯x) = ker

Dh(¯x)

= ker h′(¯x).
(11.54)
The above argument suggests how to slightly weaken the hypotheses of
the Lyusternik theorem. In this connection, we consider the multifunction
h′(¯x)−1 : F ⇒E which is deﬁned as usual by
h′(¯x)−1(y) := {x ∈E | h′(¯x)(x) = y},
y ∈F.
Notice that h′(¯x)−1 is a process and ∥h′(¯x)−1∥denotes its norm according to
(10.50).
Proposition 11.5.4 Assume that h : E →F is F-diﬀerentiable at ¯x ∈
ker(h), that h′(¯x) is surjective, and that the mapping r in (11.52) is locally
Lipschitz continuous at ¯x with a Lipschitz constant λ < 1/∥h′(¯x)−1∥. Then
(11.54) holds.

11.6 Representation of Normal Cones
255
Proof. The mapping Φ : x →h′(¯x)(x), interpreted as a multifunction, is open
at a linear rate around (o, o) (cf. Remark 11.5.3) and is a bounded process.
By Proposition 10.4.2, the openness bound of Φ around (o, o) is ope(Φ)(o, o) =
1/∥h′(¯x)−1∥. Since h′(¯x) is linear, the mapping x →h′(x −¯x) is open at a
linear rate around (¯x, o) with the same openness bound 1/∥h′(¯x)−1∥. Now the
assertion follows by Theorems 10.3.6 and 11.5.2.
⊓⊔
Example 11.5.5 Deﬁne h : R2 →R deﬁned by
h(x1, x2) :=

ax1 + bx2 + x1x2
if x1 ≥0,
ax1 + bx2 −x1x2
if x1 < 0,
where |a| + |b| > 2. The function h satisﬁes the above assumptions at (0, 0)
while h is not diﬀerentiable at (0, x2) if x2 ̸= 0 and so the classical Lyusternik
theorem does not apply.
11.6 Representation of Normal Cones
In this section we characterize normal cones of a set M ⊆E which is deﬁned
by an inequality or an equation.
The Clarke Normal Cone to Sublevel Sets
We start with the set
M := {x ∈E | f(x) ≤f(¯x)}.
(11.55)
Theorem 11.6.1 Let f
: E
→R be proper and locally L-continuous
around ¯x. Assume that o /∈∂◦f(¯x). Then, with M as in (11.55), one has
NC(M, ¯x) ⊆R+∂◦f(¯x).
(11.56)
If, in addition, f is regular at ¯x, then (11.56) holds as an equation.
Proof. Taking polars in (11.46) (see Theorem 11.4.8), we obtain
NC(M, ¯x) ⊆{y ∈E | f ◦(¯x, y) ≤0}◦=

∂◦f(¯x)
◦◦.
(11.57)
Here the equation follows by Proposition 7.3.7(b). Applying the bipolar the-
orem to the right-hand side and recalling that ∂◦f(¯x) is weak∗compact not
containing o, the assertion follows. If f is regular at ¯x, then by Theorem 11.4.8
the inclusion in (11.57) is an equation and so is the inclusion in (11.56).
⊓⊔
Now let M be deﬁned by
M := {x ∈E | fi(x) ≤0,
i = 1, . . . , n}.
(11.58)

256
11 Tangent and Normal Cones
Corollary 11.6.2 For i = 1, . . . , n, let fi : E →R be strictly H-diﬀerentiable
at ¯x, where f1(¯x) = · · · = fn(¯x) = 0. If the functionals f ′
1(¯x), . . . , f ′
n(¯x) are
positively linearly independent, then the set M in (11.58) is regular at ¯x and
one has
NC(M, ¯x) =
0
n
	
i=1
λif ′
i(¯x)
 λi ≥0, i = 1, . . . , n
1
.
(11.59)
Proof. Deﬁne f := max{f1, . . . , fn}. By Proposition 7.3.9(c), each fi is locally
L-continuous around ¯x and so is f. Moreover, by Proposition 7.4.7, f is also
regular at ¯x. Since M = {x ∈E | f(x) ≤0}, Theorem 11.6.1 implies that
(11.56) holds with equality. Finally, the maximum rule of Proposition 7.4.7
yields (11.59).
⊓⊔
The Proximal Normal Cone to Sublevel Sets
Next we give the complete, geometrically appealing proof for the represen-
tation of NP (M, ¯x) in a Hilbert space and then indicate the more technical
proof for NF (M, ¯x) in a Fréchet smooth Banach space. We consider the set
M := {x ∈E | f(x) ≤0}.
(11.60)
Theorem 11.6.3 Let E be a Hilbert space and let M be given by (11.60),
where f : E →R is proper and l.s.c. Let ¯x ∈M and u ∈NP (M, ¯x). Then
either
(C1) for any ϵ > 0 and η > 0 there exists x ∈E such that
∥x −¯x∥< η,
|f(x) −f(¯x)| < η,
∂P f(x) ∩BE∗(o, ϵ) ̸= ∅
or
(C2) for any ϵ > 0 there exist x ∈E, v ∈∂P f(x), and λ > 0 such that
∥x −¯x∥< ϵ,
|f(x) −f(¯x)| < ϵ,
∥λv −u∥< ϵ.
Proof. Assuming that (C1) does not hold, we shall show that (C2) is valid.
Obviously we may suppose that u ̸= o.
(I) Since u ∈NP (M, ¯x), Proposition 11.2.7 implies that there exist ρ > 0
and σ > 0 such that
0 ≥(u | x −¯x) −σ∥x −¯x∥2
∀x ∈M ∩B(¯x, ρ∥u∥).
(11.61)
Since f is l.s.c., there exists m > 0 such that, on diminishing ρ if
necessary, f(x) ≥−m for all x ∈B(¯x, ρ∥u∥). The functional x →
(u | x−¯x)−σ∥x−¯x∥2 attains a positive value at x = ¯x+2ηu if η ∈(0, 1
2σ).
By continuity, for η > 0 suﬃciently small we have
(u | x −¯x) −σ∥x −¯x∥2 > 0
∀x ∈K := B(¯x + 2ηu, 2η∥u∥) \ {¯x}.
Hence if x ∈K, then x /∈M and so f(x) > 0.

11.6 Representation of Normal Cones
257
(II) For any positive α < min{η, 1/m} let
hα(x) := α−1
max{0, ∥x −¯x −ηu∥−η∥u∥}
2,
pα(z) := f(z) + hα(z) + δB(¯x,ρ∥u∥)(z).
Since (C1) does not hold, o is not a proximal subderivative of f at ¯x and
so infE pα < 0. By Theorem 8.3.3 applied to pα with
λ :=
!
2ϵα/α,
ϵ := ϵα := min{α/2, −inf
E pα/2}
there exist yα, wα ∈E such that
∥yα −wα∥< λ,
pα(yα) < inf
E pα + ϵα < 0,
and the functional
z →pα(z) + α
2 ∥z −wα∥2
(11.62)
attains a global minimum at z = yα. Moreover, since pα(yα) < 0, we
have yα ∈B(¯x, ρ∥u∥). We further obtain the following estimate:
hα(yα) ≤hα(yα) + α
2 ∥yα −wα∥2
< hα(yα) + ϵα
(because ∥yα −wα∥< λ)
= pα(yα) + ϵα −f(yα) < inf
E pα + 2ϵα −f(yα)
≤−f(yα) ≤m
(because 2ϵα ≤−inf
E pα).
The deﬁnition of hα shows that
∥yα −¯x −ηu∥≤√mα + η∥u∥,
(11.63)
i.e.,
yα ∈Kα := B(¯x + ηu, √mα + η∥u∥).
On the other hand, pα(yα) < 0 implies f(yα) < 0 and so yα /∈K (cf.
Fig. 11.6), i.e.,
∥yα −¯x −2ηu∥> 2η∥u∥.
(11.64)
K
Kα
¯x
yα
Fig. 11.6

258
11 Tangent and Normal Cones
Applying the parallelogram identity to yα −¯x −ηu and ηu, we obtain
∥yα −¯x∥2 + ∥yα −¯x −2ηu∥2 = 2∥yα −¯x −ηu∥2 + 2η2∥u∥2.
The estimates (11.63) and (11.64) now give
∥yα −¯x∥2 ≤2(η∥u∥+ √mα)2 + 2η2∥u∥2 −4η2∥u∥2 = 4η∥u∥√mα + mα,
showing that limα→0 yα = ¯x.
(III) We further have
f(yα) ≤pα(yα) < inf
E pα + ϵα ≤pα(¯x) + ϵα = f(¯x) + ϵα
and so limα→0 f(yα) = f(¯x) (recall that f is l.s.c. and ϵα →0 as α →0).
(IV) Since yα is a global minimizer of the functional in (11.62) and yα is in
˚B(¯x, ρ∥u∥) for α suﬃciently small, the functional
f −gα,
where gα(z) := −hα(z) −α
2 ∥z −wα∥2
attains a local minimum at yα. We have
g′
α(yα) = −h′(yα) −α(yα −wα) = k(α)(¯x + ηu −yα) + α(wα −yα),
where
k(α) :=
⎧
⎨
⎩
2(∥yα −¯x −ηu∥−η∥u∥)
α∥yα −¯x −ηu∥
if hα(yα) > 0,
0
if hα(yα) = 0.
Observe that the F-derivative of hα is locally L-continuous and that in
particular h′
α(x) = o whenever hα(x) = 0. Hence for each α suﬃciently
small, g′
α(yα) is a proximal subgradient of f at ¯x.
(V) Assume that lim infα→0 k(α) = 0. Then for some sequence αi →0 we
had g′(yαi) →o as i →∞and so (C1) would hold: a contradiction.
Therefore the lim inf is positive. We have g′
α(yα) = ηk(α)(u + o(1)) as
α →0. It follows that for α small enough,
∥yα −¯x∥< ϵ,
|f(yα) −f(¯x)| < ϵ,

1
ηk(α)g′
α(yα) −u
 < ϵ.
Hence assertion (C2) holds with x := yα, λ := 1/ηk(α), and v := g′(yα).
⊓⊔
The Proximal Normal Cone to Level Sets
Now we consider the set
M := {x ∈E | f(x) = 0}.
(11.65)

11.6 Representation of Normal Cones
259
Theorem 11.6.4 Let E be a Hilbert space and let M be given by (11.65),
where f : E →R is continuous. Let ¯x ∈M and u ∈NP (M, ¯x). Then either
(D1) for any ϵ > 0 and η > 0 there exists x ∈E such that
∥x −¯x∥< η,
|f(x) −f(¯x)| < η,

∂P f(x) ∪∂P (−f)(x)

∩BE∗(o, ϵ) ̸= ∅
or
(D2) for any ϵ > 0 there exist x ∈E, v ∈∂P f(x) ∪∂P (−f)(x), and λ > 0
such that
∥x −¯x∥< ϵ,
|f(x) −f(¯x)| < ϵ,
∥λv −u∥< ϵ.
Sketch of the Proof. As in the proof of Theorem 11.6.3 we may suppose that
u ̸= o. Deﬁne ρ, K, and hα as above, and m as upper bound of |f|. Then
f(x) ̸= 0 for all x ∈K and so (since K is convex and f is continuous), f does
not change sign on K. Deﬁne
pα :=

f + hα + δB(¯x,ρ∥u∥)
if f is positive on K,
−f + hα + δB(¯x,ρ∥u∥)
if f is negative on K.
The argument is now analogous to that in the preceding proof.
⊓⊔
The Fréchet Normal Cone to Sublevel Sets
Now we pass to the Fréchet normal cone. In this connection, we shall make
use of the following condition:
lim inf
x→f ¯x d

o, ∂F f(x)

> 0;
(11.66)
here, x →f ¯x means that x →¯x and f(x) →f(¯x). Condition 11.66 will serve
to exclude a case analogous to (C1) in Theorem 11.6.3.
Theorem 11.6.5 Let E be a Fréchet smooth Banach space and let M :=
{x ∈E | f(x) ≤0}, where f : E →R is proper and l.s.c. Assume that (11.66)
holds. Let ¯x ∈M and u ∈NF (M, ¯x). Then for any ϵ > 0 there exist x ∈E,
v ∈∂F f(x), and λ > 0 such that
∥x −¯x∥< ϵ,
|f(x) −f(¯x)| < ϵ,
∥λv −u∥< ϵ.
Sketch of the Proof. Let c be such that 0 < c < lim infx→f ¯x d

o, ∂F f(x)

.
It is shown that η, δ ∈(0, ϵ) can be chosen such that

¯x + K(u, η)

∩M ∩B(¯x, δ) = {¯x},

260
11 Tangent and Normal Cones
where K(u, η) denotes the Bishop–Phelps cone. Deﬁne A := ¯x+K(u, 2η) and
gi(x) := f(x) + i dA(x) for any x ∈E. We distinguish two cases:
(I) If
inf
B(¯x,δ) gi < 0, then Ekeland’s variational principle of Corollary 8.2.6
ensures the existence of some yi ∈B(¯x, δ) that minimizes the functional
hi(x) := gi(x) + 1
i ∥x −yi∥
over B(¯x, δ) and is such that gi(yi) < 0. It can be shown that
η
2η + 1∥yi −¯x∥≤dA(yi) →0
as i →∞
and so yi →¯x as i →∞. Therefore, yi ∈˚B(¯x, δ) for i suﬃciently large.
(II) If
inf
B(¯x,δ) gi = 0, then set yi := ¯x for any i.
Hence in both cases, yi is a local minimizer of hi for any suﬃciently large i.
By the approximate sum rule of Theorem 9.2.6, for these i there exist xi, zi ∈
˚B(¯x, δ), x∗
i ∈∂F f(xi), and z∗
i ∈∂F dA(zi) such that |f(xi) −f(¯x)| < δ and
∥x∗
i + iz∗
i ∥< η + 1/i.
(11.67)
By using the separation theorem it can be shown that
∂F dA(zi) ⊆{α(−u + 2η∥u∥BE∗| α > 0} ∩BE∗.
Therefore, z∗
i = αi(−u + 2η∥u∥b∗for some αi > 0 and some b∗∈BE∗. Now
it follows from (11.67) that ∥x∗
i −iαiu∥< 2iαi∥u∥η + η + 1/i. We must
conclude that iαi > c/(2∥u∥(1 + 2η)) because otherwise we had ∥x∗
i ∥< c
which contradicts the choice of c. Letting λi := 1/(iαi), we obtain
∥λix∗
i −u∥< 2η∥u∥+ 2η∥u∥(1 + 2η)
c
+ 2∥u∥(1 + 2η)
ic
.
Thus, if i > 4∥u∥(1 + 2η)/cϵ, then setting λ := λi, x := xi, and v := x∗
i , we
have ∥λv −u∥< ϵ.
⊓⊔
The Fréchet Normal Cone to Level Sets
Now we consider the condition
lim inf
x→¯x d

o, ∂F f(x) ∪∂F (−f)(x)

> 0.
(11.68)
Theorem 11.6.6 Let E be a Fréchet smooth Banach space and let M :=
{x ∈E | f(x) = 0}, where f : E →R is continuous. Assume that (11.68)
holds. Let ¯x ∈M and u ∈NF (M, ¯x). Then for any ϵ > 0 there exist x ∈E,
v ∈∂F f(x) ∪∂F (−f)(x), and λ > 0 such that
∥x −¯x∥< ϵ,
|f(x) −f(¯x)| < ϵ,
∥λv −u∥< ϵ.

11.7 Bibliographical Notes and Exercises
261
Sketch of the Proof. Let c be such that
0 < c < lim inf
x→¯x d

o, ∂F f(x) ∪∂F (−f)(x)

.
Again it is shown that η, δ ∈(0, ϵ) can be chosen such that

¯x + K(u, η)

∩M ∩B(¯x, δ) = {¯x}.
Since f is continuous, it follows that:
(a) f(x) ≥0 for all x ∈

¯x + K(u, η)

∩B(¯x, δ) or
(b) f(x) ≤0 for all x ∈

¯x + K(u, η)

∩B(¯x, δ).
Deﬁne A := ¯x + K(u, 2η) and for each i,
gi :=

f + i dA
in case (a),
−f + i dA
in case (b).
The remainder of the proof is analogous to that of Theorem 11.6.5.
⊓⊔
11.7 Bibliographical Notes and Exercises
Normal cones to convex sets can be traced back to Minkowski [131] and
were studied systematically by Fenchel [66]. The contingent cone goes back to
Bouligand [26]. Clarke [34] introduced (in ﬁnite-dimensional spaces) the cone
TC(A, ¯x) according to the formula in Proposition 11.1.6. The sequential char-
acterization of TC(A, ¯x), taken here as deﬁnition, is due to Hiriart-Urruty [85].
Proposition 11.1.9 was established by Rockafellar [184].
Proximal normals already appear, under the name perpendicular vectors,
with Clarke [33]. The results on proximal normals presented above are essen-
tially taken from Clarke et al. [39]. Theorem 11.4.8 is due to Rockafellar [183]
(cf. Clarke [36]).
Theorem 11.4.1 was established by Robinson [175] and Zowe and Kur-
cyusz [228], while Theorem 11.4.2 is a classical result of Lyusternik [128]
(see also Graves [79]). The concept of contingent cone was introduced by
Aubin [5]. Theorem 11.5.2 is due to P¨uhl and Schirotzek [173] (see also
P¨uhl [172]). Proposition 11.5.4 and its proof are taken from P¨uhl [172]. In
a diﬀerent way, Ledzevicz and Walczak [122] deduced the result under the ad-
ditional hypothesis that ker h′(¯x) has a topological complement in E. These
authors also constructed Example 11.5.5. Lyusternik type results related to
Theorem 11.5.2 were established, among others, by Cominetti [40], Klatte and
Kummer [110], and Penot [161].
Theorems 11.6.3–11.6.6 are taken from Borwein et al. [21] (see also Borwein
and Zhu [24]).
For more results on tangents and normals, we refer to Aubin and
Frankowska [8] and Clarke et al. [39]. By now, a lot of further tangent

262
11 Tangent and Normal Cones
and normal sets, not all of them cones and most of them not convex, have
been introduced in the literature (see the detailed discussion in Rockafellar
and Wets [189]).
Exercise 11.7.1 Fill the gaps in the proof of Proposition 11.1.2.
Exercise 11.7.2 Prove the inclusion (11.1) in Proposition 11.1.3.
Exercise 11.7.3 Verify Proposition 11.1.5.
Exercise 11.7.4 Prove Lemma 11.1.8.
Exercise 11.7.5 Prove Proposition 11.1.13.
Exercise 11.7.6 Prove Proposition 11.2.8.
Exercise 11.7.7 Let A ⊆E be closed and ¯x ∈A. Show that NF (A, ¯x) is
closed and convex.
Exercise 11.7.8 Let A be a closed subset of a Fréchet smooth Banach space
and ¯x ∈A. Formulate and verify a representation of NC(A, ¯x) in terms of
F-normals to A at ¯x. Hint: Recall Proposition 9.5.1.
Exercise 11.7.9 Verify the assertions (11.35), (11.36), and (11.38) of
Proposition 11.4.5.
Exercise 11.7.10 Deﬁne for any (x1, x2) ∈R2,
g1(x1, x2) := x2 −x3
1, g2(x1, x2) := −x2, ˜g1 = g1, ˜g2 := g2, ˜g3(x1, x2) := −x1.
Show that
M := {(x1, x2) ∈R2 | gi(x1, x2) ≤0 (i = 1, 2)}
= {(x1, x2) ∈R2 | ˜gk(x1, x2) ≤0 (k = 1, 2, 3)}
but for ¯x := (0, 0) one has L≤((γ1, γ2), ¯x) ̸= L≤((˜γ1, ˜γ2, ˜γ3), ¯x). Also calculate
T(M, ¯x) (cf. Elster et al. [59]).
Exercise 11.7.11 The aim of this exercise is to generalize Theorem 11.4.9
(cf. Schirotzek [196]). Assume that E and H are Banach spaces, G is a normed
vector space, A ⊆E is nonempty closed and convex, P ⊆G is a convex cone
with nonempty interior, and Q ⊆H is a closed convex cone. Further let
g : E →G and h : E →H be given, deﬁne
M := {x ∈E | g(x) ∈−P, h(x) ∈−Q}
and let ¯x ∈A ∩M. Assume that the directional H-derivative dHg(¯x, ·) exists
and is P-convex on E, and that h is continuous on E and continuously
diﬀerentiable at ¯x. Finally deﬁne
Li(g, ¯x) := {y ∈E | dH(¯x, y) ∈−int P + R g(¯x)},
L(g, ¯x) := {y ∈E | dH(¯x, y) ∈−P + R g(¯x)},
L(h, ¯x) := {y ∈E | h′(¯x)y ∈−Q + R h(¯x)}.

11.7 Bibliographical Notes and Exercises
263
(a) Modeling the proof of Theorem 11.4.9(b), prove the following:
Theorem 11.7.12 Assume that
R+(A −¯x) ∩Li(g, ¯x) ∩L(h, ¯x) ̸= ∅
and
h′(¯x)

R+(A −¯x)

+ R+(Q + h(¯x)) = H.
Then one has
R+(A −¯x) ∩L(g, ¯x) ∩L(h, ¯x) ⊆T(A ∩M, ¯x).
(b) Formulate and verify a corresponding result that is analogous to
Theorem 11.4.9(a).

12
Optimality Conditions for Nonconvex Problems
12.1 Basic Optimality Conditions
Let f : E →R be proper, let A ⊆E, and let ¯x ∈A ∩dom f. As shown in
Sect. 7.1, the method of tangent directions leads to the following result.
Proposition 12.1.1 Let ¯x be a local minimizer of f on A.
(a) One has f G(¯x, y) ≥0 for any y ∈Tr(A, ¯x) and f H(¯x, y) ≥0 for any
y ∈T(A, ¯x).
(b) If f is G-diﬀerentiable at ¯x, then ⟨f ′(¯x), y⟩≥0 for any y ∈Tr(A, ¯x).
(c) If f is H-diﬀerentiable at ¯x, then ⟨f ′(¯x), y⟩≥0 for any y ∈T(A, ¯x).
We apply the method of penalization (cf. Sect. 7.1). In the case of a locally
L-continuous functional, a penalty term of the form λdA is adequate.
Proposition 12.1.2 Let f be locally L-continuous with L-constant ˆλ on an
open set U containing A. If ¯x is a minimizer of f on A, then for all λ ≥ˆλ, ¯x
is a minimizer of f + λdA on U (hence a local minimizer of f + λdA on E).
Proof. By assumption we have
f(z) −ˆλ∥y −z∥≤f(y) ≤f(z) + ˆλ∥y −z∥
∀y, z ∈U,
f(¯x) ≤f(y)
∀y ∈A.
Let z ∈U and ϵ > 0. Then there exists y ∈A such that ∥y −z∥≤dA(z) + ϵ.
It follows that
f(¯x) + λdA(¯x) = f(¯x) ≤f(y) ≤f(z) + ˆλ∥y −z∥≤f(z) + λdA(z) + λϵ.
Letting ϵ ↓0 proves the assertion.
⊓⊔
Now we can supplement the optimality criteria in Proposition 12.1.1.

266
12 Optimality Conditions for Nonconvex Problems
Proposition 12.1.3 Let f be locally L-continuous on an open set contain-
ing A. If ¯x is a local minimizer of f on A, then
f ◦(¯x, y) ≥0
∀y ∈TC(A, ¯x)
and
o ∈∂◦f(¯x) + NC(A, ¯x).
Proof.
(I) Let η > 0 be such that ¯x minimizes f on Aη := A ∩B(¯x, η). Then
0 ≤(f + λdAη)◦(¯x, y) ≤f ◦(¯x, y) + λd◦
Aη(¯x, y)
∀y ∈E;
(12.1)
the inequalities are a consequence of Proposition 12.1.2 and the deﬁni-
tion of Clarke’s directional derivative. By Proposition 11.1.6 we obtain
f ◦(¯x, y) ≥0 for all y ∈TC(Aη, ¯x). By Proposition 11.1.2(c), TC(Aη, ¯x) is
equal to TC(A, ¯x).
(II) From (12.1) we deduce o ∈∂◦(f + λdAη)(¯x). The sum rule (Proposi-
tion 7.4.3) and Proposition 11.2.4 show that o ∈∂◦f(¯x) + NC(Aη, ¯x).
As in step (I) we have NC(Aη, ¯x) = NC(A, ¯x).
⊓⊔
Next we assume that f is l.s.c. only. Again we apply the method of penal-
ization, now with the penalty term δA. Recall that if ¯x is a local minimizer of
f on A, then ¯x is a local minimizer of f + δA on E. The generalized Fermat
rule of Proposition 9.1.5 thus yields
o ∈∂F (f + δA)(¯x).
(12.2)
It remains to apply a sum rule. However, in general we only have approximate
sum rules for F-subdiﬀerentials unless f is F-diﬀerentiable at ¯x. Accordingly
we obtain approximate optimality conditions only. In particular, applying the
weak approximate sum rule of Theorem 9.2.7 to (12.2), we obtain:
Proposition 12.1.4 Assume that E is a Fréchet smooth Banach space, f :
E →R is proper and l.s.c., and A is a closed subset of E. Let ¯x ∈A be a local
minimizer of f on A. Then for any ϵ > 0 and any weak∗neighborhood V of
zero in E∗, there exist x0, x1 ∈B(¯x, ϵ) such that x1 ∈A, |f(x0) −f(x1)| < ϵ,
and
o ∈∂F f(x0) + NF (A, x1) + V.
Proof. See Exercise 12.6.1.
⊓⊔
In Sect. 13.7 we shall derive, in Fréchet smooth Banach spaces, exact nec-
essary optimality conditions in terms of another subdiﬀerential.
To conclude, recall that ∂Ff(¯x)
:=
−∂F (−f)(¯x) denotes the F-
superdiﬀerential of f at ¯x. For certain classes of nondiﬀerentiable functionals
this is an adequate derivative-like object, e.g., for concave continuous func-
tionals. In this case, we have a quite strong optimality condition.

12.2 Application to the Calculus of Variations
267
Proposition 12.1.5 Assume that E is a Fréchet smooth Banach space and
f : E →R is proper and l.s.c. If ¯x is a local minimizer of f on A, then
−∂Ff(¯x) ⊆NF (A, ¯x).
Proof. There is nothing to prove if ∂Ff(¯x) is empty. Now let x∗∈−∂Ff(¯x)
be given. Then there exists a function g : E →R that is F-diﬀerentiable at ¯x
with g′(¯x) = x∗and
0 = (−f −g)(¯x) ≤(−f −g)(x)
for any x near ¯x.
By assumption on ¯x we further have f(¯x) ≤f(x) for any x ∈A near ¯x.
It follows that ¯x is a local minimizer of −g on A. From Proposition 9.2.2 we
obtain that
x∗= −(−g)′(¯x) ∈∂F δA(¯x) = NF (A, ¯x),
which completes the proof.
⊓⊔
12.2 Application to the Calculus of Variations
We consider the classical ﬁxed end point problem in the calculus of variations:
Minimize f(x) :=
 b
a
ϕ

t, x(t), ˙x(t)

dt,
x ∈A,
where
A := {x ∈E | x(a) = α, x(b) = β},
E := AC∞[a, b].
(12.3)
Recall that E is a Banach space with respect to the norm ∥x∥1,∞(see
Example 3.6.3). The following results hold analogously for absolutely con-
tinuous functions on [a, b] with values in Rn.
The Smooth Case
First we repeat a classical result, making the following assumptions:
(A) The real-valued function (t, x, v) →ϕ(t, x, v) is continuous on [a, b]×R×R
and has continuous ﬁrst-order partial derivatives with respect to x and
v there; a, b, α, β are given real numbers with a < b.
If ¯x ∈E, we write
ϕ(t) := ϕ

t, ¯x(t), ˙¯x(t)

,
t ∈[a, b].
As shown in Example 3.6.3, the functional f is G-diﬀerentiable (even contin-
uously diﬀerentiable) at each ¯x ∈E and
⟨f ′(¯x), y⟩=
 b
a

ϕx(t) · y(t) + ϕv(t) · ˙y(t)

dt,
y ∈E.

268
12 Optimality Conditions for Nonconvex Problems
It is immediate that
T(A, ¯x) = Tr(A, ¯x) = {x ∈E | x(a) = x(b) = 0} =: E0.
(12.4)
Assume now that ¯x ∈A is a local minimizer of f on A. Then Proposition 12.1.1
gives
 b
a

ϕx(t) · y(t) + ϕv(t) · ˙y(t)

dt = 0
∀y ∈E0;
(12.5)
notice that we have equality here since E0 is a linear subspace of E. Let
q(t) :=
 t
a
ϕx(s) ds,
t ∈[a, b].
Then q is absolutely continuous and
˙q(t) = ϕx(t)
for almost all t ∈[a, b].
(12.6)
Using this and applying partial integration to the ﬁrst term on the left-hand
side of (12.5), we obtain
 b
a

ϕv(t) −q(t)

· ˙y(t) dt = 0
∀y ∈E0.
(12.7)
Now we need the following fundamental lemma of the calculus of variations.
Lemma 12.2.1 (Du Bois–Reymond) Assume that g, h ∈L1[a, b] and
 b
a

h(t) · y(t) + g(t) · ˙y(t)

dt = 0
∀y ∈E0.
Then the function g is absolutely continuous and satisﬁes ˙g(t) = h(t) for
almost all t ∈[a, b].
The proof of this lemma or one of its various modiﬁcations can be found in
any standard book on the calculus of variations (see, for instance, Cesari [30]
or Giaquinta and Hildebrandt [71], see also Loewen [123]).
Applying Lemma 12.2.1 with h = o to (12.7), we obtain the following
result.
Proposition 12.2.2 Let the assumptions (A) be satisﬁed. If ¯x is a local
solution of (12.3), then there exists an absolutely continuous function p :
[a, b] →R such that

˙p(t)
p(t)

=

ϕx(t)
ϕv(t)

for almost all t ∈[a, b].
(12.8)
Eliminating the function p, we see that under the assumptions of Propo-
sition 12.2.2 the function t →ϕv(t) is absolutely continuous on [a, b] and
satisﬁes
d
dtϕv(t) = ϕx(t)
for almost all t ∈[a, b].
(12.9)
This is the Euler–Lagrange equation for Problem (12.3).

12.2 Application to the Calculus of Variations
269
The Nonsmooth Case
Our purpose now is to weaken the diﬀerentiability hypotheses of (A).
Denote by L1 the σ-algebra of all Lebesgue measurable subsets of [a, b], by
Bn the σ-algebra of all Borel subsets of Rn, and by L1×Bn the corresponding
product σ-algebra. Let ¯x ∈M be given. We make the following assumptions:
(ˆA) The function ϕ : [a, b]×R×R →R∪{+∞} is L1×B2-measurable. There
exist ϵ > 0 and a positive function g ∈L1[a, b] such that for almost all
t ∈[a, b] the function (x, v) →ϕ(t, x, v) is real-valued and Lipschitz
continuous on

¯x(t), ˙¯x(t)

+ ϵB with Lipschitz constant g(t).
We establish a generalization of Proposition 12.2.2.
Theorem 12.2.3 Let the assumptions (ˆA) be satisﬁed. If ¯x is a local solution
of (12.3), then there exists an absolutely continuous function p : [a, b] →R
such that
 ˙p(t)
p(t)

∈∂◦ϕ(t, ¯x(t), ˙¯x(t))
for almost all t ∈[a, b].
(12.10)
Here, ∂◦ϕ(t, ¯x(t), ˙¯x(t)) denotes the Clarke subdiﬀerential of the function
(x, v) →ϕ(t, x, v) at the point ((x(t), ˙x(t)).
Notice that under the assumptions (A), Proposition 7.3.9 implies
∂◦ϕ(t, ¯x(t), ˙¯x(t)) =
ϕx(t)
ϕv(t)

so that (12.10) passes into (12.8).
To prepare the proof of Theorem 12.2.3, we quote two propositions. The
ﬁrst is a measurable selection statement which we take from Loewen [123].
Proposition 12.2.4 Let g : [a, b] × R →R ∪{+∞} be L1 × B1-measurable
and let p ∈[1, +∞). Assume that:
– For each t ∈[a, b] the function v →g(t, v) is lower semicontinuous and
real-valued at some point of R.
– There exists ˜u ∈Lp[a, b] such that the function t →g(t, ˜u(t)) is integrable
over [a, b].
Then the integral of the function t →infv∈R g(t, v) over [a, b] is deﬁned (per-
haps equal to −∞), and one has
 b
a
inf
v∈R g(t, v) dt =
inf
u∈Lp[a,b]
 b
a
g(t, u(t)) dt.
The next result is Aubin’s nonsymmetric minimax theorem (see Aubin [6] or
Aubin and Ekeland [7]).

270
12 Optimality Conditions for Nonconvex Problems
Proposition 12.2.5 Let K be a compact convex subset of a topological vector
space, let U be a convex subset of a vector space, and let h : K × U →R be a
function such that:
– For each u ∈U, the function x →h(x, u) is convex and l.s.c.
– For each x ∈K, the function u →−h(x, u) is convex.
Then there exists ˆx ∈K such that
sup
u∈U
h(ˆx, u) = sup
u∈U
inf
x∈K
h(x, u).
In particular,
inf
x∈K
sup
u∈U
h(x, u) = sup
u∈U
inf
x∈K
h(x, u).
Proof of Theorem 12.2.3. By Proposition 12.1.1 and (12.4) we have for each
y ∈E0,
0 ≤f G(¯x, y)
= lim sup
τ↓0
 b
a
τ −1
ϕ

t, ¯x(t) + τy(t), ˙¯x(t) + τ ˙y(t)

−ϕ

t, ¯x(t), ˙¯x(t)

dt.
By assumption (ˆA), the integrand on the right-hand side is a measurable
function of t and, for almost all t ∈[a, b], is majorized by the integrable
function g(t)∥

y(t), ˙y(t)

∥. Hence by a variant of the Fatou lemma, we have
lim sup
" b
a · · · ≤
" b
a lim sup · · · , and it follows that
0 ≤
 b
a
ϕ◦
t, ¯x(t), ˙¯x(t); y(t), ˙y(t)

dt;
(12.11)
here ϕ◦(· · · ) denotes the Clarke directional derivative of the function (x, v) →
ϕ(t, x, v) at the point (¯x(t), ˙¯x(t)) in the direction (y(t), ˙y(t)). The relation
(12.11) holds for any y ∈E0, in particular for y = o. Therefore we have
0 = inf
y∈E0
 b
a
ϕ◦
t, ¯x(t), ˙¯x(t); y(t), ˙y(t)

dt.
Applying Proposition 7.3.7 we further obtain
0 = inf
y∈E0
 b
a
sup

(u(t), p(t)), (y(t), ˙y(t))
  (u(t), p(t)) ∈∂◦ϕ(t, ¯x(t), ˙¯x(t))

dt,
which by Proposition 12.2.4 passes into
0 = inf
y∈E0
sup
(u,p)∈K
 b
a

u(t) y(t) + p(t) ˙y(t)

dt,
(12.12)
where
K := {(u, p) ∈L1 × L1  (u(t), p(t)) ∈∂◦ϕ(t, ¯x(t), ˙¯x(t)), t ∈[a, b] (a.e.)};

12.2 Application to the Calculus of Variations
271
here, L1 stands for L1[a, b]. The set K is convex and weakly compact and the
integral in (12.12) depends bilinearly on u, p. Hence by Proposition 12.2.5, the
inﬁmum and the supremum in (12.12) can be interchanged and the supremum
is attained at some (u, p) ∈K, i.e., we have
0 = inf
y∈E0
 b
a

u(t) y(t) + p(t) ˙y(t)

dt.
Since the integral depends linearly on y, we can conclude that
0 =
 b
a

u(t) y(t) + p(t) ˙y(t)

dt
∀y ∈E0.
Applying Lemma 12.2.1, we see that p is absolutely continuous and ˙p(t) = u(t)
for almost all t ∈[a, b]. In view of the deﬁnition of K, the proof is complete.
⊓⊔
Finally we indicate how to extend the class of problems that can be treated
using the tools of nonsmooth analysis. Recall that E := AC∞[a, b]. Consider
the so-called Bolza problem
f(x) := γ

x(a), x(b)

+
 b
a
ϕ

t, x(t), ˙x(t)

dt −→min, x ∈E.
(12.13)
This is a classical problem if the function ϕ satisﬁes the assumptions (A) and
the function (ξ, η) →γ(ξ, η) mapping R2 into R is diﬀerentiable at (¯x(a), ¯x(b)).
Here ¯x ∈E denotes a local minimum point of f on E. In this case, necessary
conditions are (12.8) together with the natural boundary conditions
p(a) = γξ(¯x(a), ¯x(b)),
p(b) = −γη(¯x(a), ¯x(b)).
However, within the framework of nonsmooth analysis the functions ϕ and γ
are allowed to attain the value +∞. For instance, let
γ(ξ, η) :=

0
if ξ = α and η = β,
+∞
otherwise.
Then (12.13) passes into the ﬁxed end point problem (12.3). Now we consider
a more interesting class of problems. Let the function γ : R2 →R ∪{+∞}
and the multifunction F : R2 ⇒R be given. Consider the problem
γ(x(a), x(b)) −→min, x ∈E, ˙x(t) ∈F(t, x(t)), t ∈[a, b] (a.e.).
(12.14)
Setting
ϕ(t, x, v) :=

0
if v ∈F(t, x),
+∞
otherwise,

272
12 Optimality Conditions for Nonconvex Problems
we have
 b
a
ϕ(t, x(t), ˙x(t)) dt =

0
if ˙x(t) ∈F(t, x(t)), t ∈[a, b] (a.e.),
+∞
otherwise.
Hence problem (12.14) is of the form (12.13). Of course, the assumptions (ˆA)
are not satisﬁed for the function ϕ in this case. Nevertheless, it is possible to
reduce problem (12.14) in such a way that Theorem 12.2.3 applies. However,
this requires facts on diﬀerentiable inclusions that lie beyond the scope of this
book (we refer to Clarke [36], Clarke et al. [39], and Loewen [123]).
12.3 Multiplier Rules Involving Upper Convex
Approximations
Our aim in this section is to establish necessary optimality conditions for the
problem
f(x) →min,
x ∈M ∩A,
under the assumption that M is described by scalar inequalities and/or an
operator equation. First we consider the problem:
(P1) Minimize f(x)
subject to gi(x) ≤0 (i = 1, . . . , m),
x ∈A.
We set
I := {1, . . . , m}, I(¯x) := {i ∈I | gi(¯x) = 0}
(12.15)
and make the following assumptions:
(A1) E is a normed vector space,
A ⊂E is nonempty and convex, D ⊂E is nonempty and open,
f, gi : D →R for i = 1, . . . , m,
there exist ϕ ∈UCr(f, ¯x) and ψi ∈UCr(gi, ¯x) for i ∈I(¯x),
gi is upper semicontinuous at ¯x for i ∈I \ I(¯x).
Theorem 12.3.1 Let (A1) be satisﬁed and assume that ¯x is a local solution
of (P1).
(a) One has:
∃λ ∈R+ ∃µi ∈R+ (i ∈I(¯x)) : not all equal to zero,
λ ϕ(y) +
	
i∈I(¯x)
µi ψi(y) ≥0
∀y ∈A −¯x.
(12.16)
(b) Let the following condition be satisﬁed:
∃y0 ∈A −¯x
∀i ∈I(¯x) : ψi(y0) < 0.
(12.17)

12.3 Multiplier Rules Involving Upper Convex Approximations
273
Then (a) holds with λ = 1.
Proof.
(a) Let y ∈A −¯x and ψi(y) < 0 for each i ∈I(¯x). Then it follows from
Proposition 11.4.5(a) that y ∈Tr(M1 ∩A, ¯x), where
M1 := {x ∈D | gi(x) ≤0 (i = 1, . . . , m)}.
In this connection, notice that A −¯x ⊆Tr(A, ¯x) because A is convex.
Since ¯x is a local solution of f on M1 ∩A, Proposition 12.1.1(a) implies
that ϕ(y) ≥0. Consequently, the system
y ∈A −¯x, ϕ(y) < 0, ψi(y) < 0 ∀i ∈I(¯x)
has no solution. The assertion now follows by Proposition 10.2.1 with
H := {o}. (Notice that to verify (10.3), we need only set ¯yi := ψi(x0) + 1
for each i ∈I(¯x), with some x0 ∈A −¯x.)
(b) This is an immediate consequence of (a).
⊓⊔
Remark 12.3.2
(a) In terms of radial upper convex approximations, the conditions in (a)
and (b) above are generalized John conditions and generalized Karush–
Kuhn–Tucker conditions, respectively (cf. Sect. 5.2). Likewise, (12.17) is
a generalized Slater condition.
(b) Concerning the existence of (radial) upper convex approximations ϕ and
ψi, we refer to Theorem 7.3.2 (cf. Remark 11.4.6(a)).
Now we consider the problem:
(P2) Minimize f(x)
subject to gi(x) ≤0 (i = 1, . . . , m),
h(x) = o,
x ∈A.
Recall the notation (12.15). We agree on the following assumptions:
(A2) E and F are Banach spaces,
A ⊆E is nonempty, convex, and closed, D ⊆E is nonempty and open,
f, gi : D →R for i = 1, . . . , m,
there exist ϕ ∈UC(f, ¯x) and ψi ∈UC(gi, ¯x) for i ∈I(¯x),
gi is upper semicontinuous at ¯x for i ∈I \ I(¯x),
h : D →F is F-diﬀerentiable on a neighborhood of ¯x, h′ is continuous
at ¯x.
Theorem 12.3.3 Let (A2) be satisﬁed and assume that ¯x is a local solution
of (P2):
(a) If h′(¯x)
&
R+(A −¯x)

is closed or F is ﬁnite dimensional, then
∃λ ∈R+
µi ∈R+ (i ∈I(¯x))
∃v ∈F ∗:
λ, µi, v not all zero,
λ ϕ(y) +
	
i∈I(¯x)
µi ψi(y) +

v ◦h′(¯x), y
 
≥0
∀y ∈A −¯x.
(12.18)

274
12 Optimality Conditions for Nonconvex Problems
(b) Let ϕ and ψi, i ∈I(¯x), be continuous on E and let the following condition
be satisﬁed:
h′(¯x)

R+(A −¯x)

= F.
(12.19)
Then (12.18) holds with λ, µi, i ∈I(¯x), not all zero.
(c) Let (12.19) and the following condition be satisﬁed:
∃y0 ∈A −¯x : ψi(y0) < 0 ∀i ∈I(¯x), h′(¯x)y0 = o.
(12.20)
Then (12.18) holds with λ = 1.
Proof.
(a) In view of (b), we may assume that h′(¯x)

R+(A−¯x)

̸= F. Then by a sep-
aration theorem (Theorem 1.5.9 in the general case, or Proposition 1.5.7
if F is ﬁnite dimensional), there exists v ∈F ∗satisfying v ̸= o and
⟨v, z⟩≥0 for each z ∈h′(¯x)

R+(A −¯x)]. Hence the assertion holds with
λ = 0 and µi = 0 for each i ∈I(¯x).
(b) Let y ∈A −¯x, ψi(y) < 0 for each i ∈I(¯x), and h′(¯x)y = o. Then it
follows from Theorem 11.4.9 that y ∈T(M2 ∩A, ¯x), where M2 is deﬁned
by the functional constraints. Since ¯x is a local solution of f on M2 ∩A,
Proposition 12.1.1(b) says that ϕ(y) ≥0. Consequently, the system
y ∈A −¯x, ϕ(y) < 0, ψi(y) < 0 ∀i ∈I(¯x), h′(¯x)y = o
has no solution. The assertion now follows by Proposition 10.2.4.
(c) This is an immediate consequence of (b).
⊓⊔
Remark 12.3.4
(a) The optimality condition (12.18) is again a generalized John condition or,
if λ = 1, a generalized Karush–Kuhn–Tucker condition, with the Lagrange
multipliers µi and v.
(b) If, in particular, f is H-diﬀerentiable at ¯x, we set ϕ := f ′(¯x), analogously
for gi, i ∈I(¯x). If, in addition, A = E, then (12.18) reduces to
λ f ′(¯x) +

i∈I(¯x)
µi g′
i(¯x) + v ◦h′(¯x) = o.
Moreover, if F := Rr and so h = (h1, . . . , hr), where hk : D →R for
k = 1, . . . , r, then (12.18), (12.19), and (12.20) pass, respectively, into
∃λ ∈R+,
∃µi ∈R+ (i ∈I(¯x)),
∃νj ∈R (j = 1, . . . , r) :
not all zero,
λ f ′(¯x) +

i∈I(¯x)
µi g′
i(¯x) +
r

j=1
νj h′
j(¯x) = o ,
(12.21)
h′
1(¯x), . . . , h′
r(¯x) are linearly independent elements of E∗,
(12.22)
∃y0 ∈E : ⟨g′
i(¯x), y0⟩< 0 ∀i ∈I(¯x), ⟨h′
j(¯x), y0⟩= 0 ∀j = 1, . . . , r.
(12.23)

12.3 Multiplier Rules Involving Upper Convex Approximations
275
The conditions (12.22) and (12.23) together are the Mangasarian–
Fromowitz regularity condition.
(c) If, in (P2), the inequalities gi(x) ≤0, i ∈I, are absent, then the corre-
sponding data in Theorem 12.3.3 have to be omitted. This is veriﬁed by
applying Theorem 11.4.1 instead of Theorem 11.4.9.
For ﬁnite-dimensional F, we now relax the diﬀerentiability hypothesis on
the mapping h. We assume that h is F-diﬀerentiable at the point ¯x only. Also
we now choose concrete upper convex approximations for the functionals gi.
More precisely, we consider the following nonsmooth optimization problem:
(P3) Minimize f(x)
subject to gi(x) ≤0,
i = 1, . . . , p,
˜gj(x) ≤0,
j = 1, . . . , q,
hk(x) = 0,
k = 1, . . . , r,
x ∈A.
We want to establish a necessary condition for a point ¯x ∈E to be a local
solution of (P3). We set
I := {1, . . . , p},
I(¯x) := {i ∈I | gi(¯x) = 0},
J := {1, . . . , q},
J(¯x) := {j ∈J | ˜gj(¯x) = 0}.
The assumptions are:
(A3) E is a Banach space, A ⊆E is closed and epi-Lipschitz at ¯x,
f : E →R is H-diﬀerentiable at ¯x or locally L-continuous around ¯x,
gi : E →R is H-diﬀerentiable at ¯x for i ∈I(¯x),
gi : E →R is continuous at ¯x for i ∈I \ I(¯x),
˜gj : E →R is locally L-continuous around ¯x for j ∈J(¯x),
˜gj : E →R is continuous at ¯x for j ∈J \ J(¯x),
hk : E →R is F-diﬀerentiable at ¯x and continuous in a neighborhood
of ¯x for k = 1, . . . , r.
Further we need certain constraint qualiﬁcations:
h′
1(¯x), . . . , h′
r(¯x) are linearly independent elements of E∗.
(12.24)
∃y0 ∈TC(A, ¯x) : ⟨g′
i(¯x), y0⟩< 0 ∀i ∈I(¯x), ˜g♦
j (¯x, y0) < 0 ∀j ∈J(¯x),
⟨h′
k(¯x), y0⟩= 0 ∀k = 1, . . . , r.
(12.25)
Theorem 12.3.5 Let the assumptions (A3) be satisﬁed and let ¯x be a local
solution of (P3):
(a) There exist scalars λ ≥0, µi ≥0 for i ∈I(¯x), ˜µj ≥0 for j ∈J(¯x), and
νk for k = 1, . . . , r that are not all zero, such that for any y ∈TC(A, ¯x),
λ f ♦(¯x, y) +
	
i∈I(¯x)
µi⟨g′
i(¯x), y⟩+
	
j∈J(¯x)
˜µj ˜g♦
j (¯x, y) +
r
	
k=1
νk⟨h′
k(¯x), y⟩≥0.
(12.26)

276
12 Optimality Conditions for Nonconvex Problems
(b) If (12.24) is satisﬁed, then (a) holds, where λ, µi (i ∈I(¯x)), and ˜µj (j ∈
J(¯x)) are not all zero.
(c) If (12.24) and (12.25) are satisﬁed, then (a) holds with λ = 1.
Proof.
(I) Deﬁne h : E →Rr by h := (h1, . . . , hr). If (12.24) is not satisﬁed,
then h′(¯x)(E) is a proper linear subspace of Rr. Hence there exists
(ν1, . . . , νr) ∈Rr \ {o} such that r
k=1 νk⟨h′
k(¯x), y⟩= 0 for any y ∈E.
Setting λ = µi = ˜µj = 0, we see that (12.26) holds.
(II) Assume now that (12.24) is satisﬁed. We show that (b) holds, which
also veriﬁes (a) in this case. Since the F-derivative h′(¯x) is surjective,
Halkin’s correction theorem (Theorem 3.7.5) ensures that there exist a
neighborhood U of ¯x and a mapping ρ : U →E that is F-diﬀerentiable
at ¯x and satisﬁes
ρ(¯x) = o,
ρ′(¯x) = o,
(12.27)
hk

x + ρ(x)

= ⟨h′
k(¯x), x −¯x⟩
∀x ∈U
∀k = 1, . . . , r.
(12.28)
(III) We claim that the following system has no solution:
y ∈int TC(A, ¯x),
(12.29)
f ♦(¯x, y) < 0,
(12.30)
⟨g′
i(¯x), y⟩< 0,
i ∈I(¯x),
(12.31)
˜g♦
j (¯x, y) < 0,
j ∈J(¯x),
(12.32)
⟨h′
k(¯x), y⟩= 0,
k = 1, . . . , r.
(12.33)
Assume, to the contrary, that the system does have a solution y. Set
θ(τ) := ¯x + τy + ρ(¯x + τy),
τ ∈[0, 1].
The relations (12.28) and (12.33) show that hk

θ(τ)

= 0 for k = 1, . . . , r
whenever τ ∈[0, 1] is so small that ¯x+τy ∈U. The properties of ρ entail
θ(0) = ¯x and θ′(0) = y. Hence the chain rule (Proposition 3.4.4) gives
lim
τ↓0 τ −1&
gi

θ(τ)

−gi

θ(0)

= ⟨g′
i(¯x), y⟩
<
(12.31) 0
∀i ∈I(¯x).
Since, for i ∈I(¯x), gi

θ(0)

= gi(¯x) = o, we deduce that
gi

θ(τ)

< 0
for τ ∈(0, 1] suﬃciently small and all i ∈I(¯x).
(12.34)
Since ˜gj is locally L-continuous around ¯x, the Michel–Penot directional
derivative can be written as
˜g♦
j (¯x, y) = sup
z∈E
lim sup
τ↓0
y′→y
τ −1&
˜gj

¯x + τ(y′ + z)

−˜gj(¯x + τz)

∀j ∈J(¯x).
(12.35)

12.3 Multiplier Rules Involving Upper Convex Approximations
277
By (12.27) we have
y′ := y + τ −1ρ(¯x + τy) →y
as τ ↓0.
(12.36)
From this, (12.32), and (12.35) we conclude that
τ −1&
˜gj

¯x + τy + ρ(¯x + τy)

−˜gj(¯x)

< 0
∀j ∈J(¯x)
and so
˜gj

θ(τ)

< 0
for τ ∈(0, 1] suﬃciently small and all j ∈J(¯x).
(12.37)
Analogously, by (12.30) we obtain
f

θ(τ)

< f(¯x)
for τ ∈(0, 1] suﬃciently small.
(12.38)
By assumption (A3), the hypertangent cone H(A, ¯x) is nonempty and so
coincides with int TC(A, x) (Proposition 11.1.9). Therefore y ∈H(A, ¯x).
In view of (12.36) and Lemma 11.1.8, we obtain
θ(τ) = ¯x + τ

y + τ −1ρ(¯x + τy)

∈A.
(12.39)
Since gi, i /∈I(¯x), and ˜gj, j /∈J(¯x), are continuous at ¯x, we further have
gi

θ(τ)

< 0
for τ ∈(0, 1] suﬃciently small and all i ∈I \ I(¯x),
(12.40)
˜gj

θ(τ)

< 0
for τ ∈(0, 1] suﬃciently small and all j ∈J \ J(¯x).
(12.41)
The relations (12.34)–(12.41) contradict the fact that ¯x is a local solution
of (P3). Thus we have shown that the system (12.29)–(12.33) has no
solution.
(IV) We want to apply Proposition 10.2.4. Deﬁne
s := card I(¯x),
t := card J(¯x),
G := E × R × Rs × Rt,
P := −TC(A, ¯x) × R+ × Rs
+ × Rt
+,
S(y) :=

y, f ♦(¯x, y), (⟨g′
i(¯x), y⟩)i∈I(¯x), (˜g♦
j (¯x, y))j∈J(¯x)

,
y ∈E,
T(y) :=

⟨h′
1(¯x), y⟩, . . . , ⟨h′
r(¯x), y⟩

,
y ∈E.
Notice that P is a convex cone with nonempty interior in G and that
the mapping S : E →G is P-convex. By step (III), the system
y ∈E, S(y) ∈−int P, T(y) = o

278
12 Optimality Conditions for Nonconvex Problems
has no solution. Hence by Proposition 10.2.4 there exist u ∈TC(A, ¯x)◦,
λ ≥0, µi ≥0, i ∈I(¯x), and ˜µj ≥0, j ∈J(¯x), not all zero, as well as
ν1, . . . , νr ∈R satisfying
−⟨u, y⟩−λ f ♦(¯x, y) −
	
i∈I(¯x)
µi⟨g′
i(¯x), y⟩
−
	
j∈J(¯x)
˜µj ˜g♦
j (¯x, y) −
r
	
k=1
νk⟨h′
k(¯x), y⟩≤0
∀y ∈E.
(12.42)
The multipliers λ, µi, i ∈I(¯x), and ˜µj, j ∈J(¯x), cannot be simultane-
ously equal to zero since otherwise the inequality (12.42) would imply
that u is also zero which is contradictory. The assertion of the theorem
now follows from (12.42) since ⟨u, y⟩≤0 for any y ∈TC(A, ¯x).
(V) The assertion (c) is obvious.
⊓⊔
12.4 Clarke’s Multiplier Rule
A drawback of the multiplier rules established so far is the diﬀerentiability
assumption on the operator h : E →F deﬁning the equality constraint. In this
section, we present a multiplier rule under a crucially weakened assumption
on h, provided F is ﬁnite dimensional. We consider the following problem:
(P4) Minimize f(x)
subject to gi(x) ≤0 (i = 1, . . . , m), hj(x) = 0 (j = 1, . . . , n),
x ∈A.
The assumptions are:
(A4) E is a Banach space, A ⊆E is nonempty and closed,
f, gi, hj
:
E
→
R (i
=
1, . . . , m, j
=
i, . . . , n)
are all locally
L-continuous around any x ∈A.
Theorem 12.4.1 (Clarke’s Multiplier Rule) Let (A4) be satisﬁed and
assume that ¯x is a local solution of (P4). Then:
∃λ ∈R+ ∃µi ∈R+ (i = 1, . . . , m) ∃νj ∈R (j = 1, . . . , n) : not all zero,
µigi(¯x) = 0 (i = 1, . . . , m),
(12.43)
o ∈λ ∂◦f(¯x) +
m
	
i=1
µi ∂◦gi(¯x) +
n
	
j=1
νj ∂hj(¯x) + NC(A, ¯x).
(12.44)
Proof.
(I) We may and do assume that ¯x is a global solution of (P4) because the
following argument can be applied with A replaced by A∩B(¯x, η), where
η > 0 is suﬃciently small.

12.4 Clarke’s Multiplier Rule
279
(II) Let ϵ > 0 be given. Deﬁne ψ : E →R by
ψ(x) := max

f(x) −f(¯x) + ϵ
2, g1(x), . . . , gm(x), |h1(x)|, . . . , |hn(x)|

.
Then ψ is locally L-continuous and so l.s.c. Since ¯x is a solution of (P4),
we have
ψ(x) > 0
∀x ∈A,
(12.45)
which, together with ψ(¯x) = ϵ/2, implies
ψ(¯x) < inf
x∈A ψ(x) + ϵ.
(12.46)
(III) By step (II), Ekeland’s variational principle in the form of Corollary 8.2.6
applies to ψ. Choosing λ := √ϵ we conclude that there exists xϵ ∈A
such that
∥xϵ −¯x∥≤√ϵ,
(12.47)
ψ(xϵ) ≤ψ(x) + √ϵ ∥xϵ −x∥
∀x ∈A.
(12.48)
(IV) Let κ0 be a common local Lipschitz constant of the functionals f,
g1, . . . , gm, and h1, . . . , hn around ¯x. Then, as is easy to see, each κ > κ0
is a local Lipschitz constant of the functional x →ψ(x) + √ϵ ∥xϵ −x∥
around xϵ for ϵ suﬃciently small. Since by (12.48), this functional has
a minimum on A at xϵ, Proposition 12.1.2 shows that xϵ is a local
minimizer of
%ψ(x) := ψ(x) + √ϵ ωxϵ(x) + κdA(x),
where ωxϵ(x) := ∥xϵ −x∥.
Hence the sum rule (Proposition 7.4.3) gives
o ∈∂◦%ψ(xϵ) ⊆∂◦ψ(xϵ) + √ϵ ∂◦ωxϵ(xϵ) + κ∂◦dA(xϵ).
(V) Now we apply the maximum rule (Proposition 7.4.7) to ψ, Proposi-
tions 4.6.2 and 7.3.9 to ωxϵ, and Proposition 11.2.4 to dA. Hence there
exist nonnegative numbers ˆλ, ˆµ1, . . . , ˆµm and ν′
1, . . . , ν′
n such that
ˆλ +
m
	
i=1
ˆµi +
n
	
j=1
ν′
j = 1,
(12.49)
o ∈ˆλ∂◦f(xϵ) +
m
	
i=1
ˆµi∂◦fi(xϵ) +
n
	
j=1
ν′
j∂◦|hj|(xϵ) + √ϵ BE∗+ NC(A, xϵ).
(12.50)
Since in the maximum rule, the active indices only count and ψ(xϵ) > 0
(see (12.45)), we also have
gi(xϵ) ≤0
=⇒
ˆµi = 0 (i = 1, . . . , m),
hj(xϵ) = 0
=⇒
ν′
j = 0
(j = 1, . . . , n).
(12.51)

280
12 Optimality Conditions for Nonconvex Problems
For j = 1, . . . , n deﬁne
ˆνj :=

sign(hj(xϵ)

ν′
j
if hj(xϵ) ̸= 0,
0
if hj(xϵ) = 0.
By the chain rule (Corollary 7.4.6 with g := | · |), we then obtain
ν′
j ∂◦|hj|(xϵ) ⊆ˆνj ∂◦hj(xϵ)
(j = 1, . . . , n).
This and (12.50) imply the existence of some x∗
ϵ ∈E∗satisfying
x∗
ϵ ∈ˆλ ∂◦f(xϵ) +
n
	
i=1
ˆµi ∂◦gi(xϵ) +
n
	
j=1
ˆνj ∂◦hj(xϵ),
(12.52)
x∗
ϵ ∈√ϵBE∗−NC(A, xϵ).
(12.53)
(VI) Now we replace ϵ by a sequence ϵk ↓0. From (12.47) we obtain xϵk →¯x
as k →∞. Moreover, in view of (12.52) the sequence (x∗
ϵk) is contained
in a σ(E∗, E)-compact set (cf. Proposition 7.3.7) and so has a σ(E∗, E)-
cluster point x∗. Observe that the numbers ˆµi also depend on ϵk, and by
(12.49) have cluster points µi. An analogous observation yields scalars
λ and νj, j = 1, . . . , n. By Proposition 7.3.7(c) we have
x∗∈λ∂◦f(¯x) +
n
	
i=1
µi∂◦gi(¯x) +
n
	
j=1
νj∂◦hj(¯x)
and
x∗∈−NC(A, ¯x),
which is equivalent to (12.44).
(VII) The numbers ˆλ and ˆµi, i = 1, . . . , m, are nonnegative and so are λ
and µi. By (12.49) the numbers λ, µi, and νj are not all zero. It remains
to verify (12.43). Let i ∈{1, . . . , m} be such that gi(¯x) < 0. Then the
continuity of gi implies that, for all k suﬃciently large, gi(xϵk) < 0 and
so (by (12.51)) ˆµi = 0. Hence µi = 0.
⊓⊔
12.5 Approximate Multiplier Rules
We again consider problem (P4). However, for technical reasons we now adopt
a somewhat diﬀerent notation for the functionals involved. More precisely, we
consider the problem:
(P5) Minimize f(x)
subject to fi(x) ≤0 (i = 1, . . . , m),
fi(x) = 0 (i = m + 1, . . . , n),
x ∈A.

12.5 Approximate Multiplier Rules
281
Our aim now is to derive multiplier rules under the following weak
assumptions:
(A5) E is a Fréchet smooth Banach space, A ⊆E is nonempty and closed,
fi : E →R is l.s.c. for i = 0, 1, . . . , m,
fi : E →R is continuous for i = m + 1, . . . , n.
The principal ingredients of the proof of the following multiplier rule are
the weak local approximate sum rule (Theorem 9.2.7) and the representation
results of Theorems 11.6.5 and 11.6.6.
Theorem 12.5.1 (Approximate Multiplier Rule) Let (A5) be satisﬁed
and assume that ¯x is a local solution of (P5).
(a) For any ϵ > 0 and any σ(E∗, E)-neighborhood V of zero, the following
holds:
∃(xi, fi(xi)) ∈(¯x, fi(¯x)) + ϵBE×R
(i = 0, 1, . . . , n)
∃xn+1 ∈¯x + ϵBE
∃µi ≥0 (i = 0, . . . , n) :
µi not all zero,
o ∈
m
	
i=0
µi∂F fi(xi)+
n
	
i=m+1
µi

∂F fi(xi) ∪∂F (−fi)(xi)

+NF (A, xn+1)+V.
(b) Assume that, in addition, the following conditions are satisﬁed:
lim inf
x→f ¯x d(∂F fi(x), o) > 0
for i = 1, . . . , m,
lim inf
x→¯x d(∂F fi(x) ∪∂F (−fi)(x), o) > 0
for i = m + 1, . . . , n.
(12.54)
Then conclusion (a) holds with µ0 = 1 and µi > 0 for i = 1, . . . , n.
Proof. Let ϵ > 0 and a σ(E∗, E)-neighborhood V of zero be given:
(I) First we verify (b). By assumption, ¯x is a local minimizer of ψ := f0 +
δ(∩n
i=1Si)∩A, where
Si :=

{x ∈E | fi(x) ≤0}
if i = 1, . . . , m,
{x ∈E | fi(x) = 0}
if i = m + 1, . . . , n.
Hence we have
o ∈∂F ψ(¯x) = ∂F

f0 +
n
	
i=1
δSi + δA

(¯x).
(12.55)
Let η ∈(0, ϵ/2) and let U be a convex σ(E∗, E)-neighborhood of zero
satisfying U + ηBE∗⊆V . By Theorem 9.2.7 there exist (x0, f0(x0)) ∈

282
12 Optimality Conditions for Nonconvex Problems
(¯x, f0(¯x)) + ηBE×R, (yi, fi(yi)) ∈(¯x, fi(¯x)) + ηBE×R (i = 1, . . . , n), and
xn+1 ∈ηBE such that
o ∈∂F f(x0) +
n
	
i=1
NF (Si, yi) + NF (A, xn+1) + U;
in this connection notice that by deﬁnition ∂F δSi(yi) = NF (Si, yi). Now
let x∗
0 ∈∂F f(x0), y∗
i ∈NF (Si, yi) (i = 1, . . . , n), and y∗
n+1 ∈NF (A, xn+1)
be such that o ∈x∗
0 +n
i=1 y∗
i +y∗
n+1 +U. By Theorems 11.6.5 and 11.6.6
there exist (xi, fi(xi)) ∈(yi, fi(yi)) + ηBE×R, λi > 0, and
x∗
i ∈∂F fi(xi)
for i = 1, . . . , m,
x∗
i ∈∂F fi(xi) ∪∂F (−fi)(xi)
for i = m + 1, . . . , n
such that ∥λix∗
i −y∗
i ∥< η
n for i = 1, . . . , n. It follows that
o ∈x∗
0 +
n
	
i=1
λix∗
i + y∗
n+1 + ηBE∗+ U.
Setting
µ0 :=
1
1 + n
i=1 λi
,
µi :=
λi
1 + n
i=1 λi
for i = 1, . . . , n
and recalling that U is a convex set containing o, we obtain
o ∈
n
	
i=0
µix∗
i +

1 +
n
	
i=1
λi
−1y∗
n+1 + ηBE∗+ U.
Since NF (A, xn+1) is a cone and ηBE∗+ U ⊆V , conclusion (b) follows.
(II) Now we verify (a). In view of step (I) we may assume that con-
dition (12.54) fails. Suppose that for some i
∈
{1, . . . , m} we
have lim infx→f ¯x d(∂F fi(x), o)
=
0; the argument is analogous if
i ∈{m + 1, . . . , n}. We may assume that ϵ ∈(0, 1) is so small that
BE∗(o, ϵ) ⊆V . Then there exist xi ∈BE(¯x, ϵ) and x∗
i ∈∂F fi(xi) such
that |fi(xi) −fi(¯x)| < ϵ and ∥x∗
i ∥< ϵ. Then −x∗
i ∈V . Setting µi := 1
and µj := 0 for any j ̸= i, conclusion (a) follows.
⊓⊔
Remark 12.5.2
(a) If ∂F (−fi)(xi) = −∂F fi(xi) (as is the case if, for instance, fi is a C2
function), then µi

∂F fi(xi) ∪∂F (−fi)(xi)

, where µi ∈R+, corresponds
to µi∂F fi(xi), where µi ∈R, and so to the fact that Lagrange multi-
pliers associated with equality constraints have arbitrary sign (cf. Re-
mark 12.3.4(b)).
(b) Conclusion (a) of Theorem 12.5.1 is of John type while conclusion (b) is of
Karush–Kuhn–Tucker type. The conditions (12.54) constitute a constraint
qualiﬁcation.

12.6 Bibliographical Notes and Exercises
283
12.6 Bibliographical Notes and Exercises
Theorem 12.2.3 is due to Clarke (see [36]), our presentation follows
Loewen [123]. Concerning detailed presentations of the classical calculus of
variations we recommend Cesari [30] and Giaquinta and Hildebrandt [71,72].
Theorem 12.4.1 was established by Clarke [35]. In a similar way but with
the aid of a more sophisticated maximum rule, Clarke [36] obtained a sharp-
ened multiplier rule. Theorem 12.4.1 provides an optimality condition of the
John type (cf. Sects. 5.2 and 12.3). As a regularity condition, Clarke intro-
duced the concept of calmness, see [35,36]. A modiﬁcation of this concept is
due to Rockafellar [187].
Theorem 12.3.5 generalizes a multiplier rule of Halkin [82], where all func-
tionals involved are assumed to be F-diﬀerentiable at ¯x. For results related
to Theorem 12.3.5 but in terms of subdiﬀerentials, we refer to Ye [217]. The
multiplier rule of Theorem 12.5.1 was established by Borwein et al. [21] (see
also Borwein and Zhu [23]).
In addition to the above references, we give a (necessarily subjective) sel-
ection of further papers on optimality conditions for nonconvex problems:
Bazaraa et al. [10], Degiovanni and Schuricht [46], Hiriart-Urruty [84,85,87],
Ngai and Théra [152, 153], Ioﬀe [99], Jourani [107], Loewen [123], Mor-
dukhovich and Wang [146], Neustadt [150], Penot [159,162], Pshenichnyi [169],
Scheﬄer [190], Scheﬄer and Schirotzek [192], and Schirotzek [194, 195]. For
a detailed discussion and a lot of references on the subject we recommend
Mordukhovich [137].
Substantial applications of generalized derivatives are elaborated by Clarke
et al. [39], Panagiotopoulos [157], and Papageorgiou and Gasinski [158].
Exercise 12.6.1 Prove Proposition 12.1.4.
Exercise 12.6.2 Apply Theorem 12.3.1 to the following problem (cf. Exer-
cise 11.7.10):
minimize f(x1, x2) := x1 + x2
subject to
0 ≤x2 ≤x3
1, (x1, x2) ∈R2.
Exercise 12.6.3 Deﬁne f, h : R2 →R by f(x, y) := x and
h(x, y) :=
⎧
⎪
⎨
⎪
⎩
y
if x ≥0,
y −x2
if x < 0, y ≤0,
y + x2
if x < 0, y > 0.
The problem f(x, y) −→min subject to h(x, y) = 0 obviously has the solution
(¯x, ¯y) = (0, 0). Show that no nonzero Lagrange multipliers exist at (¯x, ¯y).
Which assumption of Theorem 12.3.5 is violated (cf. Fernandez [67])?
Exercise 12.6.4 The aim of this exercise is to generalize Theorem 12.3.3 (cf.
Schirotzek [196]):

284
12 Optimality Conditions for Nonconvex Problems
(a) Applying Theorem 11.7.12 (see Exercise 11.7.11(a)), prove the following:
Theorem 12.6.5 In addition to the assumptions of Theorem 11.7.12, sup-
pose that f : E →R is regularly locally convex at ¯x and that ¯x is a local
minimizer of f on A ∩M. Then there exist λ ∈R+, y∗∈P ◦, and z∗∈Q◦
such that (λ, y∗) ̸= o and
λfH(¯x, y) + ⟨y∗, gH(¯x, y)⟩+ ⟨z∗, h′(¯x)y⟩≥0
∀y ∈A −¯x,
⟨y∗, g(¯x)⟩= 0,
⟨z∗, h(¯x)⟩= 0.
(b) Formulate and verify corresponding variants of the other assertions of
Theorem 12.3.3.
Exercise 12.6.6 Let p, q : [a, b] →R and k : [a, b] × [a, b] →R be continuous
functions. Denote
A := {x ∈L2[a, b] | |x(t)| ≤1 for almost all t ∈[a, b]}.
Consider the problem (see Tr¨oltzsch [209], cf. Schirotzek [196])
minimize f(x) :=
 b
a
p(t)x(t) dt,
subject to
 b
a
k(s, t)x2(s) ds ≤q(t)
∀t ∈[a, b],
x ∈A.
Show that if ¯x is a local solution of the problem, then there exist a number
λ ∈R+ and a nondecreasing function v : [a, b] →R such that (λ, v) ̸= o, and
 b
a
y(t)
4
λ p(t) + 2¯x(t)
 b
a
k(t, s) dv(s)
5
dt ≥0
∀y ∈A −¯x,
 b
a
4 b
a
k(s, t)¯x2(s) ds −q(t)
5
dv(t) = 0.
Find a condition ensuring that λ > 0.
Hint: Choose, among others, G := C[a, b] with the maximum norm and apply
Theorem 12.6.5.

13
Extremal Principles and More
Normals and Subdiﬀerentials
Fréchet subdiﬀerentials are a ﬂexible tool for nonsmooth analysis, in particular
in Fréchet smooth Banach spaces where they coincide with viscosity subdif-
ferentials. But in general they admit approximate calculus rules only. Applying
set convergence operations, Mordukhovich developed concepts of subdiﬀeren-
tials and normals that admit a rich exact calculus. To a great extent the prop-
erties of these objects are based on extremal principles, which work especially
well in Fréchet smooth Banach spaces (more generally, in Asplund spaces),
where the new subdiﬀerentials and normal cones are sequential Painlevé–
Kuratowski upper limits of Fréchet subdiﬀerentials and Fréchet normal cones,
respectively.
13.1 Mordukhovich Normals and Subdiﬀerentials
We start with a deﬁnition.
Deﬁnition 13.1.1 Let A be a nonempty subset of E.
(a) If x ∈A and ϵ ≥0, then the set
*
Nϵ(A, x) :=
0
x∗∈E∗ lim sup
y→Ax
⟨x∗, y −x⟩
∥y −x∥
≤ϵ
1
is called set of ϵ-normals to A at x.
(b) If ¯x ∈A, then the set
NM(A, ¯x) := sLim sup
x→¯x
ϵ↓0
*
Nϵ(A, x)
will be called Mordukhovich normal cone (M-normal cone) to A at ¯x.

286
13 Extremal Principles and More Normals and Subdiﬀerentials
Remark 13.1.2
(a) In general, the set *
Nϵ(A, x) is not a cone unless ϵ = 0. The deﬁnitions
immediately yield
NF (A, x) = ∂F δA(x) = *
N0(A, x)
and
NF (A, x) + ϵBE∗⊆*
Nϵ(A, x)
∀ϵ > 0.
(b) We have x∗∈*
Nϵ(A, x) if and only if for any γ > 0 the function
ϕ(x) := ⟨x∗, x −¯x⟩−(ϵ + γ)∥x −¯x∥,
x ∈A,
attains a local maximum at ¯x.
(c) The set NM(A, ¯x) is easily seen to be a cone. Recalling the deﬁnition of the
sequential Painlevé–Kuratowski upper limit, we see that x∗∈NM(A, ¯x)
if and only if there exist sequences ϵk ↓0, xk →A ¯x, and x∗
k
w∗
−−→x∗such
that x∗
k ∈*
Nϵk(A, xk) for any k ∈N.
(d) We always have NF (A, x) ⊆NM(A, x). Example 13.1.3 shows that this in-
clusion may be strict; it also shows that NM(A, ¯x), in contrast to *
Nϵ(A, x),
is in general nonconvex and so cannot be the polar of any tangent cone
to A at ¯x.
Example 13.1.3 Let A := {(x, y) ∈R2 | y ≥−|x|}. Then NF (A, (0, 0)) =
{(0, 0)} but
NM(A, (0, 0)) = {(x∗, x∗) ∈R2 | x∗≤0} ∪{(x∗, −x∗) ∈R2 | x∗≥0}.
In ﬁnite-dimensional spaces there is a close relationship between the
Mordukhovich and the Fréchet normal cone.
Theorem 13.1.4 If A is a closed subset of the Euclidean space E, then
NM(A, ¯x) = sLim sup
x→¯x
NF (A, x).
(13.1)
Proof. We identify E∗with E. It is obvious that the right-hand side of (13.1)
is contained in the left-hand side. We show the opposite inclusion. Thus let
x∗∈NM(A, ¯x) be given. Then (cf. Remark 13.1.2(c)) there exist sequences
ϵk ↓0, xk →A ¯x, and x∗
k
w∗
−−→x∗such that x∗
k ∈*
Nϵk(A, xk) for any k ∈N. Let
η > 0 be arbitrary. For any k ∈N choose yk ∈projA(xk + ηx∗
k) which exists
by Corollary 5.4.5. Since yk depends on η, we also write yk = yk(η). We have
∥xk + ηx∗
k −yk∥2 ≤η2∥x∗
k∥2.
(13.2)
Calculating the left-hand side via the inner product gives
∥xk + ηx∗
k −yk∥2 = ∥xk −yk∥2 + 2η(x∗
k | xk −yk) + η2∥x∗
k∥2.

13.1 Mordukhovich Normals and Subdiﬀerentials
287
Hence (13.2) passes into
∥xk −yk∥2 ≤2η(x∗
k | yk −xk).
(13.3)
By (13.2) it follows that yk(η) →xk as η ↓0. From this and the choice of x∗
k,
we deduce that for any k there exists ηk > 0 such that, with zk := yk(ηk),
we have (x∗
k | zk −xk) ≤2ϵk∥zk −xk∥for any k ∈N. This inequality together
with (13.3) shows that ∥xk −zk∥≤4ηkϵk and so zk →¯x as k →∞. Deﬁning
z∗
k := x∗
k + (1/ηk)(xk −zk), we obtain ∥z∗
k −x∗
k∥≤4ϵk and so z∗
k →x∗as
k →∞. Therefore, to see that x∗∈sLim sup
x→¯x
NF (A, x), it remains to show
that z∗
k ∈NF (A, zk) for any k. Given x ∈A, we calculate
0 ≤∥xk + ηkx∗
k −x∥2 −∥xk + ηkx∗
k −zk∥2
= (ηkx∗
k + xk −x | ηkx∗
k + xk −zk) + (ηkx∗
k + xk −x | zk −x)
−(ηkx∗
k + xk −zk | x −zk) −(ηkx∗
k + xk −zk | ηkx∗
k + xk −x)
= −2ηk(z∗
k | x −zk) + ∥x −zk∥2.
We thus obtain (z∗
k | x −zk) ≤(1/2ηk)∥x −zk∥2 for all x ∈A, which implies
that in fact z∗
k ∈NF (A, zk).
⊓⊔
If the set A is convex, we have a simple representation of *Nϵ(A, ¯x).
Proposition 13.1.5 If A ⊆E is convex and ¯x ∈A, then
*Nϵ(A, ¯x) = {x∗∈E∗| ⟨x∗, x −¯x⟩≤ϵ∥x −¯x∥
∀x ∈A}
∀ϵ ≥0.
(13.4)
In particular, *N0(A, ¯x) = NF (A, ¯x) = N(A, ¯x).
Proof. It is clear that the right-hand side of (13.4) is contained in *Nϵ(A, ¯x)
(even if A is not convex). Now let x∗∈*Nϵ(A, ¯x) be given and ﬁx x ∈A. For
any τ ∈(0, 1] we then have xτ := ¯x + τ(x −¯x) ∈A (because A is convex)
and xτ →¯x as τ ↓0. The deﬁnition of the ϵ-normals now implies that for any
γ > 0 we obtain
⟨x∗, xτ −¯x⟩≤(ϵ + γ)∥xτ −¯x∥
for all suﬃciently small τ > 0.
It follows that x∗is an element of the right-hand side of (13.4).
⊓⊔
The concept to be introduced now will be important for calculus rules. In
this connection, recall Remark 13.1.2(d).
Deﬁnition 13.1.6 The nonempty subset A of E is said to be normally reg-
ular at ¯x ∈A if NM(A, ¯x) = NF (A, ¯x).
The next result yields examples of normally regular sets.

288
13 Extremal Principles and More Normals and Subdiﬀerentials
Proposition 13.1.7 Let A ⊆E and ¯x ∈A. Assume that for some neigh-
borhood U of ¯x the set A ∩U is convex. Then A is normally regular at ¯x
and
NM(A, ¯x) = {x∗∈E∗| ⟨x∗, x −¯x⟩≤0
∀x ∈A ∩U}.
(13.5)
Proof. By Proposition 13.1.5 and Remark 13.1.2(d) we know that the right-
hand side of (13.5) is contained in NM(A, ¯x). Now take any x∗∈NM(A, ¯x).
Then there exist sequences (ϵk), (xk), and (x∗
k) as in Remark 13.1.2(c). For all
k ∈N suﬃciently large we thus have xk ∈A∩U and so by Proposition 13.1.5,
⟨x∗
k, x −xk⟩≤ϵk∥x −xk∥
∀x ∈A ∩U.
Letting k →∞and recalling Exercise 10.10.1, we see that x∗is an element of
the right-hand side of (13.5).
⊓⊔
We will use the M-normal cone to deﬁne subdiﬀerentials of (arbitrary)
proper functions f : E →R. In view of this we ﬁrst establish a result on the
structure of the M-normal cone to an epigraph.
Lemma 13.1.8 Assume that f : E →R is proper and (¯x, ¯α) ∈epi f. Then
(x∗, −λ) ∈NM(epi f, (¯x, ¯α)) implies λ ≥0.
Proof. Let (x∗, −λ) ∈NM(epi f, (¯x, ¯α)) be given. By the deﬁnition of the M-
normal cone there exist sequences ϵk ↓0, (xk, αk) →epi f (¯x, ¯α), x∗
k
w∗
−−→x∗,
and λk →λ such that
lim sup
(x,α)→epi f (xk,αk)
⟨x∗
k, x −xk⟩−λk(α −αk)
∥(x, α) −(xk, αk)∥
≤ϵk
∀k ∈N.
Choosing x := xk we obtain
lim sup
α→αk
−λk sgn(α −αk)
∥(xk, 1)∥
≤ϵk
∀k ∈N.
Letting k →∞, we see that λ ≥0.
⊓⊔
Deﬁnition 13.1.9 Let f : E →R be proper and ¯x ∈dom f. We call
∂Mf(¯x) :=

x∗∈E∗| (x∗, −1) ∈NM

epi f, (¯x, f(¯x))

Mordukhovich subdiﬀerential (M-subdiﬀerential) or basic subdiﬀerential of f
at ¯x and we call
∂∞
Mf(¯x) :=

x∗∈E∗| (x∗, 0) ∈NM

epi f, (¯x, f(¯x))

singular Mordukhovich subdiﬀerential (singular M-subdiﬀerential) of f at ¯x.

13.1 Mordukhovich Normals and Subdiﬀerentials
289
Remark 13.1.10 It follows immediately from the deﬁnitions that the M-
normal cone can be regained from the M-subdiﬀerentials. In fact, for any
subset A of E and any point ¯x ∈A one has
NM(A, ¯x) = ∂MδA(¯x) = ∂∞
MδA(¯x).
As a consequence of Lemma 13.1.8 we have
Lemma 13.1.11 Let f : E →R be proper and ¯x ∈dom f. If NM

epi f,
(¯x, f(¯x)

̸= {(o, 0)} and ∂∞
Mf(¯x) = {o}, then ∂Mf(¯x) is nonempty.
Proof. See Exercise 13.13.1.
⊓⊔
Below we shall derive alternative descriptions of the Mordukhovich subdif-
ferential in terms of subdiﬀerentials to be deﬁned now that modify the Fréchet
subdiﬀerential.
Deﬁnition 13.1.12 Let f : E →R be proper, ¯x ∈dom f, and ϵ ≥0. The
set
*∂ϵf(¯x) :=
0
x∗∈E∗ lim inf
x→¯x
f(x) −f(¯x) −⟨x∗, x −¯x⟩
∥x −¯x∥
≥−ϵ
1
is called (Fréchet) ϵ-subdiﬀerential of f at ¯x.
Remark 13.1.13
(a) For ϵ = 0 we regain the Fréchet subdiﬀerential: *∂0f(¯x) = ∂F f(¯x).
(b) For every ϵ ≥0 we have x∗∈*∂ϵf(¯x) if and only if for any γ > 0 the
function
ψ(x) := f(x) −f(¯x) −⟨x∗, x −¯x⟩+ (ϵ + γ)∥x −¯x∥,
x ∈E,
attains a local minimum at ¯x (cf. Remark 13.1.2(b)).
We deﬁne still another sort of ϵ-subdiﬀerentials.
Deﬁnition 13.1.14 Let f : E →R be proper, ¯x ∈dom f, and ϵ ≥0. The
set
*∂gϵf(¯x) := {x∗| (x∗, −1) ∈*Nϵ(epi f, (¯x, f(¯x))}
is said to be the geometric ϵ-subdiﬀerential of f at ¯x.
The next result describes the relationship between the two ϵ-subdif-
ferentials.
Theorem 13.1.15 Let f : E →R be proper and ¯x ∈dom f.
(a) For any ϵ ≥0 one has *∂ϵf(¯x) ⊆*∂gϵf(¯x).
(b) If ϵ ∈[0, 1) and x∗∈*∂gϵf(¯x), then x∗∈*∂˜ϵf(¯x), where ˜ϵ := ϵ(1 +
∥x∗∥)/(1 −ϵ).

290
13 Extremal Principles and More Normals and Subdiﬀerentials
Proof.
(a) Let ϵ ≥0, x∗∈*∂ϵf(¯x), and γ > 0 be given. By Remark 13.1.2(b) there
exists a neighborhood U of ¯x such that
f(x) −f(¯x) −⟨x∗, x −¯x⟩≥−(ϵ + γ)∥x −¯x∥
∀x ∈U.
It follows that
⟨x∗, x −¯x⟩+ f(¯x) −α ≤(ϵ + γ)∥(x, α) −(¯x, f(¯x))∥.
Hence the function
˜ϕ(x, α) : = ⟨x∗, x −¯x⟩−(α −f(¯x))
−(ϵ + γ)∥(x, α) −(¯x, f(¯x))∥,
(x, α) ∈epi f,
attains a local maximum at (¯x, f(¯x)). By Remark 13.1.2(b) we conclude
that (x∗, −1) ∈*
Nϵ(epi f, (¯x, f(¯x)) and so x∗∈*∂gϵf(¯x).
(b) Now let ϵ ∈[0, 1) and ˜ϵ as above be given. Assume that x∗∈E is not
in *∂˜ϵf(¯x). Then there are γ > 0 and a sequence (xk) converging to ¯x as
k →∞such that
f(xk) −f(¯x) −⟨x∗, x −¯x⟩+ (˜ϵ + γ)∥xk −¯x∥< 0
∀k ∈N.
Put αk := f(¯x) + ⟨x∗, xk −¯x⟩−(˜ϵ + γ)∥xk −¯x∥. Then αk →f(¯x) as
k →∞and (xk, αk) ∈epi f for any k ∈N. An elementary consideration
shows that for any k ∈N,
⟨x∗, xk −¯x⟩−(αk −f(¯x))
∥(xk, αk) −(¯x, f(¯x))∥
=
(˜ϵ + γ)∥xk −¯x∥

xk −¯x, ⟨x∗, xk −¯x⟩−(˜ϵ + γ)∥xk −¯x∥

≥
˜ϵ + γ
1 + ∥x∗∥+ (˜ϵ + γ) >
˜ϵ
1 + ∥x∗∥+ ˜ϵ = ϵ.
Hence (x∗, −1) /∈*Nϵ

epi f, (¯x, f(¯x))

and so x∗/∈*∂gϵf(¯x).
⊓⊔
Remark 13.1.16 For ϵ = 0, Theorem 13.1.15 and Remark 13.1.13(a) yield
*∂g0f(¯x) = *∂0f(¯x) = ∂F f(¯x).
This together with the deﬁnition of the geometric ϵ-subdiﬀerential and Re-
mark 13.1.2(a) show that in any Banach space E we have (cf. Remark 11.3.6)
∂F f(¯x) =

x∗| (x∗, −1) ∈NF

epi f, (¯x, f(¯x))

.
Now
we
establish
the
announced
alternative
description
of
the
M-subdiﬀerential.

13.1 Mordukhovich Normals and Subdiﬀerentials
291
Theorem 13.1.17 Let f : E →R be proper and ¯x ∈dom f.
(a) One always has
∂Mf(¯x) = sLimsup
x→f ¯x, ϵ↓0
*∂gϵf(x) = sLim sup
x→f ¯x, ϵ↓0
*∂ϵf(x).
(13.6)
(b) If, in addition, f is l.s.c. and E is ﬁnite dimensional, then
∂Mf(¯x) = sLim sup
x→f ¯x
∂F f(x).
(13.7)
Proof.
(a) The ﬁrst equation in (13.6) follows immediately from the deﬁnitions
of the geometric ϵ-subdiﬀerential and the ϵ-normal set. This and The-
orem 13.1.15(a) further show that sLim supx→f ¯x, ϵ↓0*∂ϵf(x) ⊆∂Mf(¯x).
Now we verify the opposite inclusion. Thus let x∗∈∂Mf(¯x) be given.
Then there exist sequences ϵk ↓0, xk →f
¯x, and x∗
k
w∗
−−→x∗such
that x∗
k ∈*∂gϵkf(xk) for any k ∈N. For all suﬃciently large k we
have ϵk ∈(0, 1). By Theorem 13.1.15(b) it follows for these k that
x∗
k ∈*∂˜ϵkf(xk), where ˜ϵk := ϵk(1 + ∥x∗
k∥)/(1 −ϵk). Since the sequence
(x∗
k) is bounded, we have ˜ϵk ↓0 as k →∞. This shows that x∗is an
element of the right-hand side of (13.6).
(b) This is a consequence of Theorem 13.1.4 and Remark 13.1.16.
⊓⊔
Since ∂F f(¯x) = *∂0f(¯x) ⊆*∂ϵf(¯x) for any ϵ > 0, it follows from Theo-
rem 13.1.17 that we always have ∂F f(¯x) ⊆∂Mf(¯x). The example
f(x) :=
⎧
⎨
⎩
x2 sin(1/x)
if x ̸= 0,
0
if x = 0
shows that the inclusion may be strict. In fact, here we have ∂F f(0) =
{f ′(0)} = {0} but ∂Mf(0) = [−1, 1]. Below it will turn out that equality in
the above inclusion will ensure equality in calculus rules for M-subdiﬀerentials.
This motivates the following notion.
Deﬁnition 13.1.18 The proper functional f : E →R is said to be lower
regular at ¯x ∈dom f if ∂Mf(¯x) = ∂F f(¯x).
Proposition 13.1.19 Let A ⊆E and ¯x ∈A. The indicator functional δA is
lower regular at ¯x if and only if the set A is normally regular at ¯x.
Proof. See Exercise 13.13.2.
⊓⊔
In Fréchet smooth Banach spaces (and more generally, in Asplund spaces)
the M-subdiﬀerential at ¯x can be represented with the aid of F-subdiﬀerentials

292
13 Extremal Principles and More Normals and Subdiﬀerentials
at nearby points. We prepare this result by an approximate sum rule for
ϵ-subdiﬀerentials.
Lemma 13.1.20 Assume that E is a Fréchet smooth Banach space and that
f1, f2 : E →R are proper and l.s.c. with f1 locally L-continuous around
¯x ∈dom f1 ∩dom f2. Then for any ϵ ≥0 and any γ > 0 one has
*∂ϵ(f1 + f2)(¯x) ⊆
0
∂F f1(x1) + ∂F f2(x2)

xi ∈BE(¯x, γ), |fi(xi) −fi(¯x)| ≤γ, i = 1, 2
1
+ (ϵ + γ)BE∗.
Proof.
(I) Fix ϵ and γ as above and choose η such that 0 < η < min{γ/4, ˜η}, where ˜η
is the positive solution of ˜η2 +(2+ϵ)˜η−γ = 0. Now let x∗∈*∂ϵ(f1 +f2)(¯x)
be given and deﬁne
f0(x) := f1(x) −⟨x∗, x −¯x⟩+ (ϵ + η)∥x −¯x∥
∀x ∈E.
By Remark 13.1.13 the function f0 + f2 attains a local minimum at ¯x.
Then Lemma 9.2.5 shows that condition (9.19) is satisﬁed for f0 + f2.
Applying the approximate sum rule of Theorem 9.2.6 (with η instead of
ϵ) to the sum f0 + f2, we ﬁnd xi ∈B(¯x, η), i = 1, 2, x∗
0 ∈∂F f0(x1) and
x∗
2 ∈∂F f2(x2), such that
|f1(x1) + (ϵ + η)∥x1 −¯x∥−f1(¯x)| ≤η,
|f2(x2) −f2(¯x)| ≤η,
o ∈x∗
0 + x∗
2 + ηBE∗.
By Proposition 9.2.2 we obtain x∗
0 = x∗
1 −x∗with
x∗
1 ∈∂F

f1 + (ϵ + η)ω¯x

(x1),
where ω¯x(x) := ∥x −¯x∥.
It follows that
|f1(x1) −f1(¯x)| ≤η(ϵ + η + 1)
and
x∗∈x∗
1 + x∗
2 + ηBE∗.
(II) Now we evaluate x∗
1. Applying Remark 13.1.13 to x∗
1, we conclude that,
with
g(x) := (ϵ + η)∥x −¯x∥−⟨x∗
1, x −x1⟩+ η∥x −x1∥,
x ∈E,
the function f1 + g attains a local minimum at x1. By Proposition 4.6.2
the convex function g satisﬁes ∂g(x) ⊆−x∗
1 + (ϵ + 2η)BE∗for any x ∈E.
Now we apply Theorem 9.2.6 to the sum f1+g and obtain ˜x1 ∈BE(x1, η)
such that
∥f1(˜x1 −f1(x1)| ≤η
and
x∗
1 ∈∂F f1(˜x1) + (ϵ + 3η)BE∗.

13.1 Mordukhovich Normals and Subdiﬀerentials
293
Summarizing we have
x∗∈∂F f1(˜x1) + ∂F f2(x2) + (ϵ + 4η)BE∗,
∥˜x1 −¯x∥≤2η,
|f1(˜x1) −f1(¯x)| ≤η(ϵ + η + 2).
The deﬁnition of η shows that the proof is complete.
⊓⊔
With the aid of Lemma 13.1.20 we obtain, in a Fréchet smooth Banach
space, a limiting representation of the M-subdiﬀerential that is simpler than
the one in an arbitrary Banach space and that generalizes the corresponding
result for ﬁnite-dimensional Banach spaces (see Theorem 13.1.17).
Theorem 13.1.21
Assume that E is a Fréchet smooth Banach space, f :
E →R is proper and l.s.c., and ¯x ∈dom f.
(a) For any ϵ ≥0 and any γ > 0 one has
*∂ϵf(¯x) ⊆
0
∂F f(x)
 x ∈BE(¯x, γ), |f(x) −f(¯x)| ≤γ
1
+ (ϵ + γ)BE∗.
(13.8)
(b) One has
∂Mf(¯x) = sLim sup
x→f ¯x
∂F f(x).
Proof. Applying Lemma 13.1.20 with f1 := o and f2 := f, we immediately
obtain (a). Now choose γ := ϵ in (13.8) and pass to the limit ϵ ↓0. This
yields (b).
⊓⊔
Due to Theorem 13.1.21(b) we can reformulate Proposition 9.5.1 on the
Clarke subdiﬀerential in the following way.
Proposition 13.1.22 Let E be a Fréchet smooth Banach space and let f :
E →R be locally L-continuous on E. Then for any ¯x ∈E one has
∂◦f(¯x) = co∗∂Mf(¯x).
In this context, recall the discussion in Remark 9.5.2. The normal cone
counterpart of Theorem 13.1.21 is
Theorem 13.1.23 Assume that E is a Fréchet smooth Banach space, A is a
closed subset of E, and ¯x ∈A.
(a) For any ϵ ≥0 and any γ > 0 one has
*Nϵ(A, ¯x) ⊆
0
NF (A, x)
 x ∈A ∩B(¯x, γ)
1
+ (ϵ + γ)BE∗.
(13.9)
(b) One has
NM(A, ¯x) = sLim sup
x→¯x
NF (A, ¯x).
Proof. See Exercise 13.13.3.
⊓⊔

294
13 Extremal Principles and More Normals and Subdiﬀerentials
13.2 Coderivatives
Convention. In this section, unless otherwise speciﬁed, E and F are Fréchet
smooth Banach spaces.
In Sect. 11.5 we considered contingent derivatives as derivative-like objects
for multifunctions. Now we study an alternative concept. Since we want to
apply the approximate calculus for F-subdiﬀerentials established above, we
restrict ourselves to Fréchet smooth Banach spaces.
Deﬁnition 13.2.1 Let Φ : E ⇒F be a closed multifunction and (¯x, ¯y) ∈
graph Φ.
(a) For any ϵ ≥0, the multifunction *D∗
ϵΦ(¯x, ¯y) : F ∗⇒E∗deﬁned by
*D∗
ϵΦ(¯x, ¯y)(y∗) :=

x∗∈E∗| (x∗, −y∗) ∈*Nϵ

graph Φ, (¯x, ¯y)

∀y∗∈F ∗
is said to be the ϵ-coderivative of Φ at (¯x, ¯y). In particular, D∗
F Φ(¯x, ¯y) :=
*D∗
0Φ(¯x, ¯y) is called Fréchet coderivative (F-coderivative) of Φ at (¯x, ¯y).
(b) The multifunction D∗
MΦ(¯x, ¯y) : F ∗⇒E∗deﬁned by
D∗
MΦ(¯x, ¯y)(y∗) :=

x∗∈E∗| (x∗, −y∗) ∈NM

graph Φ, (¯x, ¯y)

∀y∗∈F ∗
is said to be the Mordukhovich coderivative (M-coderivative) of Φ at (¯x, ¯y).
Remark 13.2.2
(a) By deﬁnition of the respective normal cone we have the following charac-
terizations of these coderivatives:
D∗
MΦ(¯x, ¯y)(¯y∗) =
sLim sup
(x, y) →(¯x, ¯y)
y∗
w∗
−−−→¯y∗
ϵ ↓0
*D∗
ϵΦ(x, y)(y∗),
i.e., D∗
MΦ(¯x, ¯y)(¯y∗) consists of all ¯x∗∈E∗for which there exist sequences
ϵk ↓0, (xk, yk) →(¯x, ¯y), and (x∗
k, y∗
k)
w∗
−−→(¯x∗, ¯y∗) satisfying (xk, yk) ∈
graph Φ and x∗
k ∈*D∗
ϵΦ(xk, yk)(y∗
k).
(b) In particular, we have
x∗∈D∗
F Φ(¯x, ¯y)(y∗)
⇐⇒
(x∗, −y∗) ∈∂F δgraph Φ(¯x, ¯y).
The viscosity characterization of the F-subdiﬀerential now shows that
x∗∈D∗
F Φ(¯x, ¯y)(y∗) if and only if there exists a C1 function g : E ×F →R
such that g′(¯x, ¯y) = (x∗, −y∗) and δgraph Φ(x, y) −g(x, y) ≥0 for any
(x, y) ∈E × F near (¯x, ¯y).

13.2 Coderivatives
295
If Φ is single-valued, we write D∗
F Φ(¯x)(y∗) instead of D∗
F Φ(¯x, Φ(¯x))(y∗),
analogously for D∗
M. If f : E →R is a proper functional, we deﬁne the
epigraphical multifunction Ef : E ⇒R by
Ef(x) := {τ ∈R | τ ≥f(x)}
∀x ∈E.
Proposition 13.2.3 relates coderivatives to familiar concepts.
Proposition 13.2.3
(a) If Φ : E →F is an F-diﬀerentiable function, then
D∗
F Φ(¯x)(y∗) = {Φ′(¯x)∗y∗}
∀y∗∈F ∗,
i.e., D∗
F Φ(¯x) can be identiﬁed with the adjoint of the continuous linear
operator Φ′(¯x).
(b) If Φ : E →F is a strictly F-diﬀerentiable function, then D∗
MΦ(¯x) can be
identiﬁed with the adjoint of the continuous linear operator Φ′(¯x).
(c) If f : E →R is a proper functional and ¯x ∈dom f, then
∂Mf(¯x) = D∗
MEf(¯x, f(¯x))(1)
and
∂∞
Mf(¯x) = D∗
MEf(¯x, f(¯x))(0).
Proof. Leaving (a) and (c) as Exercise 13.13.5, we now verify (b). The proof
of (a) is independent of that of (b), thus we may assume that we already have
{Φ′(¯x)∗y∗} = D∗
F Φ(¯x)(y∗) ⊆D∗
MΦ(¯x)(y∗)
∀y∗∈F ∗.
It remains to prove the reverse inclusion. Take any y∗∈F ∗and x∗∈
D∗
MΦ(¯x)(y∗). By Remark 13.2.2 there exist sequences ϵk ↓0, xk →¯x, and
(x∗
k, y∗
k)
w∗
−−→(x∗, y∗) such that for any x close to ¯x and any k ∈N we have
⟨x∗
k, x −xk⟩−⟨y∗
k, Φ(x) −Φ(xk)⟩≤ϵk

∥x −xk∥+ ∥Φ(x) −Φ(xk∥

.
Since Φ is strictly F-diﬀerentiable, Proposition 3.2.4(iv) shows that for any
sequence ηi ↓0 as i →∞there exist ρi > 0 such that
∥Φ(x) −Φ(z) −Φ′(¯x)(x −z)∥≤ηi∥x −z∥
∀x, z ∈B(¯x, ρi) ∀i ∈N.
Hence we ﬁnd a sequence (ki) in N such that
⟨x∗
ki −Φ′(¯x)∗y∗
ki, x −xki⟩≤˜ϵi∥x −xki∥
∀x ∈B(xki, ρki) ∀i ∈N;
here, ˜ϵi := (λ + 1)(ϵki + ηi∥y∗
ki∥and λ > 0 denotes a Lipschitz constant of Φ
around ¯x. It follows that
∥x∗
ki −Φ′(¯x)∗y∗
ki∥≤˜ϵi
for all suﬃciently large i ∈N.
(13.10)
Since
˜ϵi ↓0
and
x∗
ki −Φ′(¯x)∗y∗
ki
w∗
−−→x∗−Φ′(¯x)∗y∗
as i →∞,

296
13 Extremal Principles and More Normals and Subdiﬀerentials
and the norm functional on E∗is weak∗l.s.c. (see Exercise 1.8.10), we ﬁnally
obtain from (13.10) that x∗= Φ′(¯x)∗y∗.
⊓⊔
Next we consider coderivatives of locally L-continuous mappings.
Proposition 13.2.4 Let E and F be Banach spaces and let f : E →F be
locally L-continuous around ¯x ∈E with Lipschitz constant λ > 0.
(a) For any ϵ ≥0 there exists η > 0 such that
sup

∥x∗∥
 x∗∈*D∗
ϵf(x)(y∗)

≤λ∥y∗∥+ ϵ(1 + λ)
whenever x ∈B(¯x, η), ∥f(x) −f(¯x)∥≤η, and y∗∈F ∗.
(b) If, in particular, F is ﬁnite dimensional, then
sup{∥x∗∥| x∗∈D∗
Mf(¯x)(y∗} ≤λ∥y∗∥
∀y∗∈F ∗.
Proof.
(a) Without loss of generality we may assume that λ ≥1. Let η > 0 be such
that
∥f(x) −f(u)∥≤λ∥x −u∥
∀x, u ∈B(¯x, 2η).
(13.11)
Take x ∈B(¯x, η) satisfying ∥f(x) −f(¯x)∥≤η, y∗∈F ∗, and x∗∈
*D∗
ϵf(x)(y∗). Furthermore, take γ > 0. By the deﬁnition of ϵ-coderivatives
and ϵ-normals, there exists α ∈(0, η) such that
⟨x∗, u−x⟩−⟨y∗, f(u)−f(x)⟩≤(ϵ+γ)(∥u−x∥+∥f(u)−f(x)∥) (13.12)
whenever u ∈B(x, α) and ∥f(u) −f(x)∥≤α. Take any u ∈B(x, α/λ) ⊆
B(x, α). Then u ∈B(¯x, 2η), and (13.11) yields ∥f(x) −f(u)∥≤λ(α/λ) =
α. Invoking this estimate into (13.12), we obtain
⟨x∗, u −x⟩≤∥y∗∥α + (ϵ + γ)(α/λ + α).
Since this is true for any u ∈B(x, α/λ), it follows that ∥x∗∥≤λ|∥y∗∥+
(ϵ + γ)(1 + λ). Since γ > 0 was arbitrary, the conclusion follows.
(b) Take any x∗∈D∗
Mf(¯x)(y∗). Then there exist sequences ϵk ↓0, xk →¯x,
x∗
k
w∗
−−→x∗, and y∗
k →y∗(here we exploit that F is ﬁnite dimensional)
such that x∗
k ∈D∗
ϵkf(xk)(y∗
k) for any k ∈N. By (a) we have ∥x∗
k∥≤
λ∥y∗
k∥+ ϵk(1 + λ) for all k large enough. Since the norm functional on
E∗is weak∗l.s.c. (see Exercise 1.8.10), we obtain the assertion by letting
k →∞.
⊓⊔
Corollary 13.2.5 If f : E →R is locally L-continuous around ¯x ∈E, then
D∗
Mf(¯x)(0) = ∂∞
Mf(¯x) = {o}.
(13.13)

13.2 Coderivatives
297
Proof. The Lipschitz property of f implies that the set epi f is closed and
that for some closed neighborhood U of (¯x, f(¯x)) we have U ∩graph f =
U ∩bd(epi f). By Exercise 13.13.4 we therefore obtain ∂∞
Mf(¯x) ⊆D∗
Mf(¯x)(0).
In view of Proposition 13.2.4(b) the assertion is veriﬁed.
⊓⊔
We supplement Corollary 13.2.5 by a result that we state without proof (see
Mordukhovich [137]).
Proposition 13.2.6 If f : E →R is locally L-continuous around ¯x ∈E,
then
D∗
Mf(¯x)(α) = ∂M(αf)(¯x)
∀α ∈R.
We brieﬂy turn to calculus rules for F-coderivatives. As in the case
of F-subdiﬀerentials, approximate calculus rules for F-coderivatives can be
established in weak form and in strong form.
Theorem 13.2.7 (Weak Coderivative Sum Rule) Let Φ1, . . . , Φn : E ⇒
F and Φ := n
i=1 Φi be closed multifunctions. Further let ¯x ∈E, ¯y ∈Φ(¯x),
¯yi ∈Φi(¯x) for i = 1, . . . , n and assume that ¯y = n
i=1 ¯yi. Suppose that y∗∈F ∗
and x∗∈D∗
F Φ(¯x, ¯y)(y∗).
Then for any ϵ > 0 and any weak∗neighborhoods U of zero in E∗and V of
zero in F ∗, there exist (xi, yi) ∈(graph Φi) ∩B((¯x, ¯yi), ϵ), y∗
i ∈y∗+ V , and
x∗
i ∈D∗
F Φi(xi, yi)(y∗
i ), i = 1, . . . , n, such that
max
i=1,...,n{∥x∗
i ∥, ∥y∗
i ∥} · diam{(x1, y1), . . . , (xn, yn)} < ϵ,
(13.14)
x∗∈
n
	
i=1
x∗
i + U.
(13.15)
Proof. Since x∗∈D∗
F Φ(¯x, ¯y)(y∗), there exists a C1 function g as in Re-
mark 13.2.2. Observe that
n
	
i=1
δgraph Φi(x, yi) ≥δgraph Φ

x,
n
	
i=1
yi

and
n
	
i=1
δgraph Φi(¯x, ¯yi) = δgraph Φ(¯x, ¯y) = 0.
Thus, deﬁning ˜f, ˜g : E × F × · · · × F →R by
˜f(x, y1, . . . , yn) :=
n
	
i=1
δgraph Φi(x, yi),
˜g(x, y1, . . . , yn) := g

x,
n
	
i=1
yi

,
we see that
˜f −˜g attains a local minimum at (¯x, ¯y1, . . . , ¯yn). Since
g′(¯x, ¯y) = (x∗, −y∗) (cf. Remark 13.2.2), it follows that ˜g′(¯x, ¯y1, . . . , ¯yn) =
(x∗, −y∗, . . . , −y∗). Hence
(x∗, −y∗, . . . , −y∗) ∈∂F ˜f(¯x, ¯y1, . . . , ¯yn).

298
13 Extremal Principles and More Normals and Subdiﬀerentials
By the approximate sum rule of Theorem 9.2.7 there exist xi ∈B(¯x, ϵ), yi ∈
B(¯yi, ϵ), y∗
i ∈F ∗, and x∗
i ∈D∗
F Φi(xi, yi)(y∗
i ) satisfying (13.14) and
(x∗, −y∗, . . . , −y∗) ∈(x∗
1, −y∗
1, o, . . . , o) + (x∗
2, o, −y∗
2, o, . . . , o)
+ · · · + (x∗
n, o, . . . , o, −y∗
n) + (U × V × · · · × V ).
It follows that y∗
i ∈y∗+ V for i = 1, . . . , n and that (13.15) holds.
⊓⊔
Similarly a weak chain rule can be derived for F-coderivatives. We employ
the following notation. Given multifunctions Ψ : E ⇒F and Φ : F ⇒G, we
deﬁne the composition Φ ◦Ψ : E ⇒G by
Φ ◦Ψ(x) :=

{Φ(y) | y ∈Ψ(x)}.
Theorem 13.2.8 (Weak Coderivative Chain Rule) In addition to E
and F let G be a Fréchet smooth Banach space, let Ψ : E ⇒F and Φ : F ⇒G
be closed multifunctions, let ¯x ∈E, ¯y ∈Ψ(¯x), and ¯z ∈Φ(¯y). Suppose that
z∗∈G∗and x∗∈D∗
F (Φ ◦Ψ)(¯x, ¯z)(z∗). Then for any ϵ > 0 and any weak∗
neighborhoods U of zero in E∗, V of zero in F ∗, and W of zero in G∗, there
exist x2 ∈BE(¯x, ϵ), yi ∈BF (¯y, ϵ), i = 1, 2, and z1 ∈BG(¯z, ϵ) as well as
x∗
2 ∈E∗, y∗
i ∈F ∗, i = 1, 2, and z∗
1 ∈G∗satisfying
y∗
1 −y∗
2 ∈V,
z∗
1 ∈z∗+ W,
y∗
1 ∈D∗
F Φ(y1, z1)(z∗
1),
x∗
2 ∈D∗
F Ψ(x2, y2)(y∗
2),
max{∥x∗
2∥, ∥y∗
1∥, ∥y∗
2∥, ∥z∗
1∥} · ∥y1 −y2∥< ϵ,
x∗∈x∗
2 + U.
Proof. Since x∗∈D∗
F (Φ◦Ψ)(¯x, ¯z)(z∗), there exists a C1 function g : E×G →R
such that g′(¯x, ¯z) = (x∗, −z∗) and δgraph(Φ◦Ψ)(x, z)−g(x, z) ≥0 for any (x, z)
near (¯x, ¯z). We have
δgraph Φ(y, z) + δgraph Ψ(x, y) ≥δgraph(Φ◦Ψ)(x, z)
and
δgraph Φ(¯y, ¯z) + δgraph Ψ(¯x, ¯y) = δgraph(Φ◦Ψ)(¯x, ¯z) = 0.
Deﬁning ˜f, ˜g : E × F × G →R by
˜f(x, y, z) := δgraph Φ(y, z) + δgraph Ψ(x, y),
˜g(x, y, z) := g(x, z),
we thus conclude that (¯x, ¯y, ¯z) is a local minimizer of the functional ˜f −˜g.
Moreover, we have ˜g′(¯x, ¯y, ¯z) = (x∗, o, −z∗). Therefore
(x∗, o, −z∗) ∈∂F ˜f(¯x, ¯y, ¯z).

13.2 Coderivatives
299
The conclusion of the theorem now follows by applying Theorem 9.2.7 to ˜f.
The details are left as Exercise 13.13.6.
⊓⊔
Strong calculus rules for F-coderivatives can be obtained similarly by ap-
plying the strong local approximate sum rule of Theorem 9.2.6 instead of
Theorem 9.2.7. As a consequence of the above results, we can easily derive
exact sum and chain rules for M-coderivatives in ﬁnite-dimensional spaces.
First we introduce another concept.
Deﬁnition 13.2.9 The multifunction Φ : E ⇒F is said to be inner semi-
compact at ¯x ∈Dom Φ if for any sequence xk →¯x there exists a sequence
yk ∈Φ(xk) that contains a convergent subsequence.
Observe that if Dom Φ = E and Φ is locally compact at ¯x (in particular, if F is
ﬁnite dimensional and Φ is locally bounded at ¯x), then Φ is inner semicompact
at ¯x.
Theorem 13.2.10 (Exact Coderivative Sum Rule) Let E
and F
be
ﬁnite-dimensional Banach spaces, let Φ1 and Φ2 be closed multifunctions and
let ¯y ∈Φ1(¯x) + Φ2(¯x). Assume that the multifunction S : E × F ⇒F × F
deﬁned by
S(x, y) := {(y1, y2) | y1 ∈Φ1(x) y2 ∈Φ2(x), y1 + y2 = y}
(13.16)
is inner semicompact at (¯x, ¯y). Assume also that
D∗
MΦ1(¯x, y1)(o) ∩

−D∗
MΦ2(¯x, y2)(o)

= {o}
∀(y1, y2) ∈S(¯x, ¯y).
(13.17)
Then for any y∗∈F ∗one has
D∗
M(Φ1 + Φ2)(¯x, ¯y)(y∗) ⊆

(y1,y2)∈S(¯x,¯y)

D∗
MΦ1(¯x, y1)(y∗) + D∗
MΦ2(¯x, y2)(y∗)

.
Proof. Take any x∗∈D∗
M(Φ1 + Φ2)(¯x, ¯y)(y∗). Then
(x∗, −y∗) ∈NM(graph(Φ1 + Φ2), (¯x, ¯y)).
By Theorem 13.1.4 there exist sequences (xk, yk) →(¯x, ¯y) and (x∗
k, y∗
k) →
(x∗, y∗) as k →∞such that (xk, yk) ∈graph(Φ1 + Φ2) and x∗
k ∈D∗
F (Φ1 +
Φ2)(y∗
k) for any k ∈N. Since S is inner semicompact, we may assume (omitting
relabeling) that there exists a sequence (y1k, y2k) ∈Ψ(xk, yk) converging to
(y1, y2) ∈Ψ(¯x, ¯y). Applying Theorem 13.2.7 for any k, we ﬁnd y∗
ik ∈B(y∗
k, 1/k)
such that
x∗
ik ∈D∗
F Φi(xk, yik)(y∗
ik)
and
∥x∗
k −x∗
1k −x∗
2k∥< 1/k,
i = 1, 2. (13.18)
(I) If the sequence (∥x∗
1k∥) is unbounded, we may assume (passing to a sub-
sequence if necessary) that ∥x∗
1k∥→∞and that (x∗
1k/∥x∗
1k) converges

300
13 Extremal Principles and More Normals and Subdiﬀerentials
to a unit vector z∗. Dividing the second relation in (13.18) by ∥x∗
1k∥and
letting k →∞, we conclude that (x∗
2k/∥x∗
1k∥) converges to −z∗. The ﬁrst
relation in (13.18) now shows that
z∗∈D∗
MΦ1(¯x, y1)(o) ∩

−D∗
MΦ2(¯x, y2)(o)

,
which contradicts the assumption (13.17).
(II) Since by step (I) we know that the sequence (∥x∗
1k∥) is bounded, the sec-
ond relation in (13.18) shows that the sequence (∥x∗
2k∥) is also bounded.
Thus we may assume that both sequences are convergent, and passing to
the limit in (13.18) as k →∞we conclude that x∗∈D∗
MΦ1(¯x, y1)(y∗) +
D∗
MΦ2(¯x, y2)(y∗), which proves the theorem.
⊓⊔
In a similar way, an exact coderivative chain rule can be established in
ﬁnite-dimensional spaces.
Theorem 13.2.11 (Exact Coderivative Chain Rule) Let E, F, G be
ﬁnite-dimensional Banach spaces, let Ψ : E ⇒F and Φ : F ⇒G be closed
multifunctions, let ¯x ∈E and ¯z ∈(Φ ◦Ψ)(¯x). Assume that the multifunction
T : E × G ⇒F deﬁned by T(x, z) := Ψ(x) ∩Φ−1(z) is inner semicompact at
(¯x, ¯z). Assume further that for any ¯y ∈T(¯x, ¯z) the condition
D∗
MΦ(¯y, ¯z)(o) ∩

−D∗
MΨ −1(¯y, ¯x)(o)

= {o}
is satisﬁed. Then for any z∗∈G∗one has
DM(Φ ◦Ψ)(¯x, ¯z)(z∗) ⊆

¯y∈T (¯x,¯z)

D∗
MΨ(¯x, ¯y) ◦D∗
MΦ(¯y, ¯z)(z∗)

.
Proof. See Exercise 13.13.7.
⊓⊔
The following example shows that in an inﬁnite-dimensional space, exact
calculus rules as that of Theorem 13.2.10 may fail.
Example 13.2.12 Let E be a separable inﬁnite-dimensional Banach space,
let H1 and H2 be closed subspaces of E such that H⊥
1 ∩H⊥
2
= {o} and
H⊥
1 + H⊥
2 is weak∗dense (which implies H1 ∩H2 = {o}) but not closed in
E∗; see Exercise 13.13.8 for a concrete example. Now deﬁne Φ1, Φ2 : E ⇒
R by graph Φi := Hi × R+ for i = 1, 2. Then we have graph(Φ1 + Φ2) =
{o} × R+ , S(o, o) = {(0, 0)}, and S(x, y) = ∅whenever (x, y) ̸= (o, o); here
S is as in (13.16). The multifunction S is evidently inner semicompact at
(o, o). Moreover, it is easy to see that D∗
MΦi(o, o)(0) = H⊥
i
for i = 1, 2 and
D∗
M(Φ1 +Φ2)(o, o)(0) = E∗. Hence the regularity condition (13.17) is satisﬁed
but the sum rule
D∗
M(Φ1 + Φ2)(o, o)(0) ⊆D∗
MΦ1(o, o)(0) + D∗
MΦ2(o, o)(0)
fails.

13.3 Extremal Principles Involving Translations
301
13.3 Extremal Principles Involving Translations
We start with a deﬁnition.
Deﬁnition 13.3.1 Let A1, . . . , An be nonempty subsets of the normed vector
space E. A point ¯x ∈∩n
i=1Ai is said to be a local extremal point of the system
(A1, . . . , An) if there exist sequences (z1k), . . . , (znk) in E and a neighborhood
U of ¯x such that zik →o as k →∞for i = 1, . . . , n and
n
6
i=1
(Ai −zik) ∩U = ∅
for all suﬃciently large k ∈N.
In this case, (A1, . . . , An, ¯x) is said to be an extremal system in E.
Remark 13.3.2 Geometrically this means that the sets A1, . . . , An can be
locally pushed apart by small translations. In particular, a point ¯x ∈A1 ∩A2
is a local extremal point of (A1, A2) if and only if there exists a neighbor-
hood U of ¯x such that for any ϵ > 0 there is an element z ∈B(o, ϵ) with
(A1 + z) ∩A2 ∩U = ∅.
Example 13.3.3 shows the close relationship of this extremality concept to
constrained optimization.
Example 13.3.3 Let f : E →R and let M ⊆E. If ¯x is a local solution to
the problem
minimize f(x) subject to x ∈M,
then (¯x, f(¯x)) is a local extremal point of the system (A1, A2), where A1 :=
epi f and A2 := M × {f(¯x)} (see Exercise 13.13.9).
The example A1 := {(ξ, ξ) | ξ ∈R}, A2 := {(ξ, −ξ) | ξ ∈R}, ¯x := (0, 0)
shows that the condition A1 ∩A2 = {¯x} does not imply that ¯x is a local
extremal point of (A1, A2). On the other hand, we have the following necessary
condition.
Lemma 13.3.4 If (A1, . . . , An, ¯x) is an extremal system in E, then there
exists a neighborhood U of ¯x such that
(int A1) ∩· · · ∩(int An−1) ∩An ∩U = ∅.
Proof. See Exercise 13.13.10.
⊓⊔
The next result reveals the relationship between extremality and the sep-
aration property.
Proposition 13.3.5 If A1 and A2 are subsets of E such that A1 ∩A2 ̸= ∅,
then the following holds:
(a) If A1 and A2 are separated, then (A1, A2, ¯x) is an extremal system for any
¯x ∈A1 ∩A2.

302
13 Extremal Principles and More Normals and Subdiﬀerentials
(b) Assume, in addition, that A1 and A2 are convex and int A1 ̸= ∅. If
(A1, A2, ¯y) is an extremal system for some ¯y ∈A1 ∩A2, then A1 and A2
are separated (and (A1, A2, ¯x) is an extremal system for any ¯x ∈A1 ∩A2).
Proof.
(a) If A1 and A2 are separated, then there exist x∗∈E∗\ {o} and α ∈R
such that
⟨x∗, x⟩≤α ∀x ∈A1
and
⟨x∗, y⟩≥α ∀y ∈A2.
(13.19)
Choose x0 ∈E such that ⟨x∗, x0⟩> 0 and set zk := (1/k)x0 for all k ∈N.
We show that (A1−zk)∩A2 = ∅for any k ∈N, which evidently implies the
conclusion of (a). Assume, to the contrary, there exists y ∈(A1 −zk)∩A2
for any k. Then it follows that
α ≥⟨x∗, y + zk⟩= ⟨x∗, y⟩+ 1
k ⟨x∗, x0⟩
∀k,
which contradicts the second inequality in (13.19).
(b) If (A1, A2, ¯y) is an extremal system, then Lemma 13.3.4 implies that
(int A1) ∩(A2 ∩U) is empty for some neighborhood U of ¯y which may be
assumed to be convex. By the weak separation theorem (Theorem 1.5.3)
there exist x∗∈E∗and α ∈R such that
⟨x∗, x⟩≤α ∀x ∈A1
and
⟨x∗, y⟩≥α ∀y ∈A2 ∩U.
It remains to show that ⟨x∗, y⟩≥α for all y ∈A2. Suppose we had
⟨x∗, y0⟩< α for some y0 ∈A2. Set y := λy0 + (1 −λ)¯y. If λ ∈(0, 1) is
suﬃciently small, we have y ∈A2∩U and so α ≤λ⟨x∗, y0⟩+(1−λ)⟨x∗, ¯y⟩,
which is a contradiction because ⟨x∗, y0⟩< α and ⟨x∗, ¯y⟩≤α.
⊓⊔
By Proposition 13.3.5 and the weak separation theorem we now obtain:
Corollary 13.3.6 If A1 and A2 are convex subsets of E such that A1∩A2 ̸= ∅
and int A1 ̸= ∅, then the following conditions are mutually equivalent:
(i) (A1, A2, ¯x) is an extremal system for any ¯x ∈A1 ∩A2.
(ii) A1 and A2 are separated.
(iii) (int A1) ∩A2 = ∅.
Deﬁnition 13.3.7
(a) An extremal system (A1, . . . , An, ¯x) in E is said to satisfy the exact ex-
tremal principle if there exist x∗
i ∈NM(Ai, ¯x), i = 1, . . . , n, such that
x∗
1 + · · · + x∗
n = o
and
∥x∗
1∥+ · · · + ∥x∗
n∥= 1.
(13.20)

13.3 Extremal Principles Involving Translations
303
(b) An extremal system (A1, . . . , An, ¯x) in E is said to satisfy the approximate
extremal principle if for every ϵ > 0 there exist
xi ∈Ai ∩BE(¯x, ϵ)
and
x∗
i ∈NF (Ai, xi) + ϵBE∗,
i = 1, . . . , n,
such that (13.20) holds.
Remark 13.3.8 We consider the case of two sets:
(a) An extremal system (A1, A2, ¯x) satisﬁes the exact extremal principle if
and only if there exists x∗∈E∗\ {o} such that
x∗∈NM(A1, ¯x) ∩

−NM(A2, ¯x)

.
(13.21)
If A1 and A2 are convex, then by Proposition 13.1.5 the relation (13.21)
is equivalent to
⟨x∗, y1⟩≤⟨x∗, y2⟩
∀y1 ∈A1 ∀y2 ∈A2,
which means that A1 and A2 are separated. Hence the exact extremal
principle can be considered as a statement on local separation of noncon-
vex sets.
(b) Similarly, an extremal system (A1, A2, ¯x) satisﬁes the approximate
extremal principle if and only if for any ϵ > 0 there exist xi ∈Ai ∩B(¯x, ϵ),
where i = 1, 2, and x∗∈E∗such that ∥x∗∥= 1 and
x∗∈

NF (A1, x1) + ϵBE∗
∩

−NF (A2, x2) + ϵBE∗
.
(13.22)
This can be analogously interpreted as an approximate separation of A1
and A2 near ¯x.
We consider a ﬁrst application of the approximate extremal principle.
Recall that in terms of the normal cone of convex analysis, N(A, ¯x), the set
of support points of A is

x ∈bd A | N(A, x) ̸= {o}

.
If A is closed and convex, the Bishop–Phelps theorem (Theorem 1.5.6) ensures
that this set is dense in bd A. Now we show that the approximate extremal
principle yields an approximate analogue of the Bishop–Phelps theorem with-
out the convexity hypothesis if N(A, ¯x) is replaced by the Fréchet normal cone
NF (A, ¯x).
Proposition 13.3.9 Let A be a proper closed subset of E and ¯x ∈bd A. If
the approximate extremal principle holds for the system (A, {¯x}, ¯x), then the
set

x ∈bd A | NF (A, x) ̸= {o}

is dense in bd A.

304
13 Extremal Principles and More Normals and Subdiﬀerentials
Proof. By the approximate extremal principle for (A, {¯x}, ¯x) with ϵ ∈(0, 1/2),
we ﬁnd x ∈A ∩BE(¯x, ϵ) and x∗∈NF (A, x) + ϵBE∗such that ∥x∗∥= 1/2.
It follows that x ∈bd A because otherwise we had NF (A, x) = {o} and so
∥x∗∥≤ϵ < 1/2: a contradiction. In particular we see that NF (A, x) ̸= {o}.
⊓⊔
The next result will be crucial for substantial applications of the approxi-
mate extremal principle.
Theorem 13.3.10 If E is a Fréchet smooth Banach space, then the approx-
imate extremal principle holds for any extremal system (A1, . . . , An, ¯x) in E,
where n ∈N and the sets A1, . . . , An are closed.
Proof.
(I) First we consider the case n = 2.
(Ia) Let ¯x ∈A1 ∩A2 be a local extremal point of the system (A1, A2). Then
there exists a closed neighborhood U of ¯x such that for any ϵ > 0 there
is z ∈E satisfying ∥z∥≤ϵ3/2 and
(A1 + z) ∩A2 ∩U = ∅.
(13.23)
Obviously we may assume that U = E (otherwise replace A2 by A2 ∩U)
and ϵ < 1/2. Equip E × E with the Euclidean product norm, which is
also F-diﬀerentiable away from the origin. Deﬁne ϕ : E × E →R by
ϕ(x) := ω(x1 −x2 + z) = ∥x1 −x2 + z∥,
where
x := (x1, x2) ∈E × E.
By (13.23) we have ϕ(x) > 0 for any x ∈A1 × A2. Hence ϕ is a C1
function in a neighborhood of each point of A1 × A2. Set x := (¯x, ¯x) and
deﬁne the set
W(x) :=

x ∈A1 × A2 | ϕ(x) + (ϵ/2)∥x −x∥2 ≤ϕ(x)

,
which is nonempty and closed. For any x ∈W(x) we obtain (ϵ/2)∥x −
x∥2 ≤ϕ(x) and so
∥x1 −¯x∥2 + ∥x2 −¯x∥2 ≤(2/ϵ)ϕ(x) = (2/ϵ)∥z∥≤ϵ2.
We conclude that W(x) ⊆BE×E(¯x, ϵ).
(Ib) For k = 0, 1, . . . we inductively deﬁne points xk ∈A1 × A2 and sets
W(xk) as follows. Given xk and W(xk), choose xk+1 ∈W(xk) such that
ϕ(xk+1) + ϵ
k
	
i=0
∥xk+1 −xi∥2
2i+1
<
inf
x∈W (xk)

ϕ(x) + ϵ
k
	
i=0
∥x −xi∥2
2i+1

+
ϵ3
23k+2

13.3 Extremal Principles Involving Translations
305
and deﬁne
W(xk+1) :=

x ∈A1 × A2
 ϕ(x) + ϵ
k+1
	
i=0
∥x −xi∥2
2i+1
'
≤ϕ(xk+1) + ϵ
k
	
i=0
∥xk+1 −xi∥2
2i+1
'
.
For any k, the set W(xk) is a nonempty closed subset of A1 × A2 and
one has W(xk+1) ⊆W(xk). We show that diam W(xk) →0 as k →∞.
For all k ∈N and x ∈W(xk+1) we obtain
ϵ∥x −xk+1∥2
2k+2
≤ϕ(xk+1)
+ ϵ
k
	
i=0
∥xk+1 −xi∥2
2i+1
−

ϕ(x) + ϵ
k
	
i=0
∥x −xi∥2
2i+1

≤ϕ(xk+1) + ϵ
k
	
i=0
∥xk+1 −xi∥2
2i+1
−
inf
x∈W (xk)

ϕ(x) + ϵ
k
	
i=0
∥x −xi∥2
2i+1
'
<
ϵ3
23k+2 .
Thus diam W(xk) ≤ϵ/2k−1 →0 as k →∞. By the Cantor intersection
theorem the set ∩∞
k=0W(xk) consists of exactly one point ˆx = (ˆx1, ˆx2) ∈
W(x0) ⊆BE×E(x, ϵ) and one has xk →ˆx as k →∞.
(Ic) We show that ˆx is a minimizer of the function
%ϕ(x) := ϕ(x) + ϵ
∞
	
i=0
∥x −xi∥2
2i+1
,
x ∈E × E,
over A1 × A2. Thus let x ∈A1 × A2, x ̸= ˆx. The construction of W(xk)
shows that for some k ∈N we have
ϕ(x) + ϵ
k
	
i=0
∥x −xi∥2
2i+1
> ϕ(xk) + ϵ
k−1
	
i=0
∥xk −xi∥2
2i+1
.
Since the sequence on the right-hand side is nonincreasing as k →∞, it
follows that in fact ˆx is a minimizer of %ϕ on A1 × A2 and so a minimizer
of ψ := %ϕ + δA1×A2 on E × E. We conclude that o ∈∂F ψ(ˆx) (Propo-
sition 9.1.5). Since ϕ is a C1 function in a neighborhood of ˆx, so is the
function %ϕ. By Proposition 9.2.2 and the deﬁnition of the Fréchet normal
cone we obtain
−%ϕ′(ˆx) ∈NF (A1 × A2, ˆx) = NF (A1, ˆx) × NF (A2, ˆx).
(13.24)

306
13 Extremal Principles and More Normals and Subdiﬀerentials
(Id) We calculate %ϕ′(ˆx). It follows from the deﬁnition of %ϕ that %ϕ′(ˆx) =
(u∗
1, u∗
2) ∈E∗× E∗, where
u∗
1 := x∗+ ϵ
∞
	
i=0
v∗
1i
∥ˆx1 −x1i∥
2i
,
u∗
2 := −x∗+ ϵ
∞
	
i=0
v∗
2i
∥ˆx2 −x2i∥
2i
,
x∗:= ω′(ˆx1 −ˆx2 + z),
(x1i, x2i) := xi,
v∗
ji :=

ω′(ˆxj −xji)
if ˆxj −xji ̸= o,
o
otherwise;
here i = 0, 1, . . . and j = 1, 2. We have ∥x∗∥= 1 and for j = 1, 2,
∞
	
i=0
∥v∗
ji∥∥ˆxj −xji∥
2i
≤1.
Thus, putting xj := ˆxj and x∗
j := (−1)jx∗/2 for j = 1, 2, we obtain the
conclusion of the theorem in the case n = 2.
(II) Now we treat the general case by induction. If ¯x is a local extremal point
of the system (A1, . . . , An), where n > 2, then y := (¯x, . . . , ¯x) ∈En−1 is
a local extremal point of the system (B1, B2), where
B1 := A1 × · · · × An−1
and
B2 := {(x, . . . , x) ∈En−1 | x ∈An}.
By step (I) the approximate extremal principle holds for the system
(B1, B2, y), from which the assertion follows. The details are left as
Exercise 13.13.12.
⊓⊔
Now we are going to discuss the relationship between the approximate
extremal principle and other properties of a Banach space. In this connection
we adopt the following terminology.
Deﬁnition 13.3.11 We say that the subdiﬀerential variational principle
holds in the Banach space E if for every proper l.s.c. functional f : E →R
bounded below, every ϵ > 0, every λ > 0, and every ¯x ∈E such that
f(¯x) < infE f + ϵ, there exist z ∈E and z∗∈∂F f(z) satisfying
∥z −¯x∥< λ,
f(z) < inf
E f + ϵ
and
∥z∗∥< ϵ/λ.
Theorem 13.3.12 (Characterization of Asplund Spaces) For
any
Banach space E the following assertions are mutually equivalent:
(a) E is an Asplund space.
(b) The approximate extremal principle holds for any extremal system
(A1, . . . , An, ¯x), where n ∈N and A1, . . . , An are closed sets.
(c) The subdiﬀerential variational principle holds in E.

13.3 Extremal Principles Involving Translations
307
Proof. Remarks on (a) =⇒(b): By Theorem 13.3.10 we know that the approx-
imate extremal principle holds if E is Fréchet smooth. If now E is an arbitrary
Asplund space, then every separable subspace is Fréchet smooth (see Deville
et al. [50]). By a method called separable reduction certain problems concern-
ing F-subdiﬀerentials and F-normal cones can be reduced from an arbitrary
Banach space to separable subspaces. In this way, the approximate extremal
principle can be transmitted from a Fréchet smooth Banach space to an ar-
bitrary Asplund space. However, the method of separable reduction is quite
involved and will not be treated here; we refer to Borwein and Zhu [24] and
Mordukhovich [136].
(b) =⇒(c): Let f, ϵ, λ, and ¯x be as in the deﬁnition of the subdiﬀerential vari-
ational principle. Choose ˜ϵ ∈(0, ϵ) such that f(¯x) < infE f + (ϵ −˜ϵ) and put
˜λ := (2ϵ−˜ϵ)λ/(2ϵ). Notice that ˜λ < λ. By Ekeland’s variational principle (The-
orem 8.2.4) there exists z ∈E satisfying ∥z −¯x∥< ˜λ, f(z) < infE f + (ϵ −˜ϵ),
and
f(z) < f(x) + ∥x −z∥(ϵ −˜ϵ)/˜λ
∀x ∈E \ {z}.
(13.25)
We equip E × R with the norm (x, τ) := ∥x∥+ |τ| and E∗× R with the
corresponding dual norm (x∗, τ ∗)∥= max{∥x∗∥, |τ ∗|}. Put g(x) := ∥x−z∥(ϵ−
˜ϵ)/˜λ and deﬁne
A1 := epi f
and
A2 := {(x, τ) ∈E × R | τ ≤f(z) −g(x)}.
Then A1 and A2 are closed in E ×R, and it follows from (13.25) that (z, f(z))
is a local extremal point of the system (A1, A2). Hence (b) ensures that the
approximate extremal principle holds in E and so in E ×R. Consequently, for
any η > 0 we ﬁnd (xi, τi) ∈Ai and (x∗
i , τ ∗
i ) ∈NF (Ai, (xi, τi)), where i = 1, 2,
such that
∥xi −z∥+ |τi −f(z)| < η,
(13.26)
1/2 −η < max{∥x∗
i ∥, |τ ∗
i |} < 1/2 + η,
(13.27)
max{∥x∗
1 + x∗
2∥, |τ ∗
1 + τ ∗
2 |} < η.
(13.28)
The deﬁnition of the Fréchet normal cone entails that for i = 1, 2 we have
lim sup
(x,τ)→Ai(xi,τi)
⟨x∗
i , x −xi⟩+ τ ∗
i (τ −τi)
∥x −xi∥+ |τ −τi|
≤0.
(13.29)
It follows from the deﬁnition of A2 and (13.26) that τ2 = f(z)−g(x) whenever
η is suﬃciently small. Moreover, by (13.27) we see that (x∗
2, τ ∗
2 ) ̸= o. Thus,
(13.29) shows that τ ∗
2 > 0. Hence we obtain
x∗
2/τ ∗
2 ∈∂F g(x2)
and
∥x∗
2∥/τ ∗
2 ≤(ϵ −˜ϵ)/˜λ.
The latter inequality together with (13.27) yields
τ ∗
2 ≥min

(1 −2η)˜λ
2(ϵ −˜ϵ) , 1
2 −η
'
.
(13.30)

308
13 Extremal Principles and More Normals and Subdiﬀerentials
From this estimate and (13.28) we must conclude that τ ∗
1 < 0 whenever η
is suﬃciently small. Now it follows that τ1 = f(x1). In fact, by (13.29) with
i = 1 the inequality τ1 > f(x1) would imply that τ ∗
1 = 0. Thus we have shown
that −x∗
1/τ ∗
1 ∈∂F f(x1). The estimate (13.30) also yields η/τ ∗
2 →0 as η ↓0.
Therefore, for η suﬃciently small we have
∥x∗
1∥
|τ ∗
1 | < ∥x∗
2∥+ η
τ ∗
2 −η
=
∥x∗
2∥
τ ∗
2
+ η
τ ∗
2
 7
1 −η
τ ∗
2

< ϵ
λ.
Furthermore, the deﬁnition of ˜λ and (13.26) give
∥x1 −¯x∥< ˜λ + η
and
f(x1) = τ1 < inf
E f + ϵ −˜ϵ + η.
Deﬁning z := x1 and z∗:= −x∗
1/τ ∗
1 , the conclusion of (c) follows.
(c) =⇒(a): Let ϕ : E →R be convex and continuous. Then for any x ∈E
the set ∂F ϕ(x) coincides with ∂ϕ(x) and is nonempty (Proposition 4.1.6).
We show that there exists a dense subset D of E such that ∂F (−ϕ)(x) is
nonempty for any x ∈D. It is evident that this implies F-diﬀerentiability of
ϕ on D. Choose ¯x ∈E and ϵ > 0. Since ψ := −ϕ is continuous, there exists
η ∈(0, ϵ) such that ψ(x) > ψ(¯x) −ϵ for every x ∈B(¯x, η). The functional
f := ψ +δB(¯x,η) is l.s.c. on E. By applying (c) to f we obtain z ∈E satisfying
∥z −¯x∥< η and ∂F f(z) ̸= ∅. It follows that ∂F (−ϕ)(z) ̸= ∅. Therefore, ϕ is
F-diﬀerentiable on a dense subset of E.
⊓⊔
By Theorem 13.3.12 the approximate extremal principle holds in an
Asplund space for arbitrary closed sets. Next we shall show that the exact
extremal principle holds in an Asplund space for closed sets with an addi-
tional property to be deﬁned now.
Deﬁnition 13.3.13 The set A ⊆E is said to be sequentially normally com-
pact (SNC) at ¯x ∈A if for any sequence ((ϵk, xk, x∗
k)) in (0, +∞) × A × E∗
one has
&
ϵk ↓0,
xk →¯x,
x∗
k ∈*Nϵk(A, xk),
x∗
k
w∗
−−→o
as
k →∞

=⇒
x∗
k →o
as
k →∞.
If E is an Asplund space, then due to Theorem 13.1.23 we may choose
ϵk = 0 for any k ∈N in Deﬁnition 13.3.13. Clearly in a ﬁnite-dimensional
Banach space any nonempty subset is SNC at each of its points. In Sect. 13.4
we shall describe classes of SNC sets in inﬁnite-dimensional Banach spaces.
Theorem 13.3.14 Let E be an Asplund space and (A1, . . . , An, ¯x) be an
extremal system in E. Assume that the sets A1, . . . , An are closed and all
but one of them are SNC at ¯x. Then the exact extremal principle holds for
(A1, . . . , An, ¯x).

13.4 Sequentially Normally Compact Sets
309
Proof. Let (ϵk) be a sequence of positive numbers such that ϵk ↓0 as k →∞.
Since the approximate extremal principle holds for (A1, . . . , An, ¯x), for any k ∈
N and i = 1, . . . , n there exist xik ∈Ai∩B(¯x, ϵk) and x∗
ik ∈NF (Ai, xik)+ϵkBE∗
satisfying
x∗
1k + · · · + x∗
nk = o
and
∥x∗
1k∥+ · · · + ∥x∗
nk∥= 1.
(13.31)
We have xik →¯x as k →∞for i = 1, . . . , n. Since for i = 1, . . . , n the sequence
(x∗
ik)k∈N is bounded in the dual of the Asplund space E, Theorem 4.3.21
implies that a subsequence, again denoted (x∗
ik)k∈N, is weak∗convergent to
some x∗
i ∈E∗. Since x∗
ik ∈*Nϵk(Ai, xik) for any k (cf. Remark 13.1.2(a)), the
deﬁnition of the M-normal cone shows that x∗
i ∈NM(Ai, ¯x). It is evident that
x∗
1 + · · · + x∗
n = o. It remains to show that the x∗
i are not simultaneously zero.
By hypothesis we may assume that A1, . . . , An−1 are SNC. We now suppose
we had x∗
i = o for i = 1, . . . , n −1. Since
∥x∗
nk∥≤∥x∗
1k∥+ · · · + ∥x∗
n−1k∥
∀k ∈N,
we must conclude, letting k →∞, that x∗
n = o. But this contradicts the
second equation in (13.31).
⊓⊔
Applying Theorem 13.3.14 to the system (A, {¯x}, ¯x), we obtain the follow-
ing result.
Corollary 13.3.15 Let E be an Asplund space and A be a proper closed
subset of E. Then NM(A, ¯x) ̸= {o} at every boundary point ¯x of A where A
is SNC.
13.4 Sequentially Normally Compact Sets
We will now describe classes of SNC sets. For this we introduce a concept that
generalizes that of an epi-Lipschitzian set (cf. Exercise 13.13.13).
Deﬁnition 13.4.1 The set A ⊆E is said to be compactly epi-Lipschitzian
at ¯x ∈A if there exist a compact set C ⊆E and numbers η > 0 and ˆτ > 0
such that
A ∩B(¯x, η) + τB(o, η) ⊆A + τC
∀τ ∈(0, ˆτ).
(13.32)
If E is ﬁnite dimensional, then choosing η = ˆτ := 1 and C := B(o, 1) we
see that any subset A of E is compactly epi-Lipschitzian at each point ¯x ∈A
but A need not be epi-Lipschitzian (see Remark 11.1.11).
Proposition 13.4.2 If A ⊆E is compactly epi-Lipschitzian at ¯x ∈A, then
A is SNC at ¯x.

310
13 Extremal Principles and More Normals and Subdiﬀerentials
Proof. Let C, η, and ˆτ be as in Deﬁnition 13.4.1. We will show that there
exists α > 0 such that for any ϵ > 0 we have
*Nϵ(A, x) ⊆

x∗∈E∗ η∥x∗∥≤ϵ(α + η) + max
z∈C ⟨x∗, z⟩

∀x ∈A ∩B(¯x, η).
(13.33)
Let x ∈A ∩B(¯x, η) and a sequence (τk) in (0, ˆτ) with τk ↓0 be given. In view
of (13.32), for any k ∈N and any y ∈B(o, 1) there exists zk ∈C such that
x + τk(ηy −zk) ∈A. Since C is compact, a subsequence of (zk) is convergent
to some point ˆz ∈C as k →∞. By the deﬁnition of *Nϵ(A, x) it follows that
⟨x∗, ηy −ˆz⟩−ϵ∥ηy −ˆz∥≤0
∀x∗∈*Nϵ(A, x).
Since this is true for any y ∈B(o, 1), it follows that (13.33) holds with α :=
maxz∈C ∥z∥.
Now let sequences ϵk ↓0, xk →A ¯x, and x∗
k
w∗
−−→o be given such that
x∗
k ∈*Nϵk(A, xk) for all k ∈N. Since C is compact, we have ⟨x∗
k, z⟩→0 as
k →∞uniformly in z ∈C. Therefore, (13.33) implies that ∥x∗
k∥→0 as
k →∞. Hence A is SNC.
⊓⊔
Our aim now is to give a suﬃcient condition for the intersection of SNC sets
to be SNC. This result will later be applied to derive optimality conditions.
To prepare the result, we ﬁrst establish an approximate intersection rule for
F-normal cones that is also remarkable on its own.
Proposition 13.4.3 Assume that E is a Fréchet smooth Banach space, A1
and A2 are closed subsets of E, and ¯x ∈A1 ∩A2. Further let x∗∈NF (A1 ∩
A2, ¯x). Then for any ϵ > 0 there exist λ ≥0, xi ∈Ai ∩B(¯x, ϵ), and x∗
i ∈
NF (Ai, xi) + ϵBE∗, i = 1, 2, such that
λx∗= x∗
1 + x∗
2
and
max{λ, ∥x∗
1∥} = 1.
(13.34)
Proof. Fix ϵ > 0. The deﬁnition of the F-normal cone implies that there is a
neighborhood U of ¯x such that
⟨x∗, x −¯x⟩−ϵ∥x −¯x∥≤0
∀x ∈A1 ∩A2 ∩U.
(13.35)
Equip E × R with the norm ∥(x, α)∥:= ∥x∥+ |α|. Deﬁne closed subsets B1,
B2 of E × R by
B1 := {(x, α) | x ∈A1, α ≥0},
B2 := {(x, α) | x ∈A2, α ≤⟨x∗, x −¯x⟩−ϵ∥x −¯x∥}.
From (13.35) we obtain
B1 ∩(B2 −(o, ρ)) ∩(U × R) = ∅
∀ρ > 0.

13.4 Sequentially Normally Compact Sets
311
Hence (¯x, 0) ∈B1 ∩B2 is a local extremal point of the system (B1, B2). By
the approximate extremal principle of Theorem 13.3.10 we ﬁnd (xi, αi) ∈Bi
and (˜x∗
i , λi) ∈NF (Bi, (xi, αi)), i = 1, 2, such that
max{∥˜x∗
1 + ˜x∗
2∥, |λ1 + λ2|} < ϵ,
(13.36)
1
2 −ϵ < max{∥˜x∗
i ∥, |λi|} < 1
2 + ϵ,
i = 1, 2,
(13.37)
∥xi −¯x∥+ |αi| < ϵ
i = 1, 2.
(13.38)
The deﬁnition of the F-normal cone implies that ˜x∗
1 ∈NF (A1, x1), λ1 ≤0,
and
lim sup
(x,α)→B2(x2,α2)
⟨˜x∗
2, x −x2⟩+ λ2(α −α2)
∥x −x2∥+ |α −α2|
≤0.
(13.39)
The deﬁnition of B2 shows that λ2 ≥0 and
α2 ≤⟨x∗, x2 −¯x⟩−ϵ∥x2 −¯x∥.
(13.40)
Now we distinguish two cases:
Case 1. We assume that the inequality in (13.40) is strict. Then (13.39) implies
that λ2 = 0 and ˜x∗
2 ∈NF (A2, x2). Deﬁne
x∗
1 := ˜x∗
1
and
x∗
2 := −˜x∗
1 = ˜x∗
2 −(˜x∗
1 + ˜x∗
2).
It then follows from (13.36) to (13.38) that the assertion (13.34) holds with
λ = 0.
Case 2. Now we assume that (13.40) holds as an equation. Take any (x, α) ∈
B2 such that
α = ⟨x∗, x −¯x⟩−ϵ∥x −¯x∥,
x ∈A2 \ {x2}.
(13.41)
Substituting this into (13.39), we conclude that for some neighborhood V of
x2 we have
⟨˜x∗
2, x −x2⟩+ λ2(α −α2) ≤ϵ(∥x −x2∥+ |α −α2|)
∀x ∈A2 ∩V ; (13.42)
here, α satisﬁes (13.41) and so
α −α2 = ⟨x∗, x −x2⟩+ ϵ(∥x2 −¯x∥−∥x −¯x∥).
(13.43)
It follows that
|α −α2| ≤(∥x∗∥+ ϵ)∥x −x2∥.
(13.44)
Now we substitute the right-hand side of (13.43) for α −α2 into the left-hand
side of (13.42), and we apply the estimate (13.44) to the right-hand side of
(13.42). In this way, (13.42) passes into
⟨˜x∗
2 + λ2x∗, x −x2⟩≤ϵc∥x −x2∥
∀x ∈A2 ∩V,

312
13 Extremal Principles and More Normals and Subdiﬀerentials
where c := 1 + ∥x∗∥+ λ2 + ϵ. The deﬁnition of ϵ-normals shows that
˜x∗
2 + λ2x∗∈*Nϵc(A2, x2).
Recall that λ2 is nonnegative, and by (13.37) we have λ2 + ϵ < 1 if ϵ is suﬃ-
ciently small. It follows that 1 + ∥x∗∥< c < 2 + ∥x∗∥and so the positive con-
stant c may be chosen depending only on x∗. By virtue of Theorem 13.1.23(a)
there exists z2 ∈A2 ∩B(x2, ϵ) such that
˜x∗
2 + λ2x∗∈NF (A2, z2) + 2ϵc BE∗.
Put η := max{λ2, ∥˜x∗
2∥}. For ϵ < 1
4 we obtain from (13.37) that 1
4 < η < 3
4.
Now deﬁne
λ := λ2/η,
x∗
1 := −˜x∗
2/η,
x∗
2 := (˜x∗
2 + λ2x∗)/η.
Then λ ≥0, max{λ, ∥x∗
1∥} = 1, and λx∗= x∗
1 + x∗
2. By (13.36) we further
have ∥˜x∗
1 + ˜x∗
2∥/η ≤4ϵ. Hence we ﬁnally obtain
x∗
1 = ˜x∗
1/η −(˜x∗
1 + ˜x∗
2)/η ∈NF (A1, x1) + 4ϵ BE∗,
x∗
2 ∈NF (A2, z2) + 8ϵc BE∗.
Recalling that c > 0 depends on x∗only completes the proof.
⊓⊔
In Sect. 13.6 we will describe the M-normal cone of the inverse image of
a multifunction. In this context we shall need SNC properties of sets in a
product space which we now deﬁne.
Deﬁnition 13.4.4 Assume that E and F are Fréchet smooth Banach spaces,
A is a nonempty closed subset of E × F, and (¯x, ¯y) ∈A.
(a) The set A is said to be partially sequentially normally compact (PSNC)
at (¯x, ¯y) with respect to E if for any sequences (xk, yk) →A (¯x, ¯y) and
(x∗
k, y∗
k) ∈NF (A, (xk, yk)), one has
&
x∗
k
w∗
−−→o and ∥y∗
k∥→0 as k →∞

=⇒
∥x∗
k∥→0 as k →∞.
(b) The set A is said to be strongly partially sequentially normally com-
pact (strongly PSNC) at (¯x, ¯y) with respect to E if for any sequences
(xk, yk) →A (¯x, ¯y) and (x∗
k, y∗
k) ∈NF (A, (xk, yk)), one has
&
x∗
k
w∗
−−→o and y∗
k
w∗
−−→o as k →∞

=⇒
∥x∗
k∥→0 as k →∞.
The (strong) PSNC property with respect to F is deﬁned analogously.
It is clear that if the set A is SNC, then it is strongly PSNC and so PSNC.
The strong PSNC property will not be needed until Sect. 13.6; for comparison
with the PSNC property we already introduced it here. We also need the
following concept.

13.4 Sequentially Normally Compact Sets
313
Deﬁnition 13.4.5 Assume that E and F are Fréchet smooth Banach spaces,
A1 and A2 are closed subsets of E × F, and (¯x, ¯y) ∈A1 ∩A2. The system
(A1, A2) is said to satisfy the mixed qualiﬁcation condition at (¯x, ¯y) with
respect to F if for any sequences (xik, yik) →Ai (¯x, ¯y) and (x∗
ik, y∗
ik)
w∗
−−→
(x∗
i , y∗
i ) as k →∞with (x∗
ik, y∗
ik) ∈NF (Ai, (xik, yik)), i = 1, 2, one has
&
x∗
1k +x∗
2k
w∗
−−→o, ∥y∗
1k +y∗
2k∥→0 as k →∞

=⇒
(x∗
1, y∗
1) = (x∗
2, y∗
2) = o.
Remark 13.4.6 It is left as Exercise 13.13.14 to show that the condition
NM(A1, (¯x, ¯y)) ∩

−NM(A2, (¯x, ¯y))

= {(o, o)}
is suﬃcient for the system (A1, A2) to satisfy the mixed qualiﬁcation condition
at (¯x, ¯y) with respect to F.
Theorem 13.4.7 Assume that E and F are Fréchet smooth Banach spaces,
A1 and A2 are closed subsets of E ×F, and (¯x, ¯y) ∈A1 ∩A2, one of A1, A2 is
SNC and the other is PSNC at (¯x, ¯y) with respect to E. Assume further that
(A1, A2) satisﬁes the mixed qualiﬁcation condition at (¯x, ¯y) with respect to F.
Then A1 ∩A2 is PSNC at (¯x, ¯y) with respect to E.
Proof.
(I) Assume that A1 is SNC at (¯x, ¯y) and A2 is PSNC at (¯x, ¯y) with respect
to E. Take any sequences (xk, yk) ∈A1 ∩A2 and (x∗
k, y∗
k) ∈NF (A1 ∩
A2, (xk, yk)) satisfying (xk, yk) →(¯x, ¯y), x∗
k
w∗
−−→o, and ∥y∗
k∥→0 as
k →∞. We have to show that ∥x∗
k∥→0 as k →∞. Observe that it
suﬃces to show that some subsequence of (x∗
k) is norm convergent to
zero. In fact, if this is done and the entire sequence (x∗
k) were not norm
convergent to zero, we could ﬁnd a subsequence (x∗
kν) and some ρ > 0
such that ∥x∗
kν∥≥ρ for any ν ∈N. Applying the above to the sequences
(xkν) and (x∗
kν), we would ﬁnd a subsequence of the latter that is norm
convergent to zero, which contradicts the construction of (x∗
kν).
(II) Take an arbitrary sequence ϵk ↓0 as k →∞. Applying Proposi-
tion 13.4.3 to x∗
k for every k, we obtain sequences (xik, yik) ∈Ai,
(x∗
ik, y∗
ik) ∈NF (Ai, (xik, yik)), where i = 1, 2, and λk ≥0 such that
∥(xik, yik) −(xk, yk)∥≤ϵk
∀k ∈N,
i = 1, 2,
(13.45)
∥(x∗
1k, y∗
1k) + (x∗
2k, y∗
2k) −λk(x∗
k, y∗
k)∥≤2ϵk
∀k ∈N,
(13.46)
1 −ϵk ≤max{λk, ∥x∗
1k∥, ∥y∗
1k∥} ≤1 + ϵk
∀k ∈N.
(13.47)
Since the sequence (x∗
k, y∗
k) is weak∗convergent, it is bounded. Hence
by (13.46) and (13.47) the sequences (x∗
ik), (y∗
ik), i = 1, 2, and (λk) are
also bounded. Since E and F are Asplund spaces, we conclude by The-
orem 4.3.21 that a subsequence of (x∗
ik, y∗
ik) (which we do not relabel) is

314
13 Extremal Principles and More Normals and Subdiﬀerentials
weak∗convergent as k →∞to some (˜x∗
i , ˜y∗
i ), i = 1, 2, and that the corre-
sponding subsequence of λk is convergent to some λ ≥0. From x∗
k
w∗
−−→o,
∥y∗
k∥→0, and (13.46) we obtain
x∗
1k + x∗
2k
w∗
−−→o
and
∥y∗
1k + y∗
2k∥→0
as k →∞.
(13.48)
The mixed qualiﬁcation condition implies that ˜x∗
i = ˜y∗
i = o for i = 1, 2.
Since A1 is SNC, we conclude that ∥x∗
1k∥→0 and ∥y∗
1k∥→0. The latter
together with (13.48) yields ∥y∗
2k∥→0. Moreover, since A2 is PSNC at
(¯x, ¯y) with respect to E, we obtain ∥x∗
2k∥→0. From (13.47) we now see
that λ > 0. Hence (13.46) implies that (x∗
k) is norm convergent to zero
as k →∞.
⊓⊔
Corollary 13.4.8 Assume that A1, . . . , An are closed subsets of the Fréchet
smooth Banach space E, that ¯x ∈∩n
i=1Ai, and that
&
x∗
i ∈NM(Ai, ¯x), i = 1, . . . , n, x∗
1 + · · · + x∗
n = o

=⇒x∗
1 = · · · = x∗
n = o.
(13.49)
If each Ai is SNC at ¯x, then so is A1 ∩· · · ∩An.
Proof. For n = 2 this follows immediately from Theorem 13.4.7 with F := {o}.
In this connection observe that by Remark 13.4.6 the condition (13.49) ensures
that the mixed qualiﬁcation condition is satisﬁed. For n > 2 the assertion
follows by induction.
⊓⊔
Now we turn to the SNC property of sets of the form Φ−1(S). First we
formulate some hypotheses:
(H1) E and F are Fréchet smooth Banach spaces, S is a closed subset of F.
(H2) Φ : E ⇒F is a multifunction, ¯x ∈Φ−1(S).
(H3) The multifunction x →Φ(x) ∩S is inner semicompact at ¯x.
(H4) graph Φ is closed and is SNC at (¯x, ¯y) for every ¯y ∈Φ(¯x) ∩S.
(H5) NM(S, ¯y) ∩kerD∗
MΦ(¯x, ¯y) = {o} for every ¯y ∈Φ(¯x) ∩S.
Theorem 13.4.9 If the hypotheses (H1)–(H5) are satisﬁed, then Φ−1(S) is
SNC at ¯x.
Proof.
(I) Consider sequences xk →¯x and x∗
k
w∗
−−→o, where x∗
k ∈NF (Φ−1(S), xk)
for any k ∈N. We have to show that ∥x∗
k∥→0 as k →∞. By (H3) and
(H4) we ﬁnd a sequence yk ∈Φ(xk) ∩S that contains a subsequence,
again denoted (yk), converging to some ¯y ∈Φ(xk) ∩S. Deﬁning
B1 := graph Φ
and
B2 := E × S,
we obtain that (x∗
k, o) ∈NF (B1 ∩B2, (xk, yk)).

13.5 Calculus for Mordukhovich Subdiﬀerentials
315
(II) We want to apply Theorem 13.4.7. Therefore, we check the SNC prop-
erties of the sets B1 and B2. First notice that
NF (B2, (xk, yk)) = NF (E, xk) × NF (S, yk) = {o} × NF (S, yk).
(13.50)
Hence B2 is always PSNC at (¯x, ¯y) with respect to E. Moreover, by (H4)
the set B1 is SNC at (¯x, ¯y) or B1 is PSNC at (¯x, ¯y) with respect to F.
Thus, the SNC properties required in Theorem 13.6.4 are satisﬁed.
(III) It is left as Exercise 13.13.15 to show that the hypothesis (H5) implies
the mixed qualiﬁcation condition with respect to F.
(IV) By Theorem 13.4.7 the set B1 ∩B2 is PSNC at (¯x, ¯y) with respect to E.
Hence it follows that (x∗
k) is norm convergent to zero.
⊓⊔
13.5 Calculus for Mordukhovich Subdiﬀerentials
We start with a special case of a sum rule for M-subdiﬀerentials.
Proposition 13.5.1 Assume that f : E →R is proper and l.s.c., ¯x ∈dom f,
and g : E →R.
(a) If g is strictly F-diﬀerentiable at ¯x, then
∂M(f + g)(¯x) = ∂Mf(¯x) + {g′(¯x)}.
(13.51)
(b) If g is locally L-continuous around ¯x, then ∂∞
Mg(¯x) = {o} and
∂∞
M(f + g)(¯x) = ∂∞
Mf(¯x).
(13.52)
Proof.
(a) (I) First we show that
∂M(f + g)(¯x) ⊆∂Mf(¯x) + {g′(¯x)}.
(13.53)
Since g is strictly F-diﬀerentiable, for any sequence ηi ↓0 as i →∞
there exists a sequence δi ↓0 such that
|g(z) −g(x) −⟨g′(¯x), z −x⟩| ≤ηi∥z −x∥
∀x, z ∈B(¯x, δi)
∀i ∈N.
(13.54)
Now let x∗∈∂M(f + g)(¯x) be given. By Theorem 13.1.17 there are
sequences xk →f+g ¯x, x∗
k
w∗
−−→x∗, and ϵk ↓0 as k →∞satisfying
x∗
k ∈*∂ϵk(f + g)(xk)
∀k ∈N.
(13.55)
Let (ki) be a strictly increasing sequence of positive integers such that
∥xki −¯x∥≤δi/2 for any i ∈N. In view of (13.55) we ﬁnd ˆδi ∈(0, δi/2)
such that for all x ∈B(xki, ˆδi) and any i ∈N we have
f(x)−f(xki)+g(x)−g(xki)−⟨x∗
ki, x−xki⟩≥−2ϵki∥x−xki∥. (13.56)

316
13 Extremal Principles and More Normals and Subdiﬀerentials
Since x ∈B(xki, ˆδi) implies x ∈B(¯x, δi), it follows from (13.54) and
(13.56) that for all x ∈B(xki, ˆδi) and any i ∈N we obtain
g(x) −g(xki) −⟨x∗
ki −g′(¯x), x −xki⟩≥−(2ϵki + ηi)∥x −xki∥.
We conclude that
x∗
ki −g′(¯x) ∈*∂˜ϵif(xki),
where ˜ϵi := 2ϵki + ηi
∀i ∈N.
(13.57)
Since f(xki) + g(xki) →f(¯x) + g(¯x) and g is continuous at ¯x, we
see that f(xki) →f(¯x) as i →∞. Therefore, by Theorem 13.1.17 it
follows from (13.57) that x∗−g′(¯x) ∈∂Mf(¯x). This veriﬁes (13.53).
(II) The opposite inclusion to (13.53) is obtained from the latter inclusion
in the following way:
∂Mf(¯x) = ∂M[(f + g) + (−g)](¯x) ⊆∂M(f + g)(¯x) −g′(¯x).
(b) Now we prove
∂∞
M(f + g)(¯x) ⊆∂∞
Mf(¯x).
(13.58)
Once this is done, the opposite inclusion follows as in step (II) above.
Finally, the relation ∂∞
Mg(¯x) = {o} is the special case f = o of (13.52)
(and is already contained in Corollary 13.2.5).
Let x∗∈∂∞
M(f + g)(¯x) be given. By deﬁnition of the singular M-
subdiﬀerential there exist sequences xk →¯x, αk →(f + g)(¯x), ϵk ↓0,
ηk ↓0, and γk →0 such that αk ≥f(xk) + g(xk) and
⟨x∗
k, x −xk⟩+ γk(α −αk) ≤2ϵk(∥x −xk∥+ |α −αk|)
(13.59)
for all (x, α) ∈epi (f + g) satisfying x ∈B(xk, ηk) and |α −αk| ≤ηk for
any k ∈N. Let λ > 0 denote a Lipschitz constant of g around ¯x and put
˜ηk :=
ηk
2(λ + 1),
˜αk := αk −g(xk).
It follows that ˜αk ≥f(xk) for any k and ˜αk →f(¯x) as k →∞. Notice
that for any k and any (x, ˜α) satisfying
(x, ˜α) ∈epi f,
x ∈B(xk, ˜ηk)
and
|˜α −˜αk| ≤˜ηk,
(13.60)
we have
(x, ˜α + g(x)) ∈epi (f + g)
and
|(˜α + g(x)) −αk| ≤ηk.
This and (13.59) give
⟨x∗
k, x −xk⟩+ αk(˜α −˜αk)
≤˜ϵk(∥x −xk∥+ |˜α −˜αk|), where ˜ϵk := 2ϵk(λ + 1) + |γk|λ
for any (x, ˜α) satisfying (13.60). It follows that
(x∗
k, γk) ∈*N˜ϵk(epi f, (xk, ˜αk))
∀k ∈N.
This implies x∗∈∂∞
Mf(¯x) and completes the proof.
⊓⊔

13.5 Calculus for Mordukhovich Subdiﬀerentials
317
Next we derive a useful property of M-subdiﬀerentials of locally L-
continuous functionals.
Proposition 13.5.2 Let E be an Asplund space and f : E →R be a proper
l.s.c. functional. Then ∂Mf(¯x) ̸= ∅for every ¯x ∈dom f where f is locally
L-continuous.
Proof. The assumptions on f imply that the set A := epi f is closed and epi-
Lipschitzian around (¯x, f(¯x)). By Proposition 13.4.2, epi f is also SNC. Hence
Corollary 13.3.15 implies that NM

epi f, (¯x, f(¯x)

) ̸= {(o, 0)}. By Proposi-
tion 13.5.1 we know that ∂∞
Mf(¯x) = {o}. Hence Lemma 13.1.11 completes the
proof.
⊓⊔
Applying the approximate extremal principle, we now establish an ex-
act sum rule for M-subdiﬀerentials in a Fréchet smooth Banach space. In
this context, the following property will compensate for the absence of ﬁnite
dimensionality.
Deﬁnition 13.5.3 The proper functional f : E →R is said to be sequentially
normally epi-compact (SNEC) at ¯x ∈dom f if epi f is SNC at (¯x, f(¯x)).
Remark 13.5.4 The functional f is SNEC at ¯x if epi f is compactly epi-
Lipschitzian at (¯x, f(¯x)) (Proposition 13.4.2) and so, in particular, if epi f is
epi-Lipschitzian at (¯x, f(¯x)) (Exercise 13.13.13) or E is ﬁnite dimensional.
We will also make use of the following qualiﬁcation condition:
&
x∗
i ∈∂∞
Mfi(¯x), i = 1, . . . , n and x∗
1 + · · · + x∗
n = o

=⇒x∗
1 = · · · = x∗
n = o.
(13.61)
Theorem 13.5.5 (Sum Rule for M-Subdiﬀerentials) Let E be a Fréchet
smooth Banach space, let f1, . . . , fn : E →R be l.s.c., and let ¯x ∈∩n
i=1dom fi.
Assume that all but one of fi are SNEC at ¯x ∈∩n
i=1dom fi and that condi-
tion (13.61) is satisﬁed. Then
∂M(f1 + · · · + fn)(¯x) ⊆∂Mf1(¯x) + · · · + ∂Mfn(¯x).
(13.62)
If, in addition, f1, . . . , fn are all lower regular at ¯x, then so is f1 + · · · + fn
and (13.62) holds with equality.
Proof. We verify the assertions for the case that n = 2, leaving the induction
proof in the case n > 2 as Exercise 13.13.18. Thus let f1 and f2 be given and
assume that f1 is SNEC at ¯x. Take any x∗∈∂M(f1 +f2)(¯x). By the deﬁnition
of the M-subdiﬀerential there exist sequences xk →¯x and x∗
k
w∗
−−→x∗such that
fi(xk) →fi(¯x) as k →∞, where i = 1, 2, and x∗
k ∈∂F (f1 + f2)(xk) for all
k ∈N. Let (ϵk) be a sequence of positive real numbers such that ϵk ↓0 as

318
13 Extremal Principles and More Normals and Subdiﬀerentials
k →∞. The deﬁnition of the F-subdiﬀerential implies that for any k ∈N
there exists a neighborhood Uk of xk such that
(f1+f2)(x)−(f1+f2)(xk)−⟨x∗
k, x−xk⟩+ϵk∥x−xk∥≥0
∀x ∈Uk. (13.63)
Since f1 and f2 are l.s.c., the sets
A1k := {(x, µ) ∈E × R | f1(x) −f1(xk) ≤µ}
and
A2k := {(x, µ) ∈E × R | f2(x) −f2(xk) −⟨x∗
k, x −xk⟩+ ϵk∥x −xk∥≤−µ}
are closed. Applying (13.63) we obtain for any k,
(xk, 0) ∈A1k ∩A2k
and
A1k ∩(A2k −(0, α)) ∩(Uk × R) = ∅
∀α > 0.
Hence (A1k, A2k, (xk, 0)) is an extremal system and so by Theorem 13.3.10 the
extremal principle holds for this system. It follows that for i = 1, 2 and any
k ∈N there exist (xi,k, µi,k) ∈(epi fi) ∩B(xk, fi(xk), ϵk), (˜x∗
k, αk) ∈E∗× R,
and (˜y∗
k, βk) ∈E∗× R satisfying
1/2 −ϵk ≤∥˜x∗
k∥+ |αk| ≤1/2 + ϵk,
(13.64)
1/2 −ϵk ≤∥˜y∗
k∥+ |βk| ≤1/2 + ϵk,
(13.65)
∥(˜x∗
k, αk) + (˜y∗
k, βk)∥≤ϵk,
(13.66)
(˜x∗
k, αk) ∈NF

A1k, (x1,k, µ1,k −f1(xk))

,
(13.67)
(˜y∗
k, βk) ∈NF

A2k, (x2,k, γk)

,
(13.68)
where γk := −µ2,k + f2(xk) + ⟨x∗
k, x2,k −xk⟩−ϵk∥x2,k −xk∥. For i = 1, 2 the
sequence (xi,k, µi,k) converges in epi fi to (¯x, fi(¯x)) as k →∞. Since the se-
quences (˜x∗
k, αk) and (˜y∗
k, βk) are bounded and E is an Asplund space (Propo-
sition 4.7.15), the sequences contain subsequences, again denoted (˜x∗
k, αk) and
(˜y∗
k, βk), that are weak∗convergent to some (˜x∗, α) and (˜y∗, β), respectively
(Theorem 4.3.21). In view of (13.67) and the deﬁnition of the Mordukhovich
normal cone we conclude that
(˜x∗, α) ∈NM

epi f1, (¯x, f1(¯x))

.
(13.69)
Moreover, by (13.68) and the deﬁnition of the Fréchet normal cone we obtain
lim sup
(x,µ) →
epif2
(x2,k, µ2,k)
⟨˜y∗
k, x −x2,k⟩−βk

µ −µ2,k −⟨x∗
k, x −x2,k⟩+ ϵk∥x −x2,k∥
∥x −x2,k∥+ |µ −µ2,k| + |⟨x∗
k, x −x2,k⟩| + ϵk∥x −x2,k∥
≤0,

13.5 Calculus for Mordukhovich Subdiﬀerentials
319
which implies
(βkx∗
k + ˜y∗
k, −βk) ∈*Nηk

epi f2, (x2,k, µ2,k)

,
where ηk := ϵk(1+∥x∗
k∥+ϵk +|βk|) for each k. Letting k →∞, we deduce that
(βx∗+ ˜y∗, −β) ∈NM

epi f2, (¯x, f2(¯x))

, where by (13.66) we have ˜y∗= −˜x∗
and β = −α. Thus,
(−αx∗−˜x∗, α) ∈NM

epi f2, (¯x, f2(¯x))

.
(13.70)
Now we show that α ̸= 0. Suppose we have α = 0, then (13.69) and (13.70)
give
(˜x∗, 0) ∈NM

epi f1, (¯x, f1(¯x))

and (−˜x∗, 0) ∈NM

epi f2, (¯x, f2(¯x))

.
Hence the deﬁnition of the singular subdiﬀerential and the condition (13.61)
imply that x∗= o, which entails that (˜x∗
k, αk)
w∗
−−→(o, 0) as k →∞. Notice
that by (13.67) we have (˜x∗
k, αk) ∈NF (epi f1, (x1,k, µ1,k)) and that f1 is
SNEC at ¯x. Therefore the sequence ((˜x∗
k, αk)) is norm convergent to (o, 0) as
k →∞. But this contradicts the inequalities (13.64) and (13.65). Hence we
must conclude that α ̸= 0 and so α < 0 because αk ≤0 for any k. Now (13.69)
and (13.70) pass into
(˜x∗/|α|, −1) ∈NM

epi f1, (¯x, f1(¯x))
and (x∗−˜x∗/|α|, −1) ∈NM

epi f2, (¯x, f2(¯x))
.
Deﬁning x∗
1 :=
˜x∗/|α|, x∗
2 := x∗−x∗
1, and recalling that ∂Mfi(¯x) =
NM

epi fi, (¯x, fi(¯x))

, we obtain x∗∈∂Mf1(¯x) + ∂Mf2(¯x), and the proof
of (13.62) is complete.
To verify the statement on equality, notice that we always have
∂F f1(¯x) + · · · + ∂F fn(¯x) ⊆∂F (f1 + · · · + fn)(¯x).
If each fi is lower regular at ¯x, then it follows from the latter inclusion and
(13.62) that f1 + · · · + fn is also lower regular at ¯x and (13.62) holds with
equality.
⊓⊔
If E is ﬁnite dimensional, any function f : E →R is SNEC at any
¯x ∈dom f. Therefore the next result is an immediate consequence of The-
orem 13.5.5.
Corollary 13.5.6 Let E be a ﬁnite-dimensional Banach space, let f1, . . . , fn :
E →R be l.s.c., and let ¯x ∈∩n
i=1dom fi. Assume that condition (13.61) is
satisﬁed. Then (13.62) holds. If, in addition, f1, . . . , fn are all lower regular
at ¯x, then so is f1 + · · · + fn and (13.62) holds with equality.
By examples similar to Example 13.2.12 one can show that in an inﬁnite-
dimensional Banach space the SNEC property is not dispensable.

320
13 Extremal Principles and More Normals and Subdiﬀerentials
13.6 Calculus for Mordukhovich Normals
The sum rule for M-subdiﬀerentials implies an intersection rule for M-normal
cones that will be crucial for deriving multiplier rules. We need the following
qualiﬁcation condition:
&
x∗
i ∈NM(Ai, ¯x),
i = 1, . . . , n
and
x∗
1 + · · · + x∗
n = o

=⇒
x∗
1 = · · · = x∗
n = o.
(13.71)
Theorem 13.6.1 (Intersection Rule 1 for M-normal Cones) Let E be
a Fréchet smooth Banach space, let A1, . . . , An be nonempty closed subsets of
E, and let ¯x ∈∩n
i=1Ai. Assume that all but one of Ai are SNC at ¯x and that
condition (13.71) is satisﬁed. Then
NM(A1 ∩· · · ∩An, ¯x) ⊆NM(A1, ¯x) + · · · + NM(An, ¯x).
(13.72)
If, in addition, A1, . . . , An are all normally regular at ¯x, then so is A1∩· · ·∩An
and (13.72) holds with equality.
Proof. Apply Theorem 13.5.5 to fi := δAi and use the statement of Exer-
cise 13.13.17.
⊓⊔
Next we will establish an intersection rule for M-normal cones in a product
space Z := E ×F that we equip with the norm ∥(x, y)∥:= ∥x∥+∥y∥, (x, y) ∈
E × F. Recall that if E and F are Fréchet smooth, so is E × F. We will make
use of the following concept.
Deﬁnition 13.6.2 Let A1 and A2 be closed subsets of the Fréchet smooth
Banach space Z and let ¯z ∈A1 ∩A2. The system (A1, A2) is said to satisfy
the limiting qualiﬁcation condition at ¯z if for any sequences zik →Ai ¯z, z∗
ik ∈
NF (Ai, zik), and z∗
ik
w∗
−−→z∗
i as k →∞, i = 1, 2, one has
&
∥z∗
1k + z∗
2k∥→0 as k →∞

=⇒
z∗
1 = z∗
2 = o.
Remark 13.6.3 Observe that the limiting qualiﬁcation condition is a special
case of the mixed qualiﬁcation condition with respect to E when F := {o}.
Hence by Remark 13.4.6 the condition
NM(A1, ¯z) ∩

−NM(A2, ¯z)

= {o}
(13.73)
is suﬃcient for the system (A1, A2) to satisfy the limiting qualiﬁcation condi-
tion.
Theorem 13.6.4 (Intersection Rule 2 for M-normal Cones) Let
E
and F be Fréchet smooth Banach spaces, A1 and A2 be closed subsets of
E × F, and (¯x, ¯y) ∈A1 ∩A2. Assume that (A1, A2) satisﬁes the limiting
qualiﬁcation condition, A1 is PSNC at (¯x, ¯y) with respect to E, and A2 is
strongly PSNC at (¯x, ¯y) with respect to F. Then one has
NM(A1 ∩A2, (¯x, ¯y)) ⊆NM(A1, (¯x, ¯y)) + NM(A2, (¯x, ¯y)).
(13.74)

13.6 Calculus for Mordukhovich Normals
321
Proof.
(I) Take any (x∗, y∗) ∈NM(A1 ∩A2, (¯x, ¯y)). By Theorem 13.1.23 there exist
sequences (xk, yk) ∈A1∩A2 and (x∗
k, y∗
k) ∈NF (A1∩A2, (xk, yk)) satisfying
(xk, yk) →(¯x, ¯y)
and
(x∗
k, y∗
k)
w∗
−−→(x∗, y∗).
Take any sequence ϵk ↓0 as k →∞. By applying the approximate in-
tersection rule of Proposition 13.4.3 for every k, we ﬁnd (uik, vik) ∈Ai,
(u∗
ik, v∗
ik) ∈NF (Ai, (uik, vik)), where i = 1, 2, and λk ≥0 such that
∥(uik, vik) −(xk, yk)∥≤ϵk,
i = 1, 2,
(13.75)
∥(u∗
1k, v∗
1k) + (u∗
2k, v∗
2k) −λk(x∗
k, y∗
k)∥≤2ϵk,
(13.76)
1 −ϵk ≤max{λk, ∥(u∗
1k, v∗
1k)∥} ≤1 + ϵk.
(13.77)
The sequence (xk, yk) is weak∗convergent and therefore bounded. By
(13.76) and (13.77), for i = 1, 2 the sequence (u∗
ik, v∗
ik) is also bounded
and so by Theorem 4.3.21 some subsequence (which we do not relabel)
is weak∗convergent to (u∗
i , v∗
i ). We further have λk →λ ≥0. From
(13.76) and (13.77) we obtain for k →∞that (u∗
i , v∗
i ) ∈NM(Ai, (¯x, ¯y)),
i = 1, 2, and λ(x∗, y∗) = (u∗
1, v∗
1) + (u∗
2, v∗
2). It remains to show that
λ > 0.
(II) Suppose that λ = 0. Then (13.76) shows that ∥(u∗
1k, v∗
1k)+(u∗
1k, v∗
1k)∥→0
as k →∞. Since (A1, A2) satisﬁes the limiting qualiﬁcation condition, it
follows that (u∗
i , v∗
i ) = o for i = 1, 2. Hence
(u∗
ik, v∗
ik)
w∗
−−→(o, o)
as k →∞,
i = 1, 2.
(13.78)
The strong PSNC property of A2 implies that ∥v∗
2k∥→0 as k →∞and
(13.76) shows that ∥v∗
1k∥→0, too. This, (13.78), and the PSNC property
of A1 now yield ∥u∗
1k∥→0 and so ∥(u∗
1k, v∗
1k)∥→0 as k →∞, which
contradicts the estimate (13.77).
⊓⊔
Applying Theorem 13.6.4 with F := {o} immediately gives the following
result.
Corollary 13.6.5 Let E be a Fréchet smooth Banach space, A1 and A2 be
closed subsets of E, and ¯x ∈A1 ∩A2. Assume that (A1, A2) satisﬁes the
limiting qualiﬁcation condition at ¯x and that A1 or A2 is SNC at ¯x. Then
(13.74) holds.
Our aim now is to describe the M-normal cone to a set of the form Φ−1(S),
where Φ : E ⇒F is a multifunction and S ⊆F. We make the following
assumptions:
(A1) The multifunction x →Φ(x) ∩S is inner semicompact at ¯x.

322
13 Extremal Principles and More Normals and Subdiﬀerentials
(A2) For every ¯y ∈Φ(¯x)∩S, the set S is SNC at ¯y or the set graph Φ is PSNC
at (¯x, ¯y) with respect to F.
(A3) For every ¯y ∈Φ(¯x) ∩S one has NM(S, ¯y) ∩ker D∗
MΦ(¯x, ¯y) = {o}.
Theorem 13.6.6 Let E and F be Fréchet smooth Banach spaces, Φ : E ⇒F
be a multifunction with closed graph, and S be a closed subset of F. Let the
assumptions (A1)–(A3) be satisﬁed. Then one has
NM(Φ−1(S), ¯x) ⊆

D∗
M Φ(¯x, ¯y)(y∗)
 y∗∈NM(S, ¯y), ¯y ∈Φ(¯x) ∩S

.
(13.79)
Proof.
(I) Take an arbitrary x∗∈NM(Φ−1(S), ¯x). Then there are sequences xk →¯x
and x∗
k ∈NF (Φ−1(S), xk) such that xk →¯x and x∗
k
w∗
−−→x∗. By (A1) we
ﬁnd a subsequence of yk ∈Φ(xk) ∩S that converges to some ¯y ∈F. The
closedness assumptions ensure that ¯y ∈Φ(¯x) ∩S. Deﬁne B1 := graph Φ
and B2 := E × S, which are closed subsets of the Fréchet smooth Banach
space E × F. It is clear that (xk, yk) ∈B1 ∩B2 for any k and it is easy
to see that (x∗
k, o) ∈NF (B1 ∩B2, (xk, yk)) for any k. Hence (x∗, o) ∈
NM(B1 ∩B2, (¯x, ¯y)).
(II) As in the proof of Theorem 13.4.9 it follows that B1 and B2 have the SNC
properties required in Theorem 13.6.4. We show that condition (13.73)
is satisﬁed for the system (B1, B2), which by Remark 13.6.3 implies the
limiting qualiﬁcation condition for this system. Take any
(u∗, v∗) ∈NM(B1, (¯x, ¯y)) ∩

−NM(B2, (¯x, ¯y))

.
By deﬁnition of the coderivative we immediately obtain u∗∈D∗
MΦ(¯x, ¯y)
(−v∗). In view of (13.50) we further have (−u∗, −v∗) ∈{o} × NM(S, ¯y).
It follows that u∗= o and so
−v∗∈NM(S, ¯y) ∩kerD∗
MΦ(¯x, ¯y).
Assumption (A3) now implies that v∗= o. Hence (13.73) is satisﬁed.
Therefore we may apply Theorem 13.6.4, which yields the existence of
(x∗
1, y∗
1) ∈NM(graph Φ, (¯x, ¯y)) and y∗
2 ∈NM(S, ¯y) satisfying (x∗, o) =
(x∗
1, y∗
1) + (o, y∗
2) and so
(x∗, −y∗
2) = (x∗
1, y∗
1) ∈NM(graph Φ, (¯x, ¯y)).
Thus x∗∈D∗
MΦ(¯x, ¯y)(y∗
2), and it follows that x∗is an element of the
right-hand side of (13.79).
⊓⊔

13.7 Optimality Conditions
323
13.7 Optimality Conditions
Convention. Throughout this section, we assume that E and F are Fréchet
smooth Banach spaces and f : E →R is a proper l.s.c. functional.
We consider the problem
minimize f(x) subject to x ∈A,
where A is a closed subset of E. From the discussion in Sect. 12.1 we know
that if ¯x is a local minimizer of f on A, then it follows that o ∈∂F (f +δA)(¯x).
This implies
o ∈∂M(f + δA)(¯x).
(13.80)
We now formulate hypotheses (H1) and a qualiﬁcation condition (Q1)
ensuring that we may apply the exact sum rule of Theorem 13.5.5:
(H1) A is a closed subset of E, ¯x ∈A, A is SNC at ¯x or f is SNEC at ¯x.
(Q1) ∂∞
Mf(¯x) ∩

−NM(A, ¯x)

= {o}.
Proposition 13.7.1 Assume that (H1) and (Q1) are satisﬁed. If ¯x is a local
minimizer of f on A, then
o ∈∂Mf(¯x) + NM(A, ¯x).
(13.81)
Proof. Since epi δA = A × [0, +∞), the functional δA is SNEC if (and only if)
the set A is SNC. Moreover, we have ∂∞
MδA(¯x) = NM(A, ¯x) (Remark 13.1.10).
Therefore, (Q1) implies that the condition (13.61) is satisﬁed for f and δA.
Applying Theorem 13.5.5 to (13.80) yields the assertion.
⊓⊔
From Proposition 13.7.1 we can deduce further optimality conditions. First
we formulate the assumptions:
(H2) For i = 1, . . . , r the set Ai ⊆E is closed and SNC at ¯x ∈∩r
i=1Ai.
(Q2)
&
x∗∈∂∞
Mf(¯x),
x∗
i ∈NM(Ai, ¯x),
x∗+ x∗
1 + · · · + x∗
r = o

=⇒x∗= x∗
1 = · · · = x∗
r = o.
Proposition 13.7.2 Let the hypotheses (H2) and the qualiﬁcation condition
(Q2) be satisﬁed. If ¯x is a local minimizer of f on ∩r
i=1Ai, then one has
o ∈∂Mf(¯x) + NM(A1, ¯x) + · · · + NM(Ar, ¯x).
(13.82)
Proof. We verify the assertion for r = 2; it then follows for r ≥2 by induction.
We want to apply Proposition 13.7.1 to A := A1∩A2. From (Q2) with x∗:= o
we obtain
NM(A1, ¯x) ∩

−N(A2, ¯x)

= {o}.
(13.83)

324
13 Extremal Principles and More Normals and Subdiﬀerentials
This and (H2) imply by Corollary 13.4.8 that A1 ∩A2 is SNC at ¯x. By The-
orem 13.6.4 and Remark 13.6.3, the condition (13.83) also implies that
NM(A1 ∩A2, ¯x) ⊆NM(A1, ¯x) + NM(A2, ¯x).
(13.84)
Now we convince ourselves that condition (Q1) holds. Take any x∗∈∂∞
Mf(¯x)
such that −x∗∈NM(A1 ∩A2, ¯x). By (13.84) there exist x∗
i ∈NM(Ai, ¯x),
i = 1, 2, such that −x∗= x∗
1 + x∗
2. Hence x∗= o by (Q2). Refering to
Proposition 13.7.1 and (13.84) completes the proof.
⊓⊔
If f is locally L-continuous around ¯x, then by Proposition 13.5.1 the con-
dition (Q2) reduces to
(Q2∗)
&
x∗
i ∈NM(Ai, ¯x),
x∗
1 + · · · + x∗
r = o

=⇒
x∗
1 = · · · = x∗
r = o,
which is a pure constraint qualiﬁcation. We show that (Q2∗) is implied by a
classical constraint qualiﬁcation. Let the constraint sets be given as
Ai := {x ∈E | fi(x) ≤0},
i = 1, . . . , r,
where for i = 1, . . . , r the functional fi : E →R is strictly F-diﬀerentiable
at ¯x ∈∩r
i=1Ai. Assume the following variant of the Mangasarian–Fromowitz
constraint qualiﬁcation:
f ′
1(¯x), . . . , f ′
r(¯x)
are positively linearly independent.
(13.85)
By Theorem 11.6.1 we have
NM(Ai, ¯x) = NCAi, ¯x) = {λf ′
i(x) | λ ≥0}.
Suppose now that x∗
i ∈NM(Ai, ¯x) for i = 1, . . . , r and x∗
1 +· · ·+x∗
r = o. Then
there exist λi ≥0 such that x∗
i = λif ′
i(¯x) for i = 1, . . . , r. Condition (13.85)
thus implies that for any i we have λi = 0 and so x∗
i = o.
Finally we consider the problem
minimize f(x) subject to x ∈Φ−1(S) ∩A.
In this connection we make the following assumptions:
(H3) Φ : E ⇒F is a multifunction with closed graph, A ⊆E and S ⊆F
are closed.
x →Φ(x) ∩S is inner semicompact at ¯x ∈Φ−1(S).
A is SNC at ¯x and graph Φ is SNC at (¯x, ¯y) for every ¯y ∈Φ(¯x) ∩S.
(Q3a) NM(S, ¯y) ∩kerD∗
MΦ(¯x, ¯y) = {o} for every ¯y ∈Φ(¯x) ∩S.
(Q3b)
#
x∗∈∂∞
Mf(¯x),
x∗
1 ∈
D∗
MΦ(¯x, ¯y)(y∗)
 ¯y ∈Φ(¯x) ∩S, y∗∈
NM(S, ¯y)

, x∗
2 ∈NM(A, ¯x),
x∗+ x∗
1 + x∗
2 = o
$
=⇒x∗= x∗
1 = x∗
2 = o.

13.7 Optimality Conditions
325
Theorem 13.7.3 Let the hypotheses (H3) and the qualiﬁcation conditions
(Q3a) and (Q3b) be satisﬁed. If ¯x is a local minimizer of f on Φ−1(S) ∩A,
then
o ∈∂Mf(¯x) +

D∗
MΦ(¯x, ¯y)(y∗)
 ¯y ∈Φ(¯x) ∩S, y∗∈NM(S, ¯y)

+ NM(A, ¯x).
Proof. Deﬁne A1 := Φ−1(S) and A2 := A. By Theorem 13.6.6 we have
NM(A1, ¯x) ⊆

D∗
MΦ(¯x, ¯y)(y∗)
 ¯y ∈Φ(¯x) ∩S, y∗∈NM(S, ¯y)

.
(13.86)
Moreover, A is SNC at ¯x by hypothesis and Φ−1(S) is SNC at (¯x, ¯y) due
to Theorem 13.4.9. Finally, the qualiﬁcation condition (Q3b) together with
(13.86) ensures by Corollary 13.4.8 that Φ−1(S) ∩A is SNC. Hence the asser-
tion follows from Proposition 13.7.2.
⊓⊔
Notice that (Q3a) depends on the constraints only. If f is locally L-
continuous around ¯x and Φ : E →F is strictly F-diﬀerentiable at ¯x, then
by Propositions 13.2.3 and 13.5.1 the qualiﬁcation condition (Q3b) reduces to

−NM(A, ¯x)

∩Φ′(¯x)∗
NM(S, Φ(¯x))

= {o},
(13.87)
which is now also a constraint qualiﬁcation; compare (Q2∗). The optimality
condition of Theorem 13.7.3 in this case reads
o ∈∂Mf(¯x) + Φ′(¯x)∗
NM(S, Φ(¯x))

+ NM(A, ¯x).
In connection with the hypotheses (H3) recall that in ﬁnite-dimensional spaces
any nonempty subset is an SNC set.
Theorem 13.7.3 is a very general result from which various speciﬁc opti-
mality conditions can be derived. Assume, for instance, that the constraints
are functional inequalities and equations of the following form (compare, for
instance, problem (P5) in Sect. 12.5):
fi(x) ≤0,
i = 1, . . . , r,
fi(x) = 0,
i = r + 1, . . . , r + s,
x ∈A,
(13.88)
where fi : E →R for i = 1, . . . , r + s. We deﬁne Φ : E →Rr+s by Φ :=
(f1, . . . , fr+s) and put
S :=

(α1, . . . , αr+s) ∈Rr+s | αi ≤0 for i = 1, . . . , r
and αi = 0 for i = r + 1, . . . , r + s

.
Then (13.88) is of the form x ∈Φ−1(S) ∩A and so Theorem 13.7.3 can be
applied. For exploiting D∗
MΦ(¯x) we may write
Φ(x) = (f1(x), 0, . . . , 0) + · · · + (0, . . . , 0, fr+s(x)),
x ∈E,
and apply one or the other coderivative sum rule.

326
13 Extremal Principles and More Normals and Subdiﬀerentials
So far we considered optimality conditions of the Karush–Kuhn–Tucker
type. It is not diﬃcult using, for instance, Theorem 13.7.3 to derive optimality
conditions of the John type. We shall not pursue this way. Rather we will
demonstrate how to obtain optimality conditions of the John type by a direct
application of the exact extremal principle. We consider the problem
minimize f(x) subject to the constraints (13.88).
In addition to the convention at the beginning of this section, we make the
following hypotheses:
(H4) The functions f1, . . . , fr+s are continuous.
All but one of the sets epi f, epi fi (i = 1, . . . , r), graph fi (i = r +
1, . . . , r + s), and A are SNC at (¯x, f(¯x)), (¯x, 0), and ¯x, respectively.
Theorem 13.7.4 Let the assumptions (H4) be satisﬁed. Assume that ¯x is a
local minimizer of f subject to the constraints (13.88).
(a) There exist
(x∗, −λ) ∈NM

epi f, ((¯x, f(¯x))

,
y∗∈NM(A, ¯x),
(x∗
i , −λi) ∈NM

epi fi, ((¯x, 0)

,
i = 1, . . . , r,
(x∗
i , −λi) ∈NM

graph fi, ((¯x, 0)

,
i = r + 1, . . . , r + s
satisfying
x∗+ x∗
i + · · · + x∗
r+s + y∗= o,
∥(x∗, λ)∥+ ∥(x∗
1, λ1)∥+ · · · + ∥(x∗
r+s, λr+s)∥+ ∥y∗∥= 1,
λifi(¯x) = 0,
i = 1, . . . , r.
(13.89)
(b) Assume, in addition, that the functions f, f1, . . . , fr+s are locally L-
continuous around ¯x. Then there exist nonnegative real numbers λ,
λ1, . . . , λr+s such that λifi(¯x) = 0 for i = 1, . . . , r and
o ∈λ∂Mf(¯x) +
r+s
	
i=r+1
λi

∂Mfi(¯x) ∪∂M(−fi)(¯x)

+ NM(A, ¯x).
Proof.
(a) Deﬁne the following subsets of E × Rr+s+1:
B := {(x, α, α1, . . . , αr+s) | α ≥f(x)},
Bi := {(x, α, α1, . . . , αr+s) | αi ≥fi(x)},
i = 1, . . . , r,
Bi := {(x, α, α1, . . . , αr+s) | αi = fi(x)},
i = r + 1, . . . , r + s,
Br+s+1 := A × {o}.

13.8 The Mordukhovich Subdiﬀerential of Marginal Functions
327
Without loss of generality we may assume that f(¯x) = 0. Then (¯x, o) ∈
E × Rr+s+1 is a local extremal point of the system of closed sets B,
B1, . . . , Br+s+1. Therefore the hypotheses (H4) ensure that by Theo-
rem 13.3.14 the exact extremal principle holds for the above system, which
immediately yields the assertion except for the equations λifi(¯x) = 0,
i = 1, . . . , r. Assume we have fi(¯x) < 0 for some i ∈{1, . . . , r}. Then by
continuity, it follows that fi(x) < 0 for all x in a neighborhood of ¯x. Hence
(¯x, o) is an interior point of epi fi. It follows that NM

epi fi, (¯x, o))

= {o}
and so λi = 0.
(b) By the deﬁnition of the M-subdiﬀerential and by Lemma 13.1.8 we have
(x∗, −λ) ∈NM

epi f, (¯x, f(¯x))

⇐⇒
x∗∈λ∂f(¯x) and λ ≥0.
Moreover, the deﬁnition of the M-coderivative and Proposition 13.2.6
imply that
(x∗, −λ) ∈NM

graph f, (¯x, f(¯x))

⇐⇒
x∗∈D∗
Mf(¯x)(λ) = ∂M(λf)(¯x).
Notice that ∂M(λf)(¯x) ⊆|λ|

∂Mf(¯x) ∪∂(−f)(¯x)

for any λ ∈R. The
assertion now follows from (a).
⊓⊔
13.8 The Mordukhovich Subdiﬀerential of Marginal
Functions
Convention. In this section, E and F denote Banach spaces.
In Sect. 9.7 we derived representations of the F-subdiﬀerential of a mar-
ginal function f of the form f(x) := infy∈F ϕ(x, y), x ∈E (see Proposi-
tions 9.7.1 and 9.7.2). In this section we establish a representation of the
(singular) M-subdiﬀerential of the more general marginal function f : E →R
deﬁned by
f(x) := inf{ϕ(x, y) | y ∈Φ(x)},
(13.90)
where the function ϕ : E×F →R and the multifunction Φ : E ⇒F are given.
Marginal functions like f appear as value functions in parametric optimization
problems of the form
minimize ϕ(x, y)
subject to y ∈Φ(x),
where x denotes a parameter. We will make use of the multifunction Θ : E ⇒
F deﬁned by
Θ(x) := {y ∈Φ(x) | ϕ(x, y) = f(x)}.
(13.91)
In terms of parametric optimization, Θ(x) consists of all y ∈Φ(x) at which
the inﬁmum of ϕ(x, ·) is attained. Recall the notion of an inner semicompact
multifunction. We also need the following auxiliary function ϑ : E × F →R:
ϑ(x, y) := ϕ(x, y) + δgraph Φ(x, y).

328
13 Extremal Principles and More Normals and Subdiﬀerentials
Theorem 13.8.1 Assume that ϕ : E × F →R is l.s.c., Φ is closed, and Θ is
inner semicompact at ¯x ∈dom f ∩Dom Θ.
(a) One has
∂Mf(¯x) ⊆
0
x∗∈E∗ (x∗, o) ∈

¯y∈Θ(¯x)
∂Mϑ(¯x, ¯y)
1
,
(13.92)
∂∞
Mf(¯x) ⊆
0
x∗∈E∗ (x∗, o) ∈

¯y∈Θ(¯x)
∂∞
Mϑ(¯x, ¯y)
1
.
(13.93)
(b) If, in addition, ϕ is strictly F-diﬀerentiable at any (¯x, ¯y), where ¯y ∈Θ(¯x),
then
∂Mf(¯x) ⊆

¯y∈Θ(¯x)

ϕ 1(¯x, ¯y) + D∗
MΦ(¯x, ¯y)(ϕ 2(¯x, ¯y))

,
(13.94)
∂∞
Mf(¯x) ⊆

¯y∈Θ(¯x)
D∗
MΦ(¯x, ¯y)(o).
(13.95)
Proof.
(a) (I) We verify (13.92). Take any x∗∈∂Mf(¯x). By Theorem 13.1.17 there
exist sequences xk →f ¯x, x∗
k
w∗
−−→x∗, and ϵk ↓0 as k →∞satisfying
x∗
k ∈*∂ϵkf(xk) for any k ∈N. Hence there exists a sequence ηk ↓0
such that
⟨x∗
k, x −xk⟩≤f(x) −f(xk) + 2ϵk∥x −xk∥
∀x ∈B(xk, ηk).
Recalling the deﬁnition of f, Θ, and ϑ, we obtain for all yk ∈Θ(xk),
all (x, y) ∈B((xk, yk), ηk), and all k ∈N the estimate
⟨(x∗
k, o), (x, y)−(xk, yk)⟩≤ϑ(x, y)−ϑ(xk, yk)+2ϵk(∥x−xk∥+∥y−yk∥).
From this we conclude that
(x∗
k, o) ∈*∂2ϵkϑ(xk, yk)
∀k ∈N.
(13.96)
Since Θ is inner semicompact at ¯x, we ﬁnd a sequence yk ∈Θ(xk) that
contains a subsequence, again denoted (yk), that converges to some
¯y ∈F. Since xk →¯x, yk ∈Φ(xk) for any k, and Φ has a closed graph,
it follows that ¯y ∈Φ(¯x). The lower semicontinuity of ϕ implies
ϕ(¯x, ¯y) ≤lim inf
k→∞ϕ(xk, yk) = lim inf
k→∞f(xk) = f(¯x),
which together with the deﬁnition of f gives ϕ(¯x, ¯y) = f(¯x) and so ¯y ∈
Θ(¯x). This, (13.96), and Theorem 13.1.17 show that inclusion (13.92)
holds.
(II) The veriﬁcation of (13.93) is left as Exercise 13.13.19.

13.8 The Mordukhovich Subdiﬀerential of Marginal Functions
329
(b) The representations (13.94) and (13.95) follow from (a) by applying
the sum rule of Proposition 13.5.1 to the function ϑ and recalling
Remark 13.1.10 and the deﬁnition of the M-coderivative.
⊓⊔
Now let Φ be a single-valued mapping which we denote T : E →F. Then
(13.90) passes into
f(x) = ϕ(x, T(x)) =: (ϕ ◦T)(x),
x ∈E.
(13.97)
If, in particular, ϕ does not explicitly depend on x, then ϕ ◦T is the usual
composition of ϕ and T. Recall that if ϕ is (strictly) F-diﬀerentiable at (¯x, ¯y),
then the partial derivative ϕ 2(¯x, ¯y) is an element of F ∗and ⟨ϕ 2(¯x, ¯y), T⟩:
E →R denotes the scalarization of T.
Applying Theorem 13.8.1 we now establish another chain rule (cf. Theo-
rem 9.2.9).
Theorem 13.8.2 (Chain Rule) Let T : E →F be locally L-continuous
around ¯x ∈E and ϕ : E × F →R be strictly F-diﬀerentiable at (¯x, T(¯x)).
Then
∂M(ϕ ◦T)(¯x) = ϕ 1(¯x, ¯y) + ∂M

ϕ 2(¯x, ¯y), T
 
(¯x),
where ¯y := T(¯x). (13.98)
Proof. Since ϕ is strictly F-diﬀerentiable at (¯x, ¯y), for any sequence ηi ↓0
there exists a sequence δi ↓0 such that
|ϕ(z, T(z)) −ϕ(x, T(x)) −⟨ϕ 1(¯x, ¯y), z −x⟩−⟨ϕ 2(¯x, ¯y), T(z) −T(x)⟩|
≤ηi(∥z −x∥+ ∥T(z) −T(x)∥)
∀x, z ∈B(¯x, δi)
∀i ∈N.
(13.99)
Now let x∗∈∂M(ϕ◦T)(¯x) be given. By Theorem 13.1.17 there exist sequences
xk →¯x, x∗
k
w∗
−−→x∗, and ϵk ↓0 as k →∞satisfying (ϕ ◦T)(xk) →(ϕ ◦T)(¯x)
and
x∗
k ∈*∂ϵk(ϕ ◦T)(xk)
∀k ∈N.
(13.100)
Choose a strictly increasing sequence (ki) of positive integers such that ∥xki −
¯x∥≤δi/2 for any i ∈N. In view of (13.100), for any i we can further choose
˜δi ∈(0, δi/2) such that for all x ∈B(xki, ˜δi) and any i ∈N we obtain
ϕ(x, T(x)) −ϕ(xki, T(xki)) −⟨x∗
ki, x −xki⟩≥−2ϵki∥x −xki∥.
(13.101)
Let λ > 0 be a Lipschitz constant of ϕ in a neighborhood of ¯x containing xk
for all suﬃciently large k ∈N. Since x ∈B(xki, ˜δi) implies x ∈B(¯x, δi), the
estimates (13.99) and (13.101) give
⟨ϕ 2(¯x, ¯y), T(x)⟩−⟨ϕ 2(¯x, ¯y), T(xki)⟩−⟨x∗
ki −ϕ 1(¯x, ¯y), x −xki⟩
≥−(2ϵki + ηi(λ + 1))∥x −xki∥
∀x ∈B(xki, ˜δi)
∀i ∈N.

330
13 Extremal Principles and More Normals and Subdiﬀerentials
Hence the deﬁnition of the ϵ-subdiﬀerential shows that, with ˜ϵi := 2ϵki +
ηi(λ + 1), we have
x∗
ki −ϕ 1(¯x, ¯y) ∈∂˜ϵi

ϕ 2(¯x, ¯y), T
 
(xki)
∀i ∈N.
Letting i →∞and recalling Theorem 13.1.17, we obtain
x∗−ϕ 1(¯x, ¯y) ∈∂M

ϕ 2(¯x, ¯y), T
 
(¯x).
Thus we have veriﬁed the inclusion ⊆of (13.98). The veriﬁcation of the
opposite inclusion is left as Exercise 13.13.20.
⊓⊔
13.9 A Nonsmooth Implicit Function Theorem
Consider a multifunction Φ : E × F ⇒G between Banach spaces E, F, and
G. Let (¯x, ¯y) ∈E × F be such that o ∈Φ(¯x, ¯y). As in the classical implicit
function theorem (see Theorem 3.7.2), we want to locally solve the generalized
equation o ∈Φ(x, y) for y, i.e., we seek conditions ensuring that, for y near
¯y, the set {x ∈E | o ∈Φ(x, y)} is nonempty. Let
f(x, y) := d(Φ(x, y), o).
Our approach is based on the observation that o ∈Φ(x, y) if and only if
f(x, y) = 0 or equivalently, f(x, y) ≤0. Consequently, we can treat the set-
valued problem by a single-valued one. Therefore we start with an implicit
function theorem associated with the inequality f(x, y) ≤0, where for the
time being the functional f is arbitrary. We set
Ψ(y) := {x ∈E | f(x, y) ≤0}
and
f+(x, y) := max{0, f(x, y)}.
Furthermore, ∂F,1f(¯x, ¯y) denotes the F-subdiﬀerential of x →f(x, ¯y) at (¯x, ¯y).
We consider the following assumptions:
(A1) E and F are Fréchet smooth Banach spaces, U is a nonempty open
subset of E × F, and (¯x, ¯y) ∈U.
(A2) f : E × F →R is proper and such that f(¯x, ¯y) ≤0.
(A3) The functional y →f(¯x, y) is u.s.c. at ¯y.
(A4) For any y near ¯y the functional x →f(x, y) is l.s.c.
(A5) There exists σ > 0 such that for any (x, y) ∈U with f(x, y) > 0,
x∗∈∂F,1f(x, y) implies ∥x∗∥≥σ.
Assumption (A5) is a nonsmooth substitute for the bijectivity requirement
on f 1(x, y) in the classical implicit function theorem (see Theorem 3.7.2 with
x and y interchanged). This classical theorem yields, among others, a repre-
sentation of the F-derivative of the implicit function in terms of the partial
F-derivatives of the given function. In the following remarkable result, the
coderivative of the multifunction Ψ is represented in terms of F-subderivatives
of f+.

13.9 A Nonsmooth Implicit Function Theorem
331
Theorem 13.9.1 (Nonsmooth Implicit Function Theorem) Suppose
that the assumptions (A1)–(A5) are satisﬁed. Then there exist open sets
V ⊆E and W ⊆F such that ¯x ∈V and ¯y ∈W and that the following holds:
(a) For any y ∈W the set V ∩Ψ(y) is nonempty.
(b) For any (x, y) ∈V × W one has
d(x, Ψ(y)) ≤f+(x, y)
σ
.
(c) For any (x, y) ∈V × W such that x ∈Ψ(y) and any x∗∈E∗one has
D∗
F Ψ(y, x)(x∗) =
0
y∗∈F ∗ (−x∗, y∗) ∈

λ>0
λ ∂F f+(x, y)
1
.
Proof. Let ρ′ > 0 be such that B(¯x, ρ′)×B(¯y, ρ′) ⊆U and set ρ := ρ′/3. Since
f(¯x, ¯y) ≤0, it follows from (A3) that there exists an open neighborhood W
of ¯y with W ⊆B(¯y, ρ) such that f(¯x, y) < ρσ for any y ∈W. We show that
W and V := ˚B(¯x, ρ) have the required properties.
Ad (a). Let y ∈W be given. Suppose we had V ∩Ψ(y) = ∅. Then for any
τ ∈(0, ρ) and any x ∈B(¯x, τ) it would follow that f(x, y) > 0. Choosing τ
close enough to ρ, we may assume that f(¯x, y) < τσ. The decrease principle
(Theorem 9.6.3) then implies
inf{f(x, y) | x ∈B(¯x, ρ)} ≤f(¯x, y) −τσ < 0,
which is a contradiction to inf{f(x, y) | x ∈B(¯x, ρ)} ≥0. Therefore V ∩
Ψ(y) ̸= ∅.
Ad (b). Let (x, y) ∈V × W be given. First we assume that B(x, f+(x, y)/σ)
is not a subset of ˚B(¯x, ρ′). Then ∥x −¯x∥+ f+(x, y)/σ ≥ρ′ and so
f+(x, y)/σ ≥ρ′ −ρ = 2ρ > d(x, Ψ(y)),
where the latter inequality follows from (a). Now assume that B(x, f+(x, y)/σ)
is a subset of ˚B(¯x, ρ′). Let τ > f+(x, y)/σ be such that B(x, τ) ⊆˚B(¯x, ρ′).
Since f(x, y) < τσ, we can conclude arguing similarly as in the proof of (a)
that there exists ˆx ∈B(x, τ) such that f(ˆx, y) ≤0. Hence d(x, Ψ(y)) < τ.
Letting τ ↓f+(x, y)/σ we again obtain (b).
Ad (c). Take any (x, y) ∈V × W such that x ∈Ψ(y) and any x∗∈E∗. We
will show that
D∗
F Ψ(y, x)(x∗) ⊆
0
y∗∈Y ∗ (−x∗, y∗) ∈

λ>0
λ ∂F f+(x, y)
1
.
(13.102)
Thus let y∗∈D∗
F Ψ(y, x)(x∗) be given. Then
(y∗, −x∗) ∈NF (graph Ψ, (y, x)) =

λ>0
λ ∂F d (graph Ψ, (y, x));

332
13 Extremal Principles and More Normals and Subdiﬀerentials
in this connection we write ∂F d(graph Ψ, (y, x)) for the F-subdiﬀerential of
the functional (v, u) →d((v, u), graph Ψ) at (y, x). It follows that there exist
λ > 0 and a C1 functional g : F × E →R with g′(y, x) = (y∗, −x∗) such that
for any (v, u) ∈F × E we have (noticing that d((y, x), graph Ψ) = 0),
g(v, u) ≤λ d((v, u), graph Ψ) + g(y, x)
≤λ d(u, Ψ(v)) + g(y, x) ≤(λ/σ)f+(u, v) + g(y, x).
Since f+(x, y) = 0, it thus follows that the functional (v, u) →(λ/σ)f+(u, v)−
g(v, u) attains a minimum at (y, x). Hence (−x∗, y∗) ∈(λ/σ)∂F f+(x, y) (ob-
serve the order of variables). This veriﬁes (13.102). Since the reverse inclusion
follows immediately from δgraph Ψ ≥λ f+ for any λ > 0, the proof is complete.
⊓⊔
We apply Theorem 13.9.1 to the special case
f(x, y) := ∥T(x, y)∥,
(13.103)
where T : E × F →G is a continuously diﬀerentiable mapping. We consider
the following conditions:
(C1) E, F, and G are Fréchet smooth Banach spaces, U is a nonempty open
subset of E × F, and (¯x, ¯y) ∈U.
(C2) T : E × F →G is a C1 mapping such that T(¯x, ¯y) = o.
(C3) There exists σ > 0 such that σ BG ⊆T 1(x, y)

BE

for any (x, y) ∈U.
Proposition 13.9.2 Let the conditions (C1)–(C3) be satisﬁed and let
Ψ(y) := {x ∈E | T(x, y) = o}.
Then there exist open sets V ⊆E and W ⊆F such that ¯x ∈V and ¯y ∈W
and that the following holds:
(a) For any y ∈W the set V ∩Ψ(y) is nonempty.
(b) For any (x, y) ∈V × W one has
d(x, Ψ(y)) ≤∥T(x, y)∥
σ
.
(c) For any x∗∈E∗one has
D∗
F Ψ(¯y, ¯x)(x∗) =

−

T 2(¯x, ¯y)
∗z∗ z∗∈G∗,

T 1(¯x, ¯y)
∗z∗= x∗
.
(13.104)
If, in particular, T 1(¯x, ¯y) is invertible, then D∗
F Ψ(¯y, ¯x)(x∗) is a singleton con-
sisting of −

(T 1(¯x, ¯y))−1T 2(¯x, ¯y)
∗x∗.

13.9 A Nonsmooth Implicit Function Theorem
333
Proof. Ad (a), (b). Clearly the functional f : E × F →R deﬁned by (13.103)
satisﬁes the assumptions (A1)–(A4). We show that it also satisﬁes (A5). Let
(x, y) ∈U be such that T(x, y) ̸= o. Applying the chain rule we conclude that
x∗∈∂F,1f(x, y) if and only if
⟨x∗, u⟩=

T(x, y) | T 1(x, y)u

∥T(x, y)∥
∀u ∈E,
in other words,
x∗= T 1(x, y)∗v,
where v :=
T(x, y)
∥T(x, y)∥.
(13.105)
By (C3) there exists u ∈BE such that T 1(x, y)u = σv. Consequently,
∥x∗∥= ∥T 1(x, y)∗v∥≥⟨T 1(x, y)∗v, u⟩= ⟨v, T 1(x, y)u⟩= ⟨v, σv⟩= σ.
Therefore (A5) is also fulﬁlled. Conclusions (a) and (b) now follow immedi-
ately from Theorem 13.9.1.
Ad (c). We calculate the coderivative of the multifunction Ψ. Recall that
T(¯x, ¯y) = o. Let λ > 0 and (−x∗, y∗) ∈λ∂F f(x, y) be given. By Proposi-
tion 9.1.9(a) we have
⟨−x∗, u⟩+ ⟨y∗, v⟩≤λfG

(¯x, ¯y), (u, v)

∀(u, v) ∈E × F.
(13.106)
Observe that
fG

(¯x, ¯y), (u, v)

= ∥T 1(¯x, ¯y)u + T 2(¯x, ¯y)v∥
= max
z∗∈B∗
G
⟨z∗, T 1(¯x, ¯y)u + T 2(¯x, ¯y)v⟩;
(13.107)
concerning the latter equation see Example 2.2.6. From (13.106) and (13.107)
we conclude that
min
u∈BE
v∈BF
max
z∗∈λBG∗

T 1(¯x, ¯y)
∗z∗−x∗, u
 
+

T 2(¯x, ¯y)
∗z∗+ y∗, v
 
≥0.
Hence there exists z∗∈λBG∗satisfying
x∗=

T 1(¯x, ¯y)
∗z∗
and
y∗= −

T 2(¯x, ¯y)
∗z∗.
Now Theorem 13.9.1(c) implies (13.104), from which the special case where
T 1(¯x, ¯y) is invertible is immediate.
⊓⊔
As a consequence of Proposition 13.9.2 we obtain a classical result of
Lyusternik [128] and Graves [79].
Corollary 13.9.3 Assume that (A1) holds and that T : E × F →F is a C1
mapping such that T(¯x, ¯y) = o and the partial derivative T 1(¯x, ¯y) is surjective.
Then the conclusions of Proposition 13.9.2 hold.

334
13 Extremal Principles and More Normals and Subdiﬀerentials
Proof. In view of Proposition 13.9.2 we only have to show that condition (C3)
is satisﬁed. Since T 1(¯x, ¯y) is surjective, the classical open mapping theorem
implies that there exists σ > 0 such that 2σBF ⊆T 1(¯x, ¯y)(BE). Since T 1 is
continuous, there further exist open neighborhoods V of ¯x and W of ¯y such
that
∥T 1(¯x, ¯y) −T 1(x, y)∥≤σ
∀(x, y) ∈V × W.
It follows that
2σBF ⊆

T 1(¯x, ¯y) −T 1(x, y)

(BE) + T 1(x, y)(BE) ⊆σBF + T 1(x, y)(BE)
and so σBF ⊆T 1(x, y)(BE) for any (x, y) ∈V × W. Hence (C3) is satisﬁed.
⊓⊔
13.10 An Implicit Multifunction Theorem
We start with an auxiliary result. Let E, G be Fréchet smooth Banach spaces
and U an open subset of E. With a given multifunction Γ : U ⇒G we
associate the function g : U →R deﬁned by
g(x) := d(Γ(x), o) = inf{∥z∥| z ∈Γ(x)}.
(13.108)
It will be crucial for the following that g can be written as inﬁmum over a
ﬁxed set:
g(x) = inf
z∈G γ(x, z),
where γ(x, z) := ∥z∥+ δgraph Γ (x, z).
(13.109)
The lemma below establishes the relationship between the F–subdiﬀerential
of g and the coderivative of Γ. In this connection, if S ⊆G, ¯z ∈G and η > 0,
we call
projη(¯z, S) := {z ∈G | ∥z −¯z∥≤d(¯z, S) + η}
the η–approximate projection of ¯z to S.
Lemma 13.10.1 Let E and G be Fréchet smooth Banach spaces and U an
open subset of E. Further let the multifunction Γ : U ⇒G be closed-valued
and u.s.c. and let g : U →R be deﬁned by (13.108). Assume that there exists
σ > 0 such that for any x ∈U with o /∈Γ(x), one has
σ ≤lim inf
η→0

∥x∗∥
 x∗∈D∗
F Γ(ˆx, ˆz)(z∗), z∗∈G∗, ∥z∗∥= 1,
ˆx ∈B(x, η), ˆz ∈projη

o, Γ(ˆx)

.
Then for any x ∈U with g(x) > 0, x∗∈∂F g(x) implies ∥x∗∥≥σ.

13.10 An Implicit Multifunction Theorem
335
Proof. Since Γ is closed–valued and u.s.c., graph Γ is a closed set. Hence γ is
l.s.c. Moreover, since Γ is u.s.c., the function g is l.s.c. (Exercise 13.13.11) and
so coincides with its l.s.c. closure g. Let x ∈U with g(x) > 0 and x∗∈∂F g(x)
be given. Choose η > 0 such that g(ˆx) ≥g(x)/2 for any ˆx ∈B(x, η). By
Proposition 9.7.1 there exist (uη, wη) and (u∗
η, w∗
η) ∈∂F γ(uη, wη) satisfying
0 < g(uη) < γ(uη, wη) < g(uη) + η,
(13.110)
∥uη −x∥< η,
∥u∗
η −x∗∥< η,
∥w∗
η∥< η.
(13.111)
From (13.110) we see that wη ∈projη(o, Γ(uη)). By the sum rule of Theorem
9.2.6 there exist (xη, zη), (ˆxη, ˆzη) close to (uη, wη) and z∗
η ∈∂ω(ˆzη), where
ω(z) := ∥z∥, such that
zη ∈projη

o, Γ(xη)

,
∥ˆzη∥> 0,
(u∗
η, w∗
η) ∈(o, z∗
η) + NF

(xη, zη), graph Γ

+ η(BE∗× BG∗).
Hence there exist (ˆu∗
η, ˆw∗
η) ∈η (BE∗× BG∗) satisfying
u∗
η −ˆu∗
η ∈D∗Γ

(xη, zη

(z∗
η −w∗
η + ˆw∗
η)
and so
u∗
η −ˆu∗
η
∥z∗η −w∗η + ˆw∗η∥∈D∗Γ(xη, zη)
 z∗
η −w∗
η + ˆw∗
η
∥z∗η −w∗η + ˆw∗η∥

.
Since ∥z∗
η −w∗
η + ˆw∗
η∥≥1 −2η (recall that ∥z∗
η∥= 1), we obtain
lim inf
η↓0
∥u∗
η∥= lim inf
η↓0
∥u∗
η −ˆu∗
η∥
∥z∗η −w∗η + ˆw∗η∥≥σ;
here the last inequality follows from the assumption concerning σ. Hence
(13.111) shows that ∥x∗∥≥σ.
⊓⊔
Now we turn to the announced implicit multifunction theorem. For this,
we need the following hypotheses.
(H 1) E, F and G are Fréchet smooth Banach spaces, U is a nonempty open
subset of E × F and (¯x, ¯y) ∈U.
(H 2) Φ : U ⇒G is a closed–valued multifunction such that o ∈Φ(¯x, ¯y).
(H 3) The multifunction Φ(¯x, ·) is l.s.c. at ¯y.
(H 4) For any y near ¯y the multifunction Φ(·, y) is u.s.c..
(H 5) There exists σ > 0 such that for any (x, y) ∈U with o /∈Φ(x, y), one
has
σ ≤lim inf
η→0
0
∥x∗∥
 x∗∈D∗
F Φ

(ˆx, y), ˆz

(z∗), z∗∈G∗, ∥z∗∥= 1,
ˆx ∈B(x, η), ˆz ∈projη

o, Φ(ˆx, y)
1
.

336
13 Extremal Principles and More Normals and Subdiﬀerentials
Further let
Ψ(y) := {x ∈E | o ∈Φ(x, y)},
(13.112)
that is, Ψ : F ⇒E is the implicit multifunction deﬁned by the generalized
equation o ∈Φ(x, y). Applying Theorem 13.9.1 and making use of Lemma
13.10.1, we immediately obtain the following result.
Theorem 13.10.2 (Implicit Multifunction Theorem) Assume that the
hypotheses (H1)–(H5) are satisﬁed. Then there exist open sets V ⊆E and
W ⊆F with ¯x ∈V and ¯y ∈W such that the following holds:
(a) For any y ∈W the set V ∩Ψ(y) is nonempty.
(b) For any (x, y) ∈V × W one has
d(Ψ(y), x) ≤d(Φ(x, y), o)
σ
.
(c) For any (x, y) ∈V × W with x ∈Ψ(y) and any x∗∈E∗, one has
D∗
F Ψ(y, x)(x∗) =
0
y∗∈F ∗ (−x∗, y∗) ∈

λ>0
λ ∂F d(Φ(x, y), o)
1
.
(13.113)
This theorem characterizes the coderivative of the implicit multifunction
Ψ in terms of the Fréchet subdiﬀerential of the scalar function (x, y) →
d(Φ(x, y), 0). It is natural to ask how the coderivative of Ψ can be charac-
terized directly in terms of Φ. The following result gives a partial answer.
Proposition 13.10.3 Assume that the hypotheses (H1)–(H5) are satisﬁed.
Then for any (x, y) ∈V ×W with x ∈Ψ(y) (notation as in Theorem 13.10.2),
the following holds:
(a) For any x∗∈E∗one has

z∗∈G∗
0
y∗∈F ∗ (−x∗, y∗) ∈D∗
F Φ(x, y, o)(z∗)
1
⊆D∗
F Ψ(y, x)(x∗).
(13.114)
(b) For any x∗∈E∗, y∗∈D∗
F Ψ(y, x)(x∗), and ϵ > 0 there exist (xϵ, yϵ, zϵ) ∈
graph Φ and (x∗
ϵ, y∗
ϵ , z∗
ϵ ) ∈E∗× F ∗× G∗such that
∥x −xϵ∥< ϵ,
∥y −yϵ∥< ϵ,
∥zϵ∥< ϵ,
∥x∗−x∗
ϵ∥< ϵ,
∥y∗−y∗
ϵ ∥< ϵ,
(−x∗
ϵ, y∗
ϵ ) ∈D∗
F Φ(xϵ, yϵ, zϵ)(z∗
ϵ ).
(13.115)
(c) If, in addition, graph Φ is normally regular at (x, y, o), then (13.114) holds
with equality.
Proof.
(a) Let y∗be an element of the left-hand side of (13.114). Then there exists
z∗∈G∗such that

13.11 An Extremal Principle Involving Deformations
337
(−x∗, y∗, z∗) ∈NF (graph Φ, (x, y, o)).
Hence there further exists a C1 function g such that g′(x, y, o) =
(−x∗, y∗, z∗) and δgraph Φ −g has a local minimum at (x, y, o). Since
δgraph Φ(ˆx, ˆy, o) = δgraph Ψ(ˆy, ˆx) for any ˆx ∈E and any ˆy ∈F, it follows
that the function
(ˆy, ˆx) →δgraph Ψ(ˆy, ˆx) −g(ˆx, ˆy, o)
attains a local minimum at (y, x). Therefore, y∗∈D∗
F (y, x)(x∗).
(b) Let y∗∈D∗
F Ψ(y, x)(x∗) be given. Then
(y∗, −x∗) ∈

λ>0
λ∂F d(graph Ψ, (y, x)).
Thus there exist a C1 function h satisfying h′(y, x) = (y∗, −x∗) and a
constant λ > 0 such that
h(y, x) ≤h(ˆy, ˆx) + λd(graph Ψ, (ˆy, ˆx))
≤h(ˆy, ˆx) + λd(Ψ(ˆy, ˆx) ≤h(ˆy, ˆx) + (λ/σ)d(Φ(ˆx, ˆy), o);
(13.116)
here the last inequality follows by Theorem 13.10.2(b). Since d(Φ(ˆx, ˆy), o) =
inf ˆz∈G{∥ˆz∥+ δgraph Φ(ˆx, ˆy, ˆz)}, the estimate (13.116) shows that
(y∗, −x∗) ∈∂F

inf
ˆz∈G

(λ/σ)∥ˆz∥+ δgraph Φ(ˆx, ˆy, ˆz)

.
Applying Proposition 9.7.1, we obtain the conclusion of (b).
(c) This follows from (13.115) by letting ϵ ↓0.
⊓⊔
We now derive a suﬃcient condition for metric regularity. In view of Theo-
rems 10.3.3 and 10.5.2 this is at the same time a suﬃcient condition for linear
openness and pseudo-Lipschitz continuity (Theorem 13.10.2)
Given the multifunction *Φ : E ⇒F, deﬁne Φ : E × F ⇒F by
Φ(x, y) := *Φ(x) −y,
x ∈E,
y ∈F.
(13.117)
Proposition 13.10.4 Assume that *Φ : E ⇒F is a multifunction such that,
with G := F and Φ according to (13.117), the hypotheses (H1)–(H5) are sat-
isﬁed. Then *Φ is metrically regular around (¯x, ¯y) with constant 1/σ.
Proof. Notice that in this case we have Ψ
=
*Φ−1 and d(Φ(x, y), o) =
d(*Φ(x), y). Hence the assertion follows from Theorem 13.10.2(b).
⊓⊔
13.11 An Extremal Principle Involving Deformations
The concept of an extremal system introduced in Sect. 13.3 refers to the trans-
lation of sets (cf. Remark 13.3.2). Now we introduce the concept of an ex-
tended extremal system which refers to the deformation of sets and so applies
to multifunctions.

338
13 Extremal Principles and More Normals and Subdiﬀerentials
Deﬁnition 13.11.1 Assume that Si, i = 1, . . . , n, are metric spaces with
metrics ρi, E is a Banach space, and Φi : Si ⇒E are closed-valued multi-
functions. A point ¯x ∈E is said to be a local extremal point of the system
(Φ1, . . . , Φn) at (¯s1, . . . , ¯sn) ∈S1 × · · · × Sn if ¯x ∈Φ1(¯s1) ∩· · · ∩Φn(¯sn)
and there is a neighborhood U of ¯x such that for any ϵ > 0 there exist
(s1, . . . , sn) ̸= (¯s1, . . . , ¯sn) with
ρi(si, ¯si) ≤ϵ,
d(Φi(si), ¯x) < ϵ,
i = 1, . . . , n,
Φ1(s1) ∩· · · ∩Φn(sn) ∩U = ∅.
If the system (Φ1, . . . , Φn) admits a local extremal point, it is said to be an
extended extremal system.
Remark 13.11.2 Let (A1, A2, ¯x) be an extremal system in the sense of Def-
inition 13.3.1. Deﬁning
S1 := E, Φ1(s1) := s1 + A1 ∀s1 ∈E, S2 := {o}, Φ2(o) := A2,
we see that ¯x is a local extremal point of the system (Φ1, Φ2) at (o, o) and so
(Φ1, Φ2) is an extended extremal system.
We now establish an extremal principle for extended extremal systems
that corresponds to the approximate extremal principle of Theorem 13.3.10.
The result will be applied in Sect. 13.12 to multiobjective optimization.
Theorem 13.11.3 Let E be a Fréchet smooth Banach space. Assume that,
for i = 1, . . . , n, Si is a metric space with metric ρi and Φi : Si ⇒E is
a closed-valued multifunction. Further let ¯x be a local extremal point of the
system (Φ1, . . . , Φn) at (¯s1, . . . , ¯sn). Then for any ϵ > 0 there exist si ∈Si,
xi ∈BE(¯x, ϵ), and x∗
i ∈E∗such that
ρi(si, ¯si) ≤ϵ,
xi ∈Φi(si),
x∗
i ∈NF (Φi(si), xi) + ϵBE∗,
max{∥x∗
i ∥, . . . , ∥x∗
n∥} ≥1,
x∗
1 + · · · + x∗
n = o.
(13.118)
Proof.
(I) We equip En with the Euclidean product norm. Choose ρ > 0 such that
U := B(¯x, ρ) is a neighborhood of ¯x as in Deﬁnition 13.11.1. Now let ϵ > 0
be given and choose η such that
0 < η < min
0
ϵ2
5ϵ + ϵ2 + 12n2 , ρ2
4
1
.
Further let s1, . . . , sn be as in Deﬁnition 13.11.1 with ϵ replaced by η so
that, in particular, d(Φi(si), ¯x) < η. Put A := Φ1(si) × · · · × Φn(sn) and
deﬁne ϕ : U n →R by
ϕ(y1, . . . , yn) :=
n
	
i,k=1
∥yi −yk∥+ δA(y1, . . . , yn).

13.11 An Extremal Principle Involving Deformations
339
Since every set Φi(si) is closed, the function ϕ is l.s.c. Moreover, since ¯x
is a local extremal point of the system (Φ1, . . . , Φn), we conclude that ϕ
is positive on U n. Choose ˜yi ∈Φi(si), i = 1, . . . , n, satisfying
∥˜yi −˜yk| ≤d(Φi(si), ¯x) + d(Φk(sk), ¯x) + η ≤3η.
It follows that ϕ(y1, . . . , yn) ≤3n2η < ϵ2/4.
(II) Applying Ekeland’s variational principle in the form of Corollary 8.2.6,
we ﬁnd ˜xi ∈B(˜yi, ϵ/2) ⊆B(¯x, ϵ) such that the function
f(y1, . . . , yn) :=
n
	
i,k=1
∥yi −yk∥+ ϵ
2
n
	
i=1
∥yi −˜xi∥+ δA(y1, . . . , yn)
attains its minimum over U n at (˜x1, . . . , ˜xn). Obviously we may assume
that U n = En. Deﬁne ψ : En →R by
ψ(y1, . . . , yn) :=
n
	
i,k=1
∥yi −yk∥.
We have ψ(˜x1, . . . , ˜xn) = ϕ(˜x1, . . . , ˜xn) > 0.
(III) Applying the approximate sum rule of Theorem 9.2.6 (in connection with
Lemma 9.2.5) to the function f, we ﬁnd
xi ∈Φ(si) ∩B(˜xi, η) ⊆B(¯x, ϵ),
zi ∈B(˜xi, η),
(z∗
1, . . . , z∗
n) ∈∂F ψ(z1, . . . , zn)
satisfying
o ∈(z∗
1, . . . , z∗
n) + NF (Φ1(s1), x1) × · · · × NF (Φn(sn), xn)
+ B(En)∗
o, η(n + 1)

;
(13.119)
here we made use of the representation
∂F δA(y1, . . . , yn) = NF (Φ1(y1), y1) × · · · × NF (Φn(yn), yn)
∀yi ∈Φi(si),
(13.120)
the veriﬁcation of which is left as Exercise 13.13.21. Putting x∗
i := −z∗
i
for i = 1, . . . , n we derive from (13.119) that x∗
i ∈NF (Φi(si), xi)+ϵBE∗.
From (z∗
1, . . . , z∗
n) ∈∂F ψ(z1, . . . , zn) we conclude that
(z∗
1, . . . , z∗
n)
≤lim inf
τ→0
ψ(z1 + τh, . . . , zn + τh) −ψ(z1, . . . , zn)
τ
= 0
∀h ∈E,
where the latter equation follows from the deﬁnition of ψ by symmetry.
Hence we obtain
x∗
1 + · · · + x∗
n = −(z∗
1 + · · · + z∗
n) = o.
(13.121)

340
13 Extremal Principles and More Normals and Subdiﬀerentials
It remains to verify that max{∥x∗
1∥, . . . , ∥x∗
n∥} ≥1. We ﬁrst obtain
n
	
i=1
⟨z∗
i , −zi⟩
≤lim inf
τ→0
ψ(z1 −τz1, . . . , zn −τzn) −ψ(z1, . . . , zn)
τ
= −ψ(z1, . . . , zn).
In view of (13.121) we have z∗
1 = −n
i=2 z∗
i and it follows that
ψ(z1, . . . , zn) ≤
n
	
i=1
⟨z∗
i , zi⟩=
n
	
i=2
⟨z∗
i , zi −z1⟩
≤max{∥z∗
1∥, . . . , ∥z∗
n∥} ψ(z1, . . . , zn).
(13.122)
Since ψ(˜x1, . . . , ˜xn) > 0 and ∥zi −˜xi∥≤η, we may assume (shrinking η
further if necessary) that ψ(z1, . . . , zn) > 0. Hence (13.122) implies that
max{∥z∗
1∥, . . . , ∥z∗
n∥} ≥1, which also holds with z∗
i replaced by x∗
i .
⊓⊔
13.12 Application to Multiobjective Optimization
We want to apply the extremal principle of Theorem 13.11.3 to multiobjective
optimization problems. Let P be a nonempty subset of a Banach space F. We
deﬁne a preference relation ≺on F by writing z1 ≺z2 (read z1 is preferred
to z2) if and only if (z1, z2) ∈P. Given z ∈F, we denote the level set of ≺at
z by L(z), i.e.,
L(z) := {y ∈F | y ≺z}.
Deﬁnition 13.12.1 The preference relation ≺is said to be:
– nonreﬂexive if z ≺z does not hold for any z ∈F.
– locally satiated at ¯z ∈F if z ∈cl L(z) for any z in a neighborhood of ¯z.
– almost transitive on F if y ∈cl L(z) and z ≺z′ imply y ≺z′.
Example 13.12.2 Let Q be a closed cone in F. The generalized Pareto pref-
erence ≺is deﬁned by z1 ≺z2 if and only if z1 −z2 ∈Q and z1 ̸= z2.
We have L(z) = z + (Q \ {o}). Hence ≺is a nonreﬂexive preference relation
that is locally satiated at any ¯z ∈F. It is left as Exercise 13.13.22 to show
that ≺is almost transitive on F if and only if the cone Q is pointed (i.e.,
Q ∩(−Q) = {o}) and convex.
Now we make the following assumptions:
(A) E and F are Banach spaces, f : E →F, M ⊆E,
≺is a nonreﬂexive, satiated, almost transitive preference relation on F.

13.12 Application to Multiobjective Optimization
341
We consider the multiobjective optimization problem:
(MOP) Minimize f(x) with respect to ≺
subject to x ∈M.
A point ¯x ∈E is said to be a local solution of (MOP) if there is no x ∈M
near ¯x such that f(x) ≺f(¯x).
Lemma 13.12.3 establishes the relationship between the problem (MOP)
and extended extremal systems.
Lemma 13.12.3 Let the assumptions (A) be satisﬁed. Deﬁne
S1 := L(f(¯x)) ∪{f(¯x)},
Φ1(s1) := M × cl L(s1)
∀s1 ∈S1,
S2 := {o},
Φ2(o) := {(x, f(x)) | x ∈E}.
(13.123)
If ¯x is a local solution of (MOP), then (¯x, f(¯x)) is a local extremal point of
the system (Φ1, Φ2).
Proof. See Exercise 13.13.23.
⊓⊔
Applying the extremal principle of Theorem 13.11.3, we now derive a neces-
sary optimality condition for (MOP) in terms of F-subdiﬀerentials. Recall that
for y∗∈F ∗, the scalarization ⟨y∗, f⟩of f is deﬁned by ⟨y∗, f⟩(x) := ⟨y∗, f(x)⟩
for any x ∈E.
Theorem 13.12.4 In addition to the assumptions (A) let E and F be Fréchet
smooth Banach spaces and let f be locally L-continuous around ¯x ∈M. If ¯x
is a local solution of (MOP), then for any ϵ > 0 there exist x0, x1 ∈BE(¯x, ϵ),
y0, y1 ∈BF (f(¯x), ϵ), x∗∈NF (M, x1), and y∗∈NF (cl L(y0), y1) such that
∥y∗∥= 1 and
o ∈x∗+ ∂F ⟨y∗, f⟩(x0) + ϵBE∗.
(13.124)
Proof.
(I) We equip E × F with the norm ∥(x, y)∥:= ∥x∥+ ∥y∥and E∗× F ∗with
the corresponding dual norm ∥(x∗, y∗)∥= max{∥x∗∥, ∥y∗∥}. Let ρ ∈(0, 1)
be such that f is Lipschitz continuous on B(¯x, ρ) with Lipschitz constant
λ > 0. Let any ϵ > 0 be given and choose
η := min
0 2ϵλ
1 + λ,
1
8(2 + λ), ϵ
2, ρ
4
1
.
By Lemma 13.12.3, (¯x, f(¯x)) is a local extremal point of the sys-
tem
(Φ1, Φ2)
deﬁned
in
that
lemma.
Therefore,
Theorem
13.11.3
(with ϵ replaced by η) implies that there exist y0
∈
BF (f(¯x), η),
(xi, yi) ∈BE×R

(¯x, f(¯x)), η

, i = 1, 2, (x∗
1, y∗
1) ∈NF (Φ1(y0), (x1, y1)),
and (x∗
2, y∗
2) ∈NF (Φ2(o), (x2, y2)) such that
max{∥(x∗
1, y∗
1)∥, ∥(x∗
2, y∗
2)∥} > 1 −η
and
∥(x∗
1, y∗
1) + (x∗
2, y∗
2)∥< η.
(13.125)

342
13 Extremal Principles and More Normals and Subdiﬀerentials
It follows that
∥(x∗
i , y∗
i )∥> 1 −2η ≥1/2,
i = 1, 2.
(13.126)
The deﬁnition of the F-normal cone implies that for any (x, y) ∈Φ2(o)
suﬃciently close to (x2, y2) we obtain
⟨x∗
2, x −x2⟩+ ⟨y∗
2, y −y2⟩−η∥(x −x2, y −y2)∥≤0.
In this connection we have y = f(x) and y2 = f(x2). Hence the function
g : E →R deﬁned by
g(x) := −

⟨x∗
2, x −x2⟩+ ⟨y∗
2, f(x) −f(x2)⟩−η∥(x −x2, f(x) −f(x2))∥

attains the local minimum 0 at x = x2. It follows that o ∈∂F g(x2).
(II) Applying the approximate sum rule of Theorem 9.2.6 and the chain rule
of Theorem 9.2.9 to g, we conclude that there exists x0 ∈BE(x2, η) ⊆
BE(¯x, 2η) such that
o ∈−x∗
2 −∂F ⟨y∗
2, f⟩(x0) + (1 + λ)ηBE∗.
(13.127)
From this and the second relation in (13.125) we obtain
o ∈x∗
1 + ∂F ⟨y∗
1, f⟩(x0) + 2(2 + λ)ηBE∗.
(13.128)
We claim that ∥y∗
1∥≥1/(4(1 + λ)). To see this, take z∗∈∂F ⟨y∗
1, f⟩(x0)
and u∗∈ηBE∗such that o = x∗
1 + z∗+ 2(2 + λ)u∗. It follows that
1/2 < ∥(x∗
1, y∗
1)∥≤∥x∗
1∥+ ∥y∗
1∥= ∥z∗+ 2(2 + λ)u∗∥+ ∥y∗
1∥
≤∥z∗∥+ 2(2 + λ)η + ∥y∗
1∥.
(13.129)
From the choice of z∗and the L-continuity of f on B(¯x, ρ) we obtain
⟨z∗, h⟩≤⟨y∗
1, f(x0 + h) −f(x0)⟩≤∥y∗
1∥λ∥h∥
∀h ∈B(o, ρ/2)
and so ∥z∗∥≤λ∥y∗
1∥. This, (13.129), and the choice of η imply
∥y∗
1∥≥
1
2 −2(2 + λ)η
1 + λ
≥
1
4(1 + λ)
as claimed. Now dividing (13.128) by ∥y∗
1∥and deﬁning x∗:= x∗
1/∥y∗
1∥
and y∗:= y∗
1/∥y∗
1∥, the conclusion of the theorem follows.
⊓⊔
Remark 13.12.5 Theorem 13.12.4 is the starting point for deriving neces-
sary conditions for multiobjective optimization problems with speciﬁed con-
straints. For instance, let the set M in (MOP) be of the form M = A1∩A2∩A,
where A is any subset of E and

13.13 Bibliographical Notes and Exercises
343
A1 := {x ∈E | g(x) ≤0}, A2 := {x ∈E | h(x) = 0}
with functionals g, h : E →R. Let ¯x be a local solution of (MOP) in this case.
Then Theorem 13.12.4 implies the condition (13.124). Here, x∗∈NF (M, ¯x1)
and the deﬁnition of the F-normal cone shows that
ϕ(y) := −⟨x∗, y −x1⟩+ (ϵ/3)∥y −x1∥≥0
for all y ∈M close to x1. Hence x1 is a local solution to the scalar optimization
problem
minimize
ϕ(y)
subject to
g(y) ≤0,
h(y) = 0,
y ∈A.
A necessary condition for this problem can be derived, for instance, with
the aid of the approximate multiplier rule of Theorem 12.5.1. It is left as
Exercise 13.13.24 to elaborate the details.
13.13 Bibliographical Notes and Exercises
The presentation of this chapter was strongly inﬂuenced by the seminal two-
volume monograph [136,137] of Mordukhovich, in particular by the ﬁrst vol-
ume. The second volume contains profound investigations of optimal con-
trol governed by ordinary diﬀerential equations and by functional–diﬀerential
relations. Concerning variational analysis in ﬁnite-dimensional spaces we rec-
ommend the comprehensive monograph [189] of Rockafellar and Wets.
The limiting objects, which we call here Mordukhovich normal cone and
Mordukhovich subdiﬀerential, are called by Mordukhovich basic normal cone
and basic subdiﬀerential, respectively. These objects as well as the idea of
extremal principles ﬁrst appear in [132]. We refer to the monograph cited
above for a detailed discussion of the development of this theory as well as
a lot of references. The exact sum rule of Theorem 13.5.5 was obtained by
Mordukhovich and Shao [142] in an arbitrary Asplund space. Further calculus
rules for F- and M-subdiﬀerentials as well as necessary optimality conditions
were obtained, among others, by Ngai et al. [151] and Ngai and Théra [154].
Proposition 13.4.3 is due to Mordukhovich and Wang [145]. Mordukhovich
coderivatives (called normal coderivatives by Mordukhovich) were introduced
in [133]. They were systematically studied in ﬁnite-dimensional spaces by
Mordukhovich [134] and Ioﬀe [95]. The approximate calculus rules for F-
coderivatives in Fréchet smooth Banach spaces (Theorems 13.2.7 and 13.2.8)
and their exact counterparts for M-coderivatives in ﬁnite-dimensional Ba-
nach spaces were taken from Borwein and Zhu [24]. Mordukhovich and
Shao [141, 143] derived exact calculus rules for M-coderivatives in Asplund
spaces. Example 13.2.12 (together with the concrete data of Exercise 13.13.8

344
13 Extremal Principles and More Normals and Subdiﬀerentials
and further similar examples) was constructed by Borwein and Zhu [23].
Weak∗sequential limits of proximal subgradients are studied by Clarke
et al. [39].
The results of Sects. 13.9 and 13.10, in particular the remarkable implicit
multifunction theorem (Theorem 13.10.2), are due to Ledyaev and Zhu [120].
Investigating multiobjective optimal control problems, Zhu [227] observed
that the approximate extremal principle holds for more general deformations
than translations of the set system. This observation ﬁnally led to the gen-
eral concept of an extended extremal system that was developed and applied
by Mordukhovich et al. [144]. Readers interested in multiobjective optimiza-
tion (also known as vector optimization) are referred to G¨opfert et al. [77],
Jahn [102], Pallaschke and Rolewicz [156], and the literature cited in these
books.
Exercise 13.13.1 Verify Lemma 13.1.11.
Exercise 13.13.2 Prove Proposition 13.1.19.
Exercise 13.13.3 Verify Theorem 13.1.23.
Exercise 13.13.4 Let A be a closed subset of E and ¯x ∈A. Prove the
following assertions:
(a) If ¯x ∈A and U is a closed neighborhood of ¯x, then NM(A ∩U, ¯x) =
NM(A, ¯x).
(b) If ¯x ∈bd A, then NM(A, ¯x) ⊆NM(bd A, ¯x).
Hint: Take any nonzero x∗∈NM(A, ¯x) and ﬁnd a sequence (ϵk, xk, x∗
k), such
that, in particular, x∗
k
w∗
−−→x∗. Since it follows that lim inf ∥x∗
k∥> 0, conclude
that xk /∈int A for k large enough.
Exercise 13.13.5 Verify the assertions (a) and (c) of Proposition 13.2.3.
Exercise 13.13.6 Elaborate the details of the proof of Theorem 13.2.8.
Exercise 13.13.7 Prove Theorem 13.2.11.
Exercise 13.13.8 Let E be the sequence space l2. For any k ∈N, let uk
denote the kth unit vector of l2, let αk be a positive number such that
8
1 −1
k2 ≤αk < 1 and deﬁne
yk := u2k,
zk :=
8
1 −α2
k u2k−1 −αku2k.
Finally deﬁne H1 := cl span{yk | k ∈N} and H2 := cl span{zk | k ∈N}. Show
that H◦
1 ∩H◦
2 = {o} and H◦
1 + H◦
2 is weak∗dense but not closed in E∗(cf.
Example 13.2.12).
Hint: Verify that
H◦
1 = cl span{y∗
k | k ∈N},
H◦
2 = cl span{z∗
k | k ∈N},
where y∗
k := u2k−1 and z∗
k := αku2k−1 +
!
1 −α2
k u2k.

13.13 Bibliographical Notes and Exercises
345
Exercise 13.13.9 Verify the statement in Example 13.3.3
Exercise 13.13.10 Prove Lemma 13.3.4.
Exercise 13.13.11 Let Γ : E ⇒G be a multifunction between the Banach
spaces E and G. Deﬁne g : E →R by g(x) := d(Γ(x), o). Show that if Γ is
u.s.c., then g is l.s.c.
Exercise 13.13.12 Elaborate step (II) of the proof of Theorem 13.3.10.
Exercise 13.13.13 Show that the set A ⊆E is epi-Lipschitzian at ¯x ∈A if
and only if it is compactly epi-Lipschitzian at ¯x, where the associated compact
set C can be chosen as a singleton.
Exercise 13.13.14 Verify Remark 13.4.6.
Exercise 13.13.15 Carry out step (III) in the proof of Theorem 13.4.9.
Exercise 13.13.16 For i = 1, 2 let Ai be a nonempty subset of the normed
vector space Ei and ¯xi ∈Ai. Prove that
NM(A1 × A2, (¯x1, ¯x2)) = NM(A1, ¯x1) × NM(A2, ¯x2).
Exercise 13.13.17 Show that for any nonempty subset A of E and ¯x ∈A
one has
∂MδA(¯x) = ∂∞
MδA(¯x) = NM(A, ¯x).
Exercise 13.13.18 Carry out the induction proof for Theorem 13.5.5.
Exercise 13.13.19 Prove the assertion (13.93) of Theorem 13.8.1.
Exercise 13.13.20 Verify the inclusion ⊇of (13.98) under the assumptions
of Theorem 13.8.2.
Exercise 13.13.21 Verify the representation of ∂F δA(y1, . . . , yn) in (13.120).
Exercise 13.13.22 Verify the assertion in Example 13.12.2.
Exercise 13.13.23 Verify Lemma 13.12.3.
Exercise 13.13.24 Carry out the program indicated in Remark 13.12.5.

A
Appendix: Further Topics
In this ﬁnal chapter we brieﬂy indicate some concepts and developments in
nonsmooth analysis that have not been treated in the preceding text. For a
comprehensive discussion we refer to the monograph [189] by Rockafellar
and Wets (ﬁnite-dimensional theory) and the monograph [136, 137] by
Mordukhovich (inﬁnite-dimensional theory).
In the sequel, unless otherwise speciﬁed, let E be a normed vector space,
f : E →R a proper functional, and ¯x ∈dom f.
(I) Clarke [34] deﬁnes the subdiﬀerential
∂↑f(¯x) := {x∗∈E∗| (x∗, −1) ∈NC

epi f, (¯x, f(¯x))

}.
This set is always σ(E∗, E)-closed but may be empty. However, if ¯x is a
local minimizer of f, then o ∈∂↑f(¯x). Moreover, Corollary 11.3.2 shows that
∂↑f(¯x) = ∂◦f(¯x) for any ¯x ∈E whenever f is locally L-continuous on E.
(II) Rockafellar [184] (see also [186, 189]) deﬁnes the (regular) subderivative
f ↑(¯x, ·) : E →R of f at ¯x as
f ↑(¯x, y) := lim
ϵ↓0 lim sup
(x,α)→f ¯x
inf
z∈B(y,ϵ)
f(x + τz) −α
τ
.
In this context, (x, α) →f ¯x means (x, α) ∈epi f, x →¯x, and α →f(¯x).
Rockafellar shows that f ↑(¯x, ·) is l.s.c. and that f ↑(¯x, o) = −∞if and only if
∂↑f(¯x) = ∅. If f ↑(¯x, o) > −∞, then f ↑(¯x, o) = 0, f ↑(¯x, ·) is sublinear, and
epi f ↑(¯x, ·) = TC

epi f, (¯x, f(¯x))

.
It then follows that f ↑(¯x, ·) is the support functional of the Clarke subdiﬀer-
ential, i.e.,
∂↑f(¯x) = {x∗∈E∗| ⟨x∗, y⟩≤f ↑(¯x, y)
∀y ∈E}.

348
A Appendix: Further Topics
The functional f is said to be directionally Lipschitz at ¯x if epi f is epi-
Lipschitz at (¯x, f(¯x)). Moreover, f is said to be subdiﬀerentially regular if
f ↑(¯x, y) = f H(¯x, y)
∀y ∈E;
this is equivalent to epi f being a tangentially regular set. If f is locally L-
continuous around ¯x, then f is subdiﬀerentially regular if and only if f is
regular in the sense of Clarke. Rockafellar shows that the sum rule
∂↑(f + g)(¯x) ⊆∂↑f(¯x) + ∂↑g(¯x)
(⋄)
holds if g is directionally Lipschitz at ¯x and dom f ↑(¯x, ·) ∩int domg↑(¯x, ·)
is nonempty. The sum rule holds with equality if, in addition, f and g are
subdiﬀerentially regular. Certain chain rules are also established.
(III) Michel and Penot [129,130] study several types of directional derivatives
and associated subdiﬀerentials. Their aim is to generalize the G-derivative
rather than the strict H-derivative as does the Clarke subdiﬀerential (cf. Re-
mark 7.3.10).
Using the epi-limit convergence concept, Michel and Penot deﬁne, among
others, the pseudo-strict derivative of f at ¯x as
f ∧(¯x, y) := sup
z∈E
eLim sup
τ↓0,z′→z
(¯x+τz′,α)→f ¯x
1
τ

f(¯x + τy + τz′) −α

.
The functional f ∧(¯x, ·) is shown to be l.s.c. and sublinear. If f is locally L-
continuous around ¯x, then f ∧(¯x, ·) coincides with f ♦(¯x, ·). If the directional
G-derivative fG(¯x, ·) exists, is ﬁnite and sublinear, then f ∧(¯x, ·) = fG(¯x, ·).
The associated subdiﬀerential, deﬁned as
∂∧f(¯x) := {x∗∈E∗| ⟨x∗, y⟩≤f ∧(¯x, y) ∀y ∈E},
thus satisﬁes ∂∧f(¯x) = {f ′(¯x)} whenever f is G-diﬀerentiable at ¯x. If ¯x is a
local minimizer of f, then o ∈∂∧f(¯x). Under certain regularity assumptions,
the sum rule ∂∧(f +g)(¯x) ⊆∂∧f(¯x)+∂∧g(¯x) and a chain rule are established.
Finally, multiplier rules are derived in [130].
(IV) Various other generalized derivative concepts were introduced and stud-
ied. Some of them are Halkin’s screen [83], Treiman’s B-derivatives [206,207],
and Warga’s derivate containers [213, 214]. Much was done by Hiriart-
Urruty [84,85,87] in clarifying and reﬁning these derivative concepts.
(V) Concerning sensitivity analysis, we refer in the ﬁnite-dimensional case to
Klatte and Kummer [111], Luderer et al. [126], and Rockafellar and Wets [189],
and in the inﬁnite-dimensional case to Bonnans and Shapiro [16], Clarke et
al. [39], and Mordukhovich [136] as well as to the literature cited in these
books.

A Appendix: Further Topics
349
(VI) Following Borwein and Zhu [23], we started the diﬀerential analysis of
lower semicontinuous functionals with Zhu’s nonlocal fuzzy sum rule which,
in turn, is based on the Borwein–Preiss smooth variational principle. The
basis of Mordukhovich’s work constitutes his extremal principle. Another
fundamental result in nonsmooth analysis is a multidirectional mean value
theorem (such as Theorem 9.6.2) that originally goes back to Clarke and
Ledyaev [37,38]. In [39] this result is applied to establish, among others, non-
smooth implicit and inverse function theorems. Mordukhovich and Shao [140]
showed the equivalence of the extremal principle and the local fuzzy sum rule,
and Zhu [226] proved the equivalence of the latter to the nonlocal fuzzy sum
rule and to the multidirectional mean value theorem.
(VII) Ioﬀe systematically investigated approximate subdiﬀerentials; see,
among others, [94–98,100].
Let F denote the collection of all ﬁnite-dimensional vector subspaces of E.
If S is a nonempty subset of E, we write
f(S)(x) :=

f(x)
if x ∈S,
+∞
if x ∈E \ S.
Ioﬀe starts with the lower directional Hadamard derivative, which he calls
lower directional Dini derivative,
f H(¯x, y) := lim inf
τ↓0, z→y
1
τ

f(¯x + τz) −f(¯x)

∀y ∈E.
He then deﬁnes the Hadamard subdiﬀerential (or Dini subdiﬀerential)
∂−f(¯x) := {x∗∈E∗| ⟨x∗, y⟩≤f H(¯x, y) ∀y ∈E}
and the A-subdiﬀerential
∂Af(¯x) :=
6
L∈F
Lim sup
x→f ¯x ∂−f(x+L)(x).
Here, the Painlevé–Kuratowski upper limit is taken with respect to the norm
topology in E and the weak star topology in E∗. Observe that Ioﬀe utilizes
the topological form of the Painlevé–Kuratowski upper limit whereas Mor-
dukhovich utilizes the sequential form. The interrelation between the concepts
of Ioﬀe and Mordukhovich is discussed by Mordukhovich and Shao [142], see
also Mordukhovich [136].
Ioﬀe further deﬁnes the G-normal cone to the set M ⊆E at ¯x ∈M as
NG(M, ¯x) := cl∗
λ>0
λ∂AdM(¯x)

350
A Appendix: Further Topics
and, respectively, the G-subdiﬀerential and the singular G-subdiﬀerential of
f at ¯x as
∂Gf(¯x) :=

x∗∈E∗| (x∗, −1) ∈NG

epi f, (¯x, f(¯x))

,
∂∞
G f(¯x) :=

x∗∈E∗| (x∗, 0) ∈NG

epi f, (¯x, f(¯x))

.
The G-subdiﬀerential and the A-subdiﬀerential coincide for any function on
ﬁnite-dimensional normed vector spaces and for directionally Lipschitz func-
tions on arbitrary normed vector spaces. For convex functionals on any normed
vector space, the G-subdiﬀerential (in contrast to the A-subdiﬀerential) coin-
cides with the subdiﬀerential of convex analysis. In general, the sets ∂Af(¯x)
and ∂Gf(¯x) are not convex. However, they are minimal in a certain sense
among all “reasonable” subdiﬀerential constructions. In particular, for any
proper functional f one has ∂Cf(¯x) = co∗
∂Gf(¯x) + ∂∞
G f(¯x)

.
Ioﬀe develops an extensive calculus for these objects. For instance, if M1
and M2 are closed sets one of them being epi-Lipschitz at ¯x, then an appro-
priate regularity assumption ensures that
NG(M1 ∩M2, ¯x) ⊆NG(M1, ¯x) + NG(M2, ¯x),
with equality if NG(Mi, ¯x) = T(Mi, ¯x)◦for i = 1, 2. This result is veri-
ﬁed with the aid of Ekeland’s variational principle. It is then applied to
derive the following sum rule. If the functionals f and g are l.s.c. and one
of them is directionally Lipschitz at ¯x, then under the regularity assumption
∂∞
G f(¯x) ∩(−∂∞
G g(¯x)) = {o}, the sum rule (⋄) holds with ∂↑replaced by ∂G.
An analogous result is obtained for the A-subdiﬀerential. For an extended
chain rule in terms of ∂A see Jourani and Thibault [106]. We also refer to the
survey paper by Hiriart-Urruty et al. [90].
Multiplier rules in terms of G-subdiﬀerentials were established by Glover
et al. [74]. For an alternative proof of these multiplier rules and an interesting
discussion of the absence of constraint qualiﬁcations we refer to P¨uhl [172].
Modiﬁed multiplier rules were obtained by Glover and Craven [73].
(VIII) In these lectures, we conﬁned ourselves to ﬁrst-order necessary
optimality conditions (which are also suﬃcient in the convex case). For
second-order necessary and/or suﬃcient conditions we refer in the smooth
case to Bonnans and Shapiro [16] and the literature cited therein. Second-
order optimality conditions in terms of generalized derivatives are also treated
in many papers. As a small selection we refer to Ben-Tal and Zowe [14], Casas
and Tr¨oltzsch [29], Chaney [31], Cominetti [40], Mordukhovich [135], Mor-
dukhovich [136], Mordukhovich and Outrata [138], and Rockafellar [188].

References
1. R. A. Adams. Sobolev Spaces. Academic, Boston, 1978
2. C. D. Aliprantis and K. C. Border. Inﬁnite Dimensional Analysis. Springer,
Berlin Heidelberg New York, 1994
3. E. Asplund. Fréchet diﬀerentiability of convex functions. Acta Math., 121:
31–47, 1968
4. K. Atkinson and W. Han. Theoretical Numerical Analysis. Springer, Berlin
Heidelberg New York, 2001
5. J. -P. Aubin. Contingent derivatives of set-valued maps and existence of solu-
tions to nonlinear inclusions and diﬀerential inclusions. In L. Nachbin, editor,
Advances in Mathematics, Supplementary Studies, pages 160–232. Academic,
New York, 1981
6. J. -P. Aubin. Optima and Equilibria. Springer, Berlin Heidelberg New York,
1993
7. J. -P. Aubin and I. Ekeland. Applied Nonlinear Analysis. Wiley, New York,
1984
8. J. -P. Aubin and H. Frankowska. Set-Valued Analysis. Birkhäuser, Boston, 1990
9. V. Barbu and Th. Precupanu. Convexity and Optimization in Banach Spaces.
Sijthoﬀand Noordhoﬀ, Alphen aan de Rijn, 1978
10. M. S. Bazaraa, J. J. Goode, and M. Z. Nashed. On the cones of tangents
with applications to mathematical programming. J. Optim. Theory Appl., 13:
389–426, 1974
11. M. S. Bazaraa, H. D. Sherali, and C. M. Shetty. Nonlinear Programming:
Theory and Algorithms. Wiley, New York, 1993
12. M. S. Bazaraa and C. M. Shetty. Foundations of Optimization, volume 122
of Lecture Notes in Economics and Mathematical Systems. Springer, Berlin
Heidelberg New York, 1976
13. B. Beauzamy. Introduction to Banach Spaces and Their Geometry. North-
Holland, Amsterdam, 1985
14. A. Ben-Tal and J. Zowe. A uniﬁed theory of ﬁrst and second order conditions
for extremum problems in topological vector spaces. Math. Progr. Stud., 19:
39–76, 1982
15. E. Bishop and R. R. Phelps. A proof that every Banach space is subreﬂexive.
Bull. Am. Math. Soc., 67:97–98, 1961

352
References
16. J. F. Bonnans and A. Shapiro. Perturbation Analysis of Optimization Problems.
Springer, Berlin Heidelberg New York, 2000
17. J. M. Borwein and A. D. Ioﬀe. Proximal analysis in smooth spaces. Set-Valued
Anal., 4:1–24, 1996
18. J. M. Borwein and A. S. Lewis. Convex Analysis and Nonlinear Optimization.
Springer, Berlin Heidelberg New York, 2000
19. J. M. Borwein and D. Preiss. A smooth variational principle with applications
to subdiﬀerentiability and to diﬀerentiability of convex functions. Trans. Am.
Math. Soc., 303:517–527, 1987
20. J. M. Borwein and H. M. Strójwas. Proximal analysis and boundaries of closed
sets in Banach space. I: Theory. Can. J. Math., 38:431–452, 1986
21. J. M. Borwein, J. S. Treiman, and Q. J. Zhu. Necessary conditions for con-
strained optimization problems with semicontinuous and continuous data.
Trans. Am. Math. Soc., 350:2409–2429, 1998
22. J. M. Borwein and Q. J. Zhu. Viscosity solutions and viscosity subderivatives in
smooth Banach spaces with applications to metric regularity. SIAM J. Control
Optim., 34:1568–1591, 1996
23. J. M. Borwein and Q. J. Zhu. A survey of subdiﬀerential calculus with appli-
cations. Nonlinear Anal., 38:687–773, 1999
24. J. M. Borwein and Q. J. Zhu. Techniques of Variational Analysis. Springer,
Berlin Heidelberg New York, 2005
25. J. M. Borwein and D. M. Zhuang. Veriﬁable necessary and suﬃcient conditions
for openness and regularity of set-valued and single-valued maps. J. Math.
Anal. Appl., 134:441–459, 1988
26. G. Bouligand. Sur les surfaces dépourvues de points hyperlimites. Ann. Soc.
Polon. Math., 9:32–41, 1930
27. D. Braess. Nonlinear Approximation Theory. Springer, Berlin Heidelberg
New York, 1986
28. A. Brøndsted. Conjugate convex functions in topological vector spaces. Fys.
Medd. Dans. Vid. Selsk., 34:1–26, 1964
29. E. Casas and F. Tröltzsch. Second-order necessary and suﬃcient optimality
conditions for optimization problems and applications to control theory. SIAM
J. Optim., 13:406–431, 2002
30. L. Cesari. Optimization – Theory and Applications. Springer, Berlin Heidelberg
New York, 1983
31. R. W. Chaney. A general suﬃciency theorem for nonsmooth nonlinear pro-
gramming. Trans. Am. Math. Soc., 276:235–245, 1983
32. I. Cioranescu. Geometry of Banach Spaces, Duality Mappings and Nonlinear
Problems. Kluwer, Dordrecht, 1990
33. F. H. Clarke. Necessary Conditions for Nonsmooth Problems in Optimal Con-
trol and the Calculus of Variations. Ph.D. Thesis, University of Washington,
1973
34. F. H. Clarke. Generalized gradients and applications. Trans. Am. Math. Soc.,
205:247–262, 1975
35. F. H. Clarke. A new approach to Lagrange multipliers. Math. Oper. Res., 1:
165–174, 1976
36. F. H. Clarke. Optimization and Nonsmooth Analysis. SIAM, Philadelphia, 1990
37. F. H. Clarke and Yu. S. Ledyaev. Mean value inequalities. Proc. Am. Math.
Soc., 122:1075–1083, 1994

References
353
38. F. H. Clarke and Yu. S. Ledyaev. Mean value inequalities in Hilbert space.
Trans. Am. Math. Soc., 344:307–324, 1994
39. F. H. Clarke, Yu. S. Ledyaev, R. J. Stern, and P. R. Wolenski. Nonsmooth
Analysis and Control Theory. Springer, Berlin Heidelberg New York, 1998
40. R. Cominetti. Metric regularity, tangent sets and second-order optimality con-
ditions. Appl. Math. Optim., 21:265–287, 1990
41. M. G. Crandall, L. C. Evans, and P. -L. Lions. Some properties of viscosity
solutions of Hamilton–Jacobi equations. Trans. Am. Math. Soc., 282:487–502,
1984
42. M. G. Crandall and P. -L. Lions. Viscosity solutions of Hamilton–Jacobi equa-
tions. Trans. Am. Math. Soc., 277:1–41, 1983
43. B. D. Craven. Mathematical Programming and Control Theory. Chapman and
Hall, London, 1978
44. B. D. Craven. Control and Optimization. Chapman and Hall, London, 1995
45. B. D. Craven, J. Gwinner, and V. Jeyakumar. Nonconvex theorems of the
alternative and minimization. Optimization, 18:151–163, 1987
46. M. Degiovanni and F. Schuricht. Buckling of nonlinearly elastic rods in the
presence of obstacles treated by nonsmooth critical point theory. Math. Ann.
311, 675–728, 1998
47. V. F. Demyanov and A. M. Rubinov. Quasidiﬀerentiable Calculus. Optimiza-
tion Software, Publications Division, New York, 1986
48. V. F. Demyanov and A. M. Rubinov. Foundations of Nonsmooth Analysis and
Quasidiﬀerentiable Calculus. Nauka, Moscow, 1990 (in Russian)
49. R. Deville, G. Godefroy, and V. Zizler. A smooth variational principle with
applications to Hamilton–Jacobi equations in inﬁnite dimensions. J. Funct.
Anal., 111:197–212, 1993
50. R. Deville, G. Godefroy, and V. Zizler. Smoothness and Renormings in Banach
Spaces. Pitman Monographs and Surveys in Pure and Applied Mathematics,
No. 64. Wiley, New York, 1993
51. J. Diestel. Geometry of Banach Spaces. Lecture Notes in Mathematics.
Springer, Berlin Heidelberg New York, 1974
52. J. Diestel. Sequences and Series in Banach Spaces. Springer, Berlin Heidelberg
New York, 1983
53. J. Dieudonné. Foundations of Modern Analysis. Academic, New York, 1960
54. A. V. Dmitruk, A. A. Milyutin, and N. P. Osmolovskii. Lyusternik’s theorem
and the theory of extrema. Russ. Math. Surv., 35:11–51, 1980
55. S. Dolecki. A general theory of necessary optimality conditions. J. Math. Anal.
Appl., 78:267–308, 1980
56. I. Ekeland. On the variational principle. J. Math. Anal. Appl., 47:324–353, 1974
57. I. Ekeland. Nonconvex minimization problems. Bull. Am. Math. Soc. (N.S.),
1:443–474, 1979
58. I. Ekeland and R. Temam. Convex Analysis and Variational Problems. North-
Holland, Amsterdam, 1976
59. K. -H. Elster, R. Reinhardt, M. Schäuble, and G. Donath. Einführung in die
nichtlineare Optimierung. Teubner, Leipzig, 1977
60. J. Elstrodt. Maß- und Integrationstheorie. Springer, Berlin Heidelberg New
York, 1999
61. E. Ernst, M. Théra, and C. Zalinescu. Slice-continuous sets in reﬂexive Banach
spaces: convex constrained optimization and strict convex separation. J. Funct.
Anal., 223:179–203, 2005

354
References
62. H. Eschrig. The Fundamentals of Density Functional Theory. Edition am
Gutenbergplatz, Leipzig, 2003
63. L. C. Evans and R. F. Gariepy. Measure Theory and Fine Properties of Func-
tions. CRC, Boca Raton, 1992
64. K. Fan. Asymptotic cones and duality of linear relations. In O. Shisha, editor,
Inequalities, volume 2, pages 179–186. Academic, London, 1970
65. W. Fenchel. On conjugate convex functions. Can. J. Math., 1:73–77, 1949
66. W. Fenchel. Convex Cones, Sets and Functions. Lecture Notes. Princeton
University, Princeton, 1951
67. L. A. Fernandez. On the limits of the Lagrange multiplier rule. SIAM Rev.,
39:292–297, 1997
68. O. Ferrero. Theorems of the alternative for set-valued functions in inﬁnite-
dimensional spaces. Optimization, 20:167–175, 1989
69. D. G. Figueiredo. Lectures on the Ekeland Variational Principle with Applica-
tions and Detours. Springer (Published for the Tata Institute of Fundamental
Research, Bombay), Berlin Heidelberg New York, 1989
70. F. Giannessi. Theorems of the alternative for multifunctions with applications
to optimization: general results. J. Optim. Theory Appl., 55:233–256, 1987
71. M. Giaquinta and S. Hildebrandt. Calculus of Variations I. Springer, Berlin
Heidelberg New York, 1996
72. M. Giaquinta and S. Hildebrandt. Calculus of Variations II. Springer, Berlin
Heidelberg New York, 1996
73. B. M. Glover and B. D. Craven. A Fritz John optimality condition using the
approximate subdiﬀerential. J. Optim. Theory Appl., 82:253–265, 1994
74. B. M. Glover, B. D. Craven, and S. D. Flåm. A generalized Karush–Kuhn–
Tucker optimality condition without constraint qualiﬁcation using the approx-
imate subdiﬀerential. Numer. Funct. Anal. Optim., 14:333–353, 1993
75. B. M. Glover, V. Jeyakumar, and W. Oettli. A Farkas lemma for diﬀerence
sublinear systems and quasidiﬀerentiable programming. Math. Oper. Res., 63:
109–125, 1994
76. A.
Göpfert.
Mathematische
Optimierung
in
allgemeinen
Vektorräumen.
Teubner, Leipzig, 1973
77. A. Göpfert, Chr. Tammer, H. Riahi, and C. Zalinescu. Variational Methods in
Partially Ordered Spaces. Springer, Berlin Heidelberg New York, 2003
78. A. Göpfert, Chr. Tammer, and C. Zalinescu. On the vectorial Ekeland’s vari-
ational principle and minimal points in product spaces. Nonlinear Anal., 39:
909–922, 2000
79. L. M. Graves. Some mapping theorems. Duke Math. J., 17:111–114, 1950
80. K. Groh. On monotone operators and forms. J. Convex Anal., 12:417–429, 2005
81. Ch. Großmann and H. -G. Roos. Numerical Treatment of Partial Diﬀerential
Equations. Springer, Berlin Heidelberg, New York, to appear
82. H. Halkin. Implicit functions and optimization problems without continuous
diﬀerentiability of the data. SIAM J. Control, 12:229–236, 1974
83. H. Halkin. Mathematical programming without diﬀerentiability. In D. L. Russell,
editor, Calculus of Variations and Control Theory, pages 279–288. Academic,
New York, 1976
84. J. -B. Hiriart-Urruty. Reﬁnements of necessary optimality conditions in non-
diﬀerentiable programming I. Appl. Math. Optim., 5:63–82, 1979
85. J. -B. Hiriart-Urruty. Tangent cones, generalized gradients and mathematical
programming in Banach spaces. Math. Oper. Res., 4:79–97, 1979

References
355
86. J. -B. Hiriart-Urruty. Mean value theorems in nonsmooth analysis. Numer.
Funct. Anal. Optim., 2:1–30, 1980
87. J. -B. Hiriart-Urruty. Reﬁnements of necessary optimality conditions in non-
diﬀerentiable programming II. Math. Progr. Stud., 19:120–139, 1982
88. J. -B. Hiriart-Urruty and C. Lemaréchal. Convex Analysis and Minimization
Algorithms. I: Fundamentals. Springer, Berlin Heidelberg New York, 1993
89. J. -B. Hiriart-Urruty and C. Lemaréchal. Convex Analysis and Minimiza-
tion Algorithms. II: Advanced Theory and Bundle Methods. Springer, Berlin
Heidelberg New York, 1993
90. J. -B. Hiriart-Urruty, M. Moussaoui, A. Seeger, and M. Volle. Subdiﬀerential
calculus without constraint qualiﬁcation, using approximate subdiﬀerentials:
a survey. Nonlinear Anal., 24:1727–1754, 1995
91. R. B. Holmes. A Course on Optimization and Best Approximation. Springer,
Berlin Heidelberg New York, 1972
92. R. B. Holmes. Geometric Functional Analysis and Its Applications. Springer,
Berlin Heidelberg New York, 1975
93. A. D. Ioﬀe. Regular points of Lipschitz functions. Trans. Am. Math. Soc.,
251:61–69, 1979
94. A. D. Ioﬀe. Nonsmooth analysis: diﬀerential calculus of nondiﬀerentiable map-
pings. Trans. Am. Math. Soc., 266:1–56, 1981
95. A. D. Ioﬀe. Approximate subdiﬀerentials and applications. I. The ﬁnite dimen-
sional theory. Trans. Am. Math. Soc., 281(1):389–416, 1984
96. A. D. Ioﬀe. Approximate subdiﬀerentials and applications. II. Mathematika,
33:11–128, 1986
97. A. D. Ioﬀe. Approximate subdiﬀerentials and applications. III. The metric
theory. Mathematika, 36:1–38, 1989
98. A. D. Ioﬀe. Proximal analysis and approximate subdiﬀerentials. J. Lond. Math.
Soc., 41:175–192, 1990
99. A. D. Ioﬀe. A Lagrange multiplier rule with small convex-valued subdiﬀeren-
tials for nonsmooth problems of mathematical programming involving equality
and nonfunctional constraints. Math. Progr. Stud., 58:137–145, 1993
100. A. D. Ioﬀe. Nonsmooth subdiﬀerentials: their calculus and applications.
In V. Lakshmikantham, editor, Proceedings of the First World Congress of
Nonlinear Analysts, pages 2299–2310. De Gruyter, Berlin, 1996
101. A. D. Ioﬀe and V. Tikhomirov. Theory of Extremal Problems. North-Holland,
New York, 1978 (German ed.: Deutscher Verlag der Wissenschaften, Berlin,
1979; original Russian ed.: Nauka, Moskow, 1974)
102. J. Jahn. Vector Optimization: Theory, Applications and Extensions. Springer,
Berlin Heidelberg New York, 2004
103. G. J. O. Jameson. Topology and Normed Spaces. Chapman and Hall, London,
1974
104. V. Jeyakumar. Convexlike alternative theorems and mathematical program-
ming. Optimization, 16:643–652, 1985
105. F. John. Extremum problems with inequalities as side conditions. In K. O.
Friedrichs, O. E. Neugebauer, and J. J. Stoker, editors, Studies and Essays:
Courant Anniversary Volume, pages 187–204. Wiley-Interscience, New York,
1948
106. A. Jourani and L. Thibault. The approximate subdiﬀerential of composite func-
tions. Bull. Aust. Math. Soc., 47:443–455, 1993

356
References
107. A. Jourani and L. Thibault. Metric regularity for strongly compactly
Lipschitzian mappings. Nonlinear Anal., 24:229–240, 1995
108. M. Kadec. Spaces isomorphic to a locally uniformly convex space. Izv. Vysš.
Učebn. Zaved. Mat., 6:51–57, 1959 (in Russian)
109. W. Karush. Minima of Functions of Several Variables with Inequalities as Side
Conditions. Master’s Thesis, University of Chicago, Chicago, 1939
110. D. Klatte and B. Kummer. Contingent derivatives of implicit (multi-)functions
and stationary points. Ann. Oper. Res., 101:313–331, 2001
111. D. Klatte and B. Kummer. Nonsmooth Equations in Optimization. Regularity,
Calculus, Methods and Applications. Kluwer, Dordrecht, 2002
112. W. Krabs. Optimierung und Approximation. Teubner, Stuttgart, 1975
113. A. Y. Kruger and B. S. Mordukhovich. Extremal points and Euler equations
in nonsmooth optimization. Dokl. Akad. Nauk BSSR, 24:684–687, 1980 (in
Russian)
114. H. W. Kuhn and A. W. Tucker. Nonlinear programming. In J. Neyman, editor,
Proceedings of the Second Berkeley Symposium on Mathematical Statistics and
Probability, pages 481–492. University of California Press, Berkeley, 1951
115. G. Köthe. Topologische lineare Räume I. Springer, Berlin Heidelberg New York,
1960
116. M. Landsberg and W. Schirotzek. Mazur–Orlicz type theorems with some
applications. Math. Nachr., 79:331–341, 1977
117. J. B. Lasserre. A Farkas lemma without a standard closure condition. SIAM
J. Control Optim., 35:265–272, 1997
118. P. -J. Laurent. Approximation et Optimisation. Hermann, Paris, 1972
119. G. Lebourg. Valeur moyenne pour gradient généralisé. C. R. Acad. Sci. Paris,
281:795–797, 1975
120. Yu. S. Ledyaev and Q. J. Zhu. Implicit multifunction theorems. Set-Valued
Anal., 7:209–238, 1999
121. Yu. S. Ledyaev and Q. J. Zhu. Implicit multifunction theorems. Preprint
(revised
version),
http://homepages.wmich.edu/~zhu/papers/implicit.
html, 2006
122. U. Ledzewicz and S. Walczak. On the Lyusternik theorem for nonsmooth
operators. Nonlinear Anal., 22:121–128, 1994
123. P. D. Loewen. Optimal Control via Nonsmooth Analysis. American Mathemat-
ical Society, Providence, 1993
124. P. D. Loewen. A mean value theorem for Fréchet subgradients. Nonlinear
Anal., 23:1365–1381, 1994
125. P. D. Loewen and X. Wang. A generalized variational principle. Can. J. Math.,
53(6):1174–1193, 2001
126. B. Luderer, L. Minchenko, and T. Satsura. Multivalued Analysis and Nonlinear
Programming Problems with Perturbations. Kluwer, Dordrecht, 2002
127. D. Luenberger. Optimization by Vector Space Methods. Wiley, New York, 1969
128. L. A. Lyusternik. On constrained extrema of functionals. Mat. Sb., 41:390–401,
1934 (in Russian)
129. P. Michel and J. -P. Penot. Calcul sous-diﬀérentiel pour les fonctions lipschitzi-
ennes et non lipschitziennes. C. R. Acad. Sci. Paris, 298:269–272, 1984
130. P. Michel and J. -P. Penot. A generalized derivative for calm and stable func-
tions. Diﬀ. Int. Eqs., 5:433–454, 1992
131. H. Minkowski. Theorie der konvexen Körper, insbesondere Begründung ihres
Oberﬂächenbegriﬀs. Teubner, Leipzig, 1911

References
357
132. B. S. Mordukhovich. Maximum principle in the problem of time optimal control
with nonsmooth constraints. J. Appl. Math. Mech., 40:960–969, 1976
133. B. S. Mordukhovich. Metric approximations and necessary optimality condi-
tions for general classes of nonsmooth extremal problems. Sov. Math. Dokl.,
22:526–530, 1980
134. B. S. Mordukhovich. Approximation Methods in Problems of Optimization and
Control. Nauka, Moscow, 1988 (in Russian)
135. B. S. Mordukhovich. Sensitivity analysis in nonsmooth optimization. In
D. A. Field and V. Komkov, editors, Theoretical Aspects of Industrial Design,
volume 58 of Proceedings in Applied Mathematics, pages 32–46. SIAM,
Philadelphia, 1992
136. B. S. Mordukhovich. Variational Analysis and Generalized Diﬀerentiation I:
Basic Theory. Springer, Berlin Heidelberg New York, 2006
137. B. S. Mordukhovich. Variational Analysis and Generalized Diﬀerentiation II:
Applications. Springer, Berlin Heidelberg New York, 2006
138. B. S. Mordukhovich and J. V. Outrata. On second-order subdiﬀerentials and
their applications. SIAM J. Optim., 12:139–169, 2001
139. B. S. Mordukhovich and Y. Shao. Diﬀerential characterizations of cover-
ing, metric regularity, and Lipschitzian properties of multifunctions between
Banach spaces. Nonlinear Anal., 25:1401–1424, 1995
140. B. S. Mordukhovich and Y. Shao. Extremal characterizations of Asplund
spaces. Proc. Am. Math. Soc., 124:197–205, 1996
141. B. S. Mordukhovich and Y. Shao. Nonconvex coderivative calculus for inﬁnite-
dimensional multifunctions. Set-Valued Anal., 4:205–236, 1996
142. B. S. Mordukhovich and Y. Shao. Nonsmooth sequential analysis in Asplund
spaces. Trans. Am. Math. Soc., 348:1235–1280, 1996
143. B. S. Mordukhovich and Y. Shao. Mixed coderivatives of set-valued mappings
in variational analysis. J. Appl. Anal., 4:269–294, 1998
144. B. S. Mordukhovich, J. S. Treiman, and Q. J. Zhu. An extended extremal
principle with applications to multiobjective optimization. SIAM J. Optim.,
14:359–379, 2003
145. B. S. Mordukhovich and B. Wang. Extensions of generalized diﬀerential calcu-
lus in Asplund spaces. J. Math. Anal. Appl., 272:164–186, 2002
146. B. S. Mordukhovich and B. Wang. Necessary suboptimality and optimality
conditions via variational principles. SIAM J. Control Optim., 41:623–640, 2002
147. J. -J. Moreau. Functions convexes duales et points proximaux dans un espace
hilbertian. C. R. Acad. Sci. Paris, 255:2897–2899, 1962
148. J. -J. Moreau. Propriété des applications ‘prox’. C. R. Acad. Sci. Paris,
256:1069–1071, 1963
149. M. M. Mäkelä and P. Neittaanmäki. Nonsmooth Optimization. World Scientiﬁc,
Singapore, 1992
150. L. W. Neustadt. Optimization: A Theory of Necessary Conditions. Princeton
University Press, Princeton, 1976
151. H. V. Ngai, D. T. Luc, and M. Théra. Extensions of Fréchet ϵ-subdiﬀerential
calculus and applications. J. Math. Anal. Appl., 268:266–290, 2002
152. N. V. Ngai and M. Théra. Metric inequality, subdiﬀerential calculus and
applications. Set-Valued Anal., 9:187–216, 2001
153. N. V. Ngai and M. Théra. A fuzzy necessary optimality condition for non-
Lipschitz optimization in Asplund spaces. SIAM J. Optim., 12:656–668, 2002

358
References
154. N. V. Ngai and M. Théra. Error bounds and implicit multifunction theorem
in smooth Banach spaces and applications to optimization. Set-Valued Anal.,
12:195–223, 2004
155. D. Pallaschke. Ekeland’s variational principle, convex functions and Asplund
spaces. In W. Krabs and J. Zowe, editors, Modern Methods of Optimization,
pages 274–312. Springer, Berlin Heidelberg New York, 1992
156. D. Pallaschke and S. Rolewicz. Foundations of Mathematical Optimization:
Convex Analysis Without Linearity. Kluwer, Dordrecht, 1997
157. P.
D.
Panagiotopoulos.
Hemivariational
Inequalities.
Springer,
Berlin
Heidelberg New York, 1993
158. N. S. Papageorgiou and L. Gasinski. Nonsmooth Critical Point Theory and
Nonlinear Boundary Value Problems. Chapman and Hall, Boca Raton, 2004
159. J. -P. Penot. Calcul sous-diﬀerentiel et optimisation. J. Funct. Anal., 27:
248–276, 1978
160. J. -P. Penot. On regularity conditions in mathematical programming. Math.
Progr. Stud., 19:167–199, 1982
161. J. -P. Penot. Open mapping theorems and linearization stability. Numer. Funct.
Anal. Optim., 8:21–35, 1985
162. J. -P. Penot. The drop theorem, the petal theorem and Ekeland’s variational
principle. Nonlinear Anal., 10:813–822, 1986
163. J. -P. Penot. On the mean value theorem. Optimization, 19:147–156, 1988
164. J. -P. Penot. Metric regularity, openness and Lipschitzian behavior of multi-
functions. Nonlinear Anal., 13:629–643, 1989
165. R. R. Phelps. Convex Functions, Monotone Operators and Diﬀerentiability,
volume 1364 of Lecture Notes in Mathematics. Springer, Berlin Heidelberg New
York, 1993
166. D. Preiss. Fréchet derivatives of Lipschitzian functions. J. Funct. Anal., 91:312–
345, 1990
167. D. Preiss and L. Zajíček. Fréchet diﬀerentiation of convex functions in a Banach
space with a separable dual. Proc. Am. Math. Soc., 91(2):202–204, 1984
168. B. N. Pšeničnyi. Convex Analysis and Extremal Problems. Nauka, Moscow,
1969 (in Russian)
169. B. N. Pšeničnyj. Notwendige Optimalitätsbedingungen. Teubner, Leipzig, 1972
170. B. N. Pshenichnyi. Necessary Conditions for an Extremum. Dekker, New
York, 1971 (German ed.: Teubner, Leipzig, 1972; original Russian ed.: Nauka,
Moscow, 1969)
171. H. Pühl. Convexity and openness with linear rate. J. Math. Anal. Appl.,
227:382–395, 1998
172. H. Pühl. Nichtdiﬀerenzierbare Extremalprobleme in Banachräumen: Regular-
itätsbedingungen sowie die Approximation von Niveaumengen. Doctoral Thesis,
Technische Universität Dresden, Dresden, 1999
173. H. Pühl and W. Schirotzek. Linear semi-openness and the Lyusternik theorem.
Eur. J. Oper. Res., 157:16–27, 2004
174. A. Roberts and D. Varberg. Convex Functions. Academic, New York, 1973
175. S. M. Robinson. Regularity and stability for convex multivalued functions.
Math. Oper. Res., 1:130–143, 1976
176. S. M. Robinson. Stability theory for systems of inequalities. Part II. Diﬀeren-
tiable nonlinear systems. SIAM J. Numer. Anal., 13:497–513, 1976
177. R. T. Rockafellar. Convex Functions and Dual Extremum Problems. Ph.D.
Thesis, Harvard University, Cambridge, 1963

References
359
178. R. T. Rockafellar. Level sets and continuity of conjugate convex functions.
Trans. Am. Math. Soc., 123:46–63, 1966
179. R. T. Rockafellar. Duality and stability in extremum problems involving convex
functions. Pac. J. Math., 21:167–187, 1967
180. R. T. Rockafellar. Convex Analysis. Princeton University Press, Princeton,
1970
181. R. T. Rockafellar. On the maximal monotonicity of subdiﬀerential mappings.
Pac. J. Math., 33:209–216, 1970
182. R. T. Rockafellar. On the maximality of sums of nonlinear monotone operators.
Trans. Am. Math. Soc., 149:75–88, 1970
183. R. T. Rockafellar. Directionally Lipschitzian functions and subdiﬀerential cal-
culus. Proc. Lond. Math. Soc., 39:331–355, 1979
184. R. T. Rockafellar. Generalized directional derivatives and subgradients of non-
convex functions. Can. J. Math., 32:157–180, 1980
185. R. T. Rockafellar. Proximal subgradients, marginal values and augmented
Lagrangians in nonconvex optimization. Math. Oper. Res., 6:424–436, 1981
186. R. T. Rockafellar. The Theory of Subgradients and Its Applications to Problems
of Optimization: Convex and Nonconvex Functions. Heldermann, Berlin, 1981
187. R. T. Rockafellar. Extensions of subgradient calculus with applications to
optimization. Nonlinear Anal., 9:665–698, 1985
188. R. T. Rockafellar. Second-order optimality conditions in nonlinear program-
ming obtained by way of epi-derivatives. Math. Oper. Res., 14:462–484, 1989
189. R. T. Rockafellar and R. J. -B. Wets. Variational Analysis. Springer, Berlin
Heidelberg New York, 1998
190. H. -P. Scheﬄer. Beiträge zur Analysis von nichtglatten Optimierungsproblemen.
Doctoral Thesis, Technische Universität Dresden, Dresden, 1987
191. H. -P. Scheﬄer. Mean value properties of nondiﬀerentiable functions and their
application in nonsmooth analysis. Optimization, 20:743–759, 1989
192. H. -P. Scheﬄer and W. Schirotzek. Necessary optimality conditions for non-
smooth problems with operator constraints. Z. Anal. Anwend., 7:419–430, 1988
193. W. Schirotzek. On Farkas type theorems. Commentat. Math. Univ. Carol.,
22:1–14, 1981
194. W. Schirotzek. On a theorem of Ky Fan and its application to nondiﬀerentiable
optimization. Optimization, 16:353–366, 1985
195. W. Schirotzek. Nonasymptotic necessary conditions for nonsmooth inﬁnite
optimization problems. J. Math. Anal. Appl., 118:535–546, 1986
196. W. Schirotzek. Diﬀerenzierbare Extremalprobleme. Teubner, Leipzig, 1989
197. L. Schwartz. Analyse II. Calcul Diﬀérentiel et Équations Diﬀérentielles.
Hermann, Paris, 1997
198. S. Simons. The least slope of a convex function and the maximal monotonicity
of its subdiﬀerential. J. Optim. Theory Appl., 71:127–136, 1991
199. I. Singer. Generalizations of methods of best approximation to convex opti-
mization in locally convex spaces I: extension of continuous linear functionals
and characterizations of solutions of continuous convex programs. Rev. Roum.
Math. Pures Appl., 19:65–77, 1974
200. C. Stegall. The Radon–Nikodým property in conjugate Banach spaces. Trans.
Am. Math. Soc., 264:507–519, 1984
201. J. Stoer and C. Witzgall. Convexity and Optimization in Finite Dimensions.
Springer, Berlin Heidelberg New York, 1970

360
References
202. M. Studniarski. Mean value theorems and suﬃcient optimality conditions for
nonsmooth functions. J. Math. Anal. Appl., 111:313–326, 1985
203. M. Studniarski. Mean value theorems for functions possessing ﬁrst order convex
approximations. Applications in optimization theory. Z. Anal. Anwend., 4:125–
132, 1985
204. A. I. Subbotin. Generalized Solutions of First-Order PDEs. The Dynamical
Optimization Perspective. Birkhäuser, Basel, 1994
205. K. Sundaresan and S. Swaminathan. Geometry and Nonlinear Analysis in
Banach Spaces. Lecture Notes in Mathematics. Springer, Berlin Heidelberg New
York, 1985
206. J. S. Treiman. Finite dimensional optimality conditions: B-gradients. J. Optim.
Theory Appl., 62:139–150, 1989
207. J. S. Treiman. Optimal control with small generalized gradients. SIAM J. Con-
trol Optim., 28:720–732, 1990
208. S. Troyanski. On locally uniformly convex and diﬀerentiable norms in certain
non-separable spaces. Stud. Math., 37:173–180, 1971
209. F. Tröltzsch. Optimality Conditions for Parabolic Control Problems and
Applications. Teubner, Leipzig, 1984
210. H. Tuy. Convex Inequalities and the Hahn–Banach Theorem. Number 97 in
Dissertationes Mathematicae (Rozprawy Matematyczne), Warszawa, 1972
211. C. Ursescu. Multifunctions with convex closed graph. Czech. Math. J., 25:438–
441, 1975
212. W. Walter. Analysis 1. Springer, Berlin Heidelberg New York, 2004
213. J. Warga. Derivate containers, inverse functions, and controllability. In
D. L. Russell, editor, Calculus of Variations and Control Theory, pages 13–
46. Academic, New York, 1976
214. J. Warga. Fat homeomorphisms and unbounded derivate containers. J. Math.
Anal. Appl., 81:545–560, 1981
215. D. Werner. Funktionalanalysis. Springer, Berlin Heidelberg New York, 1997
216. S. Yamamuro. Diﬀerential Calculus in Topological Linear Spaces, volume 374
of Lecture Notes in Mathematics. Springer, Berlin Heidelberg New York, 1974
217. J. J. Ye. Multiplier rules under mixed assumptions of diﬀerentiability and
Lipschitz continuity. SIAM J. Control Optim., 39:1441–1460, 1999
218. K. Yosida. Functional Analysis. Springer, Berlin Heidelberg New York, 1965
219. D. Yost. Asplund spaces for beginners. Acta Univ. Carol. Math. Phys., 34:159–
177, 1993
220. D. Zagrodny. Approximate mean value theorem for upper subderivatives. Non-
linear Anal., 12:1413–1428, 1988
221. E. Zeidler. Nonlinear Functional Analysis and Its Applications III: Variational
Methods and Optimization. Springer, Berlin Heidelberg New York, 1984
222. E. Zeidler. Nonlinear Functional Analysis and Its Applications I. Fixed-Point
Theory. Springer, Berlin Heidelberg New York, 1986
223. E. Zeidler. Nonlinear Functional Analysis and Its Applications II A: Linear
Monotone Operators. Springer, Berlin Heidelberg New York, 1990
224. E. Zeidler. Nonlinear Functional Analysis and Its Applications II B: Nonlinear
Monotone Operators. Springer, Berlin Heidelberg New York, 1990
225. Q. J. Zhu. Clarke–Ledyaev mean value inequality in smooth Banach spaces.
Nonlinear Anal., 32:315–324, 1998
226. Q. J. Zhu. The equivalence of several basic theorems for subdiﬀerentials. Set-
Valued Anal., 6:171–185, 1998

References
361
227. Q. J. Zhu. Hamiltonian necessary conditions for a multiobjective optimal con-
trol problem with endpoint constraints. SIAM J. Control Optim., 39:97–112,
2000
228. W. P. Ziemer. Weakly Diﬀerentiable Functions. Springer, Berlin Heidelberg
New York, 1989
229. J. Zowe and S. Kurcyusz. Regularity and stability for the mathematical pro-
gramming problem in Banach spaces. Appl. Math. Optim., 5:49–62, 1979

Notation
N, R, R+, R, 5
E[τ], 20
E∗, 6
E∗
β, 45
L(E, F), 41
Lβ(E, F), 45
σ(E, F), 19
x∗
k
w∗
−−→x∗, 21
BE(¯x, ϵ), B(¯x, ϵ), 6
BE, B, 6
˚BE(¯x, ϵ), ˚B(¯x, ϵ), 6
˚BE, ˚B, 6
K(x∗, α), 70
S(x), 78
αA + βB, 5
A + y, 5
R+A, 5
cr A, 6
int A, 5
cl A, 5
bd A, 5
co A, 24
cc A, 35
cl∗A, 20
co∗A, 20
A◦, 35
A◦◦, 35
Ap, 34
ep A, 23
C(T), 80
C1(D, F), 46
C2(D, F), 48
Ck(G), 105
C∞
c (G), 105
Lp(G), 105
W1,p(G), 105
W1,p
0 (G), 105
AC∞[a, b], 50
Lp[a, b], 50
M(T), 80
L1, 269
Bn, 269
u
p, 105
u
1,p, 106
u
1,p,0, 106

364
Notation
dom f, 8
epi f, 8
infE f, 156
f ′(¯x), 42
∇f(¯x), 42
f 1(¯x, ¯y), 51
D1f(¯x, ¯y), 51
∆f(¯x, y), 39
fG(¯x, y), 39
f s
G(¯x, y), 39
f G(¯x, y), 40
f G(¯x, y), 40
fH(¯x, y), 39
f s
H(¯x, y), 39
f H(¯x, y), 40
f H(¯x, y), 40
f ◦(¯x, y), 139
f ♦(¯x, y), 139
∂f(¯x), 59
∂∗f(¯x, y), 138
∂◦f(¯x), 142
∂♦f(¯x), 142
∂F f(¯x), 167
∂V f(¯x), 167
∂P f(¯x), 167
∂F f(¯x), 181
∂F,1f(¯x, ¯y), 330
∂Mf(¯x), 288
∂∞
Mf(¯x), 288
*∂ϵf(¯x), 289
A(f), 27
f Γ (x), 27
f ∗(x∗), 29
f ∗∗(x), 31
f0 ⊕f1(x), 32
Tr(A, ¯x), 131, 231
T(A, ¯x), 132, 231
TC(A, ¯x), 231
Ir(A, ¯x), 231
I(A, ¯x), 231
H(A, ¯x), 231
NC(A, ¯x), 238
NF (A, ¯x), 238
NV (A, ¯x), 238
NP (A, ¯x), 238
*
Nϵ(A, x), 285
NM(A, x), 285
L<
γ, ¯x

, 248
L≤
γ, ¯x

, 248
I(¯x), 248
T +(¯x), 80
T −(¯x), 80
T(¯x), 80
L(x; µ1, . . . , µm), 93
*L(x; λ, µ1, . . . , µm), 93
L(x, q), 111
UCr(f, ¯x), 136
UC(f, ¯x), 136
dA(x), d(A, x), 10
pM(x), 10
δM(x), 9
σA(x), 9
ωz(x), ω(x), 78
projA(z), 96
Φ : E ⇒F, 63
Φ−1, 195
Dom Φ, 63
ker Φ, 195
range Φ, 195
graph Φ, 63
ope(Φ)(¯x, ¯y), 209
DΦ(¯x, ¯y), 252
D∗
ϵΦ(¯x, ¯y), 294
D∗
F Φ(¯x, ¯y), 294
D∗
MΦ(¯x, ¯y), 294
⟨x∗, x⟩, 6
(x y), 6
[x∗= α], 15
[¯x, z], 45

Notation
365
x ≤P y, 13
x →A ¯x, 231
x →f ¯x, 259
x →Φ ¯x, 226
Lim sup
α∈A
Sα, 225
Lim inf
α∈A
Sα, 225
Lim sup
x→¯x
Φ(x), 225
Lim inf
x→¯x
Φ(x), 225
sLim sup
x→¯x
Φ(x), 226

Index
Gδ set, 69
P-convex mapping, 197
β-derivative, 41
β-diﬀerentiable mapping, 41
β-smooth mapping, 46
ϵ-coderivative, 294
C1-mapping, 46
C2-mapping, 48
absorbing set, 6
aﬃne functional, 9
almost transitive preference
relation, 340
approximate extremal principle,
303
approximate subdiﬀerential, 349
approximation
radial upper convex, 135
upper convex, 135
Asplund space, 70
Aubin property, 211
basic subdiﬀerential, 288
basis, 103
biconjugate functional, 31
bilinear functional, 49
bipolar cone, 35
bornology, 41
Fréchet (F-bornology), 41
Gâteaux (G-bornology), 41
Hadamard (H-bornology), 41
boundary value problem
classical, 106
genralized, 106
bounded process, 209
bounded-valued
multifunction, 195
bump functional, 162
Clarke directional derivative, 139
Clarke generalized gradient, 142
Clarke normal cone, 238
Clarke subdiﬀerential, 142
Clarke tangent cone, 231
classical boundary value problem,
106, 118
closed multifunction, 195
closed-valued multifunction, 195
coderivative
ϵ-, 294
Fréchet (F-), 294
Mordukhovich (M-), 294

368
Index
coercive functional, 100
coercive multifunction, 223
compactly epi-Lipschitzian set,
309
compatible topology, 20
condition
core, 208
generalized John, 274
generalized
Karush–Kuhn–Tucker, 274
John, 94
Karush–Kuhn–Tucker, 94
Kolmogorov, 98
Mangasarian–Fromowitz, 275
regularity, 94, 250
Robinson, 208
Slater, 93
Zowe–Kurcyusz, 208
conditions
local optimality, 94
cone, 13
bipolar, 35
Bishop–Phelps, 70
Clarke normal, 238
Clarke tangent, 231
contingent, 132, 231
convex, 13
Fréchet normal, 238
linearizing, 248
normal, 135, 237
of feasible directions, 231
of hypertangents, 231
of inner directions, 231
of radial directions, 131, 231
of radial inner directions, 231
polar, 35
proximal normal, 238
tangent, 231
viscosity normal, 238
conjugate functional, 29
constant
of metric regularity, 200
constraint
functional, 92
qualiﬁcation, 250
residual, 92
constraint qualiﬁcation, 94
contingent cone, 132, 231
contingent derivative, 252
continuously diﬀerentiable
mapping, 46
convex cone, 13
convex functional, 8
convex multifunction, 195
convex set, 5
core, 6
core condition, 208
derivative
β-, 41
Clarke directional, 139
contingent, 252
directional G-, 39
directional H-, 39
F-, 42
G-, 42
H-, 42
lower directional G-, 40
lower directional H-, 40
Michel–Penot directional, 139
partial, 51
second order, 48
strict β-, 42
strict F-, 42
strict G-, 42
strict H-, 42
upper directional G-, 40
upper directional H-, 40
Dini derivates, 41
distance functional, 10
dual pair
of locally convex spaces, 20
of vector spaces, 19
dual problem, 112
duality gap, 112
duality mapping, 80
eﬀective domain, 8
epi-limit
lower, 226
upper, 226

Index
369
epi-Lipschitzian set, 236
epigraph, 8
equation
generalized, 200
Euler–Lagrange equation, 268
exact extremal principle, 302
extended extremal system, 338
extremal principle
approximate, 303
exact, 302
extremal set, 23
extremal system, 301
extended, 338
extreme point, 23
F-derivative (=Fréchet
derivative), 42
F-diﬀerentiable mapping, 42
F-subderivative, 167
F-subdiﬀerentiable functional, 167
Fenchel conjugate, 29
ﬁxed end point problem, 267
Fréchet ϵ-subdiﬀerential, 289
Fréchet (F-)coderivative, 294
Fréchet (F-)subdiﬀerential, 167
Fréchet (F-)superdiﬀerential, 181
Fréchet normal, 238
Fréchet normal cone, 238
Fréchet smooth Banach space, 88
functional
aﬃne, 9
biconjugate, 31
bilinear, 19
bounded bilinear, 49
bump, 162
coercive, 100
conjugate, 29
constraint, 92
convex, 8
distance, 10
F-subdiﬀerentiable, 167
indicator, 9
Lagrange, 93
locally convex, 136
locally L-continuous, 11
lower regular, 291
lower semicontinuous (l.s.c.), 22
lower semicontinuous closure of
a, 25
marginal, 123
Minkowski, 10
proper, 8
quadratic, 9, 49
quasidiﬀerentiable, 136
regular, 146
regularly locally convex, 136
sequentially lower
semicontinuous, 22
sequentially normally
epi-compact (SNEC), 317
stricly convex, 8
strongly positive bilinear, 67
sublinear, 9
support, 9
symmetric bilinear, 49
upper semicontinuous (u.s.c.),
22
value, 123
viscosity subdiﬀerentiable, 167
G-derivative (=Gâteaux
derivative), 42
directional, 39
lower directional, 40
strict directional, 39
upper directional, 40
G-diﬀerentiable mapping, 42
Gamma regularization, 27
gauge, 10
general dualization principle, 114
generalized boundary value
problem, 106
generalized derivative, 105
generalized equation, 200
generalized gradient
Clarke, 142
generalized John condition, 274
generalized Karush–Kuhn–Tucker
condition, 274
generalized solution, 106

370
Index
generating set, 217
global minimizer, 91
global solution, 91
gradient, 42
H-derivative (=Hadamard
derivative), 42
directional, 39
lower directional, 40
strict directional, 39
upper directional, 40
H-diﬀerentiable mapping, 42
Hamilton–Jacobi equation, 181
hemicontinuous mapping, 220
hyperplane, 15
supporting, 17
indicator functional, 9
inﬁmal convolution, 32
inner semicompact, 299
John conditions, 94
Kadec norm, 86
Karush–Kuhn–Tucker conditions,
94
Kolmogorov condition, 98
Lagrange functional, 93
Lagrange multiplier, 274
limiting qualiﬁcation condition,
320
linear rate
of openness, 201
linearizing cone, 248
linearly semiopen mapping, 213
local extremal point, 301
local minimizer, 91
local optimality conditions, 94
local solution, 91
local solution of a multiobjective
optimization problem, 341
locally compact mapping, 180
locally convex functional, 136
locally convex space, 5
locally convex subdiﬀerential, 138
locally L-continuous, 11
locally satiated preference
relation, 340
locally uniformly convex space, 85
lower epi-limit, 226
lower regular functional, 291
lower semicontinuous (l.s.c.), 22
lower semicontinuous
multifunction, 64
M-subdiﬀerential, 288
mapping
P-convex, 197
β-diﬀerentiable, 41
β-smooth, 46
C1, 46
C2, 48
continuously diﬀerentiable, 46
duality, 80
F-diﬀerentiable, 42
G-diﬀerentiable, 42
H-diﬀerentiable, 42
hemicontinuous, 220
linearly semiopen, 213
locally compact, 180
metrically semiregular, 213
open, 196
radially continuous, 45
scalarization of a, 180
semi-pseudo-Lipschitz, 213
strictly β-diﬀerentiable, 42
strictly F-diﬀerentiable, 42
strictly G-diﬀerentiable, 42
strictly H-diﬀerentiable, 42
twice continuously
diﬀerentiable, 48
marginal functional, 123
method of penalty functions, 131
method of tangent directions, 131
metric regularity
constant of, 200
metrically regular multifunction,
200
metrically semiregular mapping,
213

Index
371
Michel–Penot directional
derivative, 139
Michel–Penot subdiﬀerential, 142
minimizer
global, 91
local, 91
strict, 156
strong, 156
minimizing sequence, 99
Minkowski functional, 10
mixed qualiﬁcation condition, 313
Mordukhovich (M-)coderivative,
294
Mordukhovich (M-)normal cone,
285
Mordukhovich
(M-)subdiﬀerential, 288
multifunction, 63
Aubin property of a, 211
bounded-valued, 195
closed, 195
closed-valued, 195
coercive, 223
convex, 195
domain of a, 63
graph of a, 63
inner semicompact, 299
inverse of a, 195
locally bounded, 64
lower semicontinuous, 64
maximal monotone, 219
metrically regular, 200
monotone, 64
open at a linear rate, 201
openness bound of a, 209
pseudo-Lipschitz, 211
range of a, 195
strictly monotone, 64
strongly monotone, 64
uniformly monotone, 64
upper semicontinuous, 64
weakly metrically regular, 211
multiplier
Lagrange, 274
natural boundary conditions, 271
normal
Fréchet, 238
proximal, 238
viscosity, 238
normal cone, 135, 237
Fréchet, 238
Mordukhovich, 285
proximal, 238
viscosity, 238
normally regular set, 287
normed vector space
locally uniformly convex, 85
separable, 70
smooth, 84
uniformly convex, 85
open mapping, 196
openness
linear rate of, 201
openness bound
of a multifunction, 209
operator
strongly elliptic, 118
Painlevé–Kuratowski lower limit,
225
Painlevé–Kuratowski upper limit,
225
sequential, 226
parameter
metric semiregularity, 213
semi-pseudo-Lipschitz, 213
semiopenness, 213
partially sequentially normally
compact (PSNC), 312
peak point, 82
peaking function, 82
point
local extremal, 301
polar cone, 35
preference relation, 340
almost transitive, 340
locally satiated, 340

372
Index
preorder, 14
primal problem, 112
problem
classical boundary value, 118
dual, 112
ﬁxed end point, 267
primal, 112
Ritz minimum, 103
process, 209
bounded, 209
convex, 209
norm of a, 209
projection, 96
projector, 96
proper functional, 8
proximal normal, 238
proximal normal cone, 238
proximal subdiﬀerential, 167
proximal subgradient, 167
pseudo-Lipschitz multifunction,
211
quadratic functional, 9
quasidiﬀerentiable functional, 136
radial upper convex
approximation, 135
radially continuous mapping, 45
regular functional, 146
regularity condition, 94, 250
Mangasarian–Fromowitz, 275
Slater, 93
regularly locally convex
functional, 136
residual constraint, 92
Ritz
equations, 103
method, 103
minimum problem, 103
Robinson condition, 208
saddle point, 93
scalarization, 180
selection, 64
semi-pseudo-Lipschitz mapping,
213
semiopenness parameter, 213
separable normed vector space, 70
separated sets, 16
sequence
minimizing, 99
weak∗convergent, 21
weakly convergent, 20
sequentially lower semicontinuous,
22
sequentially normally compact
(SNC), 308
sequentially normally epi-compact
(SNEC), 317
set
absorbing, 6
bounded in E, 217
circled, 5
compactly epi-Lipschitzian, 309
convex, 5
cs-closed, 6
epi-Lipschitzian, 236
epi-Lipschitzian at ¯x, 236
extremal, 23
generating, 217
normally regular, 287
partially sequentially normally
compact (PSNC), 312
sequentially normally compact,
308
SNC see sequentially normally
compact, 308
strongly partially sequentially
normally compact (strongly
PSNC), 312
tangentially regular, 250
weakly sequentially closed, 21
set of ϵ-normals, 285
set-valued mapping, 63
sets
separated, 16
strongly separated, 16
singular Mordukhovich (M-)
subdiﬀerential, 288
Slater condition, 93
smooth space, 84

Index
373
solution
generalized, 106
global, 91
local, 91
strict β-derivative, 42
strict F-derivative, 42
strict G-derivative, 42
strict H-derivative, 42
strict minimizer, 156
strictly β-diﬀerentiable mapping,
42
strictly convex functional, 8
strictly F-diﬀerentiable mapping,
42
strictly G-diﬀerentiable mapping,
42
strictly H-diﬀerentiable mapping,
42
strong minimizer, 156
strongly elliptic, 118
strongly partially sequentially
normally compact (strongly
PSNC), 312
strongly separated sets, 16
subdiﬀerential, 59
approximate, 349
basic, 288
Clarke, 142
Fréchet ϵ-, 289
Fréchet (F-), 167
locally convex, 138
Michel–Penot, 142
Mordukhovich (M-), 288
proximal, 167
singular Mordukhovich (M-),
288
viscosity, 167
subdiﬀerential mapping, 63
subgradient, 59
proximal, 167
sublinear functional, 9
superdiﬀerential
Fréchet (F-), 181
support functional, 9
support point, 17
tangent cone, 231
tangentially regular set, 250
topological vector space, 5
topology
compatible, 20
weak, 19
weak star, 20
weak∗, 20
Treﬀtz method, 121
uniformly convex space, 85
upper convex approximation, 135
upper epi-limit, 226
upper semicontinuous functional,
22
upper semicontinuous
multifunction, 64
value functional, 123
variational equation, 92
variational inequality, 92
variational problem, 106
vector space, 5
locally convex, 5
topological, 5
viscosity normal, 238
viscosity normal cone, 238
viscosity solution, 181
viscosity subderivative, 167
viscosity subdiﬀerentiable, 167
viscosity subdiﬀerential, 167
viscosity subsolution, 181
viscosity supersolution, 181
weak star topology, 20
weak topology, 19
weak∗topology, 20
weakly metrically regular
multifunction, 211
Young inequality, 29
Zowe–Kurcyusz condition, 208

Universitext
Aguilar, M.; Gitler, S.; Prieto, C.: Algebraic
Topology from a Homotopical Viewpoint
Aksoy, A.; Khamsi, M. A.: Methods in Fixed
Point Theory
Alevras, D.; Padberg M. W.: Linear Opti-
mization and Extensions
Andersson, M.: Topics in Complex Analysis
Aoki, M.: State Space Modeling of Time
Series
Arnold, V. I.: Lectures on Partial Differen-
tial Equations
Arnold, V. I.; Cooke, R.: Ordinary Differen-
tial Equations
Audin, M.: Geometry
Aupetit, B.: A Primer on Spectral Theory
Bachem, A.; Kern, W.: Linear Programming
Duality
Bachmann, G.; Narici, L.; Beckenstein, E.:
Fourier and Wavelet Analysis
Badescu, L.: Algebraic Surfaces
Balakrishnan, R.; Ranganathan, K.: A Text-
book of Graph Theory
Balser, W.: Formal Power Series and Linear
Systems of Meromorphic Ordinary Differ-
ential Equations
Bapat, R.B.:
Linear Algebra and Linear
Models
Benedetti, R.; Petronio, C.: Lectures on Hy-
perbolic Geometry
Benth, F. E.: Option Theory with Stochastic
Analysis
Berberian, S. K.:
Fundamentals of Real
Analysis
Berger, M.: Geometry I, and II
Bliedtner, J.; Hansen, W.: Potential Theory
Blowey, J. F.; Coleman, J. P.; Craig, A. W.
(Eds.): Theory and Numerics of Differential
Equations
Blowey, J. F.; Craig, A.; Shardlow, T. (Eds.):
Frontiers in Numerical Analysis, Durham
2002, and Durham 2004
Blyth, T. S.: Lattices and Ordered Algebraic
Structures
B¨orger, E.; Gr¨adel, E.; Gurevich, Y.: The
Classical Decision Problem
B¨ottcher, A; Silbermann, B.: Introduction
to Large Truncated Toeplitz Matrices
Boltyanski, V.; Martini, H.; Soltan, P. S.:
Excursions into Combinatorial Geometry
Boltyanskii, V. G.; Efremovich, V. A.: Intu-
itive Combinatorial Topology
Bonnans, J. F.; Gilbert, J. C.; Lemarchal, C.;
Sagastizbal, C. A.: Numerical Optimization
Booss, B.; Bleecker, D. D.: Topology and
Analysis
Borkar, V. S.: Probability Theory
Brunt B. van: The Calculus of Variations
B¨uhlmann, H.; Gisler, A.: A Course in Cred-
ibility Theory and its Applications
Carleson, L.; Gamelin, T. W.:
Complex
Dynamics
Cecil, T. E.:
Lie Sphere Geometry: With
Applications of Submanifolds
Chae, S. B.: Lebesgue Integration
Chandrasekharan, K.:
Classical Fourier
Transform
Charlap, L. S.: Bieberbach Groups and Flat
Manifolds
Chern, S.:
Complex Manifolds without
Potential Theory
Chorin, A. J.; Marsden, J. E.: Mathematical
Introduction to Fluid Mechanics
Cohn, H.: A Classical Invitation to Alge-
braic Numbers and Class Fields
Curtis, M. L.: Abstract Linear Algebra
Curtis, M. L.: Matrix Groups
Cyganowski, S.; Kloeden, P.; Ombach, J.:
From Elementary Probability to Stochastic
Differential Equations with MAPLE
Da Prato, G.: An Introduction to Inﬁnite
Dimensional Analysis
Dalen, D. van: Logic and Structure
Das, A.: The Special Theory of Relativity:
A Mathematical Exposition

Debarre, O.: Higher-Dimensional Algebraic
Geometry
Deitmar, A.: A First Course in Harmonic
Analysis
Demazure, M.:
Bifurcations and Cata-
strophes
Devlin, K. J.: Fundamentals of Contempo-
rary Set Theory
DiBenedetto,
E.:
Degenerate Parabolic
Equations
Diener, F.; Diener, M.(Eds.): Nonstandard
Analysis in Practice
Dimca, A.: Sheaves in Topology
Dimca, A.: Singularities and Topology of
Hypersurfaces
DoCarmo, M. P.:
Differential Forms and
Applications
Duistermaat, J. J.; Kolk, J. A. C.: Lie Groups
Dumortier.: Qualitative Theory of Planar
Differential Systems
Dundas, B. I.; Levine, M.; Østvaer, P. A.;
R¨ondip, O.; Voevodsky, V.: Motivic Homo-
topy Theory
Edwards, R. E.: A Formal Background to
Higher Mathematics Ia, and Ib
Edwards, R. E.: A Formal Background to
Higher Mathematics IIa, and IIb
Emery, M.: Stochastic Calculus in Mani-
folds
Emmanouil, I.: Idempotent Matrices over
Complex Group Algebras
Endler, O.: Valuation Theory
Engel, K.-J.; Nagel, R.: A Short Course on
Operator Semigroups
Erez, B.: Galois Modules in Arithmetic
Everest, G.; Ward, T.: Heights of Polynomi-
als and Entropy in Algebraic Dynamics
Farenick, D. R.: Algebras of Linear Trans-
formations
Foulds, L. R.: Graph Theory Applications
Franke, J.; Hrdle, W.; Hafner, C. M.: Statis-
tics of Financial Markets: An Introduction
Frauenthal, J. C.: Mathematical Modeling in
Epidemiology
Freitag, E.; Busam, R.: Complex Analysis
Friedman, R.: Algebraic Surfaces and Holo-
morphic Vector Bundles
Fuks, D. B.;
Rokhlin, V. A.:
Beginner’s
Course in Topology
Fuhrmann, P. A.: A Polynomial Approach
to Linear Algebra
Gallot, S.; Hulin, D.; Lafontaine, J.: Rie-
mannian Geometry
Gardiner, C. F.: A First Course in Group
Theory
G˚arding, L.; Tambour, T.: Algebra for Com-
puter Science
Godbillon,
C.:
Dynamical Systems on
Surfaces
Godement, R.: Analysis I, and II
Goldblatt, R.: Orthogonality and Spacetime
Geometry
Gouvˆea, F. Q.: p-Adic Numbers
Gross, M. et al.: Calabi-Yau Manifolds and
Related Geometries
Gustafson, K. E.; Rao, D. K. M.: Numerical
Range. The Field of Values of Linear Oper-
ators and Matrices
Gustafson, S. J.; Sigal, I. M.: Mathematical
Concepts of Quantum Mechanics
Hahn, A. J.:
Quadratic Algebras, Clifford
Algebras, and Arithmetic Witt Groups
H´ajek, P.; Havr´anek, T.: Mechanizing Hy-
pothesis Formation
Heinonen, J.: Lectures on Analysis on Met-
ric Spaces
Hlawka, E.; Schoißengeier, J.; Taschner, R.:
Geometric and Analytic Number Theory
Holmgren, R. A.: A First Course in Discrete
Dynamical Systems
Howe, R., Tan, E. Ch.: Non-Abelian Har-
monic Analysis
Howes, N. R.: Modern Analysis and Topol-
ogy
Hsieh, P.-F.; Sibuya, Y. (Eds.): Basic Theory
of Ordinary Differential Equations
Humi, M., Miller, W.: Second Course in Or-
dinary Differential Equations for Scientists
and Engineers

Hurwitz, A.; Kritikos, N.: Lectures on Num-
ber Theory
Huybrechts, D.: Complex Geometry: An In-
troduction
Isaev, A.:
Introduction to Mathematical
Methods in Bioinformatics
Istas, J.: Mathematical Modeling for the Life
Sciences
Iversen, B.: Cohomology of Sheaves
Jacod, J.; Protter, P.: Probability Essentials
Jennings, G. A.:
Modern Geometry with
Applications
Jones, A.; Morris, S. A.; Pearson, K. R.: Ab-
stract Algebra and Famous Inpossibilities
Jost, J.: Compact Riemann Surfaces
Jost, J.: Dynamical Systems. Examples of
Complex Behaviour
Jost, J.: Postmodern Analysis
Jost, J.: Riemannian Geometry and Geomet-
ric Analysis
Kac, V.; Cheung, P.: Quantum Calculus
Kannan, R.;
Krueger, C. K.:
Advanced
Analysis on the Real Line
Kelly, P.; Matthews, G.: The Non-Euclidean
Hyperbolic Plane
Kempf, G.: Complex Abelian Varieties and
Theta Functions
Kitchens, B. P.: Symbolic Dynamics
Kloeden, P.; Ombach, J.; Cyganowski, S.:
From Elementary Probability to Stochastic
Differential Equations with MAPLE
Kloeden, P. E.; Platen; E.; Schurz, H.: Nu-
merical Solution of SDE Through Computer
Experiments
Koralov, L.; Sina, Ya. G.: Theory of Proba-
bility and Random Processes
Kostrikin, A. I.: Introduction to Algebra
Krasnoselskii, M. A.; Pokrovskii, A. V.: Sys-
tems with Hysteresis
Kuo, H.-H.: Introduction to Stochastic In-
tegration
Kurzweil, H.; Stellmacher, B.: The Theory of
Finite Groups. An Introduction
Kyprianou, A.E.: Introductory Lectures on
Fluctuations of L´evy Processes with Appli-
cations
Lang, S.:
Introduction to Differentiable
Manifolds
Lefebvre, M.: Applied Stochastic Processes
Lorenz, F.:
Algebra I: Fields and Galois
Theory
Luecking, D. H., Rubel, L. A.:
Complex
Analysis. A Functional Analysis Approach
Ma, Zhi-Ming; Roeckner, M.: Introduction
to the Theory of (non-symmetric) Dirichlet
Forms
Mac Lane, S.; Moerdijk, I.:
Sheaves in
Geometry and Logic
Marcus, D. A.: Number Fields
Martinez, A.: An Introduction to Semiclas-
sical and Microlocal Analysis
Matouˇsek, J.: Using the Borsuk-Ulam The-
orem
Matsuki, K.: Introduction to the Mori Pro-
gram
Mazzola, G.; Milmeister G.; Weissman J.:
Comprehensive Mathematics for Computer
Scientists 1
Mazzola, G.; Milmeister G.; Weissman J.:
Comprehensive Mathematics for Computer
Scientists 2
Mc Carthy, P. J.: Introduction to Arithmeti-
cal Functions
McCrimmon, K.: A Taste of Jordan Alge-
bras
Meyer, R. M.:
Essential Mathematics for
Applied Field
Meyer-Nieberg, P.: Banach Lattices
Mikosch, T.:
Non-Life Insurance Mathe-
matics
Mines, R.; Richman, F.; Ruitenburg, W.: A
Course in Constructive Algebra
Moise, E. E.: Introductory Problem Courses
in Analysis and Topology
Montesinos-Amilibia, J. M.: Classical Tes-
sellations and Three Manifolds
Morris, P.: Introduction to Game Theory
Nicolaescu, L.:
An Invitation to Morse
Theory

Nikulin, V. V.; Shafarevich, I. R.: Geome-
tries and Groups
Oden, J. J.; Reddy, J. N.: Variational Meth-
ods in Theoretical Mechanics
Øksendal, B.: Stochastic Differential Equa-
tions
Øksendal, B.; Sulem, A.: Applied Stochastic
Control of Jump Diffusions
Orlik, P.; Welker, V.: Algebraic Combina-
torics
Poizat, B.: A Course in Model Theory
Polster, B.: A Geometrical Picture Book
Porter, J. R.; Woods, R. G.: Extensions and
Absolutes of Hausdorff Spaces
Procesi, C.: Lie Groups
Radjavi, H.; Rosenthal, P.: Simultaneous
Triangularization
Ramsay, A.; Richtmeyer, R. D.: Introduc-
tion to Hyperbolic Geometry
Rautenberg, W.: A concise Introduction to
Mathematical Logic
Rees, E. G.: Notes on Geometry
Reisel, R. B.: Elementary Theory of Metric
Spaces
Rey, W. J. J.: Introduction to Robust and
Quasi-Robust Statistical Methods
Ribenboim, P.: Classical Theory of Alge-
braic Numbers
Rickart, C. E.: Natural Function Algebras
Rotman, J. J.: Galois Theory
Rubel, L. A.:
Entire and Meromorphic
Functions
Ruiz-Tolosa, J. R.; Castillo E.: From Vectors
to Tensors
Runde, V.: A Taste of Topology
Rybakowski, K. P.: The Homotopy Index
and Partial Differential Equations
Sagan, H.: Space-Filling Curves
Samelson, H.: Notes on Lie Algebras
Sauvigny, F.:
Partial Differential Equa-
tions I
Sauvigny, F.:
Partial Differential Equa-
tions II
Schiff, J. L.: Normal Families
Schirotzek, W.: Nonsmooth Analysis
Sengupta, J. K.: Optimal Decisions under
Uncertainty
S´eroul, R.: Programming for Mathemati-
cians
Seydel,
R.:
Tools
for
Computational
Finance
Shafarevich, I. R.: Discourses on Algebra
Shapiro, J. H.: Composition Operators and
Classical Function Theory
Simonnet, M.: Measures and Probabilities
Smith, K. E.; Kahanp¨a¨a, L.; Kek¨al¨ainen, P.;
Traves, W.:
An Invitation to Algebraic
Geometry
Smith, K. T.: Power Series from a Computa-
tional Point of View
Smory´nski, C.: Logical Number Theory I.
An Introduction
Stichtenoth, H.: Algebraic Function Fields
and Codes
Stillwell, J.: Geometry of Surfaces
Stroock, D. W.: An Introduction to the The-
ory of Large Deviations
Sunder, V. S.: An Invitation to von Neu-
mann Algebras
Tamme,
G.:
Introduction
to
´Etale
Cohomology
Tondeur, P.:
Foliations on Riemannian
Manifolds
Toth, G.:
Finite Mbius Groups, Minimal
Immersions of Spheres, and Moduli
Tu, L. W.: An Introduction to Manifolds
Verhulst, F.: Nonlinear Differential Equa-
tions and Dynamical Systems
Weintraub, S. H.: Galois Theory
Wong, M. W.: Weyl Transforms
Xamb´o-Descamps, S.:
Block Error-Cor-
recting Codes
Zaanen, A.C.: Continuity, Integration and
Fourier Theory
Zhang, F.: Matrix Theory
Zong, C.: Sphere Packings
Zong, C.: Strange Phenomena in Convex
and Discrete Geometry
Zorich, V. A.: Mathematical Analysis I
Zorich, V. A.: Mathematical Analysis II

