

Winfried Schirotzek
Nonsmooth Analysis
With 31 Figures

Winfried Schirotzek
Institut fÂ¨ur Analysis
Fachrichtung Mathematik
Technische UniversitÂ¨at Dresden
01062 Dresden
Germany
e-mail: winfried.schirotzek@tu-dresden.de
Mathematics Subject Classiï¬cation (2000): 49-01, 49-02, 49J50, 49J52, 49J53, 49K27,
49N15, 58C06, 58C20, 58E30, 90C48
Library of Congress Control Number: 2007922937
ISBN-10: 3-540-71332-8 Springer Berlin Heidelberg New York
ISBN-13: 978-3-540-71332-6 Springer Berlin Heidelberg New York
This work is subject to copyright. All rights are reserved, whether the whole or part of the mater-
ial is concerned, speciï¬cally the rights of translation, reprinting, reuse of illustrations, recitation,
broadcasting, reproduction on microï¬lm or in any other way, and storage in data banks. Dupli-
cation of this publication or parts thereof is permitted only under the provisions of the German
Copyright Law of September 9, 1965, in its current version, and permission for use must always
be obtained from Springer. Violations are liable for prosecution under the German Copyright Law.
Springer is a part of Springer Science+Business Media
springer.com
â—¦c Springer-Verlag Berlin Heidelberg 2007
The use of general descriptive names, registered names, trademarks, etc. in this pub-
lication does not imply, even in the absence of a speciï¬c statement, that such names
are exempt from the relevant protective laws and regulations and therefore free for
general use.
Cover design: WMXDesign, Heidelberg
Typesetting by the authors and SPi using a Springer LATEX macro package
Printed on acid-free paper
SPIN: 12029495
41/2141/SPi
5 4 3 2 1 0

To the memory of my parents

Preface
One of the sources of the classical diï¬€erential calculus is the search for min-
imum or maximum points of a real-valued function. Similarly, nonsmooth
analysis originates in extremum problems with nondiï¬€erentiable data. By now,
a broad spectrum of reï¬ned concepts and methods modeled on the theory of
diï¬€erentiation has been developed.
The idea underlying the presentation of the material in this book is to start
with simple problems treating them with simple methods, gradually passing
to more diï¬ƒcult problems which need more sophisticated methods. In this
sense, we pass from convex functionals via locally Lipschitz continuous func-
tionals to general lower semicontinuous functionals. The book does not aim
at being comprehensive but it presents a rather broad spectrum of important
and applicable results of nonsmooth analysis in normed vector spaces. Each
chapter ends with references to the literature and with various exercises.
The book grew out of a graduate course that I repeatedly held at the Tech-
nische UniversitÃ¤t Dresden. Susanne Walther and Konrad Groh, participants
of one of the courses, pointed out misprints in an early script preceding the
book. I am particularly grateful to Heidrun PÂ¨uhl and Hans-Peter Scheï¬„er for
a time of proliï¬c cooperation and to the latter also for permanent technical
support. The Institut fÂ¨ur Analysis of the Technische UniversitÂ¨at Dresden pro-
vided me with the facilities to write the book. I thank Quji J. Zhu for useful
discussions and two anonymous referees for valuable suggestions. I gratefully
acknowledge the kind cooperation of Springer, in particular the patient sup-
port by Stefanie Zoeller, as well as the careful work of Nandini Loganathan,
project manager of Spi (India).
My warmest thanks go to my wife for everything not mentioned above.
Dresden, December 2006
Winfried Schirotzek

Contents
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1
1
Preliminaries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5
1.1
Terminology . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5
1.2
Convex Sets in Normed Vector Spaces . . . . . . . . . . . . . . . . . . . . .
6
1.3
Convex Functionals: Deï¬nitions and Examples . . . . . . . . . . . . . .
8
1.4
Continuity of Convex Functionals . . . . . . . . . . . . . . . . . . . . . . . . . 11
1.5
Sandwich and Separation Theorems . . . . . . . . . . . . . . . . . . . . . . . 13
1.6
Dual Pairs of Vector Spaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19
1.7
Lower Semicontinuous Functionals . . . . . . . . . . . . . . . . . . . . . . . . 22
1.8
Bibliographical Notes and Exercises . . . . . . . . . . . . . . . . . . . . . . . 24
2
The Conjugate of Convex Functionals . . . . . . . . . . . . . . . . . . . . . 27
2.1
The Gamma Regularization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27
2.2
Conjugate Functionals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29
2.3
A Theorem of HÂ¨ormander and the Bipolar Theorem . . . . . . . . . 34
2.4
The Generalized Farkas Lemma . . . . . . . . . . . . . . . . . . . . . . . . . . . 36
2.5
Bibliographical Notes and Exercises . . . . . . . . . . . . . . . . . . . . . . . 38
3
Classical Derivatives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39
3.1
Directional Derivatives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39
3.2
First-Order Derivatives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41
3.3
Mean Value Theorems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44
3.4
Relationship between Diï¬€erentiability Properties . . . . . . . . . . . . 46
3.5
Higher-Order Derivatives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48
3.6
Some Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49
3.7
Implicit Function Theorems and Related Results . . . . . . . . . . . . 51
3.8
Bibliographical Notes and Exercises . . . . . . . . . . . . . . . . . . . . . . . 57

X
Contents
4
The Subdiï¬€erential of Convex Functionals . . . . . . . . . . . . . . . . . 59
4.1
Deï¬nition and First Properties . . . . . . . . . . . . . . . . . . . . . . . . . . . 59
4.2
Multifunctions: First Properties . . . . . . . . . . . . . . . . . . . . . . . . . . . 63
4.3
Subdiï¬€erentials, FrÃ©chet Derivatives, and Asplund Spaces . . . . 64
4.4
Subdiï¬€erentials and Conjugate Functionals . . . . . . . . . . . . . . . . . 73
4.5
Further Calculus Rules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76
4.6
The Subdiï¬€erential of the Norm . . . . . . . . . . . . . . . . . . . . . . . . . . 78
4.7
Diï¬€erentiable Norms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 83
4.8
Bibliographical Notes and Exercises . . . . . . . . . . . . . . . . . . . . . . . 89
5
Optimality Conditions for Convex Problems . . . . . . . . . . . . . . . 91
5.1
Basic Optimality Conditions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 91
5.2
Optimality Under Functional Constraints . . . . . . . . . . . . . . . . . . 92
5.3
Application to Approximation Theory . . . . . . . . . . . . . . . . . . . . . 96
5.4
Existence of Minimum Points and the Ritz Method. . . . . . . . . . 99
5.5
Application to Boundary Value Problems . . . . . . . . . . . . . . . . . . 105
5.6
Bibliographical Notes and Exercises . . . . . . . . . . . . . . . . . . . . . . . 110
6
Duality of Convex Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 111
6.1
Duality in Terms of a Lagrange Function. . . . . . . . . . . . . . . . . . . 111
6.2
Lagrange Duality and GÃ¢teaux Diï¬€erentiable Functionals . . . . 116
6.3
Duality of Boundary Value Problems . . . . . . . . . . . . . . . . . . . . . . 118
6.4
Duality in Terms of Conjugate Functions. . . . . . . . . . . . . . . . . . . 122
6.5
Bibliographical Notes and Exercises . . . . . . . . . . . . . . . . . . . . . . . 129
7
Derivatives and Subdiï¬€erentials of Lipschitz Functionals . . . 131
7.1
Preview: Derivatives and Approximating Cones . . . . . . . . . . . . . 131
7.2
Upper Convex Approximations
and Locally Convex Functionals . . . . . . . . . . . . . . . . . . . . . . . . . . 135
7.3
The Subdiï¬€erentials of Clarke and Michelâ€“Penot . . . . . . . . . . . . 139
7.4
Subdiï¬€erential Calculus . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 146
7.5
Bibliographical Notes and Exercises . . . . . . . . . . . . . . . . . . . . . . . 153
8
Variational Principles . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 155
8.1
Introduction. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 155
8.2
The Loewenâ€“Wang Variational Principle . . . . . . . . . . . . . . . . . . . 156
8.3
The Borweinâ€“Preiss Variational Principle . . . . . . . . . . . . . . . . . . 161
8.4
The Devilleâ€“Godefroyâ€“Zizler Variational Principle . . . . . . . . . . . 162
8.5
Bibliographical Notes and Exercises . . . . . . . . . . . . . . . . . . . . . . . 166
9
Subdiï¬€erentials of Lower Semicontinuous Functionals . . . . . . 167
9.1
FrÃ©chet Subdiï¬€erentials: First Properties . . . . . . . . . . . . . . . . . . . 167
9.2
Approximate Sum and Chain Rules . . . . . . . . . . . . . . . . . . . . . . . 172
9.3
Application to Hamiltonâ€“Jacobi Equations . . . . . . . . . . . . . . . . . 181
9.4
An Approximate Mean Value Theorem . . . . . . . . . . . . . . . . . . . . 182
9.5
FrÃ©chet Subdiï¬€erential vs. Clarke Subdiï¬€erential . . . . . . . . . . . . 184

Contents
XI
9.6
Multidirectional Mean Value Theorems . . . . . . . . . . . . . . . . . . . . 185
9.7
The FrÃ©chet Subdiï¬€erential of Marginal Functions . . . . . . . . . . . 190
9.8
Bibliographical Notes and Exercises . . . . . . . . . . . . . . . . . . . . . . . 193
10
Multifunctions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 195
10.1
The Generalized Open Mapping Theorem . . . . . . . . . . . . . . . . . . 195
10.2
Systems of Convex Inequalities . . . . . . . . . . . . . . . . . . . . . . . . . . . 197
10.3
Metric Regularity and Linear Openness . . . . . . . . . . . . . . . . . . . . 200
10.4
Openness Bounds of Multifunctions . . . . . . . . . . . . . . . . . . . . . . . 209
10.5
Weak Metric Regularity and Pseudo-Lipschitz Continuity . . . . 211
10.6
Linear Semiopenness and Related Properties . . . . . . . . . . . . . . . 213
10.7
Linearly Semiopen Processes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 217
10.8
Maximal Monotone Multifunctions . . . . . . . . . . . . . . . . . . . . . . . . 219
10.9
Convergence of Sets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 225
10.10 Bibliographical Notes and Exercises . . . . . . . . . . . . . . . . . . . . . . . 227
11
Tangent and Normal Cones . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231
11.1
Tangent Cones: First Properties . . . . . . . . . . . . . . . . . . . . . . . . . . 231
11.2
Normal Cones: First Properties . . . . . . . . . . . . . . . . . . . . . . . . . . . 237
11.3
Tangent and Normal Cones to Epigraphs . . . . . . . . . . . . . . . . . . 241
11.4
Representation of Tangent Cones . . . . . . . . . . . . . . . . . . . . . . . . . 245
11.5
Contingent Derivatives and a Lyusternik Type Theorem . . . . . 252
11.6
Representation of Normal Cones . . . . . . . . . . . . . . . . . . . . . . . . . . 255
11.7
Bibliographical Notes and Exercises . . . . . . . . . . . . . . . . . . . . . . . 261
12
Optimality Conditions for Nonconvex Problems . . . . . . . . . . . 265
12.1
Basic Optimality Conditions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 265
12.2
Application to the Calculus of Variations . . . . . . . . . . . . . . . . . . 267
12.3
Multiplier Rules Involving Upper Convex Approximations . . . . 272
12.4
Clarkeâ€™s Multiplier Rule . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 278
12.5
Approximate Multiplier Rules . . . . . . . . . . . . . . . . . . . . . . . . . . . . 280
12.6
Bibliographical Notes and Exercises . . . . . . . . . . . . . . . . . . . . . . . 283
13
Extremal Principles and More Normals
and Subdiï¬€erentials . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 285
13.1
Mordukhovich Normals and Subdiï¬€erentials . . . . . . . . . . . . . . . . 285
13.2
Coderivatives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 294
13.3
Extremal Principles Involving Translations . . . . . . . . . . . . . . . . . 301
13.4
Sequentially Normally Compact Sets . . . . . . . . . . . . . . . . . . . . . . 309
13.5
Calculus for Mordukhovich Subdiï¬€erentials . . . . . . . . . . . . . . . . . 315
13.6
Calculus for Mordukhovich Normals . . . . . . . . . . . . . . . . . . . . . . . 320
13.7
Optimality Conditions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 323
13.8
The Mordukhovich Subdiï¬€erential of Marginal Functions. . . . . 327
13.9
A Nonsmooth Implicit Function Theorem . . . . . . . . . . . . . . . . . . 330
13.10 An Implicit Multifunction Theorem . . . . . . . . . . . . . . . . . . . . . . . 334

XII
Contents
13.11 An Extremal Principle Involving Deformations. . . . . . . . . . . . . . 337
13.12 Application to Multiobjective Optimization . . . . . . . . . . . . . . . . 340
13.13 Bibliographical Notes and Exercises . . . . . . . . . . . . . . . . . . . . . . . 343
Appendix: Further Topics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 347
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 351
Notation. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 363
Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 366

Introduction
Minimizing or maximizing a function subject to certain constraints is one of
the most important problems of real life and consequently of mathematics.
Among others, it was this problem that stimulated the development of
diï¬€erential calculus.
Given a real-valued function f on a real normed vector space E and a
nonempty subset A of E, consider the following problem:
(Min) Minimize f(x) subject to x âˆˆA.
Let Â¯x be a local solution of (Min). If Â¯x is an interior point of A and f is
diï¬€erentiable (in some sense) at Â¯x, then Â¯x satisï¬es the famous Fermat rule
f â€²(Â¯x) = o,
which is thus a necessary optimality condition. If Â¯x âˆˆA is not an interior
point of A but f goes on to be diï¬€erentiable at Â¯x, then a necessary optimality
condition still holds as a variational inequality, which for A convex reads
âŸ¨f â€²(Â¯x), x âˆ’Â¯xâŸ©â‰¥0
for any x âˆˆA.
(0.1)
The assumption that f be diï¬€erentiable at Â¯x is not intrinsic to problem
(Min). Consider, for example, the classical problem of Chebyshev approxi-
mation, which is (Min) with E := C[a, b], the normed vector space of all
continuous functions x : [a, b] â†’R, and
f(x) := âˆ¥x âˆ’zâˆ¥âˆ:= max
aâ‰¤tâ‰¤b |x(t) âˆ’z(t)|,
where z âˆˆC[a, b]\A is given. In this case the functional f fails to be (GÃ¢teaux)
diï¬€erentiable at â€œmostâ€ points x âˆˆC[a, b] and so the above-mentioned app-
roach no longer works.
However, if f is a convex functional, as is the functional in the Chebyshev
approximation problem, then a useful substitute for a nonexisting derivative

2
Introduction
f
0
x
Â¯x
xâˆ—
a
n
epi f
Fig. 0.1
is a subgradient. A subgradient of f at Â¯x is a continuous linear functional xâˆ—
on E satisfying
âŸ¨xâˆ—, yâŸ©â‰¤f(Â¯x + y) âˆ’f(Â¯x)
for all y âˆˆE.
Geometrically this means that the â€œparallelâ€ aï¬ƒne functional a(x) := âŸ¨xâˆ—,
x âˆ’Â¯xâŸ©+ f(Â¯x) satisï¬es a(x) â‰¤f(x) for any x âˆˆE and a(Â¯x) = f(Â¯x) (see
Fig. 0.1). Typically a function admits many subgradients (if any) at a point of
nondiï¬€erentiability. The set of all subgradients of f at Â¯x is called subdiï¬€erential
of f at Â¯x and is denoted âˆ‚f(Â¯x).
Initiated by Rockafellar [177] and Moreau [148], a rich theory of convex sets
and functions including optimality conditions in terms of subdiï¬€erentials has
been developed. This theory is known as convex analysis after Rockafellarâ€™s
now classical book [180]. In the convex case the notion of the conjugate func-
tional is the basis for associating with a given optimization problem another
problem, called the dual problem. The study of the relationship between the
two problems gives signiï¬cant insight into convex optimization.
Problems involving functionals that are neither diï¬€erentiable nor convex
are more diï¬ƒcult to handle. During the last three decades, however, consid-
erable progress has been made also in this area. One starting point is the
observation that in the convex case a subgradient xâˆ—of f at Â¯x can also be
characterized by the inequality
âŸ¨xâˆ—, yâŸ©â‰¤fG(Â¯x, y)
for all y âˆˆE.
(0.2)
Here, fG(Â¯x, y) denotes the directional GÃ¢teaux derivative of f at Â¯x in the
direction y, i.e.,
fG(Â¯x, y) := lim
Ï„â†“0
f(Â¯x + Ï„y) âˆ’f(Â¯x)
Ï„
,

Introduction
3
which is a convex functional of y. If f is not convex, then in general the
functional fG(Â¯x, Â·) is not convex either and a calculus ï¬nally resulting in op-
timality conditions is not available. The idea now is to replace fG(Â¯x, Â·) by
a functional that behaves better. Pshenichnyi [170] and Neustadt [150] con-
sidered upper convex approximations, i.e., convex functionals that majorize
certain directional derivatives such as fG(Â¯x, Â·). A crucial step was Clarkeâ€™s
doctoral thesis [33], which gives an intrinsic (nonaxiomatic) construction of
a convex local approximation of f at Â¯x. Another such construction is due,
among others, to Michel and Penot [129,130]. An eï¬€ective calculus as well as
applicable optimality conditions in terms of these constructs can be developed
for the class of locally Lipschitz continuous functionals. This is elaborated
and applied to problems in the calculus of variations and optimal control
in the monograph [36] by Clarke, which also coined the notion nonsmooth
analysis.
For non-Lipschitz functionals, various derivative-like concepts have been
proposed as local approximations. For lower semicontinuous functionals, two
concepts are particularly promising: On the one hand smooth local approxi-
mations from below which led to the concept of viscosity subdiï¬€erentials and
in particular to proximal subdiï¬€erentials and on the other hand suitable direc-
tional limits that led to FrÃ©chet subdiï¬€erentials. Crucial progress was reached
when it turned out that in FrÃ©chet smooth Banach spaces (Banach spaces
admitting an equivalent norm that is FrÃ©chet diï¬€erentiable at each nonzero
point) the two concepts coincide; this applies in particular to any reï¬‚exive
Banach space. Substantial contributions to this theory are due to Rockafellar,
Clarke, Borwein, Ioï¬€e, and others.
We return to the problem (Min). Beside local approximations of the func-
tional f one also needs local approximations of the set A near the minimum
point Â¯x. For various classes of optimization problems, tangent cones are ade-
quate local approximations. If fâˆ—(Â¯x, Â·) and Tâˆ—(A, Â¯x) are a directional derivative
of f at Â¯x and a tangent cone to A at Â¯x, respectively, that â€œï¬t together,â€ then
the variational inequality
fâˆ—(Â¯x, y) â‰¥0
for any y âˆˆTâˆ—(A, Â¯x)
(0.3)
is a necessary optimality condition generalizing (0.1). Another method of lo-
cally approximating the set A is via normal cones. A conventional way to
deï¬ne a normal cone is as (negative) polar of a tangent cone, which always
yields a convex cone. Polar cones can also be deï¬ned as subdiï¬€erentials of suit-
able functionals, which was done, among others, by Clarke [36] and Ioï¬€e [96].
A third way to deï¬ne normal cones is stimulated by the observation that
xâˆ—âˆˆEâˆ—is a subgradient of the convex functional f at Â¯x if and only if (xâˆ—, âˆ’1)
is a normal vector to the epigraph of f (see the vector n in Fig. 0.1). In the
nonconvex case Mordukhovich [132] ï¬rst deï¬ned normal cones by set limiting
operations and then subdiï¬€erentials via normal cones to epigraphs.

4
Introduction
In terms of some normal cone Nâˆ—(A, Â¯x) and an associated subdiï¬€erential
âˆ‚âˆ—f(Â¯x), a necessary optimality condition corresponding to (0.3) reads
âˆ’xâˆ—âˆˆNâˆ—(A, Â¯x)
for some xâˆ—âˆˆâˆ‚âˆ—f(Â¯x).
This condition is the stronger the smaller Nâˆ—(A, Â¯x) and âˆ‚âˆ—f(Â¯x) are. Under this
aspect, it turns out that convex normal cones may be too large.
In general, FrÃ©chet subdiï¬€erentials only admit an approximate (or fuzzy)
calculus and consequently approximate optimality conditions. It turned out
that the limiting normal cones and subdiï¬€erentials studied by Mordukhovich,
Ioï¬€e, and others admit a rich exact (nonapproximate) calculus at least in Asp-
lund spaces (a class of Banach spaces containing all FrÃ©chet smooth Banach
spaces), provided the functionals and sets involved satisfy suitable compact-
ness assumptions in the inï¬nite dimensional case.
At this point, we must turn to the basic tools necessary for the respective
theory. The principal tool for treating problems with convex and, to a great
extent, locally Lipschitz continuous functionals are separation theorems and
related results such as sandwich theorems. For general lower semicontinuous
functionals, variational principle take over the part of separation theorems.
A variational principle says, roughly speaking, that near a point that â€œalmostâ€
minimizes a functional f, there exists a point z that actually minimizes a
slightly perturbed functional. In the ï¬rst variational principle, discovered by
Ekeland [56], the perturbed functional is not diï¬€erentiable at z. Borwein and
Preiss [19] were the ï¬rst to establish a smooth variational principle. By now
various smooth variational principles have been derived. A third fundamental
tool are extremal principles discovered by Mordukhovich [132]. An extremal
principle provides a necessary condition for a point to be extremal (in a cer-
tain sense) with respect to a system of sets. Mordukhovich largely develops
his theory with the aid of extremal principles. They work especially well in
Asplund spaces and in fact, Asplund spaces can be characterized by an ext-
remal principle. Therefore Asplund spaces are the appropriate framework for
variational analysis.
The book ï¬rst presents the theory of convex functionals (Chaps. 2â€“6). All
the following chapters are devoted to the analysis of nonconvex nondiï¬€eren-
tiable functionals and related objects such as normal cones. A subdiï¬€erential
of f, however it may be deï¬ned, associates with each Â¯x âˆˆE a (possibly empty)
subset of the dual space Eâˆ—and thus is a set-valued mapping or a multifunc-
tion. Therefore, nonsmooth analysis includes (parts of) multifunction theory;
this is contained in Chap. 10. Each chapter ends with references to the liter-
ature and exercises. The latter partly require to carry out proofs of results
given in the text, partly contain additional information and examples. Since
nonsmooth analysis is still a rapidly growing ï¬eld of research, many aspects
had to be omitted. The Appendix indicates some of them.

1
Preliminaries
1.1 Terminology
General Convention. Throughout these lectures, vector space always means
real vector space, and topological vector space always means Hausdorï¬€topo-
logical vector space. Unless otherwise speciï¬ed, E will denote a normed vector
space.
Let N, R, and R+ denote the set of all positive integers, of all real num-
bers and of all nonnegative real numbers, respectively. Further set R :=
R âˆª{âˆ’âˆ, +âˆ}. The operations in R are deï¬ned as usual; in addition, we set
0Â·(Â±âˆ) = (Â±âˆ)Â·0 := 0, but we do not deï¬ne (+âˆ)âˆ’(+âˆ). In Remark 1.3.5
below, we shall explain that it is reasonable to allow a functional to attain
values in R and not only in R.
The zero element of any vector space except R will be denoted o. If A and
B are nonempty subsets of a vector space E and if Î±, Î² âˆˆR, we write
Î±A + Î²B := {Î±x + Î²y | x âˆˆA, y âˆˆB},
R+ A := {Î»x | Î» âˆˆR+, x âˆˆA}.
In particular we write A + y := A + {y}. If one of A, B is empty, we set
A + B := âˆ….
A nonempty subset A of the vector space E is said to be convex if x, y âˆˆA
and Î» âˆˆ(0, 1) imply Î»x + (1 âˆ’Î»)y âˆˆA. The empty set is considered to be
convex also.
Let E be a topological vector space. A subset A of E is said to be circled
if Î±A âŠ†A whenever Î± âˆˆR and |Î±| â‰¤1. Recall that each topological vector
space admits a neighborhood base of zero, U, consisting of closed circled sets.
A neighborhood base of an arbitrary point x âˆˆE is then given by x + U,
where U âˆˆU.
The interior, the closure, and the boundary of a subset A of a topological
vector space are denoted int A, cl A and bd A, respectively. If A is convex, so
are int A and cl A.
A locally convex (vector) space is a topological vector space such that each
neighborhood of zero includes a convex neighborhood of zero. It follows that a

6
1 Preliminaries
locally convex space possesses a neighborhood base of zero consisting of open
convex sets, and also a neighborhood base of zero consisting of closed circled
convex sets.
If E is a topological vector space, Eâˆ—denotes the topological dual of E, i.e.,
the vector space of all continuous linear functionals xâˆ—: E â†’R. If xâˆ—âˆˆEâˆ—,
we write âŸ¨xâˆ—, xâŸ©:= xâˆ—(x) for each x âˆˆE.
Now let E be a normed vector space with norm âˆ¥Â· âˆ¥. If Â¯x âˆˆE and Ïµ > 0,
we set
BE(Â¯x, Ïµ) := {x âˆˆE | âˆ¥x âˆ’Â¯xâˆ¥â‰¤Ïµ},
BE := BE(o, 1),
ËšBE(Â¯x, Ïµ) := {x âˆˆE | âˆ¥x âˆ’Â¯xâˆ¥< Ïµ},
ËšBE := ËšBE(o, 1).
If it is clear from the context, we simply write B(Â¯x, Ïµ), B, ËšB(Â¯x, Ïµ), and ËšB,
respectively. A normed vector space is a locally convex space with respect to
the topology induced by the norm. The inner product of a Hilbert space will
be denoted as (x | y).
1.2 Convex Sets in Normed Vector Spaces
Let E be a normed vector space. A nonempty subset A of E is said to be
absorbing if for each y âˆˆE there exists Î±0 > 0 such that Î±y âˆˆA whenever
|Î±| â‰¤Î±0. The core of A, written cr A, is the set of all x âˆˆA such that A âˆ’x
is absorbing, i.e.,
cr A := {x âˆˆA | âˆ€y âˆˆE âˆƒÎ±0 > 0 âˆ€Î± âˆˆ[âˆ’Î±0, Î±0] : x + Î±y âˆˆA}.
Each convex neighborhood of zero in E is an absorbing set. In a Banach
space, we have the following converse.
Proposition 1.2.1 If E is a Banach space, then each closed convex absorbing
subset A of E is a neighborhood of zero.
Proof. For each n âˆˆN let An := nA. Each An is closed, and since A is
absorbing, we have E = âˆ
n=1 An. By the Baire category theorem it follows
that int(An) is nonempty for at least one n and so the set int A is nonempty.
Hence there exist x âˆˆA and Ï > 0 such that B(x, Ï) âŠ†A. Since A is absorbing,
there further exists Î± > 0 such that âˆ’Î±x = Î±(âˆ’x) âˆˆA. Deï¬ne Ïµ :=
Î±Ï
1+Î±. We
show that B(o, Ïµ) âŠ†A. Let y âˆˆB(o, Ïµ) and set z := x+ 1+Î±
Î± y. Then z âˆˆB(x, Ï)
and so z âˆˆA. Since A is convex, we obtain
y =
1
1 + Î±(âˆ’Î±x) +
Î±
1 + Î±z âˆˆA.
âŠ“âŠ”
We strengthen the concept of a convex set. A nonempty subset A of E is
said to be cs-closed (for convex series closed) if Î»i â‰¥0 (i âˆˆN), âˆ
i=1 Î»i = 1,
xi âˆˆA (i âˆˆN) and x := âˆ
i=1 Î»ixi âˆˆE imply x âˆˆA. It is clear that each
cs-closed set is convex. Lemma 1.2.2 provides examples of cs-closed sets.

1.2 Convex Sets in Normed Vector Spaces
7
Lemma 1.2.2 Closed convex sets and open convex sets in a normed vector
space are cs-closed.
Proof. See Exercise 1.8.1.
âŠ“âŠ”
It is obvious that int A âŠ†cr A for each subset A of E. The following result
describes the relationship between core and interior more precisely.
Proposition 1.2.3 Let A be a nonempty subset of the normed vector space E.
(a) If A is convex and int A is nonempty, then cr A = int A.
(b) If E is a Banach space and A is cs-closed, then cr A = int A = int(cl A).
Proof.
(a) We ï¬rst show that for any Î± âˆˆ[0, 1),
Î± cl A + (1 âˆ’Î±) int A âŠ†int A.
(1.1)
Choose some x0 âˆˆint A. Then (1âˆ’Î±)(int Aâˆ’x0) is an open neighborhood
of o and so
Î± cl A = cl (Î±A) âŠ†Î±A + (1 âˆ’Î±)(int A âˆ’x0) âŠ†A âˆ’(1 âˆ’Î±)x0.
Since this holds for any x0 âˆˆint A, the left-hand side of (1.1), which is
obviously open, is contained in A. This veriï¬es (1.1). To prove cr A = int A,
it suï¬ƒces to show that cr A âŠ†int A. Let x âˆˆcr A. Then there exists Î» > 0
such that y := x + Î»(x âˆ’x0) âˆˆA. By (1.1), it follows that
x =
1
1 + Î»y +
Î»
1 + Î»x0 âˆˆint A.
(b) (I) First we verify, following Borwein and Zhu [24], that int A = int(cl A).
For this, it suï¬ƒces to show that int(cl A) âŠ†int A under the additional
assumption that int(cl A) Ì¸= âˆ…. Let y0 âˆˆint(cl A). Then there exists
Ïµ > 0 such that B(y0, Ïµ) âŠ†cl A and so B âŠ†1
Ïµ (cl Aâˆ’y0). Since together
with A, the set 1
Ïµ (Aâˆ’y0) is also cs-closed, we may assume that y0 = o
and B âŠ†cl A âŠ†A+ 1
2B. From this inclusion we obtain for i = 1, 2, . . . ,
1
2i B âŠ†1
2i A+
1
2i+1 B
and so
1
2B âŠ†1
2A+ 1
22 A+Â· Â· Â·+ 1
2i A+
1
2i+1 B.
Thus, if y âˆˆ1
2B, there exist x1, . . . , xi âˆˆA such that
y âˆˆ1
2x1 + 1
22 x2 + Â· Â· Â· + 1
2i xi +
1
2i+1 B.
It follows that y = âˆ
i=1 xi/2i and so y âˆˆA as A is cs-closed. Hence
1
2B âŠ†A and therefore y0 = o âˆˆint A.
(II) In order to verify cr A = int A, it suï¬ƒces to show cr A âŠ†int A under
the additional assumption that cr A Ì¸= âˆ…. Let z0 âˆˆcr A âŠ†cr(cl A).
Since cl A âˆ’z0 is closed and absorbing, the Baire category theorem
implies that int(cl A) Ì¸= âˆ…(cf. the proof of Proposition 1.2.1), and step
(I) shows that int A is nonempty. As the set A is cs-closed, it is also
convex. Therefore the assertion follows from (a).
âŠ“âŠ”

8
1 Preliminaries
1.3 Convex Functionals: Deï¬nitions and Examples
Convention. In this section, unless otherwise speciï¬ed, E denotes a vector
space and M denotes a nonempty subset of E.
Deï¬nition 1.3.1 If f : M â†’R, then we call
dom f := {x âˆˆM | f(x) < +âˆ}
eï¬€ective domain of f,
epi f := {(x, t) âˆˆM Ã— R | f(x) â‰¤t} epigraph of f.
Further, f is said to be proper (in German: eigentlich) if dom f Ì¸= âˆ…and
f(x) > âˆ’âˆfor each x âˆˆM.
Deï¬nition 1.3.2 is crucial for these lectures.
Deï¬nition 1.3.2 Let M âŠ†E be nonempty and convex. The functional f :
M â†’R is called convex if
f

Î»x + (1 âˆ’Î»)y

â‰¤Î»f(x) + (1 âˆ’Î»)f(y)
(1.2)
holds for all x, y âˆˆM and all Î» âˆˆ(0, 1) for which the right-hand side is
deï¬ned, i.e., is not of the form (+âˆ) + (âˆ’âˆ) or (âˆ’âˆ) + (+âˆ). If (1.2) holds
with < instead of â‰¤whenever x Ì¸= y, then f is called strictly convex.
Lemma 1.3.3 Let M âŠ†E be nonempty and convex and let f : M â†’R:
(a) f is convex if and only if epi f is a convex set.
(b) If f is convex, then for each Î» âˆˆR, the set {x âˆˆM | f(x) â‰¤Î»} is convex.
Proof. See Exercise 1.8.2.
âŠ“âŠ”
Lemma 1.3.4 Let E be a topological vector space and let f : E â†’R be
convex. If f(x0) > âˆ’âˆfor some x0 âˆˆint dom f, then f(x) > âˆ’âˆfor each
x âˆˆE.
Proof. Assume there exists x1 âˆˆE satisfying f(x1) = âˆ’âˆ. Since x0 âˆˆ
int dom f, we have x2 := x0 + Î»(x0 âˆ’x1) âˆˆdom f for each suï¬ƒciently small
Î» âˆˆ(0, 1). Since x0 =
Î»
1+Î»x1 +
1
1+Î»x2 and f is convex, we obtain
âˆ’âˆ< f(x0) â‰¤
Î»
1 + Î»f(x1) +
1
1 + Î»f(x2),
which is contradictory.
âŠ“âŠ”
Remark 1.3.5 According to Lemma 1.3.4, it is quite pathological for a con-
vex functional on a topological vector space to attain the value âˆ’âˆ. The fol-
lowing construction shows that this is not so with the value +âˆ. Let M âŠ†E

1.3 Convex Functionals: Deï¬nitions and Examples
9
be nonempty and convex, and let g : M â†’R be convex. Then the functional
f : E â†’R deï¬ned by
f(x) :=

g(x)
if x âˆˆM,
+âˆ
if x âˆˆE \ M
is proper and convex. Conversely, if f : E â†’R is proper and convex, then
M := dom f is nonempty and convex and the restriction of f to M is ï¬nite
and convex. Therefore, we may assume that a convex functional is of the form
f : E â†’R.
We consider important classes of convex functionals.
Example 1.3.6 Let M âŠ†E be nonempty. The functional Î´M : E â†’R
deï¬ned by
Î´M(x) :=

0
if x âˆˆM,
+âˆ
if x âˆˆE \ M
is called indicator functional of M. Obviously, Î´M is proper and convex if and
only if M is nonempty and convex.
Example 1.3.7 Let E be a topological vector space and A a nonempty subset
of Eâˆ—. Then the support functional ÏƒA : E â†’R of A deï¬ned by
ÏƒA(x) := sup
xâˆ—âˆˆA
âŸ¨xâˆ—, xâŸ©,
x âˆˆE,
is proper and convex. An analogous remark applies to the support functional
ÏƒM : Eâˆ—â†’R of a nonempty subset M of E.
Example 1.3.8 Let u : E â†’R be linear and c âˆˆR. The functional
f : E â†’R deï¬ned by f(x) := u(x) + c for x âˆˆE, which is called aï¬ƒne,
is convex.
Example 1.3.9 The functional f : E â†’R is said to be sublinear if f is
proper, nonnegatively homogeneous (i.e., f(Î»x) = Î»f(x) for any x âˆˆE and
any Î» â‰¥0), and subadditive (i.e., f(x + y) â‰¤f(x) + f(y) for all x, y âˆˆE).
If f is sublinear, then f is also convex, and in particular f(o) = 0 (recall that
0 Â· (+âˆ) := 0). The norm functional of a normed vector space is sublinear
and so convex.
Example 1.3.10 Let E be a Hilbert space, let T : E â†’E be linear and self
adjoint, let x0 âˆˆE, and let c âˆˆR. Consider the quadratic functional
f(x) := 1
2(Tx | x) âˆ’(x0 | x) + c,
x âˆˆE.
Then
f is convex â‡â‡’T is positively semideï¬nite (i.e. (Tx | x) â‰¥0 âˆ€x âˆˆE).

10
1 Preliminaries
We indicate the proof of this statement.
=â‡’: This follows immediately from
f
1
2x

â‰¤1
2f(x) + 1
2f(o).
â‡=: Since x â†’âˆ’(x0 | x) + c, x âˆˆE, is aï¬ƒne and so convex, it remains to
show that g(x) := (Tx | x), x âˆˆE, is convex. Let x, y âˆˆE and 0 < Î» < 1.
Then
g

Î»x + (1 âˆ’Î»)y

= Î»2
T(x âˆ’y)
 x âˆ’y

+ Î»

T(x âˆ’y)
 y

+ Î»

Ty
 x âˆ’y

+

Ty
 y

.
Since Î»2 < Î» and, by assumption,

T(x âˆ’y)
 x âˆ’y

â‰¥0, we have
Î»2
T(x âˆ’y)
 x âˆ’y

â‰¤Î»

T(x âˆ’y)
 x âˆ’y

.
Using this and the self adjointness of T, we immediately obtain
g

Î»x + (1 âˆ’Î»)y

â‰¤Î»g(x) + (1 âˆ’Î»)g(y).
Example 1.3.11 Let E be a normed vector space. If M âŠ†E, then the dis-
tance functional x â†’dM(x) is deï¬ned by
dM(x) := d(M, x) := d(x, M) := inf
yâˆˆM âˆ¥x âˆ’yâˆ¥, x âˆˆE.
Recall that inf âˆ…:= +âˆ. If M is nonempty and convex, then dM is easily seen
to be proper and convex.
Example 1.3.12 Let E be a topological vector space, let M âŠ†E be non-
empty and set
pM(x) := inf{Î» > 0 | x âˆˆÎ»M}, x âˆˆE.
The functional pM : E â†’R is called Minkowski functional or gauge.
Lemma 1.3.13 summarizes important properties of pM.
Lemma 1.3.13 Let E be a topological vector space. If M âŠ†E is nonempty
and convex and o âˆˆint M, then:
(a) 0 â‰¤pM(x) < +âˆfor all x âˆˆE.
(b) pM is sublinear and continuous.
(c) int M = {x âˆˆE | pM(x) < 1} âŠ†M âŠ†{x âˆˆE | pM(x) â‰¤1} = cl M.
(d) If, in addition, M is symmetric (i.e., x âˆˆM =â‡’âˆ’x âˆˆM) and bounded,
then pM is a norm on E that generates the topology of E.
Proof. See, for instance, Aliprantis and Border [2].
âŠ“âŠ”

1.4 Continuity of Convex Functionals
11
1.4 Continuity of Convex Functionals
In this section, we study continuity properties of convex functionals.
Recall that if E is a normed vector space, then the proper functional
f : E â†’R is said to be locally Lipschitz continuous, or brieï¬‚y locally L-
continuous, around Â¯x âˆˆdomf if there exist Ïµ > 0 and Î» > 0 such that
|f(x) âˆ’f(y)| â‰¤Î»âˆ¥x âˆ’yâˆ¥
âˆ€x, y âˆˆB(Â¯x, Ïµ).
Moreover, f is called locally L-continuous on the open subset D of E if f is
locally L-continuous around each Â¯x âˆˆD.
Theorem 1.4.1 Let E be a topological vector space and let f : E â†’R be
proper, convex and bounded above on some nonempty open subset G of E.
Then f is continuous on int dom f. If, in particular, E is a normed vector
space, then f is locally L-continuous on int dom f.
Proof.
(I) By assumption, there exists a > 0 such that f(y) < a for each y âˆˆG. In
particular, G âŠ†int domf. We ï¬rst show that f is continuous on G.
(Ia) To prepare the proof, we show the following: If Â¯x âˆˆdom f, z âˆˆE,
Â¯x + z âˆˆdom f, Â¯x âˆ’z âˆˆdom f, and Î» âˆˆ[0, 1], then
|f(Â¯x + Î»z) âˆ’f(Â¯x)| â‰¤Î» max{f(Â¯x + z) âˆ’f(Â¯x), f(Â¯x âˆ’z) âˆ’f(Â¯x)}.
(1.3)
Veriï¬cation of (1.3): Since Â¯x + Î»z = (1 âˆ’Î»)Â¯x + Î»(Â¯x + z) âˆˆdom f, we
have f(Â¯x + Î»z) â‰¤(1 âˆ’Î»)f(Â¯x) + Î»f(Â¯x + z), hence
f(Â¯x + Î»z) âˆ’f(Â¯x) â‰¤Î»

f(Â¯x + z) âˆ’f(Â¯x)

.
(1.4)
Analogously, with z replaced by âˆ’z, we obtain
f(Â¯x âˆ’Î»z) âˆ’f(Â¯x) â‰¤Î»

f(Â¯x âˆ’z) âˆ’f(Â¯x)

.
(1.5)
From Â¯x = 1
2(Â¯x + Î»z) + 1
2(Â¯x âˆ’Î»z) we conclude that f(Â¯x) â‰¤1
2f(Â¯x + Î»z) +
1
2f(Â¯x âˆ’Î»z) and so f(Â¯x) âˆ’f(Â¯x + Î»z) â‰¤f(Â¯x âˆ’Î»z) âˆ’f(Â¯x), which together
with (1.5) gives f(Â¯x) âˆ’f(Â¯x + Î»z) â‰¤Î»

f(Â¯x âˆ’z) âˆ’f(Â¯x)

. From this and
(1.4) we obtain (1.3).
(Ib) Now let Â¯x âˆˆG and let Ïµ > 0. Then there exists a circled neighborhood U
of zero such that Â¯x + U âŠ†G. Let Î» âˆˆ(0, 1] be such that Î»(a âˆ’f(Â¯x)) < Ïµ.
Then (1.3) implies |f(y)âˆ’f(Â¯x)| < Ïµ for all y in the neighborhood Â¯x+Î»U
of Â¯x. Hence f is continuous at Â¯x.
(II) We show that f is continuous at Â¯y âˆˆint dom f. Let Â¯x and U be as in
step (Ib). Then there exists Î´ > 0 such that z := Â¯y + Î´(Â¯y âˆ’Â¯x) âˆˆdom f
(see Fig. 1.1). Set Î» := Î´/(1 + Î´). If y âˆˆU, then Â¯y + Î»y = Î»Â¯x + (1 âˆ’Î»)z
and so
f(Â¯y + Î»y) â‰¤Î»f(Â¯x + y) + (1 âˆ’Î»)f(z) < Î»a + (1 âˆ’Î»)f(z).

12
1 Preliminaries
z
Â¯y + Î»U
Â¯y
Â¯x
Â¯x + U
G
Fig. 1.1
Since f(z) < +âˆ, we see that f is bounded above on the neighborhood
Â¯y + Î»U of Â¯y and so on the open set int(Â¯y + Î»U) that also contains Â¯y. By
step (I), f is continuous at Â¯y.
(III) Now let E be a normed vector space and let Â¯y âˆˆint dom f. By step (II)
there exist c, Ï > 0 satisfying
|f(x)| â‰¤c
âˆ€x âˆˆB(Â¯y, 2Ï).
(1.6)
Assume, to the contrary, that f is not locally L-continuous around Â¯y.
Then there exist x, y âˆˆB(Â¯y, Ï) such that
f(x) âˆ’f(y) > 2c
Ï âˆ¥x âˆ’yâˆ¥.
Set Î± :=
Ï
âˆ¥xâˆ’yâˆ¥and Ë†x := x + Î±(x âˆ’y). Then we have x =
1
1+Î± Ë†x +
Î±
1+Î±y
which implies f(x) â‰¤
1
1+Î±f(Ë†x) +
Î±
1+Î±f(y) and so
f(Ë†x) âˆ’f(x) â‰¥Î±

f(x) âˆ’f(y)

> 2c.
But this contradicts (1.6) as Ë†x âˆˆB(Â¯y, 2Ï).
âŠ“âŠ”
Convex functions on a ï¬nite-dimensional normed vector space have a
remarkable continuity behavior.
Corollary 1.4.2 If f : Rn â†’R is proper and convex and int dom f is non-
empty, then f is locally L-continuous on int dom f.
Proof. We shall show that f is bounded above on a nonempty open subset G
of Rn; the assertion then follows from Theorem 1.4.1. Let Â¯x = (Â¯x1, . . . , Â¯xn) âˆˆ
int dom f. Then there exists Î± > 0 such that int dom f contains the closed
cube C with center Â¯x and edge length Î±. Let
G := {(x1, . . . , xn) âˆˆRn  Â¯xi < xi < Â¯xi + Î±
n}.
Then G is nonempty, open, and contained in C (Fig. 1.2). Let

e(1), . . . , e(n)
denote the standard basis of Rn. If x âˆˆG, then we have

1.5 Sandwich and Separation Theorems
13
F
Â¯x + Î±e(2)
Â¯x + Î±e(1)
G
Â¯x
Fig. 1.2
x =
n
	
i=1
xie(i) =
n
	
i=1
xiâˆ’Â¯xi
Î±
(Â¯x + Î±e(i)) +

1 âˆ’
n
	
i=1
xiâˆ’Â¯xi
Î±

Â¯x
and so
f(x) â‰¤
n
i=1
xiâˆ’Â¯xi
Î±
f

Â¯x + Î±e(i)
+

1 âˆ’
n
i=1
xiâˆ’Â¯xi
Î±

f(Â¯x)
â‰¤max

f

Â¯x + Î±e(1)
, . . . , f

Â¯x + Î±e(n)
, f(Â¯x)

.
âŠ“âŠ”
By Corollary 1.4.2, each R-valued convex function on Rn is locally L-
continuous. Notice that, in contrast to this, on each inï¬nite-dimensional
normed vector space there always exist even linear functionals that are dis-
continuous.
1.5 Sandwich and Separation Theorems
In this and in Sect. 1.6 we repeat, in a form appropriate to our purposes, some
facts from Functional Analysis that will be frequently needed in the sequel.
A nonempty subset P of a vector space E is called cone if x âˆˆP and Î» > 0
imply Î»x âˆˆP. Moreover, P is called convex cone if P is a cone and a convex
set. Obviously, P is a convex cone if and only if x, y âˆˆP and Î», Âµ > 0 imply
Î»x + Âµy âˆˆP. By deï¬nition, the empty set is also a cone.
If P is a nonempty convex cone in E, then
x â‰¤P y
:â‡â‡’
y âˆ’x âˆˆP
deï¬nes a relation â‰¤P on E that is transitive and compatible with the vector
space structure of E, i.e., for all x, y, z âˆˆE and Î» âˆˆR we have
x â‰¤P y and y â‰¤P z
=â‡’
x â‰¤P z,
x â‰¤P y
=â‡’
x + z â‰¤P y + z,
x â‰¤P y and Î» > 0
=â‡’
Î»x â‰¤P Î»y.

14
1 Preliminaries
Moreover, we have
P = {x âˆˆE | o â‰¤P x}.
Notice that the zero element o need not belong to P and so the relation â‰¤P
need not be reï¬‚exive. We call â‰¤P the preorder generated by P.
Proposition 1.5.1 (Extension Theorem) Let M be a linear subspace of
the vector space E and P a nonempty convex cone in E satisfying P âŠ†M âˆ’P.
Suppose further that u : M â†’R is linear and satisï¬es u(x) â‰¥0 for any
x âˆˆM âˆ©P. Then there exists a linear functional v : E â†’R such that
v(x) = u(x) for every x âˆˆM and v(x) â‰¥0 for every x âˆˆP.
Proof. Set E1 := span(M âˆªP) = M + P âˆ’P and
p(x) := inf{u(y) | y âˆˆM, y âˆ’x âˆˆP},
x âˆˆE1.
Since P âŠ‚M âˆ’P, the functional p is easily seen to be ï¬nite on E1. Further
p is sublinear and satisï¬es u(x) â‰¤p(x) for any x âˆˆM. By the Hahnâ€“Banach
theorem, there exists a linear functional v1 : E1 â†’R such that v1(x) = u(x)
for any x âˆˆM and v1(x) â‰¤p(x) for any x âˆˆE1. Setting v(x) := v1(x) for
every x âˆˆE1 and v(x) := 0 for every x in the algebraic complement of E1 in
E completes the proof.
âŠ“âŠ”
The following result will be a useful tool in the analysis of convex func-
tionals.
Theorem 1.5.2 (Sandwich Theorem) Let E be a topological vector space
and let p, q : E â†’R be proper, convex and such that âˆ’q(x) â‰¤p(x) for all
x âˆˆE. Suppose further that
(A1) (int dom p) âˆ©dom q Ì¸= âˆ…and p is continuous at some point of int dom p
or
(A2) dom p âˆ©(int dom q) Ì¸= âˆ…and q is continuous at some point of int dom q.
Then there exist v âˆˆEâˆ—and c âˆˆR such that
âˆ’q(x) â‰¤âŸ¨v, xâŸ©+ c â‰¤p(x)
âˆ€x âˆˆE
(see Fig. 1.3 for E = R).
p
âˆ’q
v
v + c
Fig. 1.3

1.5 Sandwich and Separation Theorems
15
Proof. (I) We set
F := E Ã— R Ã— R,
M := {o} Ã— {0} Ã— R,
u(o, 0, Ï) := âˆ’Ï
âˆ€Ï âˆˆR,
P := {Î²(y, 1, t) âˆ’Î±(x, 1, s)
 Î±, Î² â‰¥0; s, t âˆˆR;
x âˆˆdom p; y âˆˆdom q; p(x) â‰¤s; âˆ’q(y) â‰¥t}.
Then we have:
(a) u is a linear functional on the linear subspace M of F satisfying
u(z) â‰¥0 for any z âˆˆM âˆ©P.
(b) P is a convex cone in F.
(c) P âŠ‚M âˆ’P.
It is easy to verify (a) and (b). We prove (c). Let z âˆˆP, thus z =
Î²(y, 1, t) âˆ’Î±(x, 1, s). Suppose assumption (A1) holds. Then there exists
z0 âˆˆ(int dom p) âˆ©dom q. For Î´ > 0 deï¬ne
zÎ´ := z0 + Î´

Î²y âˆ’Î±x âˆ’(Î² âˆ’Î±)z0

.
It follows that zÎ´ âˆˆdom p if Î´ is suï¬ƒciently small. Hence, with Î´ and Ï
appropriately chosen, we obtain
z = 1
Î´

zÎ´, 1, p(zÎ´)

âˆ’
 1
Î´ âˆ’Î² + Î±

z0, 1, âˆ’q(z0)

+ (o, 0, Ï) âˆˆâˆ’P + M.
(II) By Proposition 1.5.1 there exists a linear functional w : F â†’R satisfying
w(z) = u(z) for all z âˆˆM and w(z) â‰¥0 for all z âˆˆP. In particular, we
have w(o, 0, 1) = âˆ’1. Deï¬ne
v(x) := w(x, o, 0)
âˆ€x âˆˆE,
c := w(o, 1, 0).
Then v : E â†’R is linear and w(x, s, t) = v(x)+csâˆ’t for all (x, s, t) âˆˆF.
If x âˆˆdom p, then z := âˆ’

x, 1, p(x)

âˆˆP. It follows that
0 â‰¤w(z) = âˆ’v(x) âˆ’c + p(x) and so v(x) + c â‰¤p(x).
(1.7)
Analogously we obtain âˆ’q(x) â‰¤v(x) + c. Since p is continuous at
some point of int dom p, the second inequality in (1.7) implies that v is
bounded above on a nonempty open set and so, by Theorem 1.4.1, is
continuous.
(III) A similar argument applies under the assumption (A2).
âŠ“âŠ”
The sandwich theorem describes the separation of a concave functional âˆ’q
and a convex functional p by a continuous aï¬ƒne functional. Now we consider
the separation of convex sets by a hyperplane.
Recall that a hyperplane in the topological vector space E is a set of the
form
[xâˆ—= Î±] := {x âˆˆE | âŸ¨xâˆ—, xâŸ©= Î±},
(1.8)

16
1 Preliminaries
A
B
[xâˆ—= Î±]
Fig. 1.4
A
B
Fig. 1.5
where xâˆ—âˆˆEâˆ—, xâˆ—Ì¸= o, and Î± âˆˆR. The hyperplane [xâˆ—= Î±] separates the
space E into the half-spaces [xâˆ—â‰¤Î±] and [xâˆ—â‰¥Î±], where the notation is
analogous to (1.8).
The subsets A and B of E are said to be separated if there exists a hyper-
plane [xâˆ—= Î±] such that (see Fig. 1.4)
A âŠ†[xâˆ—â‰¤Î±]
and
B âŠ†[xâˆ—â‰¥Î±].
(1.9)
Further we say that the subsets A and B of E are strongly separated if there
exist a hyperplane [xâˆ—= Î±] and Ïµ > 0 such that (see Fig. 1.5)
A âŠ†[xâˆ—â‰¤Î± âˆ’Ïµ]
and
B âŠ†[xâˆ—â‰¥Î± + Ïµ].
(1.10)
Theorem 1.5.3 (Weak Separation Theorem) Let A and B be nonempty
convex subsets of the topological vector space E and assume that int A Ì¸= âˆ….
Then the following statements are equivalent:
(a) A and B are separated.
(b) (int A) âˆ©B = âˆ….
Proof. (a) =â‡’(b): Assume that there exists a nonzero xâˆ—âˆˆEâˆ—such that (1.9)
holds. Suppose, to the contrary, that there exists Â¯x âˆˆ(int A) âˆ©B. Let y âˆˆE
be given. Then for Ï > 0 suï¬ƒciently small, we have yÂ± := Â¯x Â± Ï(y âˆ’Â¯x) âˆˆA
and so
Î± â‰¥âŸ¨xâˆ—, yÂ±âŸ©= âŸ¨xâˆ—, Â¯xâŸ©Â± ÏâŸ¨xâˆ—, y âˆ’Â¯xâŸ©.

1.5 Sandwich and Separation Theorems
17
Since âŸ¨xâˆ—, Â¯xâŸ©= Î± it follows that Â±âŸ¨xâˆ—, y âˆ’Â¯xâŸ©â‰¤0 and so âŸ¨xâˆ—, yâŸ©= âŸ¨xâˆ—, Â¯xâŸ©.
Since y âˆˆE is arbitrary and xâˆ—is linear, we conclude that xâˆ—= o : a contra-
diction.
(b) =â‡’(a): Let x0 âˆˆint A and let p denote the Minkowski functional of
A âˆ’x0. Further deï¬ne q : E â†’R by q(x) := âˆ’1 for all x âˆˆB âˆ’x0 and
q(x) := +âˆfor all x âˆˆE \ (B âˆ’x0). Applying Lemma 1.3.13, it is easy to
see that the assumptions of Theorem 1.5.2 are satisï¬ed. Hence there exist
xâˆ—âˆˆEâˆ—and c âˆˆR such that
âŸ¨xâˆ—, xâŸ©+ c â‰¤p(x) âˆ€x âˆˆE
and
âŸ¨xâˆ—, xâŸ©+ c â‰¥1 âˆ€x âˆˆB âˆ’x0.
It follows that xâˆ—Ì¸= o (consider x = o) and that the hyperplane [xâˆ—= Î±],
where Î± := âŸ¨xâˆ—, x0âŸ©+ 1 âˆ’c, separates A and B.
âŠ“âŠ”
Corollary 1.5.4 Let A be a convex cone in E, B a nonempty convex subset
of E, and assume that int A Ì¸= âˆ…but (int A) âˆ©B = âˆ…. Then there exists
xâˆ—âˆˆEâˆ—, xâˆ—Ì¸= o, such that
âŸ¨xâˆ—, xâŸ©â‰¤0 âˆ€x âˆˆA
and
âŸ¨xâˆ—, yâŸ©â‰¥0 âˆ€y âˆˆB.
Proof. See Exercise 1.8.3.
âŠ“âŠ”
Let A âŠ†E and Â¯x âˆˆA. The hyperplane [xâˆ—= Î±] is said to be a supporting
hyperplane of A at Â¯x if
Â¯x âˆˆ[xâˆ—= Î±]
and
A âŠ†[xâˆ—â‰¤Î±]
or
A âŠ†[xâˆ—â‰¥Î±]
(Fig. 1.6).
A point Â¯x âˆˆA admitting a supporting hyperplane of A is said to be a support
point of A. There is an obvious relationship to the support functional ÏƒA
of A. If Â¯x is a support point of A and [xâˆ—= Î±] is a supporting hyperplane
such that A âŠ†[xâˆ—â‰¤Î±], then ÏƒA(xâˆ—) = âŸ¨xâˆ—, Â¯xâŸ©. An immediate consequence of
Theorem 1.5.3 is:
Corollary 1.5.5 Let A be closed convex subset of the topological vector space
E and assume that int A is nonempty. Then any boundary point of A is a
support point of A.
A
Â¯x
[xâˆ—= Î±]
[xâˆ—â‰¤Î±]
[xâˆ—â‰¥Î±]
Fig. 1.6

18
1 Preliminaries
We supplement the preceding results by two statements presented without
proof that refer to the case int A = âˆ….
Theorem 1.5.6 (Bishopâ€“Phelps Theorem) If A is a closed convex subset
of the Banach space E, then the set of support points of A is dense in the
boundary of A.
Proof. See, for instance, Phelps [165].
âŠ“âŠ”
Proposition 1.5.7 Let E be a ï¬nite-dimensional normed vector space, and
let A and B be nonempty convex subsets of E. Then the following statements
are equivalent:
(a) A and B are separated.
(b) A âˆ©B = âˆ….
Proof. See, for instance, Holmes [92].
âŠ“âŠ”
Notice that the condition (b) of Theorem 1.5.3 is equivalent to o /âˆˆ
(int A) âˆ’B. Strengthening this condition, we obtain a result on strong sepa-
ration, provided we restrict ourselves to locally convex spaces.
Theorem 1.5.8 (Strong Separation Theorem 1) Assume that E is a lo-
cally convex space and that A and B are nonempty convex subsets of E. Then
the following statements are equivalent:
(a) A and B are strongly separated.
(b) o /âˆˆcl (A âˆ’B).
Proof. (a) =â‡’(b): Exercise 1.8.4.
(b) =â‡’(a): By virtue of (b) there exists an open convex neighborhood U
of zero such that A âˆ©(B + U) = âˆ…. Moreover, B + U is open. Hence, by
Theorem 1.5.3, there exists a closed hyperplane [xâˆ—= Î±â€²] such that A âŠ†[xâˆ—â‰¤
Î±â€²] and B+U âŠ†[xâˆ—â‰¥Î±â€²]. Choose some z0 âˆˆâˆ’U such that âŸ¨xâˆ—, z0âŸ©> 0, which
exists since xâˆ—Ì¸= o. Set Î± := supxâˆˆAâŸ¨xâˆ—, xâŸ©+ 1
2âŸ¨xâˆ—, z0âŸ©and Ïµ := 1
2âŸ¨xâˆ—, z0âŸ©.
It follows that A âŠ†[xâˆ—â‰¤Î± âˆ’Ïµ] and B âŠ†[xâˆ—â‰¥Î± + Ïµ].
âŠ“âŠ”
The following is a frequently used special case of Theorem 1.5.8.
Theorem 1.5.9 (Strong Separation Theorem 2) Assume that A and B
are nonempty convex subsets of the locally convex space E such that A is
closed, B is compact, and A âˆ©B = âˆ…. Then A and B are strongly separated.
Proof. See Exercise 1.8.5.
âŠ“âŠ”
Simple examples, already with E = R2, show that Theorem 1.5.9 may fail
if â€œcompactâ€ is replaced by â€œclosed.â€
In analogy to Corollary 1.5.4 we now have:

1.6 Dual Pairs of Vector Spaces
19
Corollary 1.5.10 Let A be a closed convex cone in E, B a nonempty compact
convex subset of E, and assume that A âˆ©B = âˆ…. Then there exists xâˆ—âˆˆEâˆ—,
xâˆ—Ì¸= o, and Ïµ > 0 such that
âŸ¨xâˆ—, xâŸ©â‰¤0
âˆ€x âˆˆA
and
âŸ¨xâˆ—, yâŸ©â‰¥Ïµ
âˆ€y âˆˆB.
Proof. See Exercise 1.8.6.
âŠ“âŠ”
1.6 Dual Pairs of Vector Spaces
For results in this section stated without proof, see the references at the end
of the chapter. The following notion will be the basis for the duality theory
of convex optimization.
Deï¬nition 1.6.1 Let E and F be vector spaces.
(a) A functional a : E Ã— F â†’R is said to be bilinear if a(Â·, u) is linear on E
for each ï¬xed u âˆˆF and a(x, Â·) is linear on F for each ï¬xed x âˆˆE.
(b) Let a : E Ã— F â†’R be a bilinear functional with the following properties:
If a(x, u) = 0 for each x âˆˆE, then u = o,
if a(x, u) = 0 for each u âˆˆF, then x = o.
(1.11)
Then (E, F) is called dual pair of vector spaces with respect to a.
Example 1.6.2 Let E be a locally convex space. Then (E, Eâˆ—) is a dual pair
with respect to the bilinear functional
a(x, xâˆ—) := âŸ¨xâˆ—, xâŸ©
âˆ€x âˆˆE
âˆ€xâˆ—âˆˆEâˆ—.
We verify (1.11). It is clear by deï¬nition that âŸ¨xâˆ—, xâŸ©= 0 for each x âˆˆE implies
xâˆ—= o. Now let âŸ¨xâˆ—, xâŸ©= 0 for each xâˆ—âˆˆEâˆ—. Assume that x Ì¸= o. Then
there exist a closed convex (circled) neighborhood U of zero not containing
x. By Theorem 1.5.9, the closed set U and the compact set {x} are strongly
separated. Hence there exist xâˆ—âˆˆEâˆ—\ {o}, Î± âˆˆR and Ïµ > 0 such that
âŸ¨xâˆ—, yâŸ©â‰¤Î± âˆ’Ïµ
âˆ€y âˆˆU
and
âŸ¨xâˆ—, xâŸ©â‰¥Î± + Ïµ.
Considering y = o, we see that Î±âˆ’Ïµ â‰¥0, and it follows that âŸ¨xâˆ—, xâŸ©â‰¥Î±+Ïµ >
Î± âˆ’Ïµ â‰¥0: a contradiction.
We shall now show that this example provides the prototype of a dual
pair. Let (E, F) be a dual pair with respect to the bilinear functional a. The
weak topology Ïƒ(E, F) on E is by deï¬nition the weakest topology on E such
that each linear functional x â†’a(x, u) is continuous; here u varies over F.
In other words, each u âˆˆF deï¬nes an element xâˆ—
u of Eâˆ—via

20
1 Preliminaries
âŸ¨xâˆ—
u, xâŸ©:= a(x, u)
âˆ€x âˆˆE.
(1.12)
By (1.11), if u Ì¸= v, then xâˆ—
u Ì¸= xâˆ—
v. Hence we can identify xâˆ—
u with u, so that
we obtain F âŠ†Eâˆ—. Proposition 1.6.3 states, among others, that each xâˆ—âˆˆEâˆ—
is of the form xâˆ—
u for some u âˆˆF. If we want to indicate the topology, say Ï„,
of a topological vector space E, we write E[Ï„] instead of E. Similarly, we use
E[ âˆ¥Â· âˆ¥].
Proposition 1.6.3 If (E, F) is a dual pair of vector spaces with respect to
the bilinear functional a, then:
(a) The weak topology Ïƒ(E, F) is a locally convex topology on E, a neighbor-
hood base of zero being formed by the sets
U(u1, . . . , um) := {x âˆˆE
 |a(x, ui)| < 1 for i = 1, . . . , m},
where m âˆˆN and u1, . . . , um âˆˆF.
(b) For each xâˆ—âˆˆEâˆ—there exists precisely one u âˆˆF such that xâˆ—= xâˆ—
u (see
(1.12)). The dual Eâˆ—of the locally convex space E[Ïƒ(E, F)] can thus be
identiï¬ed with F.
Of course, the same holds true with the roles of E and F exchanged, i.e.,
one deï¬nes analogously the weak topology Ïƒ(F, E) on F. Then the dual F âˆ—
of F[Ïƒ(F, E)] can be identiï¬ed with E.
Let (E, F) be a dual pair with respect to some bilinear functional.
A locally convex topology Ï„E on E is said to be compatible with the dual pair
(E, F) if E[Ï„E]âˆ—= F in the sense described above, analogously for a locally
convex topology on F. If (E, F) is a dual pair of vector spaces and if Ï„E,
Ï„F are compatible topologies on E and F, respectively, then (E[Ï„E], F[Ï„F ])
is called dual pair of locally convex spaces. A complete characterization of
compatible topologies (not needed in this book) is given by the Mackeyâ€“Arens
theorem.
Remark 1.6.4
(a) Let E[Ï„] be a locally convex space. Since (E, Eâˆ—) is a dual pair of vector
spaces (see Example 1.6.2), we can consider the weak topology Ïƒ(E, Eâˆ—)
on E, which is weaker than Ï„. On Eâˆ—, we have to distinguish between
the topologies Ïƒ(Eâˆ—, Eâˆ—âˆ—) and Ïƒ(Eâˆ—, E). The latter is called weak star
topology or weakâˆ—topology. Among others, we have the following dual
pairs of locally convex spaces:

E[Ï„], Eâˆ—[Ïƒ(Eâˆ—, E)]

and

E[Ïƒ(E, Eâˆ—)], Eâˆ—[Ïƒ(Eâˆ—, E)]

.
If A is a subset of Eâˆ—, we denote by clâˆ—A the Ïƒ(Eâˆ—, E)-closure of A and
by coâˆ—A the Ïƒ(Eâˆ—, E)-closed convex hull of A. A sequence (xk) in E that
is Ïƒ(E, Eâˆ—)-convergent to x âˆˆE is said to be weakly convergent to x,

1.6 Dual Pairs of Vector Spaces
21
written xk
w
âˆ’â†’x as k â†’âˆ; this means that limkâ†’âˆâŸ¨xâˆ—, xkâŸ©= âŸ¨xâˆ—, xâŸ©for
any xâˆ—âˆˆEâˆ—. Analogously, a sequence (xâˆ—
k) in Eâˆ—is weakâˆ—convergent to
xâˆ—âˆˆEâˆ—, written
xâˆ—
k
wâˆ—
âˆ’âˆ’â†’xâˆ—
as k â†’âˆ,
if and only if limkâ†’âˆâŸ¨xâˆ—
k, xâŸ©= âŸ¨xâˆ—, xâŸ©for any x âˆˆE.
(b) In view of Proposition 1.6.3, we usually denote any dual pair of vector
spaces by (E, Eâˆ—). Moreover, when there is no need to specify the topology,
we shall use (E, Eâˆ—) also to denote a dual pair of locally convex spaces,
tacitly assuming that E and Eâˆ—are equipped with topologies compatible
with the dual pair.
(c) Now let E[ âˆ¥Â·âˆ¥] be a normed vector space and let âˆ¥Â·âˆ¥âˆ—denote the associated
norm on Eâˆ—. The weak topology Ïƒ(E, Eâˆ—) is weaker than the topology
generated by the norm âˆ¥Â· âˆ¥; the two topologies coincide if and only if E is
ï¬nite dimensional. In general, the topology generated by the norm âˆ¥Â· âˆ¥âˆ—
on Eâˆ—is not compatible with the dual pair (E, Eâˆ—). However, if E is a
reï¬‚exive Banach space, then

E[âˆ¥Â· âˆ¥], Eâˆ—[âˆ¥Â· âˆ¥âˆ—]

is a dual pair of locally convex spaces.
(d) If E is an inï¬nite-dimensional normed vector space, then the weak topol-
ogy Ïƒ(E, Eâˆ—) does not admit a countable base of neighborhoods of zero.
Hence properties referring to the weak topology can in general, not be
characterized by sequences. For instance, each weakly closed subset of E
is weakly sequentially closed but not conversely. In this connection, a sub-
set A of E is said to be weakly sequentially closed if each limit point of a
weakly convergent sequence in A is an element of A.
It turns out that certain topological properties important in the following
depend on the dual pair only.
Proposition 1.6.5 Let (E, Eâˆ—) be a dual pair of vector spaces, and let Ï„1
and Ï„2 be locally convex topologies on E compatible with the dual pair. Fur-
ther let A be a convex subset of E. Then: A is Ï„1-closed if and only if A is
Ï„2-closed.
Corollary 1.6.6 In a normed vector space, any convex closed subset is weakly
sequentially closed.
We conclude this section with two important results.
Theorem 1.6.7 (Eberleinâ€“Å mulian Theorem) In
a
reï¬‚exive
Banach
space, any bounded weakly sequentially closed subset (in particular, any con-
vex bounded closed subset) is weakly sequentially compact.

22
1 Preliminaries
Theorem 1.6.8 (Kreinâ€“Å mulian Theorem) If E is a Banach space, then
a convex subset M of Eâˆ—is weakâˆ—closed if and only if M âˆ©ÏBEâˆ—is weakâˆ—
closed for any Ï > 0.
1.7 Lower Semicontinuous Functionals
Lower semicontinuous functionals will play an important part in these lectures.
We ï¬rst repeat the deï¬nition.
Deï¬nition 1.7.1 Let E be a topological vector space, M a nonempty subset
of E, and f : M â†’R:
(a) The functional f is called lower semicontinuous (l.s.c.) at Â¯x âˆˆM if either
f(Â¯x) = âˆ’âˆor for every k < f(Â¯x) there exists a neighborhood U of Â¯x such
that
k < f(x)
âˆ€x âˆˆM âˆ©U
(cf. Fig. 1.7).
f is said to be lower semicontinuous on M if f is l.s.c. at each Â¯x âˆˆM.
Moreover, f is called upper semicontinuous at Â¯x if âˆ’f is l.s.c. at Â¯x.
(b) The functional f is said to be sequentially lower semicontinuous at Â¯x âˆˆM
if for each sequence (xn) in M satisfying xn â†’Â¯x as n â†’âˆone has
f(Â¯x) = lim infnâ†’âˆf(xn).
Lemma 1.7.2 characterizes these properties by properties of appropriate
sets.
Lemma 1.7.2 Let E be a topological vector space, M a nonempty subset of E,
and f : M â†’R. Then the following statements are equivalent:
(a) f is l.s.c. on M.
(b) For each Î» âˆˆR, the set MÎ» := {x âˆˆM | f(x) â‰¤Î»} is closed relative to M.
(c) epi f is closed relative to M Ã— R.
)
(
Â¯x
U
k
f(Â¯x)
Fig. 1.7

1.7 Lower Semicontinuous Functionals
23
Proof. We only verify (a) =â‡’(c), leaving the proof of the remaining assertions
as Exercise 1.8.7. Thus let (a) hold. We show that (M Ã— R) \ epi f is open.
Let (Â¯x, Â¯t) âˆˆ(M Ã— R) \ epi f be given. Then f(Â¯x) > Â¯t. Set Î´ := 1
2(f(Â¯x) âˆ’Â¯t).
Then f(Â¯x) > Â¯t + Î´. By (a) there exists a neighborhood U of Â¯x in E such
that f(x) > Â¯t + Î´ for each x âˆˆM âˆ©U. Then V := (M âˆ©U) Ã— (Â¯t âˆ’Î´, Â¯t + Î´)
is a neighborhood of (Â¯x, Â¯t) relative to M Ã— R. For any (x, t) âˆˆV we have
f(x) > Â¯t + Î´ > t and so (x, t) /âˆˆepi f.
âŠ“âŠ”
Proposition 1.7.3 Assume that E is a normed vector space, M âŠ†E is
nonempty convex and closed, and f : E â†’R is proper and convex. Then the
following assertions are equivalent:
(a) f is l.s.c. on M.
(b) f is weakly l.s.c. on M.
(c) f is weakly sequentially l.s.c. on M.
Proof. We only verify (a) =â‡’(c), leaving the veriï¬cation of the remaining
assertions as Exercise 1.8.8. Thus let (a) hold. Suppose, to the contrary, that
f is not weakly sequentially l.s.c. at some Â¯x âˆˆM. Then there exists a sequence
(xn) in M satisfying xn
w
âˆ’â†’Â¯x and f(Â¯x) > limnâ†’âˆf(xn). Choose Î» âˆˆR and
n0 âˆˆN such that f(Â¯x) > Î» â‰¥f(xn) for all n â‰¥n0. Since M is closed and MÎ»
is closed relative to M (Lemma 1.7.2), the latter set is closed. In addition, MÎ»
is convex (Lemma 1.3.3). By Corollary 1.6.6, MÎ» is weakly sequentially closed.
Hence xn
w
âˆ’â†’Â¯x implies Â¯x âˆˆMÎ», which is a contradiction to f(Â¯x) > Î».
âŠ“âŠ”
Proposition 1.7.4 Let E be a Banach space. If f : E â†’R is proper convex
l.s.c. and int dom f is nonempty, then f is continuous on int dom f.
Proof. We may assume that o âˆˆint dom f. Choose a number Î» > f(o) and
set A := {x âˆˆE | f(x) â‰¤Î»}. Then A is convex and closed. We show that A is
also absorbing. Let x âˆˆE, x Ì¸= o, be given. By Corollary 1.4.2 the restriction
of f to the one-dimensional subspace {Ï„x | Ï„ âˆˆR} is continuous at zero. This
and f(o) < Î» imply that there exists Î±0 > 0 such that f(Î±x) < Î» and so
Î±x âˆˆA whenever |Î±| â‰¤Î±0. By Proposition 1.2.1 the set A is a neighborhood
of zero. Now Theorem 1.4.1 completes the proof.
âŠ“âŠ”
Let A be a nonempty subset of E. A set M âŠ†A is called extremal subset
of A if the following holds:
âˆ€Î» âˆˆ(0, 1)
âˆ€x, y âˆˆA :
Î»x + (1 âˆ’Î»)y âˆˆM
=â‡’
x, y âˆˆM.
Further, Â¯x âˆˆA is called extreme point of A if {Â¯x} is an extremal subset of A.
If A is convex, then Â¯x âˆˆA is an extreme point of A if and only if the set
A \ {Â¯x} is also convex. We write ep A for the set of all extreme points of A.
Example 1.7.5 In Rn, the set ep(B(o, 1)) consists of the boundary of B(o, 1)
for the Euclidean norm and of ï¬nitely many points (which?) for the l1 norm.

24
1 Preliminaries
Lemma 1.7.6 If M is an extremal subset of A, then ep(M) = M âˆ©ep(A).
Proof. See Exercise 1.8.9.
âŠ“âŠ”
We recall an important result of Functional Analysis. In this connection,
co B denotes the closed convex hull of the set B âŠ†E, i.e., the intersection of
all closed convex sets containing B.
Theorem 1.7.7 (Kreinâ€“Milman Theorem) Let E be a locally convex
space and A a nonempty subset of E:
(a) If A is compact, then ep A Ì¸= âˆ….
(b) If A âŠ†E is compact and convex, then A = co(ep A).
Proposition 1.7.8 (Bauerâ€™s Maximum Theorem) Let E be a locally
convex space, A a nonempty compact convex subset of E, and g : A â†’R an
upper semicontinuous convex functional. Then there exists Â¯x âˆˆep A such that
g(Â¯x) = maxxâˆˆA g(x).
Proof. Let
M := {Â¯x âˆˆA | g(Â¯x) = max
xâˆˆA g(x)}.
We have to prove that M âˆ©ep A Ì¸= âˆ…. Let m := maxxâˆˆA g(x). We ï¬rst
show that M is an extremal subset of A. In fact, if Î» âˆˆ(0, 1); x, y âˆˆA and
Î»x + (1 âˆ’Î»)y âˆˆM, then
m = g

Î»x + (1 âˆ’Î»)y

â‰¤Î»g(x) + (1 âˆ’Î»)g(y) â‰¤Î»m + (1 âˆ’Î»)m = m
and so Î»g(x) + (1 âˆ’Î»)g(y) = m. Consequently, x, y âˆˆM. Hence M is an
extremal subset of A, and Lemma 1.7.6 implies that M âˆ©ep A = ep M.
The hypotheses on A and g entail that M is nonempty and compact. By
Theorem 1.7.7(a), we have ep M Ì¸= âˆ….
âŠ“âŠ”
1.8 Bibliographical Notes and Exercises
Concerning separation theorems and dual pairs, we refer to standard
textbooks on Functional Analysis, for example Aliprantis and Border [2],
Holmes [92], Werner [215], or Yosida [218]. A good introductory presentation
of convex functionals give Roberts and Varberg [174]. For cs-closed sets see
Jameson [103]. The present form of the sandwich theorem (Theorem 1.5.2) is
due to Landsberg and Schirotzek [116]. Ernst et al. [61] establish results on
the strict separation of disjoint closed sets in reï¬‚exive Banach spaces.
Exercise 1.8.1 Prove Lemma 1.2.2.
Exercise 1.8.2 Verify Lemma 1.3.3.
Exercise 1.8.3 Prove Corollary 1.5.4.

1.8 Bibliographical Notes and Exercises
25
Exercise 1.8.4 Verify the implication (a) =â‡’(b) in Theorem 1.5.8.
Exercise 1.8.5 Prove Theorem 1.5.9.
Exercise 1.8.6 Verify Corollary 1.5.10.
Exercise 1.8.7 Prove the remaining assertions of Lemma 1.7.2
Exercise 1.8.8 Verify the remaining assertions of Proposition 1.7.3.
Exercise 1.8.9 Prove Lemma 1.7.6.
Exercise 1.8.10 Show that the norm functional on the normed vector space
E is weakly l.s.c. and the norm functional on Eâˆ—is weakâˆ—l.s.c.
Exercise 1.8.11 Let E be a normed vector space, let f : E â†’R be a proper
functional, and deï¬ne the lower semicontinuous closure f : E â†’R of f by
f(x) := lim inf
yâ†’x f(y),
x âˆˆE.
Show that f is the largest l.s.c. functional dominated by f.

2
The Conjugate of Convex Functionals
2.1 The Gamma Regularization
Convention. Throughout this chapter unless otherwise speciï¬ed, (E, Eâˆ—)
denotes any dual pair of locally convex spaces (cf. Remark 1.6.4 and
Proposition 1.6.5).
In this section, we show that a l.s.c. convex functional is the upper envelope
of continuous aï¬ƒne functionals.
Deï¬nition 2.1.1 For f : E â†’R let
A(f) := {a : E â†’R | a is continuous and aï¬ƒne, a â‰¤f}.
The functional f Î“ : E â†’R deï¬ned by
f Î“ (x) := sup{a(x) | a âˆˆA(f)},
x âˆˆE,
is called Gamma regularization of f. Recall that sup âˆ…:= âˆ’âˆ.
Figure 2.1 suggests the following result.
f
a1
a2
x
Fig. 2.1

28
2 The Conjugate of Convex Functionals
Proposition 2.1.2 If f : E â†’R is proper, then the following statements are
equivalent:
(a) f = f Î“ .
(b) f is l.s.c. and convex.
Proof.
(a) =â‡’(b): See Exercise 2.5.2.
(b) =â‡’(a): It is clear that f Î“ â‰¤f. Assume now that, for some x0 âˆˆE
and some k âˆˆR, we had f Î“ (x0) < k < f(x0). We shall show that there
exists a âˆˆA(f) satisfying k < a(x0) (cf. Fig. 2.2), which would imply the
contradiction f Î“ (x0) > k.
Since f is l.s.c., epi f is closed (Lemma 1.7.2). Furthermore, epi f is con-
vex (Lemma 1.3.3) and (x0, k) Ì¸âˆˆepi f. By the strong separation theorem 2
(Theorem 1.5.9) applied with A := epi f and B := {(x0, k)}, there exist
w âˆˆ(E Ã— R)âˆ—and Î± âˆˆR such that
w(x, t) â‰¤Î± âˆ€(x, t) âˆˆepi f
and
w(x0, k) > Î±.
(2.1)
We have
w(x, t) = âŸ¨xâˆ—, xâŸ©+ ct,
where âŸ¨xâˆ—, xâŸ©:= w(x, 0), c := w(o, 1).
(2.2)
It is obvious that xâˆ—âˆˆEâˆ—. Further, since (x, t) âˆˆepi f entails (x, tâ€²) âˆˆepi f
for each tâ€² > t, we obtain
c â‰¤Î± âˆ’âŸ¨xâˆ—, xâŸ©
tâ€²
âˆ€tâ€² > max{0, t}
and so, letting tâ€² â†’+âˆ, c â‰¤0. Now we distinguish two cases.
Case 1. Assume that f(x0) < +âˆ. Then (2.1) with t := f(x0) and (2.2) imply
âŸ¨xâˆ—, x0âŸ©+ cf(x0) â‰¤Î± < âŸ¨xâˆ—, x0âŸ©+ ck.
f(x0)
epi f
f
a
k
x0
Fig. 2.2

2.2 Conjugate Functionals
29
Since k < f(x0), it follows that c < 0. The functional a : E â†’R deï¬ned by
a(x) := Î±
c âˆ’1
câŸ¨xâˆ—, xâŸ©,
x âˆˆE,
is continuous and aï¬ƒne. If x âˆˆdom f, we have by (2.1),
a(x) = 1
c

Î± âˆ’w(x, f(x))

+ f(x) â‰¤f(x).
If x /âˆˆdom f, then a(x) < +âˆ= f(x). Hence a âˆˆA(f). Moreover, we have
a(x0) = 1
c

Î± âˆ’âŸ¨xâˆ—, x0âŸ©

> k.
Case 2. Assume that f(x0) = +âˆ. If c < 0, then deï¬ne a as in Case 1. Now
suppose that c = 0. Since f is proper, there exists y0 âˆˆdom f. According to
Case 1, with y0 instead of x0, there exists a0 âˆˆA(f). Deï¬ne a : E â†’R by
a(x) := a0(x) + Ï

âŸ¨xâˆ—, xâŸ©âˆ’Î±

,
where Ï := |k âˆ’a0(x0)|
âŸ¨xâˆ—, x0âŸ©âˆ’Î± + 1.
Then a is continuous and aï¬ƒne. Further we have a(x) â‰¤a0(x) â‰¤f(x) for each
x âˆˆdom f and so a âˆˆA(f). Finally, noting that a0(x0)+|k âˆ’a0(x0)| â‰¥k and
âŸ¨xâˆ—, x0âŸ©> Î±, we obtain
a(x0) = a0(x0) + |k âˆ’a0(x0)| + âŸ¨xâˆ—, x0âŸ©âˆ’Î± > k,
and the proof is complete.
âŠ“âŠ”
2.2 Conjugate Functionals
The concept of the conjugate functional, which has its roots in the Legendre
transform of the calculus of variations, will be crucial for the duality theory
in convex optimization to be developed later.
Deï¬nition 2.2.1 Let f : E â†’R. The functional f âˆ—: Eâˆ—â†’R deï¬ned by
f âˆ—(xâˆ—) := sup
xâˆˆE

âŸ¨xâˆ—, xâŸ©âˆ’f(x)

,
xâˆ—âˆˆEâˆ—,
is called the Fenchel conjugate (or brieï¬‚y, the conjugate) of f.
If f is proper, the deï¬nition immediately implies the Young inequality
âŸ¨xâˆ—, xâŸ©â‰¤f(x) + f âˆ—(xâˆ—)
âˆ€x âˆˆE âˆ€xâˆ—âˆˆEâˆ—.
(2.3)

30
2 The Conjugate of Convex Functionals
Geometric Interpretation
Let xâˆ—âˆˆEâˆ—be such that f âˆ—(xâˆ—) âˆˆR. Then the function a : E â†’R deï¬ned by
a(x) := âŸ¨xâˆ—, xâŸ©âˆ’f âˆ—(xâˆ—),
x âˆˆE,
belongs to A(f). For each Ïµ > 0 there exists xÏµ âˆˆE satisfying âŸ¨xâˆ—, xÏµâŸ©âˆ’f(xÏµ) >
f âˆ—(xâˆ—) âˆ’Ïµ and so a(xÏµ) > f(xÏµ) âˆ’Ïµ. Hence, for E = R, a may be interpreted
as a tangent to f, and we have a(o) = âˆ’f âˆ—(xâˆ—) (Fig. 2.3).
âˆ’f âˆ—(xâˆ—)
f
a
xâˆ—
x
0
Fig. 2.3
Example 2.2.2 Let p âˆˆ(1, +âˆ) be given. Deï¬ne f : R â†’R by f(x) := |x|p
p .
We compute f âˆ—. For E = R we have Eâˆ—= R. With xâˆ—âˆˆR ï¬xed, set Ï•(x) :=
xâˆ—x âˆ’f(x). The function Ï• : R â†’R is concave (i.e., âˆ’Ï• is convex) and
diï¬€erentiable. Hence Ï• has a unique maximizer x0 which satisï¬es Ï•â€²(x0) = 0,
i.e., xâˆ—âˆ’sgn(x0)|x0|pâˆ’1 = 0. It follows that
f âˆ—(xâˆ—) = Ï•(x0) = |xâˆ—|q
q
,
where 1
p + 1
q = 1.
Thus in this case the Young inequality (2.3) is just the classical Young in-
equality for real numbers:
xâˆ—x â‰¤|x|p
p
+ |xâˆ—|q
q
.
Proposition 2.2.3 If f : E â†’R, then the following holds:
(a) f âˆ—is convex and l.s.c.
(b) If dom f Ì¸= âˆ…, then f âˆ—(xâˆ—) > âˆ’âˆfor every xâˆ—âˆˆEâˆ—.
(c) If f is proper, convex, and l.s.c., then f âˆ—is proper, convex, and l.s.c.
Proof.
(a) It is easy to see that f âˆ—is convex. To prove the second assertion, notice
that for each x âˆˆE, the functional Ï•x(xâˆ—) := âŸ¨xâˆ—, xâŸ©âˆ’f(x), xâˆ—âˆˆEâˆ—, is
continuous and so f âˆ—= supxâˆˆE Ï•x is l.s.c.

2.2 Conjugate Functionals
31
f
f âˆ—âˆ—
Fig. 2.4
(b) is obvious.
(c) Since f is proper, we have A(f) Ì¸= âˆ…(see the proof of Proposition 2.1.2).
Hence there exist xâˆ—âˆˆEâˆ—and c âˆˆR such that âŸ¨xâˆ—, xâŸ©+ c â‰¤f(x) for each
x âˆˆE. It follows that
f âˆ—(xâˆ—) = sup
xâˆˆE

âŸ¨xâˆ—, xâŸ©âˆ’f(x)

â‰¤âˆ’c < +âˆ
and so xâˆ—âˆˆdom f âˆ—.
âŠ“âŠ”
For g : Eâˆ—â†’R, the conjugate gâˆ—: E â†’R is deï¬ned analogously by
gâˆ—(x) := sup
xâˆ—âˆˆEâˆ—

âŸ¨xâˆ—, xâŸ©âˆ’g(xâˆ—)

,
x âˆˆE.
In this connection, we make use of the fact that, since (E, Eâˆ—) is a dual pair,
the dual of Eâˆ—can be identiï¬ed with E. Now let f : E â†’R be given. Applying
the above to g := f âˆ—, we obtain the biconjugate f âˆ—âˆ—: E â†’R of f:
f âˆ—âˆ—(x) = sup
xâˆ—âˆˆEâˆ—

âŸ¨xâˆ—, xâŸ©âˆ’f âˆ—(xâˆ—)

,
x âˆˆE.
Geometrically, Theorem 2.2.4 says that f âˆ—âˆ—can be interpreted as a con-
vexiï¬cation of f from below (Fig. 2.4).
Theorem 2.2.4 (Biconjugation Theorem) Let f : E â†’R.
(a) One always has f âˆ—âˆ—= f Î“ â‰¤f.
(b) If f is proper, then f âˆ—âˆ—= f if and only if f is convex and l.s.c.
Proof.
(a) It is clear that f Î“ â‰¤f. We show that f âˆ—âˆ—= f Î“ . For xâˆ—âˆˆEâˆ—and c âˆˆR,
we have
âŸ¨xâˆ—, xâŸ©+ c â‰¤f(x) âˆ€x âˆˆE
â‡â‡’
f âˆ—(xâˆ—) = sup
xâˆˆE

âŸ¨xâˆ—, xâŸ©âˆ’f(x)

â‰¤âˆ’c
and so
f Î“ (x) = sup{âŸ¨xâˆ—, xâŸ©+ c | xâˆ—âˆˆEâˆ—, c âˆˆR, c â‰¤âˆ’f âˆ—(xâˆ—)}.
(2.4)

32
2 The Conjugate of Convex Functionals
If f âˆ—(xâˆ—) > âˆ’âˆfor all xâˆ—âˆˆEâˆ—, then
f Î“ (x) =
(2.4) sup{âŸ¨xâˆ—, xâŸ©âˆ’f âˆ—(xâˆ—) | xâˆ—âˆˆEâˆ—} = f âˆ—âˆ—(x)
âˆ€x âˆˆE.
If f âˆ—(xâˆ—) = âˆ’âˆfor some xâˆ—âˆˆEâˆ—, then f Î“ (x) = +âˆ= f âˆ—âˆ—(x) for all
x âˆˆE.
(b) This follows from (a) and Proposition 2.1.2.
âŠ“âŠ”
Example 2.2.5 For the indicator functional Î´A of a nonempty subset A of E,
we have
Î´âˆ—
A(xâˆ—) = ÏƒA(xâˆ—)
âˆ€xâˆ—âˆˆEâˆ—,
where ÏƒA : Eâˆ—â†’R denotes the support functional of A. If, in particular, E
is a normed vector space and A = BE (the closed unit ball in E), then
Î´âˆ—
BE(xâˆ—) = ÏƒBE(xâˆ—) = sup
âˆ¥xâˆ¥â‰¤1
âŸ¨xâˆ—, xâŸ©= âˆ¥xâˆ—âˆ¥
âˆ€xâˆ—âˆˆEâˆ—.
Example 2.2.6 Let again E be a normed vector space and f(x)
=
âˆ¥xâˆ¥, x âˆˆE. Consider the dual pair (E[âˆ¥Â· âˆ¥], Eâˆ—[Ïƒ(Eâˆ—, E)]). We want to
determine f âˆ—:
(I) Let xâˆ—âˆˆEâˆ—, âˆ¥xâˆ—âˆ¥â‰¤1. Then âŸ¨xâˆ—, xâŸ©â‰¤âˆ¥xâˆ—âˆ¥âˆ¥xâˆ¥â‰¤âˆ¥xâˆ¥for all x âˆˆE and
âŸ¨xâˆ—, oâŸ©= 0 = âˆ¥oâˆ¥. Hence
f âˆ—(xâˆ—) = sup
xâˆˆE

âŸ¨xâˆ—, xâŸ©âˆ’âˆ¥xâˆ¥

= 0.
(II) Let xâˆ—âˆˆEâˆ—, âˆ¥xâˆ—âˆ¥> 1. Then there exists x0 âˆˆE such that Î± :=
âŸ¨xâˆ—, x0âŸ©âˆ’âˆ¥x0âˆ¥> 0. For each Ï > 0 we have âŸ¨xâˆ—, Ïx0âŸ©âˆ’âˆ¥Ïx0âˆ¥= Î±Ï. Let-
ting Ï â†’+âˆ, we see that f âˆ—(xâˆ—) = +âˆ. We conclude that f âˆ—= Î´BEâˆ—.
Therefore we obtain
âˆ¥xâˆ¥= f(x) = f âˆ—âˆ—(x) = Î´âˆ—
BEâˆ—(x) =
sup
âˆ¥xâˆ—âˆ¥â‰¤1
âŸ¨xâˆ—, xâŸ©
âˆ€x âˆˆE;
here, the second equation follows from Theorem 2.2.4 and the last follows
by applying Example 2.2.5 to Eâˆ—instead of E. As a consequence of the
Hahnâ€“Banach theorem the supremum is attained, i.e.,
âˆ¥xâˆ¥= max
âˆ¥xâˆ—âˆ¥â‰¤1âŸ¨xâˆ—, xâŸ©
âˆ€x âˆˆE.
The following operation is a useful device for calculating the conjugate of
a sum.
Deï¬nition 2.2.7 Let f0, f1 : E â†’R be proper. The functional f0 âŠ•f1 :
E â†’R deï¬ned by
f0 âŠ•f1(x) := inf
yâˆˆE

f0(x âˆ’y) + f1(y)

âˆ€x âˆˆE
is called inï¬mal convolution of f0 and f1.

2.2 Conjugate Functionals
33
Theorem 2.2.8 (Sum Theorem) Let f0, f1 : E â†’R be proper.
(a) One always has
f âˆ—
0 + f âˆ—
1 =

f0 âŠ•f1
âˆ—
and

f0 + f1
âˆ—â‰¤f âˆ—
0 âŠ•f âˆ—
1 .
(b) Suppose, in addition, that f0 and f1 are convex and that there exists Â¯x âˆˆ
dom f0 âˆ©int dom f1 such that f1 is continuous at Â¯x. Then one has

f0 + f1
âˆ—= f âˆ—
0 âŠ•f âˆ—
1 .
Moreover, for each xâˆ—âˆˆdom

f0+f1
âˆ—there exist xâˆ—
i âˆˆdom f âˆ—
i for i = 0, 1
such that
xâˆ—= xâˆ—
0 + xâˆ—
1
and

f0 + f1
âˆ—(xâˆ—) = f âˆ—
0 (xâˆ—
0) + f âˆ—
1 (xâˆ—
1),
(2.5)
i.e., the inï¬mum in (f âˆ—
0 âŠ•f âˆ—
1 )(xâˆ—) is attained.
Proof.
(a) See Exercise 2.5.3.
(b) Let xâˆ—âˆˆEâˆ—and Î± :=

f0 + f1
âˆ—(xâˆ—). If Î± = +âˆ, then (a) implies

f âˆ—
0 âŠ•f âˆ—
1

(xâˆ—) = +âˆand so we have equality. Now suppose that Î± <
+âˆ. We have to show that

f âˆ—
0 âŠ•f âˆ—
1

(xâˆ—) â‰¤Î±. Since Â¯x âˆˆdom(f0 + f1),
we have Î± > âˆ’âˆ(Proposition 2.2.3) and so Î± âˆˆR. Set p := f0 and
q := f1 âˆ’xâˆ—+ Î±. If x âˆˆdom f0 âˆ©dom f1, then Î± â‰¥âŸ¨xâˆ—, xâŸ©âˆ’(f0 + f1)(x),
which implies p(x) â‰¥âˆ’q(x) for each x âˆˆE. Moreover, q is continuous
at Â¯x. By the sandwich theorem (Theorem 1.5.2) there exist xâ€²
0 âˆˆEâˆ—and
c âˆˆR satisfying
âŸ¨xâ€²
0, xâŸ©+c â‰¤f0(x)
and
c+âŸ¨xâ€²
0, xâŸ©â‰¥âŸ¨xâˆ—, xâŸ©âˆ’f1(x)âˆ’Î±
âˆ€x âˆˆE. (2.6)
From the ï¬rst inequality in (2.6) we obtain f âˆ—
0 (xâ€²
0) â‰¤âˆ’c and so xâ€²
0 âˆˆ
dom f âˆ—
0 . For xâ€²
1 := xâˆ—âˆ’xâ€²
0, the second inequality of (2.6) implies f âˆ—
1 (xâ€²
1)âˆ’
c â‰¤Î±. It follows that xâ€²
1 âˆˆdom f âˆ—
1 and
f âˆ—
0 (xâ€²
0) + f âˆ—
1 (xâ€²
1) â‰¤Î±.
(2.7)
We have xâˆ—= xâ€²
0 + xâ€²
1 and so

f âˆ—
0 âŠ•f âˆ—
1

(xâˆ—) =
inf
yâ€²âˆˆEâˆ—

f âˆ—
0 (xâˆ—âˆ’yâ€²) + f âˆ—
1 (yâ€²)

â‰¤Î±.
This ï¬nally yields

f0 + f1
âˆ—(xâˆ—) = Î± =

f âˆ—
0 âŠ•f âˆ—
1

(xâˆ—) =
(2.7) f âˆ—
0 (xâ€²
0) + f âˆ—
1 (xâ€²
1).
âŠ“âŠ”
As a ï¬rst simple application of conjugate functionals we derive a duality
formula of approximation theory. Recall that if A âŠ†E, we write dA(x) :=
infyâˆˆA âˆ¥x âˆ’yâˆ¥.

34
2 The Conjugate of Convex Functionals
Proposition 2.2.9 If A âŠ†E is nonempty and convex, then
dA(x) = max
âˆ¥xâˆ—âˆ¥â‰¤1

âŸ¨xâˆ—, xâŸ©âˆ’sup
yâˆˆA
âŸ¨xâˆ—, yâŸ©

âˆ€x âˆˆE.
Proof. Setting f0(x) := âˆ¥xâˆ¥and f1(x) := Î´A(x), we have
(f0 âŠ•f1)(x) = inf
yâˆˆE

âˆ¥x âˆ’yâˆ¥+ Î´A(y)

= dA(x).
We further set B := BEâˆ—. Since the distance function x â†’dA(x) is proper,
convex and continuous on E, we obtain
dA(x) = (f0 âŠ•f1)âˆ—âˆ—(x) =

f âˆ—
0 + f âˆ—
1
âˆ—(x)
= sup
xâˆ—âˆˆEâˆ—

âŸ¨xâˆ—, xâŸ©âˆ’

Î´B(xâˆ—) + sup
yâˆˆA
âŸ¨xâˆ—, yâŸ©

= sup
xâˆ—âˆˆB

âŸ¨xâˆ—, xâŸ©âˆ’sup
yâˆˆA
âŸ¨xâˆ—, yâŸ©

.
Since, with respect to Ïƒ(Eâˆ—, E), the set B is compact (Alaoglu Theorem)
and the functional xâˆ—â†’âŸ¨xâˆ—, xâŸ©âˆ’supyâˆˆAâŸ¨xâˆ—, yâŸ©is upper semicontinuous, the
supremum over B is attained and so is a maximum.
âŠ“âŠ”
2.3 A Theorem of HÂ¨ormander and the Bipolar Theorem
The following result states, roughly speaking, that convex closed subsets of Eâˆ—
can be described by sublinear l.s.c. functionals on E and vice versa. In this
connection, recall the convention at the beginning of this chapter. Also recall
that the support functional ÏƒM of the set M âŠ†Eâˆ—is deï¬ned by
ÏƒM(x) := sup
xâˆ—âˆˆM
âŸ¨xâˆ—, xâŸ©, x âˆˆE.
Theorem 2.3.1 (HÂ¨ormander Theorem)
(a) Let M be a nonempty, convex, closed subset of Eâˆ—. Then the support
functional ÏƒM is proper, sublinear, and l.s.c., and one has
M = {xâˆ—âˆˆEâˆ—| âŸ¨xâˆ—, xâŸ©â‰¤ÏƒM(x) âˆ€x âˆˆE}.
(2.8)
(b) Let p : E â†’R be proper, sublinear, and l.s.c. Then the set
Mp := {xâˆ—âˆˆEâˆ—| âŸ¨xâˆ—, xâŸ©â‰¤p(x) âˆ€x âˆˆE}
is nonempty, convex, and closed, and one has ÏƒMp = p.
(c) If M1 and M2 are nonempty, convex, closed subsets of Eâˆ—, then
M1 âŠ†M2
â‡â‡’
ÏƒM1(x) â‰¤ÏƒM2(x)
âˆ€x âˆˆE.

2.3 A Theorem of HÂ¨ormander and the Bipolar Theorem
35
Proof.
(a) It is easy to see that ÏƒM is proper, sublinear, and l.s.c. We show that (2.8)
holds. By Theorem 2.2.4 and Example 2.2.5 (with Eâˆ—in place of E) we
obtain
Î´M =

Î´âˆ—
M
âˆ—= Ïƒâˆ—
M,
Ïƒâˆ—
M(xâˆ—) = sup
xâˆˆE

âŸ¨xâˆ—, xâŸ©âˆ’ÏƒM(x)

= Î´Mp(xâˆ—) âˆ€xâˆ—âˆˆEâˆ—,
where p := ÏƒM.
Hence Î´M = Î´Mp and so M = Mp.
(b) (I) Mp Ì¸= âˆ…: Since p is l.s.c. and p(o) = 0, there exists a neighborhood U
of zero in E such that âˆ’1 < p(x) for each x âˆˆU. Deï¬ne q : E â†’R by
q(x) := 1 for x âˆˆU and q(x) := +âˆfor x âˆˆE \ U. By the sandwich
theorem (Theorem 1.5.2) there exist xâˆ—âˆˆEâˆ—and c âˆˆR satisfying
âŸ¨xâˆ—, xâŸ©+ c â‰¤p(x) âˆ€x âˆˆE
and
âˆ’1 â‰¤âŸ¨xâˆ—, xâŸ©+ c âˆ€x âˆˆU.
Since p is sublinear, it follows that âŸ¨xâˆ—, xâŸ©â‰¤p(x) for each x âˆˆE and
so xâˆ—âˆˆMp.
(II) Mp is closed: For each x âˆˆE, let Ï•x(xâˆ—) := âŸ¨xâˆ—, xâŸ©, xâˆ—âˆˆEâˆ—. Then
Ï•x is continuous. Hence the set
Mx := {xâˆ—âˆˆEâˆ—| âŸ¨xâˆ—, xâŸ©â‰¤p(x)} = Ï•âˆ’1
x

âˆ’âˆ, p(x)

is closed and so is Mp = 
xâˆˆE Mx.
(III) ÏƒMp = p: We have
pâˆ—(xâˆ—) = sup
xâˆˆE

âŸ¨xâˆ—, xâŸ©âˆ’p(x)

= Î´Mp
and so, using Theorem 2.2.4 and Example 2.2.5,
p = pâˆ—âˆ—= Î´âˆ—
Mp = ÏƒMp.
(c) The implication =â‡’holds by deï¬nition, and â‡= is a consequence of (2.8).
âŠ“âŠ”
We shall now derive a well-known result of Functional Analysis, the bipolar
theorem, which in turn will yield statements on inequality systems.
If A âŠ†E is nonempty, then
Aâ—¦:= {xâˆ—âˆˆEâˆ—| âŸ¨xâˆ—, xâŸ©â‰¤0 âˆ€x âˆˆA}
is a convex cone, the (negative) polar cone of A. Furthermore, the bipolar cone
of A is
Aâ—¦â—¦:= {x âˆˆE | âŸ¨xâˆ—, xâŸ©â‰¤0 âˆ€xâˆ—âˆˆAâ—¦}.
We denote by cc A the intersection of all closed convex cones containing A,
analogously for nonempty subsets of Eâˆ—.

36
2 The Conjugate of Convex Functionals
Lemma 2.3.2
(a) If A âŠ†E is nonempty, then

cc A
â—¦= Aâ—¦.
(b) If A âŠ†E is nonempty and convex, then cc A = cl

Î»â‰¥0 Î»A

.
Proof. See Exercise 2.5.4.
âŠ“âŠ”
Proposition 2.3.3 (Bipolar Theorem) If A
âŠ†
E is nonempty, then
Aâ—¦â—¦= ccA.
Proof. Let C := cc A. By Theorem 2.3.1(a) with the roles of E and Eâˆ—
exchanged, we have
C = {x âˆˆE | âŸ¨xâˆ—, xâŸ©â‰¤ÏƒC(xâˆ—) âˆ€xâˆ—âˆˆEâˆ—}.
Since C is a cone containing o, a direct calculation gives ÏƒC = Î´Câ—¦. Hence
C = Câ—¦â—¦, and Lemma 2.3.2(a) shows that Câ—¦â—¦= Aâ—¦â—¦.
âŠ“âŠ”
2.4 The Generalized Farkas Lemma
In this section, we characterize solutions of systems of equations and inequal-
ities. We make the following hypotheses:
(H) (E, Eâˆ—) and (F, F âˆ—) are dual pairs of locally convex spaces.
P âŠ†E and Q âŠ†F are closed convex cones.
T : E â†’F is a continuous linear mapping.
Recall that the adjoint T âˆ—: F âˆ—â†’Eâˆ—of T is deï¬ned by
âŸ¨T âˆ—yâˆ—, xâŸ©= âŸ¨yâˆ—, TxâŸ©
âˆ€x âˆˆE
âˆ€yâˆ—âˆˆF âˆ—.
Lemma 2.4.1 There always holds cl(P â—¦+ T âˆ—(Qâ—¦)) = (P âˆ©T âˆ’1(Q))â—¦.
Proof. For any x âˆˆE we have
x âˆˆ(P â—¦+ T âˆ—(Qâ—¦))â—¦
â‡â‡’
âŸ¨yâ€², xâŸ©+ âŸ¨zâˆ—, TxâŸ©â‰¤0
âˆ€(yâ€², zâˆ—) âˆˆP â—¦Ã— Qâ—¦
â‡â‡’
(x, Tx) âˆˆ(P â—¦Ã— Qâ—¦)â—¦.
Since (P â—¦Ã— Qâ—¦)â—¦= P â—¦â—¦Ã— Qâ—¦â—¦= P Ã— Q (the latter by the bipolar theorem),
we see that
(P â—¦+ T âˆ—(Qâ—¦))â—¦= P âˆ©T âˆ’1(Q)
and another application of the bipolar theorem proves the assertion.
âŠ“âŠ”
An immediate consequence of this lemma is:
Proposition 2.4.2 (Generalized Farkas Lemma) If
P â—¦+ T âˆ—(Qâ—¦)
is
closed, then for each xâˆ—âˆˆEâˆ—the following statements are equivalent:

2.4 The Generalized Farkas Lemma
37
(a) âˆƒzâˆ—âˆˆQâ—¦: xâˆ—âˆ’T âˆ—zâˆ—âˆˆP â—¦.
(b) âˆ€x âˆˆP : Tx âˆˆQ =â‡’âŸ¨xâˆ—, xâŸ©â‰¤0.
Frequently the result is formulated in terms of the negation of (b) which is:
(Â¯b) âˆƒx âˆˆP : Tx âˆˆQ and âŸ¨xâˆ—, xâŸ©> 0.
Proposition 2.4.2 then states that either (a) or (Â¯b) holds. In this formulation,
the result is called theorem of the alternative.
If, in particular, P = E and so P â—¦= {o}, then Proposition 2.4.2 gives a
necessary and suï¬ƒcient condition for the linear operator equation T âˆ—zâˆ—= xâˆ—
to have a solution zâˆ—in the cone Qâ—¦.
In view of Proposition 2.4.2, it is of interest to have suï¬ƒcient conditions
for P â—¦+ T âˆ—(Qâ—¦) to be closed.
Proposition 2.4.3 If E and F are Banach spaces and T(E) âˆ’Q = F, then
P â—¦+ T âˆ—(Qâ—¦) is Ïƒ(Eâˆ—, E)-closed.
Proof. In the following, topological notions in Eâˆ—and F âˆ—refer to the weak*
topology. We show that for any Ï > 0 the set
K := (P â—¦+ T âˆ—(Qâ—¦)) âˆ©BEâˆ—(o, Ï)
is closed in BEâˆ—(o, Ï); the assertion then follows by the Kreinâ€“Å mulian theorem
(Theorem 1.6.8). Thus let (zâˆ—
Î±) be a net (generalized sequence) in K converging
to some zâˆ—âˆˆBEâˆ—(o, Ï). Then there exist nets (xâˆ—
Î±) in P â—¦and (yâ€²
Î±) in Qâ—¦such
that zâˆ—
Î± = xâˆ—
Î± + T âˆ—yâ€²
Î± for any Î±. Now let z âˆˆF be given. Since T(P) âˆ’Q = F,
there exist x âˆˆP and y âˆˆQ satisfying z = Tx âˆ’y. Hence for any Î± we have
âŸ¨yâ€²
Î±, zâŸ©=âŸ¨yâ€²
Î±, TxâŸ©âˆ’âŸ¨yâ€²
Î±, yâŸ©â‰¥âŸ¨T âˆ—yâ€²
Î±, xâŸ©=âŸ¨zâˆ—
Î±, xâŸ©âˆ’âŸ¨xâˆ—
Î±, xâŸ©â‰¥âŸ¨zâˆ—
Î±, xâŸ©â‰¥âˆ’Ïâˆ¥xâˆ¥.
Analogously there exists Ëœx âˆˆP such that âŸ¨yâ€²
Î±, âˆ’zâŸ©â‰¥âˆ’Ïâˆ¥Ëœxâˆ¥for any Î±. Hence
the net (yâ€²
Î±) is pointwise bounded and so, by the Banachâ€“Steinhaus theorem,
norm bounded in F âˆ—. The Alaoglu theorem now implies that some subnet
(yâ€²
Î±â€²) of (yâ€²
Î±) has a limit yâ€². Since Qâ—¦is closed, we have yâ€² âˆˆQâ—¦. Since xâˆ—
Î±â€² =
zâˆ—
Î±â€² âˆ’T âˆ—yâ€²
Î±â€² and zâˆ—
Î±â€² â†’zâˆ—, it follows that (xâˆ—
Î±â€²) converges to zâˆ—âˆ’T âˆ—yâ€², and so
zâˆ—âˆ’T âˆ—yâ€² âˆˆP â—¦. We conclude that zâˆ—âˆˆK.
âŠ“âŠ”
We supplement Proposition 2.4.3 by a suï¬ƒcient condition for T(P)âˆ’Q=F.
Lemma 2.4.4 If T(P) âˆ©int Q Ì¸= âˆ…, then T(P) âˆ’Q = F.
Proof. By assumption, there exist x0 âˆˆP such that Tx0 âˆˆint Q. Let V be a
neighborhood of zero in F such that Tx0 + V âŠ†Q. Now let y âˆˆF be given.
Then Ï(âˆ’y) âˆˆV for some Ï > 0 and so z := Tx0 âˆ’Ïy âˆˆQ. It follows that
y = T( 1
Ïx0) âˆ’1
Ïz âˆˆT(P) âˆ’Q.
âŠ“âŠ”

38
2 The Conjugate of Convex Functionals
Concerning the ï¬nite-dimensional case, let
E = P = Rm, F = Rn, Q = âˆ’Rn
+.
Further let A be the matrix representation of T : Rm â†’Rn with respect to the
standard bases. Then T âˆ—Qâ—¦= AâŠ¤Rn
+ is a polyhedral cone (as the nonnegative
hull of the column vectors of A) and so is closed (see, for example, Bazaraa
and Shetty [12] or Elster et al. [59]). Hence Proposition 2.4.2 implies
Corollary 2.4.5 (Classical Farkas Lemma) Let A be an (n, m)-matrix.
Then for each xâˆ—âˆˆRm, the following statements are equivalent:
(a) âˆƒzâˆ—âˆˆRn
+ : AâŠ¤zâˆ—= xâˆ—.
(b) âˆ€x âˆˆRm : Ax âˆˆâˆ’Rn
+ =â‡’âŸ¨xâˆ—, xâŸ©â‰¤0.
2.5 Bibliographical Notes and Exercises
Concerning conjugate functionals we refer to the Bibliographical Notes at
the end of Chap. 4. For theorems of the alternative in ï¬nite-dimensional
spaces, see Borwein and Lewis [18], Elster et al. [59], and the references
therein. Concerning related results in inï¬nite-dimensional spaces, for linear
and nonlinear mappings, we refer to Craven [43, 44], Craven et al. [45],
Ferrero [68], Giannessi [70], Glover et al. [75], Jeyakumar [104], Lasserre [117],
and Schirotzek [193,195]. Proposition 2.4.3 is due to Penot [160]; for further
closedness conditions of this kind, see Schirotzek [196, p. 220 ï¬€]. We shall
come back to this subject in Sect. 10.2.
Exercise 2.5.1 Calculate the conjugate of the following functions f : R â†’R:
(a) f(x) := ex, x âˆˆR.
(b) f(x) := ln x if x > 0, f(x) := +âˆif x â‰¤0.
(c)
f(x) :=
â§
âª
âª
âª
â¨
âª
âª
âª
â©
+âˆ
if x < âˆ’2,
âˆ’x
if âˆ’2 â‰¤x < 0,
x(2 âˆ’x)
if 0 â‰¤x < 2,
2x
if x â‰¥2.
Exercise 2.5.2 Verify the implication (a) =â‡’(b) in Proposition 2.1.2.
Exercise 2.5.3 Prove assertion (a) of Theorem 2.2.8.
Exercise 2.5.4 Prove Lemma 2.3.2.

3
Classical Derivatives
3.1 Directional Derivatives
Convention. Throughout this chapter, unless otherwise speciï¬ed, we assume
that E and F are normed vector spaces, D âŠ†E is nonempty and open, Â¯x âˆˆD,
and f : D â†’F.
We will recall some classical concepts and facts. To start with, we consider
directional derivatives. We write
âˆ†f(Â¯x, y) := f(Â¯x + y) âˆ’f(Â¯x)
âˆ€y âˆˆD âˆ’Â¯x.
We use the following abbreviations: G-derivative for GÃ¢teaux derivative,
H-derivative for Hadamard derivative, F-derivative for FrÃ©chet derivative.
Deï¬nition 3.1.1 Let y âˆˆE. We call
fG(Â¯x, y) := lim
Ï„â†“0
1
Ï„ âˆ†f(Â¯x, Ï„y)
directional G-derivative,
f s
G(Â¯x, y) := lim
Ï„â†“0
xâ†’Â¯x
1
Ï„ âˆ†f(x, Ï„y) strict directional G-derivative,
fH(Â¯x, y) := lim
Ï„â†“0
zâ†’y
1
Ï„ âˆ†f(Â¯x, Ï„z) directional H-derivative,
f s
H(Â¯x, y) := lim
Ï„â†“0
xâ†’Â¯x
zâ†’y
1
Ï„ âˆ†f(x, Ï„z) strict directional H-derivative
of f at Â¯x in the direction y, provided the respective limit exists.
Lemma 3.1.2
(a) If fH(Â¯x, y) exists, then fG(Â¯x, y) also exists and both directional derivatives
coincide.
(b) If f is locally L-continuous around Â¯x, then fH(Â¯x, y) exists if and only if
fG(Â¯x, y) exists.

40
3 Classical Derivatives
Proof. (a) is obvious. We verify (b). Assume that fG(Â¯x, y) exists. Let Ïµ > 0
be given. Then there exists Î´1 > 0 such that
 1
Ï„ âˆ†f(Â¯x, Ï„y) âˆ’fG(Â¯x, y)
 < Ïµ
2
whenever 0 < Ï„ < Î´1.
Since f is locally L-continuous around Â¯x, there further exist Î» > 0 and Î´2 > 0
such that
âˆ¥f(x1) âˆ’f(x2)âˆ¥â‰¤Î»âˆ¥x1 âˆ’x2âˆ¥
âˆ€x1, x2 âˆˆB(Â¯x, Î´2).
Now set
Î´3 := Ïµ
2Î»
and
Î´4 := min

Î´1,
Î´2
Î´3 + âˆ¥yâˆ¥

.
If z âˆˆB(y, Î´3) and 0 < Ï„ < Î´4, then we obtain âˆ¥Ï„yâˆ¥< Î´2 and
âˆ¥Ï„zâˆ¥â‰¤Ï„(âˆ¥z âˆ’yâˆ¥+ âˆ¥yâˆ¥) â‰¤Ï„(Î´3 + âˆ¥yâˆ¥) â‰¤Î´2
and so
 1
Ï„ âˆ†f(Â¯x, Ï„z) âˆ’fG(Â¯x, y)

â‰¤1
Ï„
f(Â¯x + Ï„z) âˆ’f(Â¯x + Ï„y)
 +
 1
Ï„ âˆ†f(Â¯x, Ï„y) âˆ’fG(Â¯x, y)

â‰¤Î»âˆ¥z âˆ’yâˆ¥+ Ïµ
2 < Ïµ.
We conclude that fH(Â¯x, y) exists and equals fG(Â¯x, y).
âŠ“âŠ”
Lemma 3.1.3 If the directional H-derivative fH(Â¯x, Â·) exists in a neighborhood
of y0 âˆˆE, then it is continuous at y0.
Proof. Let Ï0 > 0 be such that fH(Â¯x, y) exists for each y âˆˆB(y0, Ï0). Let
Ïµ > 0 be given. Then there exists Ï âˆˆ(0, Ï0) such that
 1
Ï„ âˆ†f(Â¯x, Ï„y) âˆ’fH(Â¯x, y0)
 â‰¤Ïµ
whenever 0 < Ï„ < Ï and y âˆˆB(y0, Ï).
Letting Ï„ â†“0, we obtain
âˆ¥fG(Â¯x, y) âˆ’fH(Â¯x, y0)âˆ¥â‰¤Ïµ
âˆ€y âˆˆB(y0, Ï).
By Lemma 3.1.2 we have fG(Â¯x, y) = fH(Â¯x, y) for each y âˆˆB(y0, Ï0), and the
assertion follows.
âŠ“âŠ”
Now we consider a proper function f : E â†’R. If D := int dom f is
nonempty, then of course the above applies to f|D. In addition, we deï¬ne the
following directional derivatives:
f G(Â¯x, y) := lim sup
Ï„â†“0
1
Ï„ âˆ†f(Â¯x, Ï„y) upper directional G-derivative,
f G(Â¯x, y) := lim inf
Ï„â†“0
1
Ï„ âˆ†f(Â¯x, Ï„y) lower directional G-derivative,
f H(Â¯x, y) := lim sup
Ï„â†“0
zâ†’y
1
Ï„ âˆ†f(Â¯x, Ï„z) upper directional H-derivative,
f H(Â¯x, y) := lim inf
Ï„â†“0
zâ†’y
1
Ï„ âˆ†f(Â¯x, Ï„z) lower directional H-derivative.

3.2 First-Order Derivatives
41
Notice that these directional derivatives generalize the Dini derivates of a
function f : I â†’R (I âŠ†R an interval) which are deï¬ned at Â¯x âˆˆint I by
D+f(Â¯x) := lim sup
hâ†“0
f(Â¯x + h) âˆ’f(Â¯x)
h
,
D+f(Â¯x) := lim inf
hâ†“0
f(Â¯x + h) âˆ’f(Â¯x)
h
,
Dâˆ’f(Â¯x) := lim sup
hâ†‘0
f(Â¯x + h) âˆ’f(Â¯x)
h
,
Dâˆ’f(Â¯x) := lim inf
hâ†‘0
f(Â¯x + h) âˆ’f(Â¯x)
h
.
If Â¯x âˆˆI is the left boundary point of I, then D+f(Â¯x) and D+f(Â¯x) still make
sense; an analogous remark applies to the right boundary point of I. Notice
that, among others, D+f(Â¯x) = f G(Â¯x, 1). If D+f(Â¯x) = D+f(Â¯x), then this
common value is called the right derivative of f at Â¯x and is denoted f â€²
+(Â¯x).
The left derivative f â€²
âˆ’(Â¯x) is deï¬ned analogously.
3.2 First-Order Derivatives
Our aim in this section is to recall various kinds of derivatives. For this, the
following notion will be helpful.
Deï¬nition 3.2.1 A nonempty collection Î² of subsets of E is called bornology
if the following holds:
each S âˆˆÎ² is bounded and

SâˆˆÎ²
S = E,
S âˆˆÎ²
=â‡’
âˆ’S âˆˆÎ²,
S âˆˆÎ² and Î» > 0
=â‡’
Î»S âˆˆÎ²,
S1, S2 âˆˆÎ²
=â‡’
âˆƒS âˆˆÎ² : S1 âˆªS2 âŠ‚S.
In particular:
â€“
The G-bornology Î²G is the collection of all ï¬nite sets.
â€“
The H-bornology Î²H is the collection of all compact sets.
â€“
The F-bornology Î²F is the collection of all bounded sets.
We set
L(E, F) := vector space of all continuous linear mappings T : E â†’F.
Deï¬nition 3.2.2 Let Î² be a bornology on E.
(a) The mapping f : D â†’F is said to be Î²-diï¬€erentiable at Â¯x if there exists
T âˆˆL(E, F), the Î²-derivative of f at Â¯x, such that
lim
Ï„â†’0 sup
yâˆˆS
 1
Ï„

f(Â¯x + Ï„y) âˆ’f(Â¯x)

âˆ’T(y)
 = 0
âˆ€S âˆˆÎ².
(3.1)

42
3 Classical Derivatives
(b) The mapping f : D â†’F is said to be strictly Î²-diï¬€erentiable at Â¯x if there
exists T âˆˆL(E, F), the strict Î²-derivative of f at Â¯x, such that
lim
Ï„â†’0
xâ†’Â¯x
sup
yâˆˆS
 1
Ï„

f(x + Ï„y) âˆ’f(x)

âˆ’T(y)
 = 0
âˆ€S âˆˆÎ².
(3.2)
(c) In particular, f is said to be G-diï¬€erentiable or strictly G-diï¬€erentiable
if (3.1) or (3.2), respectively, holds with Î² = Î²G. In this case, T is
called (strict) G-derivative of f at Â¯x. Analogously we use (strictly) H-
diï¬€erentiable if Î² = Î²H and (strictly) F-diï¬€erentiable if Î² = Î²F . In the
respective case, T is called (strict) H-derivative or (strict) F-derivative
of f at Â¯x.
Remark 3.2.3
(a) If the Î²-derivative T of f at Â¯x exists for some bornology Î², then
T(y) = lim
Ï„â†’0
1
Ï„

f(Â¯x + Ï„y) âˆ’f(Â¯x)

= fG(Â¯x, y)
âˆ€y âˆˆE.
Hence if two of the above derivatives exist, then they coincide. This jus-
tiï¬es denoting them by the same symbol; we choose
f â€²(Â¯x) := T.
Condition (3.1) means that we have
lim
Ï„â†’0
 1
Ï„

f(Â¯x+Ï„y)âˆ’f(Â¯x)

âˆ’f â€²(Â¯x)y
=0 uniformly in y âˆˆS for each S âˆˆÎ².
An analogous remark applies to (3.2). Here and in the following we write
f â€²(Â¯x)y instead of f â€²(Â¯x)(y). If f : D â†’R, then f â€²(Â¯x) âˆˆEâˆ—and as usual we
also write âŸ¨f â€²(Â¯x), yâŸ©instead of f â€²(Â¯x)(y).
(b) Now let E be a (real) Hilbert space with inner product (x | y) and f : E â†’
R a functional. If f is G-diï¬€erentiable at Â¯x âˆˆE, then the G-derivative
f â€²(Â¯x) is an element of the dual space Eâˆ—. By the Riesz representation
theorem, there is exactly one z âˆˆE such that âŸ¨f â€²(Â¯x), yâŸ©= (z | y) for all
y âˆˆE. This element z is called gradient of f at Â¯x and is denoted âˆ‡f(Â¯x) .
In other words, we have
âŸ¨f â€²(Â¯x), yâŸ©= (âˆ‡f(Â¯x) | y)
âˆ€y âˆˆE.
Proposition 3.2.4 says that f is G-diï¬€erentiable at Â¯x if and only if the
directional G-derivative y â†’fG(Â¯x, y) exists and is linear and continuous
on E. An analogous remark applies to strict G-diï¬€erentiability as well as
(strict) H-diï¬€erentiability. Recall that if g : E â†’F, then
g(x) = o(âˆ¥xâˆ¥), x â†’o
means
lim
xâ†’o
g(x)
âˆ¥xâˆ¥= o.

3.2 First-Order Derivatives
43
Proposition 3.2.4
(i) f is G-diï¬€erentiable at Â¯x if and only if there exists f â€²(Â¯x) âˆˆL(E, F) such
that f â€²(Â¯x)y = fG(Â¯x, y) for all y âˆˆE.
(ii) f is H-diï¬€erentiable at Â¯x if and only if there exists f â€²(Â¯x) âˆˆL(E, F) such
that f â€²(Â¯x)y = fH(Â¯x, y) for all y âˆˆE.
(iii) The following assertions are equivalent:
(a) f is strictly H-diï¬€erentiable at Â¯x.
(b) There exists f â€²(Â¯x) âˆˆL(E, F) such that f â€²(Â¯x)y = f s
H(Â¯x, y) for y âˆˆE.
(c) f is locally L-continuous around Â¯x and strictly G-diï¬€erentiable at Â¯x.
(iv) f is F-diï¬€erentiable at Â¯x if and only if there exists f â€²(Â¯x) âˆˆL(E, F) such
that

f(Â¯x + z) âˆ’f(Â¯x)

âˆ’f â€²(Â¯x)z = o(âˆ¥zâˆ¥), z â†’o.
(v) f is strictly F-diï¬€erentiable at Â¯x if and only if there exists f â€²(Â¯x) âˆˆL(E, F)
such that

f(x + z) âˆ’f(x)

âˆ’f â€²(Â¯x)z = o(âˆ¥zâˆ¥), z â†’o, x â†’Â¯x.
Proof. We only verify (iii), leaving the proof of the remaining assertions as
Exercise 3.8.4.
(a) =â‡’(c): Let (a) hold. We only have to show that f is locally L-continuous
around Â¯x. Assume this is not the case. Then there exist sequences (xn) and
(xâ€²
n) in B(Â¯x, 1
n) such that
âˆ¥f(xn) âˆ’f(xâ€²
n)âˆ¥> nâˆ¥xn âˆ’xâ€²
nâˆ¥
âˆ€n âˆˆN.
(3.3)
Setting Ï„n := âˆšnâˆ¥xn âˆ’xâ€²
nâˆ¥and yn :=
1
Ï„n (xâ€²
n âˆ’xn), we obtain as n â†’âˆ,
0 â‰¤Ï„n â‰¤âˆšn(âˆ¥xn âˆ’Â¯xâˆ¥+ âˆ¥Â¯x âˆ’xâ€²
nâˆ¥) <
2
âˆšn â†’0
and
âˆ¥ynâˆ¥=
1
âˆšn â†’0.
By (3.3) we have
 1
Ï„n âˆ†f(xn, Ï„nyn)
 >
1
Ï„n Â· nâˆ¥Ï„nynâˆ¥= âˆšn
âˆ€n âˆˆN,
and the continuity of f â€²(Â¯x) implies that, with some n0 âˆˆN, we obtain âˆ¥f â€²(Â¯x)âˆ¥Â·
âˆ¥ynâˆ¥< 1
2 for each n > n0. It follows that
 1
Ï„n âˆ†f(xn, Ï„nyn) âˆ’f â€²(Â¯x)yn)

â‰¥
 1
Ï„n âˆ†f(xn, Ï„nyn)
 âˆ’âˆ¥f â€²(Â¯x)âˆ¥Â· âˆ¥ynâˆ¥> âˆšn âˆ’1
2
âˆ€n > n0,
which contradicts (3.2) for the compact set S := {o} âˆª{yn | n > n0}.
(c) =â‡’(b): Let y âˆˆE and Ïµ > 0 be given. Since f is strictly G-diï¬€erentiable
at Â¯x, there exists Î´1 > 0 such that
 1
Ï„ âˆ†f(x, Ï„y) âˆ’f â€²(Â¯x)y
 < Ïµ
whenever 0 < |Ï„| < Î´1, âˆ¥x âˆ’Â¯xâˆ¥< Î´1.
(3.4)

44
3 Classical Derivatives
Since f is locally L-continuous around Â¯x, there further exist Î» > 0 and Î´2 > 0
such that
âˆ¥f(x1) âˆ’f(x2)âˆ¥< Î»âˆ¥x1 âˆ’x2âˆ¥
âˆ€x1, x2 âˆˆB(Â¯x, Î´2).
(3.5)
Setting x1 := x + Ï„z and x2 := x + Ï„y, we have the estimates
âˆ¥x1 âˆ’Â¯xâˆ¥â‰¤âˆ¥x âˆ’Â¯xâˆ¥+ |Ï„|(âˆ¥z âˆ’yâˆ¥+ âˆ¥yâˆ¥)
and
âˆ¥x2 âˆ’Â¯xâˆ¥â‰¤âˆ¥x âˆ’Â¯xâˆ¥+ |Ï„|âˆ¥yâˆ¥
which show that x1, x2 âˆˆB(Â¯x, Î´2) provided |Ï„|, âˆ¥z âˆ’yâˆ¥, and âˆ¥x âˆ’Â¯xâˆ¥are
suï¬ƒciently small. Under this condition, (3.4) and (3.5) imply that
 1
Ï„ âˆ†f(x, Ï„z) âˆ’f â€²(Â¯x)y

â‰¤
1
|Ï„|
f(x + Ï„z) âˆ’f(x + Ï„y)
 +
 1
Ï„ âˆ†f(x, Ï„y) âˆ’f â€²(Â¯x)y
 â‰¤Î»âˆ¥z âˆ’yâˆ¥+ Ïµ.
This veriï¬es (b).
(b) =â‡’(a): Let (b) hold and assume that (a) does not hold. Let T âˆˆL(E, F)
be given. Then for some compact subset S of E, the relation (3.2) does not
hold. Hence there exist Ïµ0 > 0 as well as sequences Ï„n â†“0, yn âˆˆS, and xn â†’Â¯x
such that
 1
Ï„ âˆ†f(xn, Ï„nyn) âˆ’T(yn)
 > Ïµ0
âˆ€n âˆˆN.
Since S is compact, a subsequence of (yn), again denoted (yn), converges to
some y âˆˆS. It follows that for any n > n0 we have
 1
Ï„ âˆ†f(xn, Ï„nyn) âˆ’T(y)

â‰¥
 1
Ï„ âˆ†f(xn, Ï„nyn) âˆ’T(yn)




> Ïµ0
âˆ’âˆ¥Tâˆ¥Â· âˆ¥yn âˆ’yâˆ¥



< Ïµ0/2
> Ïµ0
2 ;
(3.6)
in this connection, we exploited that T is linear and continuous. However, the
relation (3.6) contradicts (b).
âŠ“âŠ”
Proposition 3.2.5 If f : D â†’F is H-diï¬€erentiable at Â¯x, then f is continu-
ous at Â¯x.
Proof. See Exercise 3.8.5.
âŠ“âŠ”
3.3 Mean Value Theorems
We recall a variant of the classical mean value theorem (see, for instance,
Walter [212]).
Proposition 3.3.1 (Mean Value Theorem in Terms of Dini Derivates)
Let I and J be intervals in R and let A âŠ†I be a countable set. Further let
f : I â†’R be continuous, let D âˆˆ{D+, D+, Dâˆ’, Dâˆ’}, and assume that
Df(x) âˆˆJ
âˆ€x âˆˆI \ A.

3.3 Mean Value Theorems
45
Then
f(b) âˆ’f(a)
b âˆ’a
âˆˆJ
âˆ€a, b âˆˆI, a Ì¸= b.
If f : [a, b] â†’R is continuous on [a, b] and diï¬€erentiable on (a, b), then
by the intermediate value theorem for derivatives the set J := {f â€²(x) | x âˆˆ
(a, b)} is an interval and so the usual mean value theorem follows from
Proposition 3.3.1.
Now we return to the setting described by the convention at the beginning
of the chapter. If x, z âˆˆE, we write
[x, z] := {Î»x + (1 âˆ’Î»)z | 0 â‰¤Î» â‰¤1}.
If f : D â†’F is G-diï¬€erentiable on D (i.e., G-diï¬€erentiable at any x âˆˆD),
then we may consider the mapping f â€² : x â†’f â€²(x) of D to L(E, F).
Deï¬nition 3.3.2 Let f be G-diï¬€erentiable on D. The mapping f â€² is said to
be radially continuous if for all x, y âˆˆE such that [x, x+ y] âŠ†D, the function
Ï„ â†’f â€²(x + Ï„y)y is continuous on [0, 1].
Proposition 3.3.3 (Mean Value Theorem in Integral Form) Let f
:
D â†’R be G-diï¬€erentiable and let f â€² be radially continuous. Then for all
x, y âˆˆD such that [x, x + y] âŠ†D one has
f(x + y) âˆ’f(x) =
 1
0
âŸ¨f â€²(x + Ï„y), yâŸ©dÏ„.
(3.7)
Proof. For Ï„ âˆˆ[0, 1] let Ï•(Ï„) := f(x + Ï„y). By assumption Ï• is continuously
diï¬€erentiable and Ï•â€²(Ï„) = âŸ¨f â€²(x + Ï„y), yâŸ©. The main theorem of calculus gives
Ï•(1) âˆ’Ï•(0) =
 1
0
Ï•â€²(Ï„) dÏ„,
which is (3.7).
âŠ“âŠ”
The above result is formulated for functionals only, in which case it will be
used later. In Proposition 4.3.8 below we shall describe an important class of
functionals to which the mean value formula (3.7) applies. We mention that,
by an appropriate deï¬nition of the Riemann integral, the formula extends to
a mapping f : D â†’F provided F is a Banach space.
If Î² is a bornology of E, we denote by LÎ²(E, F) the vector space L(E, F)
equipped with the topology of uniform convergence on the sets S âˆˆÎ².
In particular, LÎ²F (E, F) denotes L(E, F) equipped with the topology gen-
erated by the norm âˆ¥Tâˆ¥:= sup{âˆ¥Txâˆ¥| x âˆˆBE}. In particular we write
Eâˆ—
Î² := LÎ²(E, R).

46
3 Classical Derivatives
Proposition 3.3.4 (Mean Value Theorem in Inequality Form) Let
y âˆˆE be such that [Â¯x, Â¯x + y] âŠ†D and f is G-diï¬€erentiable on [Â¯x, Â¯x + y].
Further let T âˆˆLÎ²F (E, F). Then one has
âˆ¥

f(Â¯x + y) âˆ’f(Â¯x)

âˆ’Tyâˆ¥â‰¤âˆ¥yâˆ¥
sup
0â‰¤Ï„â‰¤1
âˆ¥f â€²(Â¯x + Ï„y) âˆ’Tâˆ¥.
Proof. Set g(x) := f(x) âˆ’T(x âˆ’Â¯x), x âˆˆE. By the Hahnâ€“Banach theorem,
there exists v âˆˆF âˆ—satisfying âˆ¥vâˆ¥= 1 and

v, âˆ†g(Â¯x, y)
 
= âˆ¥âˆ†g(Â¯x, y)âˆ¥. Now
deï¬ne Ï•(Ï„) :=

v, g(Â¯x+Ï„y)
 
, Ï„ âˆˆ[0, 1]. It is easy to see that Ï• is diï¬€erentiable,
and one has
Ï•â€²(Ï„) =

v, gâ€²(Â¯x + Ï„y)y
 
=

v, f â€²(Â¯x + Ï„y)y âˆ’Ty
 
.
(3.8)
By the classical mean value theorem, there exists Ï„ âˆˆ(0, 1) such that Ï•â€²(Ï„) =
Ï•(1) âˆ’Ï•(0). This together with (3.8) and

v, f â€²(Â¯x + Ï„y)y âˆ’Ty
  â‰¤âˆ¥vâˆ¥âˆ¥f â€²(Â¯x + Ï„y)y âˆ’Tyâˆ¥â‰¤âˆ¥f â€²(Â¯x + Ï„y) âˆ’Tâˆ¥âˆ¥yâˆ¥
completes the proof.
âŠ“âŠ”
3.4 Relationship between Diï¬€erentiability Properties
In this section we will study the interrelations between the various diï¬€eren-
tiability properties. First we introduce some terminology.
Deï¬nition 3.4.1
(a) The mapping f : D â†’F is said to be Î²-smooth at Â¯x if f is Î²-diï¬€erentiable
for any x in an open neighborhood U of Â¯x and the mapping f â€² : x â†’f â€²(x)
of U to LÎ²(E, F) is continuous on U.
(b) The mapping f : D â†’F is said to be continuously diï¬€erentiable at Â¯x if
f is G-diï¬€erentiable for any x in an open neighborhood U of Â¯x and the
mapping f â€² : x â†’f â€²(x) of U to LÎ²F (E, F) is continuous at Â¯x.
(c) If f : D â†’F is continuously diï¬€erentiable at every point of D, then f is
said to be a C1-mapping on D, written f âˆˆC1(D, F).
We shall make use of the following abbreviations:
(G):
f is G-diï¬€erentiable at Â¯x,
(SG): f is strictly G-diï¬€erentiable at Â¯x,
(CD): f is continuously diï¬€erentiable at Â¯x.
In analogy to (G), (SG) we use (H), (SH), (F), and (SF).

3.4 Relationship between Diï¬€erentiability Properties
47
Proposition 3.4.2 The following implications hold true:
(CD) =â‡’(SF) =â‡’
â†âˆ’(SH) =â‡’
â†âˆ’(SG)
â‡“
â‡“
â‡“
(F) =â‡’
â†âˆ’(H)
=â‡’
â†âˆ’(G)
In this connection, â†âˆ’means implication provided E is ï¬nite dimensional,
and â†âˆ’means implication provided f is locally L-continuous around Â¯x.
Proof. In view of the foregoing, it only remains to verify the implication (CD)
=â‡’(SF). Thus let (CD) hold. Then there exists Ï > 0 such that f is G-
diï¬€erentiable on B(Â¯x, 2Ï). If x âˆˆB(Â¯x, Ï) and y âˆˆB(o, Ï), then [x, x + y] âŠ‚
B(Â¯x, 2Ï). By Proposition 3.3.4 with T := f â€²(Â¯x), we obtain
âˆ¥f(x + y) âˆ’f(x) âˆ’f â€²(Â¯x)yâˆ¥â‰¤âˆ¥yâˆ¥
sup
0â‰¤Ï„â‰¤1
âˆ¥f â€²(x + Ï„y) âˆ’f â€²(Â¯x)âˆ¥.
(3.9)
Now let Ïµ > 0 be given. Since f â€² is continuous at Â¯x, there exists Î´ > 0 such
that
sup
0â‰¤Ï„â‰¤1
âˆ¥f â€²(x + Ï„y) âˆ’f â€²(Â¯x)âˆ¥< Ïµ
âˆ€x âˆˆB(Â¯x, Î´)
âˆ€y âˆˆB(o, Î´).
This together with (3.9) implies (SF).
âŠ“âŠ”
Remark 3.4.3 By Proposition 3.4.2 it is clear that if f is continuously dif-
ferentiable on an open neighborhood U of Â¯x, then f is Î²-smooth at any Â¯x âˆˆU
for any bornology Î² âŠ†Î²F . In particular, f is F-diï¬€erentiable at any Â¯x âˆˆU
and the F-derivative f â€² is continuous from U to LÎ²F (E, F).
Beside E and F let G be another normed vector space. Beside f : D â†’F
let g : V â†’G be another mapping, where V is an open neighborhood of
Â¯z := f(Â¯x) in F. Assume that f(D) âŠ‚V . Then the composition g â—¦f : D â†’G
is deï¬ned.
Proposition 3.4.4 (Chain Rule) Assume that f and g are H-diï¬€erentiable
at Â¯x and Â¯z, respectively. Then g â—¦f is H-diï¬€erentiable at Â¯x, and there holds
(g â—¦f)â€²(Â¯x) = gâ€²(Â¯z) â—¦f â€²(Â¯x).
An analogous statement holds true if H-diï¬€erentiable is replaced by F-diï¬€eren-
tiable.
The proof is the same as in multivariate calculus. An analogous chain rule
for G-diï¬€erentiable mappings does not hold (see Exercise 3.8.3).

48
3 Classical Derivatives
3.5 Higher-Order Derivatives
We again use the notation introduced at the beginning of the chapter. Ass-
ume that f âˆˆC1(D, F). If the (continuous) mapping f â€² : D â†’LÎ²F (E, F)
is continuously diï¬€erentiable on D, then f is said to be a twice continuously
diï¬€erentiable mapping on D, or a C2-mapping on D, with second-order deriv-
ative f â€²â€² := (f â€²)â€². The set of all twice continuously diï¬€erentiable mappings
f : D â†’F is denoted C2(D, F).
Notice that f â€²â€² maps D into H := LÎ²F

E, LÎ²F (E, F)

. Parallel to H we
consider the vector space B(E, F) of all continuous bilinear mappings b :
E Ã— E â†’F, which is normed by
âˆ¥bâˆ¥:= sup{âˆ¥b(y, z)âˆ¥| âˆ¥yâˆ¥â‰¤1, âˆ¥zâˆ¥â‰¤1}.
(3.10)
If h âˆˆH, then
bh(y, z) := h(y)z
âˆ€(y, z) âˆˆE Ã— E
deï¬nes an element bh âˆˆB(E, F). Conversely, given b âˆˆB(E, F), set
h(y) := b(y, Â·)
âˆ€y âˆˆE.
Then h âˆˆH and bh = b. Evidently the mapping h â†’bh is an isomorphism of
H onto B(E, F). Therefore H can be identiï¬ed with B(E, F). In this sense,
we interpret f â€²â€²(Â¯x) as an element of B(E, F) and write f â€²â€²(Â¯x)(y, z) instead of

f â€²â€²(Â¯x)y

z. If, in particular, f âˆˆC2(D, R), then f â€²â€²(Â¯x) is a continuous bilinear
form on E Ã— E.
Proposition 3.5.1 (Taylor Expansion) Assume that D is open and f âˆˆ
C2(D, R). Then for all Â¯x âˆˆD, y âˆˆD âˆ’Â¯x one has
f(Â¯x + y) = f(Â¯x) + âŸ¨f â€²(Â¯x), yâŸ©+ 1
2f â€²â€²(Â¯x)(y, y) + r(y),
where lim
yâ†’o
r(y)
âˆ¥yâˆ¥2 = o.
In particular, there exist Ïƒ > 0 and Ïµ > 0 such that
f(Â¯x + y) â‰¥f(Â¯x) + âŸ¨f â€²(Â¯x), yâŸ©âˆ’Ïƒâˆ¥yâˆ¥2
âˆ€y âˆˆB(o, Ïµ).
(3.11)
Proof. The ï¬rst assertion follows readily from the classical Taylor expansion
of the function Ï•(Ï„) := f(Â¯x + Ï„y), Ï„ âˆˆ[0, 1]. From the ï¬rst result we obtain
(3.11) since in view of (3.10) we have
| 1
2f â€²â€²(Â¯x)(y, y)| â‰¤1
2âˆ¥f â€²â€²(Â¯x)âˆ¥âˆ¥yâˆ¥2
âˆ€y âˆˆE,
and the limit property of r entails the existence of Îº > 0 such that |r(y)| â‰¤
Îºâˆ¥yâˆ¥2 if âˆ¥yâˆ¥is suï¬ƒciently small.
âŠ“âŠ”
We only mention that in an analogous manner, derivatives of arbitrary
order n, where n âˆˆN, can be deï¬ned using n-linear mappings, which leads to
higher-order Taylor expansions.

3.6 Some Examples
49
3.6 Some Examples
For illustration and later purposes we collect some examples. Further examples
are contained in the exercises.
Example 3.6.1 Let E be a normed vector space and a : EÃ—E â†’R a bilinear
functional. Recall that a is said to be symmetric if a(x, y) = a(y, x) for all
x, y âˆˆE, and a is said to be bounded if there exists Îº > 0 such that
|a(x, y)| â‰¤Îºâˆ¥xâˆ¥âˆ¥yâˆ¥
âˆ€x, y âˆˆE.
Consider the quadratic functional f : E â†’R deï¬ned by
f(x) := 1
2a(x, x),
x âˆˆE,
where a is bilinear, symmetric, and bounded. It is left as Exercise 3.8.6 to show
that f is continuously diï¬€erentiable on E and to calculate the derivative.
In particular, if E is a Hilbert space with inner product (x | y), then the
functional
g(x) := 1
2âˆ¥xâˆ¥2 = 1
2(x | x),
x âˆˆE,
is continuously diï¬€erentiable on E with âŸ¨gâ€²(x), yâŸ©= (x | y) for all x, y âˆˆE.
Hence âˆ‡g(x) = x for any x âˆˆE. Finally, concerning the norm functional
Ï‰(x) := âˆ¥xâˆ¥=
!
2g(x), the chain rule gives âˆ‡Ï‰(x) =
x
âˆ¥xâˆ¥for any x Ì¸= o.
Example 3.6.2 Let again E denote a Hilbert space with inner product (x | y)
and deï¬ne g : E â†’R by
g(x) :=

Î´2 + 2Î´(u | x âˆ’Â¯x) âˆ’âˆ¥x âˆ’Â¯xâˆ¥21/2,
where the positive constant Î´ and the element u âˆˆE are ï¬xed. Choose Ïµ > 0
such that the term (Â· Â· Â· ) is positive for each x âˆˆËšB(Â¯x, Ïµ). Deï¬ne Ïˆ : (0, +âˆ) â†’
R by Ïˆ(z) := z1/2 and Ï• : ËšB(Â¯x, Ïµ) â†’R by
Ï•(x) := Î´2 + 2Î´(u | x âˆ’Â¯x) âˆ’âˆ¥x âˆ’Â¯xâˆ¥2.
Then we have g = Ïˆ â—¦Ï•, and the chain rule implies
(gâ€²(x) | y) =
Î´(u | y)

Î´2 + 2Î´(u | x âˆ’Â¯x) âˆ’âˆ¥x âˆ’Â¯xâˆ¥21/2
âˆ€x âˆˆËšB(Â¯x, Ïµ)
âˆ€y âˆˆE.
In particular, (gâ€²(Â¯x) |y ) = (u | y) for all y âˆˆE, which means âˆ‡g(Â¯x) = u.
Moreover, it is easy to see that g is a C2-mapping on ËšB(Â¯x, Ïµ). This example
will be used later in connection with proximal subdiï¬€erentials.
In view of Example 3.6.3, recall that an absolutely continuous function
x : [a, b] â†’R is diï¬€erentiable almost everywhere, i.e., outside a Lebesgue null
set N âŠ†[a, b]. Setting Ë™x(t) := 0 for each t âˆˆN, which we tacitly assume

50
3 Classical Derivatives
from now on, the function Ë™x : [a, b] â†’R belongs to L1[a, b] and one has
"
[a,b] Ë™x(t) dt = x(b) âˆ’x(a). In this connection, also recall that Lp[a, b], where
p âˆˆ[1, +âˆ), denotes the vector space of all Lebesgue measurable functions g :
[a, b] â†’R such that |g|p is Lebesgue integrable over [a, b]. In addition, Lâˆ[a, b]
denotes the vector space of all Lebesgue measurable functions g : [a, b] â†’R
such that ess supxâˆˆ[a,b]|g(x)| < +âˆ. We denote by ACâˆ[a, b] the vector space
of all absolutely continuous functions x : [a, b] â†’R such that Ë™x âˆˆLâˆ[a, b].
Notice that ACâˆ[a, b] is a Banach space with respect to the norm
âˆ¥xâˆ¥1,âˆ:= max{âˆ¥xâˆ¥âˆ, âˆ¥Ë™xâˆ¥âˆ}.
Example 3.6.3 Let E := ACâˆ[a, b], where a < b, and consider the varia-
tional functional
f(x) :=
 b
a
Ï•

t, x(t), Ë™x(t)

dt
âˆ€x âˆˆACâˆ[a, b].
If Â¯x âˆˆACâˆ[a, b] is ï¬xed, we write Ï•(t) := Ï•

t, Â¯x(t), Ë™Â¯x(t)

for any t âˆˆ[a, b].
Assume that the function (t, x, v) â†’Ï•(t, x, v) is continuous on [a, b] Ã— R Ã— R
and has continuous ï¬rst-order partial derivatives with respect to x and v
there. We shall show that the functional f is continuously diï¬€erentiable at
any Â¯x âˆˆACâˆ[a, b] and that
âŸ¨f â€²(Â¯x), yâŸ©=
 b
a

Ï•x(t) Â· y(t) + Ï•v(t) Â· Ë™y(t)

dt
âˆ€y âˆˆACâˆ[a, b].
(3.12)
Proof.
(I) The directional G-derivative fG(Â¯x, y) exists for all Â¯x, y âˆˆACâˆ[a, b]. In
fact, we have
fG(Â¯x, y) = âˆ‚
âˆ‚Ï„ f(Â¯x + Ï„y)

Ï„=0
=
 b
a
âˆ‚
âˆ‚Ï„
#
Ï•(t, Â¯x(t) + Ï„y(t), Ë™Â¯x(t) + Ï„ Ë™y(t))
$
Ï„=0
dt
=
 b
a
[ Â¯Ï•x(t)y(t) + Â¯Ï•v(t) Ë™y(t)] dt.
Notice that the assumptions on Ï• and Â¯x imply that the integrand in
the last term is bounded, which allows diï¬€erentiating under the integral
sign.
(II) It is easy to verify that the functional y â†’fG(Â¯x, y) is linear and contin-
uous. Hence the G-derivative is given by (3.12).
(III) f is continuously diï¬€erentiable at any Â¯x âˆˆACâˆ[a, b]. For arbitrary
x, Â¯x, y âˆˆACâˆ[a, b] we have
[f â€²(x) âˆ’f â€²(Â¯x)]y
=
 b
a
[Ï•x(t, x, Ë™x) âˆ’Ï•x(t, Â¯x, Ë™Â¯x)]y dt +
 b
a
[Ï•v(t, x, Ë™x) âˆ’Ï•v(t, Â¯x, Ë™Â¯x)] Ë™y dt

3.7 Implicit Function Theorems and Related Results
51
and so
âˆ¥f â€²(x) âˆ’f â€²(Â¯x)âˆ¥=
sup
âˆ¥yâˆ¥1,âˆâ‰¤1
|[f â€²(x) âˆ’f â€²(Â¯x)]y|
â‰¤
 b
a
|Ï•x(t, x, Ë™x) âˆ’Ï•x(t, Â¯x, Ë™Â¯x)| dt +
 b
a
|Ï•v(t, x, Ë™x) âˆ’Ï•v(t, Â¯x, Ë™Â¯x)| dt,
< Ïµ
if âˆ¥x âˆ’Â¯xâˆ¥1,âˆis suï¬ƒciently small.
Justiï¬cation of the last line: According to hypothesis, Ï•x and Ï•v are
continuous on [a, b]Ã—RÃ—R, hence uniformly continuous on the compact
set
{(t, Î¾, Î¶) âˆˆR3 | t âˆˆ[a, b], |Î¾ âˆ’Â¯x(t)| â‰¤1, |Î¶ âˆ’Ë™Â¯x(t)| â‰¤1}.
Thus, for each Ïµ > 0 there exists Î´ âˆˆ(0, 1) such that
|Ï•x(t, x(t), Ë™x(t)) âˆ’Ï•x(t, Â¯x(t), Ë™Â¯x(t))| <
Ïµ
2(b âˆ’a)
whenever t âˆˆ[a, b], |x(t) âˆ’Â¯x(t)| â‰¤Î´, and | Ë™x(t) âˆ’Ë™Â¯x(t)| â‰¤Î´. An analogous
estimate holds for Ï•v.
âŠ“âŠ”
3.7 Implicit Function Theorems and Related Results
Now we make the following assumptions:
(A) E, F, and G are normed vector spaces.
U and V are open neighborhoods of Â¯x âˆˆE and Â¯y âˆˆF, respectively.
f : U Ã— V â†’G.
Deï¬ne g1 : U â†’G by g1(x) := f(x, Â¯y), x âˆˆU. We denote the derivative
(in the sense of GÃ¢teaux, Hadamard, or FrÃ©chet) of g1 at Â¯x, whenever it exists,
by f 1(Â¯x, Â¯y) or by D1f(Â¯x, Â¯y) and call it partial derivative of f, with respect
to the ï¬rst variable, at (Â¯x, Â¯y). Notice that f 1(Â¯x, Â¯y) is an element of L(E, G).
If f 1(x, y) exists, say, for all (x, y) âˆˆU Ã— V , then
f 1 : (x, y) â†’f 1(x, y),
(x, y) âˆˆU Ã— V,
deï¬nes the mapping f 1 : U Ã— V â†’L(E, G). An analogous remark applies to
f 2(x, y) and D2f(Â¯x, Â¯y).
As in classical multivariate calculus, we have the following relationship.
Proposition 3.7.1 Let the assumptions (A) be satisï¬ed.
(a) If f is G-diï¬€erentiable at (Â¯x, Â¯y), then the partial G-derivatives f 1(Â¯x, Â¯y)
and f 2(Â¯x, Â¯y) exist and one has
f â€²(Â¯x, Â¯y)(u, v) = f 1(Â¯x, Â¯y)u + f 2(Â¯x, Â¯y)v
âˆ€(u, v) âˆˆE Ã— F.
(3.13)
An analogous statement holds for H- and F-derivatives.

52
3 Classical Derivatives
(b) Assume that the partial G-derivatives f 1 and f 2 exist on U Ã— V and are
continuous at (Â¯x, Â¯y). Then f is F-diï¬€erentiable at (Â¯x, Â¯y) and (3.13) holds
true.
Now we establish two implicit function theorems: one under standard
hypotheses and one under relaxed diï¬€erentiability hypotheses but with G
ï¬nite dimensional.
Theorem 3.7.2 (Classical Implicit Function Theorem) In addition to
(A), let the following hold:
(a) E, F, and G are Banach spaces.
(b) f is continuous at (Â¯x, Â¯y) and f(Â¯x, Â¯y) = 0.
(c) The partial F-derivative f 2 exists on U Ã— V and is continuous at (Â¯x, Â¯y).
(d) The (continuous linear) mapping f 2(Â¯x, Â¯y) : F â†’G is bijective.
Then:
(i)
There exist neighborhoods U â€² âŠ†U and V â€² âŠ†V of Â¯x and Â¯y, respectively,
such that for each x âˆˆU â€² there is precisely one Ï•(x) âˆˆV â€² satisfying
f

x, Ï•(x)

= o
âˆ€x âˆˆU â€².
(ii)
If f is continuous in a neighborhood of (Â¯x, Â¯y), then the function Ï• : x â†’
Ï•(x) is continuous in a neighborhood of Â¯x.
(iii) If f is continuously diï¬€erentiable in a neighborhood of (Â¯x, Â¯y), then Ï• is
continuously diï¬€erentiable in a neighborhood of Â¯x and there holds
Ï•â€²(x) = âˆ’f 2

x, Ï•(x)
âˆ’1 â—¦f 1

x, Ï•(x)

.
(3.14)
Concerning the proof of the theorem, which is based on the Banach ï¬xed point
theorem, see for instance DieudonnÃ© [53], Schirotzek [196], or Zeidler [222].
Observe that the assumptions on f 2 guarantee that f 2

x, Ï•(x)
âˆ’1 exists as
an element of L(G, F) provided âˆ¥x âˆ’Â¯xâˆ¥is suï¬ƒciently small.
Now we relax the diï¬€erentiability assumptions on f 2.
Proposition 3.7.3 In addition to (A), let the following hold:
(a) G is ï¬nite dimensional.
(b) f is continuous in a neighborhood of (Â¯x, Â¯y) and f(Â¯x, Â¯y) = 0.
(c) The partial F-derivative f 2(Â¯x, Â¯y) exists and is surjective.
Then, for each neighborhood V â€² âŠ†V of Â¯y there exist a neighborhood U â€² âŠ†U
of Â¯x and a function Ï• : U â€² â†’V â€² such that the following holds:
(i) f

x, Ï•(x)

= o
âˆ€x âˆˆU â€²,
Ï•(Â¯x) = Â¯y.
(ii) Ï• is continuous at Â¯x.

3.7 Implicit Function Theorems and Related Results
53
Proof.
(I) Without loss of generality we may assume that Â¯y = o. Further we
set T
:= f 2(Â¯x, o). By assumption, T is a continuous linear map-
ping of F onto the ï¬nite-dimensional space G. Hence there exists a
ï¬nite-dimensional linear subspace ËœF of F such that the linear mapping
T âˆ’1 : G â†’ËœF satisfying TT âˆ’1(z) = z for any z âˆˆG is a linear iso-
morphism. In order to verify the assertions (i) and (ii), we may replace
f : E Ã— F â†’G by its restriction to E Ã— ËœF. But ËœF can be identiï¬ed
with G and so we may assume that F = G. Then T is a bijective linear
mapping of G onto G.
(IIa) Let Ïµ > 0 be such that BF (o, Ïµ) âŠ†V and f is continuous on the neigh-
borhood BE(Â¯x, Ïµ) Ã— BF (o, Ïµ) of (Â¯x, o). Let Î± âˆˆ(0, Ïµ) be such that
|f(Â¯x, y) âˆ’T(y)| â‰¤
Î±
2âˆ¥T âˆ’1âˆ¥
âˆ€y âˆˆBF (o, Î±).
(3.15)
Since f is continuous and BF (o, Î±) is compact, there further exists Î² âˆˆ
(0, Ïµ) such that
|f(Â¯x, y) âˆ’f(x, y)| â‰¤
Î±
2âˆ¥T âˆ’1âˆ¥
âˆ€x âˆˆBE(Â¯x, Î²)
âˆ€y âˆˆBF (o, Î±).
(3.16)
(IIb) For any x âˆˆBE(Â¯x, Î²) deï¬ne hx : BF (o, Î±) â†’F by hx(y) := y âˆ’
T âˆ’1f(x, y). Notice that hx is continuous.
(IIc) We now show that hx maps BF (o, Î±) into itself. Let any y âˆˆBF (o, Î±)
be given. We have
âˆ¥hx(y)âˆ¥â‰¤âˆ¥y âˆ’T âˆ’1f(Â¯x, y)âˆ¥+ âˆ¥T âˆ’1
f(Â¯x, y) âˆ’f(x, y)

âˆ¥.
(3.17)
Furthermore, we obtain
âˆ¥y âˆ’T âˆ’1f(Â¯x, y)âˆ¥= âˆ¥T âˆ’1
T(y) âˆ’f(Â¯x, y)

âˆ¥
â‰¤âˆ¥T âˆ’1âˆ¥Â· âˆ¥T(y) âˆ’f(Â¯x, y)âˆ¥
â‰¤
(3.15)
Î±
2
(3.18)
as well as
âˆ¥T âˆ’1
f(Â¯x, y) âˆ’f(x, y)

âˆ¥
â‰¤
(3.16)
âˆ¥T âˆ’1âˆ¥Â·
Î±
2âˆ¥T âˆ’1âˆ¥= Î±
2 .
Hence (3.17) shows that hx maps BF (o, Î±) into itself.
(IId) In view of (IIb) and (IIc) the Brouwer ï¬xed-point theorem applies, ensu-
ring that hx has a ï¬xed point Ïˆ(x) in BF (o, Î±). This deï¬nes a mapping
Ïˆ : x â†’Ïˆ(x) of BE(Â¯x, Î²) into V satisfying
Ïˆ(x) âˆ’T âˆ’1f

x, Ïˆ(x)

= hx

Ïˆ(x)

= Ïˆ(x)
and so f

x, Ïˆ(x)

= o for any x âˆˆBE(Â¯x, Î²).

54
3 Classical Derivatives
(III) Let a neighborhood V â€² âŠ†V of o be given. Choose Î½ âˆˆN such that
BF (o, 1
Î½ ) âŠ†V â€² and set Vi := BF (o,
1
Î½+i) for i = 1, 2, . . . By step (II) we
know that for each i there exist a neighborhood Ui of Â¯x and a function
Ïˆi : Ui â†’Vi satisfying f

x, Ïˆi(x)

= o for any x âˆˆUi. Without loss
of generality we may assume that Ui+1 is a proper subset of Ui for
i = 1, 2, . . . and that âˆ
i=1 Ui = {Â¯x}. Now let U â€² := U1 and deï¬ne
Ï• : U â€² â†’V â€² by
Ï•(Â¯x) := o = Â¯y,
Ï•(x) := Ïˆi(x)
whenever x âˆˆUi \ Ui+1.
Then (i) holds by deï¬nition of Ï•. We verify (ii). Thus let Î· > 0 be given.
Then we have Vi âŠ†BF (o, Î·) for some i and Ïˆi : Ui â†’Vi. It follows that
âˆ¥Ï•(x) âˆ’oâˆ¥= âˆ¥Ïˆi(x) âˆ’oâˆ¥â‰¤Î·
whenever x âˆˆUi \ Ui+1.
By the construction of Ui and Vi, we conclude that Ï•(Ui) âŠ†BF

o, Î·

.
âŠ“âŠ”
Theorem 3.7.4 (Halkinâ€™s Implicit Function Theorem) In addition to
(A), let the following hold:
(a) G is ï¬nite dimensional.
(b) f is continuous in a neighborhood of (Â¯x, Â¯y) and f(Â¯x, Â¯y) = 0.
(c) f is F-diï¬€erentiable at (Â¯x, Â¯y) and the partial F-derivative f 2(Â¯x, Â¯y) is sur-
jective.
Then there exist a neighborhood U â€² of Â¯x and a function Ï• : U â€² â†’V satisfying:
(i) f

x, Ï•(x)

= o
âˆ€x âˆˆU â€²,
Ï•(Â¯x) = Â¯y.
(ii) Ï• is F-diï¬€erentiable at Â¯x and there holds
f 1(Â¯x, Â¯y) + f 2(Â¯x, Â¯y) â—¦Ï•â€²(Â¯x) = o.
(3.19)
Proof.
(I) With the same argument as in step (I) of the proof of Proposition 3.7.3 we
may assume without loss of generality that F = G. We may also assume
that Â¯x = o and Â¯y = o. We set S := f 1(o, o) and T := f 2(o, o). Notice
that T is a bijective linear mapping of G onto G.
(II) By Proposition 3.7.3, there exist a neighborhood U â€² of Â¯x = o and a
function Ï• : U â€² â†’V such that (i) holds and Ï• is continuous at o. We verify
(ii). Since f is F-diï¬€erentiable at o, there exists a function r : U â€² â†’F
such that
f â€²(o, o)

x, Ï•(x)

+ r

x, Ï•(x)

= o
âˆ€x âˆˆU â€²,
(3.20)
lim
âˆ¥xâˆ¥+âˆ¥yâˆ¥â†’0
r(x, y)
âˆ¥xâˆ¥+ âˆ¥yâˆ¥= o.
(3.21)

3.7 Implicit Function Theorems and Related Results
55
By Proposition 3.7.1, (3.20) passes into
S(x) + T

Ï•(x)

+ r

x, Ï•(x)

= o
âˆ€x âˆˆU â€²,
i.e.,
Ï•(x) = âˆ’T âˆ’1S(x) âˆ’T âˆ’1r

x, Ï•(x)

âˆ€x âˆˆU â€².
(3.22)
(III) We estimate âˆ¥Ï•(x)âˆ¥. Let Ïƒ > 0 be such that BE(o, Ïƒ) âŠ†U â€² and
âˆ¥r(x, y)âˆ¥â‰¤(âˆ¥xâˆ¥+ âˆ¥yâˆ¥)
2âˆ¥T âˆ’1âˆ¥
whenever âˆ¥xâˆ¥â‰¤Ïƒ, âˆ¥yâˆ¥â‰¤Ïƒ.
(3.23)
Since Ï• is continuous at o, there further exists Î± âˆˆ(0, Ïƒ) such that
âˆ¥Ï•(x)âˆ¥â‰¤Ïƒ for all x âˆˆBE(o, Î±). It follows that
âˆ¥Ï•(x)âˆ¥
â‰¤
(3.22)
âˆ¥T âˆ’1Sâˆ¥Â· âˆ¥xâˆ¥+ âˆ¥T âˆ’1âˆ¥Â· âˆ¥r

x,Â¸Ï•(x)

âˆ¥
â‰¤
(3.23)

âˆ¥T âˆ’1Sâˆ¥+ 1
2

Â· âˆ¥xâˆ¥+ 1
2âˆ¥Ï•(x)âˆ¥
âˆ€x âˆˆBE(o, Î±)
and so
âˆ¥Ï•(x)âˆ¥â‰¤(2âˆ¥T âˆ’1Sâˆ¥+ 1) Â· âˆ¥xâˆ¥
âˆ€x âˆˆBE(o, Î±).
(3.24)
We also have
âˆ¥T âˆ’1r

x, Ï•(x)

âˆ¥â‰¤âˆ¥T âˆ’1âˆ¥Â· âˆ¥r

x, Ï•(x)

âˆ¥.
The latter inequality, (3.21) and (3.24) show that âˆ¥T âˆ’1r

x, Ï•(x)

âˆ¥/âˆ¥xâˆ¥
is arbitrarily small for all x in a suï¬ƒciently small neighborhood of
Â¯x = o. In view of (3.22), we conclude that Ï• is F-diï¬€erentiable at o,
with derivative Ï•â€²(o) = âˆ’T âˆ’1S.
âŠ“âŠ”
To prepare the next result, recall (once more) that if the mapping
f : E â†’G is F-diï¬€erentiable at Â¯x âˆˆE, then with some neighborhood
U of Â¯x, one has
f(x) = f(Â¯x) + f â€²(Â¯x)(x âˆ’Â¯x) + r(x)
âˆ€x âˆˆU,
where lim
xâ†’Â¯x
r(x)
âˆ¥x âˆ’Â¯xâˆ¥= o.
Our aim now is to replace the correction term r(x) for the function values
on the right-hand side by a correction term Ï(x) for the argument on the
left-hand side:
f

x + Ï(x)

= f(Â¯x) + f â€²(Â¯x)(x âˆ’Â¯x)
âˆ€x âˆˆU,
where lim
xâ†’Â¯x
Ï(x)
âˆ¥x âˆ’Â¯xâˆ¥= o.
(3.25)
Theorem 3.7.5 says that this is possible under appropriate hypotheses.

56
3 Classical Derivatives
Theorem 3.7.5 (Halkinâ€™s Correction Theorem) Let
E
and
G
be
normed vector spaces with G ï¬nite dimensional. Further let f : E â†’G
and Â¯x âˆˆE. Assume the following:
(a) f is continuous in a neighborhood of Â¯x.
(b) The F-derivative f â€²(Â¯x) exists and is surjective.
Then there exist a neighborhood U of Â¯x and a function Ï : U â†’E such that
(3.25) holds. The function Ï satisï¬es Ï(Â¯x) = o and is F-diï¬€erentiable at Â¯x with
Ïâ€²(Â¯x) = o.
Proof. Let F be the ï¬nite-dimensional linear subspace of E which f â€²(Â¯x) maps
onto G. Deï¬ne Ëœf : E Ã— F â†’G by
Ëœf(x, y) := f(x + y) âˆ’f â€²(Â¯x)(x âˆ’Â¯x) âˆ’f(Â¯x).
Notice that Ëœf is F-diï¬€erentiable at (Â¯x, o) and that
Ëœf 1(Â¯x, o) = o,
Ëœf 2(Â¯x, o) = f â€²(Â¯x).
(3.26)
Hence Theorem 3.7.4 applies to Ëœf at (x, o). Thus there exist a neighborhood
U of Â¯x and a function Ï• : U â†’F that is F-diï¬€erentiable at Â¯x and is such that
Ëœf

x, Ï•(x)

= o
âˆ€x âˆˆU,
Ï•(Â¯x) = o,
Ëœf 1(Â¯x, o) + Ëœf 2(Â¯x, o) â—¦Ï•â€²(Â¯x) = o.
Setting Ï := Ï•, the deï¬nition of Ëœf gives
f

x + Ï(x)

= f(Â¯x) + f â€²(Â¯x)(x âˆ’Â¯x)
âˆ€x âˆˆU.
Moreover, by (3.26) we have f â€²(Â¯x)â—¦Ïâ€²(Â¯x) = o. Since f â€²(Â¯x) : F â†’G is bijective,
it follows that Ïâ€²(Â¯x) = o. From this and Ï(Â¯x) = o we ï¬nally deduce that
Ï(x)/âˆ¥x âˆ’Â¯xâˆ¥â†’o as x â†’Â¯x.
âŠ“âŠ”
Theorem 3.7.5 will be a key tool for deriving a multiplier rule for a non-
smooth optimization problem in Sect. 12.3.
Theorem 3.7.6 (Halkinâ€™s Inverse Function Theorem) Let
E
be
a
ï¬nite-dimensional normed vector space. Further let f : E â†’E and Â¯x âˆˆE.
Assume the following:
(a) f is continuous in a neighborhood of Â¯x.
(b) The F-derivative f â€²(Â¯x) exists and is surjective.
Then there exist a neighborhood U of Â¯x and a function Ï• : U â†’E such that
the following holds:
(i) f

Ï•(x)

= x
âˆ€x âˆˆU,
Ï•

f(Â¯x)

= Â¯x.
(ii) Ï• is F-diï¬€erentiable at f(Â¯x), with Ï•â€²
f(Â¯x)

= f â€²(Â¯x)âˆ’1.

3.8 Bibliographical Notes and Exercises
57
Proof. Deï¬ne Ëœf : E Ã—E â†’E by Ëœf(u, v); = uâˆ’f(v) and set Â¯u := f(Â¯x), Â¯v := Â¯x.
Then Ëœf is F-diï¬€erentiable at (Â¯u, Â¯v), with Ëœf 1(Â¯u, Â¯v) = idE and Ëœf 2(Â¯u, Â¯v) =
âˆ’f â€²(Â¯x). By Theorem 3.7.4 applied to Ëœf at (Â¯u, Â¯v), there exist a neighborhood
U of Â¯u and a function Ï• : U â†’E such that Ëœf

u, Ï•(u)

= o for any u âˆˆU and
Ï•(Â¯u) = Â¯v. Moreover, Ï• is F-diï¬€erentiable at Â¯u and satisï¬es
Ëœf 1(Â¯u, Â¯v) + Ëœf 2(Â¯u, Â¯v) â—¦Ï•â€²(Â¯u) = o.
It is obvious that Ï• meets the assertions of the theorem.
âŠ“âŠ”
3.8 Bibliographical Notes and Exercises
The subject of this chapter is standard. We refer to DieudonnÃ© [53],
Schirotzek [196], Schwartz [197], and Zeidler [222] for diï¬€erential calculus
in Banach spaces and to Zeidler [221, 224] for diï¬€erentiability properties of
integral functionals on Sobolev spaces. The results from Proposition 3.7.3 to
the end of Sect. 3.7 are due to Halkin [82]. See also the Bibliographical Notes
to Chap. 4.
Exercise 3.8.1 Deï¬ne g : R2 â†’R by
g(x1, x2) :=

x3
1
x2
if x2 Ì¸= 0,
0
if x2 = 0.
Show that g is G-diï¬€erentiable but not H-diï¬€erentiable at Â¯x = (0, 0).
Exercise 3.8.2 Show that the function
f(x) := x2 sin(1/x) if x âˆˆR \ {0},
f(x) := 0 if x = 0
is F-diï¬€erentiable but not continuously diï¬€erentiable at Â¯x = 0.
In Sect. 4.6 we shall show that the maximum norm on C[a, b], where a < b,
is H-diï¬€erentiable at certain points but nowhere F-diï¬€erentiable; compare this
and the preceding two examples with Proposition 3.4.2.
Exercise 3.8.3 Deï¬ne f
: R2 â†’R2 by f(x1, x2) := (x1, x3
2) and let
g : R2 â†’R be the function of Exercise 3.8.1. Then f is F-diï¬€erentiable
(and so G-diï¬€erentiable) on R2 and g is G-diï¬€erentiable at Â¯x = (0, 0). Is the
composite function g â—¦f G-diï¬€erentiable at Â¯x?
Exercise 3.8.4 Carry out the omitted proofs for Proposition 3.2.4.
Exercise 3.8.5 Prove Proposition 3.2.5.

58
3 Classical Derivatives
Exercise 3.8.6 Show that the functional f(x) := 1
2a(x, x), x âˆˆE, where a :
E Ã—E â†’R is bilinear, symmetric, and bounded, is continuously diï¬€erentiable
on E and calculate its derivative (cf. Example 3.6.1).
Exercise 3.8.7 Assume that Ï• : [a, b] Ã— R Ã— R â†’R is continuous and
possesses continuous partial derivatives with respect to the second and the
third variable. Modeling the proof in Example 3.6.3, show that the functional
f : C1[a, b] Ã— [a, b] Ã— [a, b] deï¬ned by
f(x, Ïƒ, Ï„) :=
 Ï„
Ïƒ
Ï•

t, x(t), Ë™x(t)

dt,
x âˆˆC1[a, b],
Ïƒ, Ï„ âˆˆ(a, b),
is continuously diï¬€erentiable and calculate its derivative. (Functionals of this
kind appear in variable-endpoint problems in the classical calculus of varia-
tions.)

4
The Subdiï¬€erential of Convex Functionals
4.1 Deï¬nition and First Properties
For convex functionals, the following notion provides an appropriate substitute
for a nonexisting derivative.
Deï¬nition 4.1.1 Let f : E â†’R be proper and convex, and let Â¯x âˆˆdom f.
The set
âˆ‚f(Â¯x) := {xâˆ—âˆˆEâˆ—| âŸ¨xâˆ—, x âˆ’Â¯xâŸ©â‰¤f(x) âˆ’f(Â¯x) âˆ€x âˆˆE}
is called subdiï¬€erential of f at Â¯x (in the sense of convex analysis). Each
xâˆ—âˆˆâˆ‚f(Â¯x) is called subgradient of f at Â¯x.
A geometric interpretation is given in Fig. 0.1 in the Introduction.
Remark 4.1.2 The main purpose of the subdiï¬€erential is to detect minimum
points. We ï¬rst consider free minimization. If f : E â†’R is convex and Â¯x âˆˆ
dom f, then we obtain
f(Â¯x) = min
xâˆˆE f(x)
â‡â‡’
0 â‰¤f(x) âˆ’f(Â¯x) âˆ€x âˆˆE
â‡â‡’
o âˆˆâˆ‚f(Â¯x).
Hence the condition o âˆˆâˆ‚f(Â¯x) is a substitute for the optimality condition
f â€²(Â¯x) = o in the diï¬€erentiable case. Concerning constrained minimization, for
A âŠ†E nonempty and convex, we have
f(Â¯x) = min
xâˆˆA f(x) â‡â‡’(f + Î´A)(Â¯x) = min
xâˆˆE(f + Î´A)(x) â‡â‡’o âˆˆâˆ‚(f + Î´A)(Â¯x).
For further exploitation, we need at least a sum rule of the form
âˆ‚(f1 + f2)(Â¯x) âŠ†âˆ‚f1(Â¯x) + âˆ‚f2(Â¯x).
This, among others, will be derived below.

60
4 The Subdiï¬€erential of Convex Functionals
The subdiï¬€erential of a convex functional f can also be characterized by
the directional G-derivative of f. This relationship will later be the starting
point for deï¬ning subdiï¬€erentials for certain classes of nonconvex functionals.
Theorem 4.1.3 Let f : E â†’R be proper and convex.
(a) If Â¯x âˆˆdomf and y âˆˆE, the function Ï„ â†’1
Ï„

f(Â¯x+Ï„y)âˆ’f(Â¯x)

is monotone
increasing on R \ {0}; hence the limit fG(Â¯x, y) exists in R and one has
f(Â¯x) âˆ’f(Â¯x âˆ’y) â‰¤fG(Â¯x, y) = inf
Ï„>0
f(Â¯x + Ï„y) âˆ’f(Â¯x)
Ï„
â‰¤f(Â¯x + y) âˆ’f(Â¯x).
(4.1)
(b) If Â¯x âˆˆdomf, the functional fG(Â¯x, Â·) of E to R is sublinear.
(c) If Â¯x âˆˆint dom f and y âˆˆE, then fG(Â¯x, y) âˆˆR.
(d) If Â¯x âˆˆint dom f and f is continuous at Â¯x, then fH(Â¯x, Â·) exists, is contin-
uous on E, and equals fG(Â¯x, Â·).
Proof.
(a) Since f is proper and convex, so is Ï•(Ï„) := f(Â¯x + Ï„y), Ï„ âˆˆR. Let Ï„1 <
Ï„2 < Ï„3 and Ï„ik := Ï„i âˆ’Ï„k for i, k = 1, 2, 3. Since Ï„2 = Ï„32
Ï„31 Ï„1 + Ï„21
Ï„31 Ï„3, it
follows that
Ï•(Ï„2) â‰¤Ï„32
Ï„31
Ï•(Ï„1) + Ï„21
Ï„31
Ï•(Ï„3)
and so
Ï•(Ï„2) âˆ’Ï•(Ï„1)
Ï„2 âˆ’Ï„1
â‰¤Ï•(Ï„3) âˆ’Ï•(Ï„1)
Ï„3 âˆ’Ï„1
â‰¤Ï•(Ï„3) âˆ’Ï•(Ï„2)
Ï„3 âˆ’Ï„2
.
(4.2)
From this, by appropriate choices of Ï„i, we obtain the monotonicity of the
function
Ï„ â†’1
Ï„

Ï•(Ï„) âˆ’Ï•(0)

= 1
Ï„

f(Â¯x + Ï„y) âˆ’f(Â¯x)

as well as the relation (4.1).
(b) For y, z âˆˆE, the convexity of f implies
f

Â¯x+Ï„(y+z)

= f
 1
2(Â¯x+2Ï„y) + 1
2(Â¯x+2Ï„z)

â‰¤1
2f(Â¯x+2Ï„y) + 1
2f(Â¯x+2Ï„z)
and so
fG(Â¯x, y + z) â‰¤fG(Â¯x, y) + fG(Â¯x, z).
It is evident that fG(Â¯x, Â·) is positively homogeneous.
(c) Since Â¯x âˆˆint dom f, there exists Ïµ > 0 such that Â¯xÂ±Ïµy âˆˆdom f. Applying
(4.1) with Ïµy instead of y, we see that Ïµ fG(Â¯x, y) (= fG(Â¯x, Ïµy)) is ï¬nite.
(d) There exists an open neighborhood U of zero in E such that
f(Â¯x + y) âˆ’f(Â¯x) â‰¤1
âˆ€y âˆˆU.
This and (4.1) imply that the convex functional fG(Â¯x, Â·) is bounded above
on U and so, by Theorem 1.4.1, is continuous on int dom fG(Â¯x, Â·) which is
equal to E. Likewise by Theorem 1.4.1, f is locally L-continuous. Hence
by Lemma 3.1.2, fH(Â¯x, Â·) exists and equals fG(Â¯x, Â·).
âŠ“âŠ”

4.1 Deï¬nition and First Properties
61
Ï„1
Ï„2
Ï„3
P1
P2
P3
Ï•
Fig. 4.1
Remark 4.1.4 For a proper convex function Ï• : R â†’R, the inequalities
(4.2) have a simple geometric meaning. With the notation of Fig. 4.1, the
inequalities say that
slope(P1P2) â‰¤slope(P1P3) â‰¤slope(P2P3).
If Ï• is a function deï¬ned on R, then obviously Ï•G(Ï„, 1) = Ï•â€²
+(Ï„), where Ï•â€²
+(Ï„)
denotes the right derivative of Ï• at Ï„ (cf. Sect. 3.1). Hence Theorem 4.1.3
immediately leads to:
Corollary 4.1.5 Let Ï• : R â†’R be proper and convex. For any Ï„0 âˆˆdom Ï•,
the right derivative Ï•â€²
+(Ï„0) exists in R and satisï¬es
Ï•â€²
+(Ï„0) = inf
Ï„>0
Ï•(Ï„0 + Ï„) âˆ’Ï•(Ï„0)
Ï„
.
In particular, if Ï„0 âˆˆint dom Ï•, then Ï•â€²
+(Ï„0) âˆˆR. If Ï„0 âˆˆdom Ï• is the left
boundary point of dom Ï•, then Ï•â€²
+(Ï„0) âˆˆR âˆª{âˆ’âˆ}.
The subdiï¬€erential can be characterized by the directional G-derivative
and vice versa.
Proposition 4.1.6 Let f : E â†’R be proper and convex.
(a) If Â¯x âˆˆdom f, then
âˆ‚f(Â¯x) = {xâˆ—âˆˆEâˆ— âŸ¨xâˆ—, yâŸ©â‰¤fG(Â¯x, y) âˆ€y âˆˆE}.
(4.3)
(b) If Â¯x âˆˆint dom f and f is continuous at Â¯x, then âˆ‚f(Â¯x) is nonempty convex
and Ïƒ(Eâˆ—, E)-compact, and one has
fH(Â¯x, y) = fG(Â¯x, y) = max{âŸ¨xâˆ—, yâŸ©| xâˆ—âˆˆâˆ‚f(Â¯x)}
âˆ€y âˆˆE.
(4.4)
Proof.
(a) Let xâˆ—âˆˆâˆ‚f(Â¯x). For each Ï„ > 0, we have
Ï„âŸ¨xâˆ—, yâŸ©= âŸ¨xâˆ—, Â¯x + Ï„yâŸ©âˆ’âŸ¨xâˆ—, Â¯xâŸ©â‰¤f(Â¯x + Ï„y) âˆ’f(Â¯x)

62
4 The Subdiï¬€erential of Convex Functionals
and so âŸ¨xâˆ—, yâŸ©â‰¤fG(Â¯x, y). Conversely, if xâˆ—belongs to the right-hand side
of (4.3), then it follows from (4.1) that
âŸ¨xâˆ—, Â¯x + yâŸ©âˆ’âŸ¨xâˆ—, Â¯xâŸ©= âŸ¨xâˆ—, yâŸ©â‰¤f(Â¯x + y) âˆ’f(Â¯x)
and so xâˆ—âˆˆâˆ‚f(Â¯x).
(b) By Theorem 4.1.3, the functional p(y) := fG(Â¯x, y), y âˆˆE, is ï¬nite, sub-
linear, and continuous. By (a), we have âˆ‚f(Â¯x) = Mp; here we use the
notation introduced in the HÂ¨ormander theorem (Theorem 2.3.1). Accord-
ing to this result, Mp is nonempty, convex, and Ïƒ(Eâˆ—, E)-closed, and we
have ÏƒMp = p, i.e.,
sup{âŸ¨xâˆ—, yâŸ©| xâˆ—âˆˆâˆ‚f(Â¯x)} = fG(Â¯x, y)
âˆ€y âˆˆE.
(4.5)
We show that âˆ‚f(Â¯x) is Ïƒ(Eâˆ—, E)-compact. Since f is continuous at Â¯x, the
set
U := {y âˆˆE | f(Â¯x + y) âˆ’f(Â¯x) â‰¤1}
is a neighborhood of zero in E. Setting U â‹„:= {xâˆ—âˆˆEâˆ—| âŸ¨xâˆ—, yâŸ©â‰¤1 âˆ€y âˆˆ
U}, we have âˆ‚f(Â¯x) âŠ†U â‹„. By the Alaoglu theorem, U â‹„is Ïƒ(Eâˆ—, E)-
compact and so is âˆ‚f(Â¯x) as a Ïƒ(Eâˆ—, E)-closed subset. For ï¬xed y âˆˆE,
the functional xâˆ—â†’âŸ¨xâˆ—, yâŸ©, xâˆ—âˆˆEâˆ—, is Ïƒ(Eâˆ—, E)-continuous and so
the supremum in (4.5) is attained. Finally, by Theorem 4.1.3(d) we may
replace fG by fH.
âŠ“âŠ”
The representation formula (4.4) can be reï¬ned using the concept of ext-
reme point.
Proposition 4.1.7 If f : E â†’R is proper, convex, and continuous at Â¯x âˆˆ
int dom f, then
fH(Â¯x, y) = fG(Â¯x, y) = max

âŸ¨xâˆ—, yâŸ©
 xâˆ—âˆˆep

âˆ‚f(Â¯x)

âˆ€y âˆˆE.
Proof. By virtue of Proposition 4.1.6(b), we may apply Proposition 1.7.8 to
Eâˆ—[Ïƒ] instead of E, A := âˆ‚f(Â¯x), and g(xâˆ—) := âŸ¨xâˆ—, yâŸ©, xâˆ—âˆˆE.
âŠ“âŠ”
Now we characterize G-diï¬€erentiability of convex functionals.
Proposition 4.1.8 (Diï¬€erentiability Criterion) Let f : E â†’R be proper
and convex, and let Â¯x âˆˆdom f.
(a) If f is G-diï¬€erentiable at Â¯x, then âˆ‚f(Â¯x) = {f â€²(Â¯x)}.
(b) If f is continuous at Â¯x and âˆ‚f(Â¯x) consists of exactly one element xâˆ—âˆˆEâˆ—,
then f is H-diï¬€erentiable (and so G-diï¬€erentiable) at Â¯x and f â€²(Â¯x) = xâˆ—.
Proof.
(a) On the one hand, we have
âŸ¨f â€²(Â¯x), Â¯x+yâŸ©âˆ’âŸ¨f â€²(Â¯x) , Â¯xâŸ©= âŸ¨f â€²(Â¯x), yâŸ©= fG(Â¯x, y) â‰¤f(Â¯x+y)âˆ’f(Â¯x)
âˆ€y âˆˆE

4.2 Multifunctions: First Properties
63
and so f â€²(Â¯x) âˆˆâˆ‚f(Â¯x). On the other hand, if xâˆ—âˆˆâˆ‚f(Â¯x), then by
Proposition 4.1.6 we obtain
âŸ¨xâˆ—, yâŸ©â‰¤fG(Â¯x, y) = âŸ¨f â€²(Â¯x), yâŸ©
âˆ€y âˆˆE.
This implies, by the linearity of xâˆ—and f â€²(Â¯x), that xâˆ—= f â€²(Â¯x).
(b) By Proposition 4.1.6, we conclude that fG(Â¯x, y) = âŸ¨xâˆ—, yâŸ©âˆ€y âˆˆE. Hence
the functional fG(Â¯x, Â·) is linear and continuous. Thus f is G-diï¬€erentiable
at Â¯x, and we have f â€²(Â¯x) = xâˆ—. Moreover, f is locally L-continuous around
Â¯x (Theorem 1.4.1) and so H-diï¬€erentiable at Â¯x (Proposition 3.4.2).
âŠ“âŠ”
Proposition 4.1.9 (Semicontinuity Criterion) Let f : E â†’R be proper,
convex, and G-diï¬€erentiable at Â¯x. Then f is lower semicontinuous at Â¯x.
Proof. Let k > 0 be given. Since f â€²(Â¯x) is continuous at y = o in particular,
there exists a neighborhood U of o in E such that
k âˆ’f(Â¯x) < âŸ¨f â€²(Â¯x), yâŸ©â‰¤f(Â¯x + y) âˆ’f(Â¯x)
âˆ€y âˆˆU.
âŠ“âŠ”
4.2 Multifunctions: First Properties
The subdiï¬€erential of a convex function f : E â†’R associates with each
x âˆˆE a (possibly empty) subset âˆ‚f(x) of Eâˆ—. The study of this and related
objects will be the prominent purpose in the sequel. We now introduce some
appropriate concepts.
Deï¬nition 4.2.1 Let E and F be vector spaces. A mapping Î¦ : E â†’2F ,
which associates to x âˆˆE a (possibly empty) subset Î¦(x) of F, is called a
multifunction or set-valued mapping and is denoted Î¦ : E â‡’F. The graph
and the domain of Î¦ are deï¬ned, respectively, by
graph Î¦ := {(x, y) âˆˆE Ã— F | x âˆˆE, y âˆˆÎ¦(x)},
Dom Î¦ := {x âˆˆE | Î¦(x) Ì¸= âˆ…}.
Observe that the notation distinguishes the domain of a multifunction
from the eï¬€ective domain dom f of a functional f : E â†’R. If A is a subset
of E, we write Î¦(A) := âˆªxâˆˆAÎ¦(x).
Remark 4.2.2 A mapping T : E â†’F can be identiï¬ed with the (single-
valued) multifunction %T : E â‡’F deï¬ned by %T(x) := {Tx}, x âˆˆE. Concepts
deï¬ned below for multifunctions will be applied to a mapping T : E â†’F
according to this identiï¬cation.
As indicated above, the prototype of a multifunction is the subdiï¬€erential
mapping âˆ‚f : E â‡’Eâˆ—of a convex functional f : E â†’R, which associates to
each x âˆˆdom f the subdiï¬€erential âˆ‚f(x) and to each x /âˆˆdom f the empty
set.

64
4 The Subdiï¬€erential of Convex Functionals
Deï¬nition 4.2.3 Let Î¦ : E â‡’F be a multifunction between locally convex
spaces E and F.
(a) Î¦ is said to be upper semicontinuous at Â¯x âˆˆDom Î¦ if for each open set V
in F containing Î¦(Â¯x) there exists an open neighborhood U of Â¯x such that
Î¦(U) âŠ†V .
(b) Î¦ is said to be lower semicontinuous at Â¯x âˆˆDom Î¦ if for each open set V
in F such that V âˆ©Î¦(Â¯x) Ì¸= âˆ…, there exists an open neighborhood U of Â¯x
such that V âˆ©Î¦(x) Ì¸= âˆ…for any x âˆˆU.
(c) Î¦ is said to be upper [lower] semicontinuous if Î¦ is upper [lower] semicon-
tinuous at any point Â¯x âˆˆDom Î¦ (cf. Exercise 4.8.1).
(d) Î¦ is said to be locally bounded at Â¯x âˆˆE if there exists a neighborhood U
of Â¯x such that Î¦(U) is a bounded subset of F.
(e) A mapping Ï• : E â†’F is said to be a selection of the multifunction Î¦ if
Ï•(x) âˆˆÎ¦(x) for each x âˆˆDom Î¦.
Recall that if Ïˆ : R â†’R is diï¬€erentiable, then
Ïˆ is convex
â‡â‡’
Ïˆâ€² is monotone increasing
â‡â‡’

Ïˆâ€²(y) âˆ’Ïˆâ€²(x)

Â· (y âˆ’x) â‰¥0
âˆ€x, y âˆˆR.
(4.6)
If we want to generalize this relationship to a G-diï¬€erentiable functional f :
E â†’R, we must ï¬rst deï¬ne a suitable monotonicity concept for the mapping
f â€² : E â†’Eâˆ—. In view of the nondiï¬€erentiable case and the subdiï¬€erential
mapping, we at once consider multifunctions.
Deï¬nition 4.2.4 The multifunction Î¦ : E â‡’Eâˆ—is said to be
monotone
if âŸ¨yâˆ—âˆ’xâˆ—, y âˆ’xâŸ©â‰¥0,
strictly monotone
if âŸ¨yâˆ—âˆ’xâˆ—, y âˆ’xâŸ©> 0,
uniformly monotone if âŸ¨yâˆ—âˆ’xâˆ—, y âˆ’xâŸ©â‰¥c Â· âˆ¥y âˆ’xâˆ¥Î³;
the respective inequality is assumed to hold for all x, y âˆˆDom Î¦, x Ì¸= y,
xâˆ—âˆˆÎ¦(x) and yâˆ—âˆˆÎ¦(y). In the last inequality, c > 0 and Î³ > 1 are constants.
If Î¦ is uniformly monotone with Î³ = 2, then Î¦ is called strongly monotone.
According to Remark 4.2.2, a mapping T : E â†’Eâˆ—is monotone if and
only if
âŸ¨T(y) âˆ’T(x), y âˆ’xâŸ©â‰¥0
âˆ€x, y âˆˆE.
An analogous remark applies to strict and to uniform monotonicity.
4.3 Subdiï¬€erentials, FrÃ©chet Derivatives,
and Asplund Spaces
In this section we study the subdiï¬€erential mapping âˆ‚f : E â‡’Eâˆ—. This will
eventually lead to remarkable results on the F-diï¬€erentiability of continuous
convex functionals and, in this connection, to Asplund spaces.

4.3 Subdiï¬€erentials, FrÃ©chet Derivatives, and Asplund Spaces
65
Recall again that, unless otherwise speciï¬ed, E is a normed vector space
and the dual Eâˆ—is equipped with the norm topology.
Proposition 4.3.1 Let f : E â†’R be proper and convex. If f is continuous
at Â¯x âˆˆint domf, then the subdiï¬€erential mapping âˆ‚f is locally bounded at Â¯x.
Proof. Since f is locally L-continuous at Â¯x (Theorem 1.4.1), there exist Ïµ > 0
and Î» > 0 such that |f(x) âˆ’f(y)| â‰¤Î»âˆ¥x âˆ’yâˆ¥for all x, y âˆˆB(Â¯x, Ïµ). Thus
if x âˆˆB(Â¯x, Ïµ) and xâˆ—âˆˆâˆ‚f(x), then âŸ¨xâˆ—, y âˆ’xâŸ©â‰¤f(y) âˆ’f(x) â‰¤Î»âˆ¥x âˆ’yâˆ¥.
It follows that
âˆ¥xâˆ—âˆ¥â‰¤Î»
âˆ€xâˆ—âˆˆâˆ‚f(x)
âˆ€x âˆˆB(Â¯x, Ïµ),
(4.7)
which completes the proof.
âŠ“âŠ”
Proposition 4.3.2 Let f : E â†’R be proper and convex, and continuous on
the nonempty set int domf.
(a) The subdiï¬€erential mapping âˆ‚f : E â‡’Eâˆ—is norm-to-weak* upper semi-
continuous on int domf.
(b) If f is F-diï¬€erentiable at Â¯x âˆˆint domf, then âˆ‚f is norm-to-norm upper
semicontinuous at Â¯x.
Proof.
(a) Assume that x âˆˆint domf and V is a weak* open subset of Eâˆ—containing
âˆ‚f(x). It suï¬ƒces to show that for any sequence (xn) in int domf with
xn â†’x as n â†’âˆ, we have âˆ‚f(xn) âŠ†V for all suï¬ƒciently large n.
Suppose this would not hold. Then for some subsequence of (xn), again
denoted (xn), we could ï¬nd xâˆ—
n âˆˆâˆ‚f(xn) \ V . Since âˆ‚f is locally bounded
at x, there exists c > 0 such that âˆ‚f(xn) âŠ†BEâˆ—(o, c) for all suï¬ƒ-
ciently large n (compare (4.7)). Since BEâˆ—(o, c) is weak* compact (Alaoglu
theorem), the sequence (xâˆ—
n) admits a weak* cluster point xâˆ—. From
xâˆ—
n âˆˆâˆ‚f(xn) \ V we can easily conclude that xâˆ—âˆˆâˆ‚f(x) \ V which is
a contradiction to âˆ‚f(x) âŠ†V .
(b) Let V be an open neighborhood of f â€²(Â¯x) âˆˆEâˆ—. Assume that for any
neighborhood U of Â¯x, we would have âˆ‚f(U) \ V Ì¸= âˆ…. Then there exist
Ïµ > 0, a sequence (xn) in int domf, and xâˆ—
n âˆˆâˆ‚f(xn) such that xn â†’Â¯x
as n â†’âˆbut âˆ¥xâˆ—
n âˆ’f â€²(Â¯x)âˆ¥> 2Ïµ. The latter implies that there exists a
sequence (zn) in E satisfying âˆ¥znâˆ¥= 1 and âŸ¨xâˆ—
n âˆ’f â€²(Â¯x), znâŸ©> 2Ïµ for all n.
On the other hand, by F-diï¬€erentiability we have for some Î´ > 0,
f(Â¯x + y) âˆ’f(Â¯x) âˆ’âŸ¨f â€²(Â¯x), yâŸ©â‰¤Ïµâˆ¥yâˆ¥
whenever y âˆˆE and âˆ¥yâˆ¥< Î´. For these y we further obtain
âŸ¨xâˆ—
n, (Â¯x + y) âˆ’xnâŸ©â‰¤f(Â¯x + y) âˆ’f(xn)
and so
âŸ¨xâˆ—
n, yâŸ©â‰¤f(Â¯x + y) âˆ’f(Â¯x) + âŸ¨xâˆ—
n, xn âˆ’Â¯xâŸ©+ f(Â¯x) âˆ’f(xn).

66
4 The Subdiï¬€erential of Convex Functionals
Setting yn := Î´zn, the choice of zn implies âˆ¥ynâˆ¥= Î´ and so
2ÏµÎ´ < âŸ¨xâˆ—
n âˆ’f â€²(Â¯x), ynâŸ©
â‰¤

f(Â¯x + yn) âˆ’f(Â¯x) âˆ’âŸ¨f â€²(Â¯x), ynâŸ©

+ âŸ¨xâˆ—
n, xn âˆ’Â¯xâŸ©+ f(Â¯x) âˆ’f(xn)
â‰¤ÏµÎ´ + âŸ¨xâˆ—
n, xn âˆ’Â¯xâŸ©+ f(Â¯x) âˆ’f(xn).
(4.8)
Since f is locally bounded at Â¯x, the sequence (xâˆ—
n) is bounded and so
âŸ¨xâˆ—
n, xn âˆ’Â¯xâŸ©â†’0 as n â†’âˆ. Moreover, since f is continuous at Â¯x, we
also have f(Â¯x) âˆ’f(xn) â†’0 as n â†’âˆ. Hence the right-hand side of (4.8)
tends to ÏµÎ´ as n â†’âˆwhich contradicts the left-hand side.
âŠ“âŠ”
Proposition 4.3.3 Let f : E â†’R be proper and convex, and continuous
on the nonempty set int domf. Then f is F-diï¬€erentiable [G-diï¬€erentiable] at
Â¯x âˆˆint domf if and only if there exists a selection Ï• : E â†’Eâˆ—of âˆ‚f which is
norm-to-norm continuous [norm-to-weak* continuous] at Â¯x.
Proof. We verify the statement concerning F-diï¬€erentiability, leaving the case
in brackets as Exercise 4.8.2.
(I) Necessity. If f is F-diï¬€erentiable at Â¯x, then âˆ‚f(Â¯x) is a singleton, and by
Proposition 4.3.2 the subdiï¬€erential mapping âˆ‚f is upper semicontinuous
at Â¯x. Hence any selection of âˆ‚f is continuous at Â¯x.
(II) Suï¬ƒciency. Let Ï• be a selection of âˆ‚f that is continuous at Â¯x. Since
int domf âŠ†Dom âˆ‚f, we have Ï•(Â¯x) âˆˆâˆ‚f(Â¯x) and Ï•(y) âˆˆâˆ‚f(y) for each
y âˆˆint domf. For these y it follows that
âŸ¨Ï•(Â¯x), y âˆ’Â¯xâŸ©â‰¤f(y) âˆ’f(x)
and
âŸ¨Ï•(y), Â¯x âˆ’yâŸ©â‰¤f(Â¯x) âˆ’f(y).
Combining these inequalities, we obtain, again for all y âˆˆint domf,
0 â‰¤f(y)âˆ’f(Â¯x)âˆ’âŸ¨Ï•(Â¯x), yâˆ’Â¯xâŸ©â‰¤âŸ¨Ï•(y)âˆ’Ï•(Â¯x), yâˆ’Â¯xâŸ©â‰¤âˆ¥Ï•(y)âˆ’Ï•(Â¯x)âˆ¥Â·âˆ¥yâˆ’Â¯xâˆ¥.
Since Ï• is continuous at Â¯x, we have âˆ¥Ï•(y)âˆ’Ï•(Â¯x)âˆ¥â‰¤1 for all y in a neigh-
borhood of Â¯x. Hence the above inequality shows that f is F-diï¬€erentiable
at Â¯x, with derivative Ï•(Â¯x).
âŠ“âŠ”
Corollary 4.3.4 If f : E â†’R is proper and convex, and F-diï¬€erentiable
on the nonempty set int domf, then f is continuously F-diï¬€erentiable on
int domf.
Applying the statement in brackets in Proposition 4.3.3, we obtain an
analogous result concerning the norm-to-weak* continuity of the G-derivative.
In this connection, the functional f has to be assumed to be continuous on
the nonempty set int dom f. Below we shall establish a related result under
relaxed assumptions (see Proposition 4.3.8).

4.3 Subdiï¬€erentials, FrÃ©chet Derivatives, and Asplund Spaces
67
Proposition 4.3.5 (Convexity Criterion) Iff : E â†’RisG-diï¬€erentiable,
then the following statements are equivalent:
(a) f is [strictly] convex.
(b) f â€² is [strictly] monotone.
Proof. See Exercise 4.8.3.
âŠ“âŠ”
Example 4.3.6 Consider the functional
f(x) := 1
2a(x, x),
x âˆˆE,
where a : E Ã—E â†’R is bilinear, symmetric, and bounded. By Example 3.6.1,
f is continuously diï¬€erentiable and the derivative satisï¬es âŸ¨f â€²(x), yâŸ©= a(x, y)
for all x, y âˆˆE. Assume now that, in addition, a is strongly positive, i.e., there
exists a constant c > 0 such that a(x, x) â‰¥c âˆ¥xâˆ¥2 for any x âˆˆE. Then we
obtain
âŸ¨f â€²(y) âˆ’f â€²(x), y âˆ’xâŸ©= a(y âˆ’x, y âˆ’x) â‰¥câˆ¥y âˆ’xâˆ¥2
âˆ€x, y âˆˆE
and so f â€² is strongly monotone. In particular, f â€² is strictly monotone and so
f is strictly convex.
If f is convex but not G-diï¬€erentiable, we still have the following result.
Proposition 4.3.7 If f : E â†’R is proper and convex, then âˆ‚f is monotone.
Proof. See Exercise 4.8.4.
âŠ“âŠ”
Now we establish the continuity result on the derivative announced after
Corollary 4.3.4.
Proposition 4.3.8 If f : E â†’R is proper and convex, and G-diï¬€erentiable
on the nonempty set int domf, then f â€² is radially continuous on int domf.
Proof. For ï¬xed x, y âˆˆD, deï¬ne Ïˆx,y : [0, 1] â†’R by Ïˆx,y(Ï„) := f

x+Ï„(yâˆ’x)

for any Ï„ âˆˆ[0, 1]. Then we have
Ïˆâ€²
x,y(Ï„) =

f â€²
x + Ï„(y âˆ’x)

, y âˆ’x
 
and it remains to show that Ïˆâ€²
x,y is continuous on [0, 1].
(I) First we show that Ïˆâ€²
x,y is continuous at any Ï„ âˆˆ(0, 1). Since Ïˆx,y is
convex, Theorem 4.1.3 applies ensuring that for any Ï, Ïƒ satisfying Ï > Ïƒ
we have
Ïˆâ€²
x,y(Ï„ + Ïƒ) â‰¤
1
Ï âˆ’Ïƒ
&
Ïˆx,y

(Ï„ + Ïƒ) + (Ï âˆ’Ïƒ)

âˆ’Ïˆx,y(Ï„ + Ïƒ)

.

68
4 The Subdiï¬€erential of Convex Functionals
Since Ïˆx,y is continuous on (0, 1) (Corollary 1.4.2), we obtain letting Ïƒ â†“0
and then Ï â†“0,
lim
Ïƒâ†“0 Ïˆâ€²
x,y(Ï„+Ïƒ) â‰¤1
Ï
#
Ïˆx,y(Ï„+Ï)âˆ’Ïˆx,y(Ï„)
$
and
lim
Ïƒâ†“0 Ïˆâ€²
x,y(Ï„+Ïƒ) â‰¤Ïˆâ€²
x,y(Ï„).
On the other hand, since Ïˆâ€²
x,y is monotone (increasing), we have
limÏƒâ†“0 Ïˆâ€²
x,y(Ï„ + Ïƒ) â‰¥Ïˆâ€²
x,y(Ï„). Hence Ïˆâ€²
x,y is right continuous at Ï„.
Analogously it is shown that Ïˆâ€²
x,y is left continuous at Ï„.
(II) To see that Ïˆâ€²
x,y is continuous on the closed interval [0, 1], notice that
since D is open, x and y may be replaced in the above argument by
x âˆ’Î´(y âˆ’x) and y + Î´(y âˆ’x), respectively, where Î´ > 0 is suï¬ƒciently
small.
âŠ“âŠ”
Proposition 4.3.9 If f : E â†’R is G-diï¬€erentiable and f â€² is uniformly
monotone with constants c > 0 and Î³ > 1, then f is strictly convex and
f(y) âˆ’f(x) â‰¥âŸ¨f â€²(x), y âˆ’xâŸ©+ c
Î³ âˆ¥y âˆ’xâˆ¥Î³
âˆ€x, y âˆˆE.
(4.9)
Proof. By assumption, f â€² is strictly monotone and so f is strictly convex.
Furthermore, by Proposition 4.3.8 the mean value formula (3.7) applies to f.
Hence for any x, y âˆˆE we have
f(y) âˆ’f(x) = âŸ¨f â€²(x), y âˆ’xâŸ©+
 1
0

f â€²
x + Ï„(y âˆ’x)

âˆ’f â€²(x), Ï„(y âˆ’x)
 dÏ„
Ï„
â‰¥âŸ¨f â€²(x), y âˆ’xâŸ©+
 1
0
cÏ„ Î³ âˆ¥y âˆ’xâˆ¥Î³ dÏ„
Ï„ ,
and (4.9) follows.
âŠ“âŠ”
Remark 4.3.10 The above result will later be used to ensure that f has a
(unique) global minimum point Â¯x. This point satisï¬es f â€²(Â¯x) = o. Hence if (xn)
is a sequence of approximate solutions of f â€²(Â¯x) = o, then we obtain from (4.9)
the error estimate
c
Î³ âˆ¥xn âˆ’Â¯xâˆ¥Î³ â‰¤f(xn) âˆ’f(Â¯x).
The next result says that F-diï¬€erentiability of a continuous convex func-
tional can be characterized without referring to a potential derivative. It will
serve us to characterize the set of points where a continuous convex functional
is F-diï¬€erentiable.
Lemma 4.3.11 Let f : E â†’R be proper, convex, and continuous on the
nonempty set int dom f. Then f is F-diï¬€erentiable at Â¯x âˆˆint dom f if and
only if for each Ïµ > 0 there exists Î´ > 0 such that
f(Â¯x + Ï„y) + f(Â¯x âˆ’Ï„y) âˆ’2f(Â¯x) < Ï„Ïµ
(4.10)
whenever y âˆˆE, âˆ¥yâˆ¥= 1 and 0 < Ï„ < Î´.

4.3 Subdiï¬€erentials, FrÃ©chet Derivatives, and Asplund Spaces
69
Proof.
(I) Necessity. See Exercise 4.8.5.
(II) Suï¬ƒciency. Assume that the above condition is satisï¬ed and choose some
xâˆ—âˆˆâˆ‚f(Â¯x) (which exists by Proposition 4.1.6). Let y âˆˆE satisfying
âˆ¥yâˆ¥= 1 be given. For all Ï„ > 0 suï¬ƒciently small such that Â¯x Â± Ï„y âˆˆD
we have
âŸ¨xâˆ—, Ï„yâŸ©= âŸ¨xâˆ—, (Â¯x + Ï„y) âˆ’Â¯xâŸ©â‰¤f(Â¯x + Ï„y) âˆ’f(Â¯x),
(4.11)
âˆ’âŸ¨xâˆ—, Ï„yâŸ©= âŸ¨xâˆ—, (Â¯x âˆ’Ï„y) âˆ’Â¯xâŸ©â‰¤f(Â¯x âˆ’Ï„y) âˆ’f(Â¯x).
(4.12)
Now let Ïµ > 0 be given and choose Î´ > 0 such that (4.10)â€“(4.12) hold
whenever âˆ¥yâˆ¥= 1 and 0 < Ï„ < Î´. Adding the inequalities (4.11) and
(4.12), we obtain for these y and Ï„,
0 â‰¤f(Â¯x + Ï„y) âˆ’f(Â¯x) âˆ’âŸ¨xâˆ—, Ï„yâŸ©â‰¤Ï„Ïµ.
Hence f is F-diï¬€erentiable at Â¯x.
âŠ“âŠ”
Recall that a subset of E is said to be a GÎ´ set if it is the intersection of
a countable number of open sets.
Proposition 4.3.12 Let f : E â†’R be proper, convex, and continuous on
the nonempty set D := int dom f. Then the set âˆ†of all x âˆˆD, where f is
F-diï¬€erentiable, is a (possibly empty) GÎ´ set.
Proof. For each n âˆˆN let Gn denote the set of all x âˆˆD for which there
exists Î´ > 0 such that
sup
âˆ¥yâˆ¥=1
f(x + Î´y) + f(x âˆ’Î´y) âˆ’2f(x)
Î´
< 1
n .
By Theorem 4.1.3, for ï¬xed x and y the functions
Ï„ â†’f(x + Ï„(Â±y)) âˆ’f(x)
Ï„
are decreasing as Ï„ â†“0. Thus Lemma 4.3.11 shows that âˆ†= âˆ©âˆ
n=1Gn.
It remains to verify that each Gn is open. Let x âˆˆGn be given. Since f
is locally L-continuous (Theorem 1.4.1), there exist Î´1 > 0 and Î» > 0 such
that |f(u) âˆ’f(v)| â‰¤Î»âˆ¥u âˆ’vâˆ¥for all u, v âˆˆB(x, Î´1), where B(x, Î´1) âŠ†D.
Moreover, since x âˆˆGn, there are Î´ > 0 and r > 0 such that for all y âˆˆE
satisfying âˆ¥yâˆ¥= 1 we have x Â± Î´y âˆˆD and
f(x + Î´y) + f(x âˆ’Î´y) âˆ’2f(x)
Î´
â‰¤r < 1
n .
Now take Î´2 âˆˆ(0, Î´1) so small that B(x, Î´2) âŠ†D and r + 4Î»Î´2/Î´ < 1/n. We
are going to show that B(x, Î´2) âŠ†Gn. Thus let z âˆˆB(x, Î´2). Then for any
y âˆˆE satisfying âˆ¥yâˆ¥= 1 it follows that

70
4 The Subdiï¬€erential of Convex Functionals
f(z + Î´y) + f(z âˆ’Î´y) âˆ’2f(z)
Î´
â‰¤f(x + Î´y) + f(x âˆ’Î´y) âˆ’2f(x)
Î´
+ 2|f(z) âˆ’f(x)|
Î´
+ |f(z + Î´y) âˆ’f(x + Î´y)|
Î´
+ |f(z âˆ’Î´y) âˆ’f(x âˆ’Î´y)|
Î´
â‰¤r + 4Î»âˆ¥z âˆ’xâˆ¥
Î´
â‰¤r + 4Î»Î´2
Î´
< 1
n
and so z âˆˆGn.
âŠ“âŠ”
Deï¬nition 4.3.13 A Banach space E is said to be an Asplund space if every
continuous convex functional deï¬ned on a nonempty open convex subset D of
E is F-diï¬€erentiable on a dense subset of D.
Usually a Banach space E is said to be an Asplund space if every contin-
uous convex functional is generically F-diï¬€erentiable, i.e., F-diï¬€erentiable on
a dense GÎ´ subset of D. Proposition 4.3.12 shows that this is equivalent to
the above deï¬nition.
Recall that the (inï¬nite dimensional) normed vector space E is said to be
separable if some countable subset is dense in E. Our aim is to verify that a
Banach space with a separable dual is an Asplund space. For this, we need a
geometric concept.
Deï¬nition 4.3.14
(a) Let xâˆ—âˆˆEâˆ—, xâˆ—Ì¸= o, and 0 < Î± < 1. The set
K(xâˆ—, Î±) := {x âˆˆE | Î±âˆ¥xâˆ¥âˆ¥xâˆ—âˆ¥â‰¤âŸ¨xâˆ—, xâŸ©},
which is a closed convex cone, is called Bishopâ€“Phelps cone associated
with xâˆ—and Î±.
(b) The set A âŠ†E is said to be Î±-cone meager, where 0 < Î± < 1, if for every
x âˆˆA and Ïµ > 0 there exist z âˆˆB(x, Ïµ) and xâˆ—âˆˆEâˆ—, xâˆ—Ì¸= o, such that
A âˆ©

z + int K(xâˆ—, Î±)

= âˆ….
(c) The set A âŠ†E is said to be angle-small if for every Î± âˆˆ(0, 1), A can be
expressed as the union of a countable number of Î±-cone meager sets.
Example 4.3.15 Consider Rn with inner product (xâˆ—| x) and identify (Rn)âˆ—
with Rn. Let xâˆ—âˆˆRn, xâˆ—Ì¸= o, and Î± âˆˆ(0, 1) be given. For any x Ì¸= o we have
x âˆˆK(xâˆ—, Î±)
â‡â‡’
Î± â‰¤

xâˆ—
âˆ¥xâˆ—âˆ¥

x
âˆ¥xâˆ¥

,
i.e., the projection of the unit vector x/âˆ¥xâˆ¥in the direction of xâˆ—is at least Î±.
The â€œice cream coneâ€ in R3 is thus a typical example of a Bishopâ€“Phelps cone.

4.3 Subdiï¬€erentials, FrÃ©chet Derivatives, and Asplund Spaces
71
   c
x
z
B(x, Ïµ)
c + K(xâˆ—, Î±)
z + K(xâˆ—, Î±)
Fig. 4.2
Example 4.3.16 Let A âŠ†R2 consist of a circle and its center c. Then A is
not Î±-cone meager for any Î± âˆˆ(0, 1) but it is the union of two Î±-cone meager
sets and so is angle-small (Fig. 4.2).
Recall that a set A âŠ†E is said to be nowhere dense if cl A has empty
interior or, equivalently, if E \ cl A is dense in E. Further, A is said to be of
ï¬rst category (or to be meager) if A is the union of a countable number of
nowhere dense sets.
Lemma 4.3.17 If A âŠ†E is Î±-cone meager for some Î± âˆˆ(0, 1), then A is
nowhere dense. Hence any angle-small subset of E is of ï¬rst category.
Proof. See Exercise 4.8.6.
âŠ“âŠ”
The converse of Lemma 4.3.17 does not hold. In fact, an Î±-cone meager
subset of R contains at most two elements. Hence a subset of R is angle-small
if and only if it is countable. On the other hand, the Cantor set is an example
of an uncountable set of ï¬rst category.
Now we can establish a remarkable result on monotone multifunctions.
Theorem 4.3.18 Let E be a Banach space with a separable dual. If Î¦ : E â‡’
Eâˆ—is a monotone multifunction, then there exists an angle-small set A âŠ†
Dom Î¦ such that Î¦ is single-valued and upper semicontinuous on (Dom Î¦)\A.
Proof. Set
A := {x âˆˆDom Î¦ | lim
Î´â†“0 diam Î¦

B(x, Î´)

> 0}.
(I) It is left as an exercise to show that if x âˆˆ(Dom Î¦) \ A, then Î¦(x) is a
singleton and Î¦ is upper semicontinuous at x.
(II) It remains to show that A is angle-small. We have A = âˆªâˆ
n=1An, where
An := {x âˆˆDom Î¦ | lim
Î´â†“0 diam Î¦

B(x, Î´)

> 1/n}.

72
4 The Subdiï¬€erential of Convex Functionals
Let (xâˆ—
k) be a dense sequence in Eâˆ—, let Î± âˆˆ(0, 1) and set
An,k := {x âˆˆAn | d(xâˆ—
k, Î¦(x)) < Î±/(4n)}.
Then obviously An = âˆªâˆ
k=1An,k for all n. Hence it suï¬ƒces to show that each
An,k is Î±-cone meager. Let x âˆˆAn,k and Ïµ > 0 be given. Since x âˆˆAn, there
exist Î´ âˆˆ(0, Ïµ) as well as elements zi âˆˆB(x, Î´) and zâˆ—
i âˆˆÎ¦(zi) for i = 1, 2
such that âˆ¥zâˆ—
1 âˆ’zâˆ—
2âˆ¥> 1/n. Hence if xâˆ—âˆˆÎ¦(x), then âˆ¥zâˆ—
1 âˆ’xâˆ—âˆ¥> 1/(2n) or
âˆ¥zâˆ—
2 âˆ’xâˆ—âˆ¥> 1/(2n). Choose xâˆ—âˆˆÎ¦(x) such that âˆ¥xâˆ—
k âˆ’xâˆ—âˆ¥< Î±/(4n) (which
is possible since x âˆˆAn,k). According to what we said about zi, zâˆ—
i , where
i = 1, 2, we can ï¬nd points z âˆˆB(x, Ïµ) and zâˆ—âˆˆÎ¦(z) satisfying
âˆ¥zâˆ—âˆ’xâˆ—
kâˆ¥â‰¥âˆ¥zâˆ—âˆ’xâˆ—âˆ¥âˆ’âˆ¥xâˆ—
k âˆ’xâˆ—âˆ¥> 1/(2n) âˆ’Î±/(4n) > 1/(4n).
We are going to show that An,k âˆ©(z + int K(zâˆ—âˆ’xâˆ—
k), Î±) = âˆ…, i.e.,
An,k âˆ©{y âˆˆE | âŸ¨zâˆ—âˆ’xâˆ—
k, y âˆ’zâŸ©> Î±âˆ¥zâˆ—âˆ’xâˆ—
kâˆ¥Â· âˆ¥y âˆ’zâˆ¥} = âˆ….
Suppose y âˆˆDom Î¦ is such that âŸ¨zâˆ—âˆ’xâˆ—
k, y âˆ’zâŸ©> Î±âˆ¥zâˆ—âˆ’xâˆ—
kâˆ¥Â· âˆ¥y âˆ’zâˆ¥and
let yâˆ—âˆˆÎ¦(y). Then
âŸ¨yâˆ—âˆ’xâˆ—
k, y âˆ’zâŸ©= âŸ¨yâˆ—âˆ’zâˆ—, y âˆ’zâŸ©+ âŸ¨zâˆ—âˆ’xâˆ—
k, y âˆ’zâŸ©
â‰¥âŸ¨zâˆ—âˆ’xâˆ—
k, y âˆ’zâŸ©> Î±âˆ¥zâˆ—âˆ’xâˆ—
kâˆ¥Â· âˆ¥y âˆ’zâˆ¥â‰¥Î±âˆ¥y âˆ’zâˆ¥/(4n).
It follows that âˆ¥yâˆ—âˆ’xâˆ—
kâˆ¥â‰¥Î±/(4n) and so y /âˆˆAn,k.
âŠ“âŠ”
With the aid of Theorem 4.3.18 we can now easily establish a suï¬ƒcient
condition for a Banach space to be an Asplund space.
Theorem 4.3.19 If the dual of the Banach space E is separable, then E is
an Asplund space.
Proof. Let f
: E â†’R be proper and convex, and continuous on the
nonempty set D:=int dom f. Then âˆ‚f is monotone (Proposition 4.3.7). By
Theorem 4.3.18, there exists an angle-small set A such that âˆ‚f is single-valued
and upper semicontinuous on D \ A and so any selection of âˆ‚f is continuous
on D \ A. By Proposition 4.3.3, f is F-diï¬€erentiable on D \ A. Since A is of
ï¬rst category (Lemma 4.3.17), the set D \ A is dense in D (and a GÎ´ set).
âŠ“âŠ”
Remark 4.3.20
(a) Notice that we actually showed somewhat more than stated, namely that
any proper convex continuous functional f is F-diï¬€erentiable outside an
angle-small subset of int dom f.
(b) According to Theorem 4.3.19, the following spaces are Asplund spaces:
the sequence spaces c0 and lp as well as the function spaces Lp[a, b], where
1 < p < âˆ, furthermore any separable reï¬‚exive Banach space. It can
be shown that any reï¬‚exive Banach space is an Asplund space (see Deville
et al. [50] or Phelps [165]). Notice that c0 is an example of a nonreï¬‚exive
Asplund space while l1 and lâˆare Banach spaces that are not Asplund
spaces.

4.4 Subdiï¬€erentials and Conjugate Functionals
73
Recall that for any normed vector space the closed unit ball of the dual
space is weakâˆ—compact (Alaoglu theorem). It turns out that Asplund spaces
have an important additional property.
Theorem 4.3.21 If E is an Asplund space, then BEâˆ—is weakâˆ—sequentially
compact.
Concerning the proof we refer to Stegall [200] and Yost [219]. For a larger
class of Banach spaces having the above property see Diestel [52].
4.4 Subdiï¬€erentials and Conjugate Functionals
Convention. The dual pair underlying the conjugation will be

E[âˆ¥Â· âˆ¥], Eâˆ—[Ïƒ(Eâˆ—, E)]

unless we have to refer to the norm on Eâˆ—in which case we explicitly assume
that E is a reï¬‚exive Banach space (cf. Remark 1.6.4).
Recall that the deï¬nition of subdiï¬€erential and conjugate functional of
f : E â†’R is given by
âˆ‚f(x) := {xâˆ—âˆˆEâˆ—| âŸ¨xâˆ—, y âˆ’xâŸ©â‰¤f(y) âˆ’f(x) âˆ€y âˆˆE},
x âˆˆdom f,
f âˆ—(xâˆ—) := supxâˆˆE

âŸ¨xâˆ—, xâŸ©âˆ’f(x)

,
xâˆ—âˆˆEâˆ—.
Proposition 4.4.1 Let f : E â†’R be proper and convex, let x âˆˆdom fand
xâˆ—âˆˆEâˆ—. Then there holds
âŸ¨xâˆ—, xâŸ©â‰¤f(x) + f âˆ—(xâˆ—)
(Young inequality),
(4.13)
âŸ¨xâˆ—, xâŸ©= f(x) + f âˆ—(xâˆ—)
â‡â‡’
xâˆ—âˆˆâˆ‚f(x).
(4.14)
Proof. See Exercise 4.8.7.
âŠ“âŠ”
Remark 4.4.2 If f and x are as in Proposition 4.4.1, we have
f(x) = min
yâˆˆE f(y)
â‡â‡’
o âˆˆâˆ‚f(x)
â‡â‡’
(4.14)
f(x) = âˆ’f âˆ—(o),
i.e., the global minimum of f is âˆ’f âˆ—(o).
If the functional f is G-diï¬€erentiable on E, then we know that âˆ‚f(Â·) =
{f â€²(Â·)}. In this case, there is a close relationship between the GÃ¢teaux deriv-
ative and the conjugate functional.

74
4 The Subdiï¬€erential of Convex Functionals
Proposition 4.4.3 Let E be a reï¬‚exive Banach space, further let f : E â†’R
be G-diï¬€erentiable with f â€² : E â†’Eâˆ—uniformly monotone. Then (f â€²)âˆ’1 exists
on Eâˆ—and is continuous as well as strictly monotone. Moreover, the following
holds:

f âˆ—â€² =

f â€²âˆ’1,
(4.15)
f(x) = f(o) +
 1
0

f â€²(Ï„x), x
 
dÏ„
âˆ€x âˆˆE,
(4.16)
f âˆ—(xâˆ—) = f âˆ—(o) +
 1
0

xâˆ—, (f â€²)âˆ’1(Ï„xâˆ—)
 
dÏ„
âˆ€xâˆ—âˆˆEâˆ—,
(4.17)
f âˆ—(o) = âˆ’f

(f â€²)âˆ’1(o)

.
(4.18)
Proof.
(I) We postpone the veriï¬cation of the existence of (f â€²)âˆ’1 : Eâˆ—â†’E to
Sect. 5.4 (see Theorem 5.4.7 and Remark 5.4.8).
(II) Since f â€² is uniformly monotone, there exist constants c > 0 and Î³ > 1
such that
c âˆ¥y âˆ’xâˆ¥Î³ â‰¤âŸ¨f â€²(y) âˆ’f â€²(x), y âˆ’xâŸ©â‰¤âˆ¥f â€²(y) âˆ’f â€²(x)âˆ¥âˆ¥y âˆ’xâˆ¥
âˆ€x, y âˆˆE.
Setting xâˆ—= f â€²(x) and yâˆ—= f â€²(y), we have
c âˆ¥(f â€²)âˆ’1(yâˆ—) âˆ’(f â€²)âˆ’1(xâˆ—)âˆ¥Î³âˆ’1 â‰¤âˆ¥yâˆ—âˆ’xâˆ—âˆ¥
âˆ€xâˆ—, yâˆ—âˆˆEâˆ—,

yâˆ—âˆ’xâˆ—, (f â€²)âˆ’1(yâˆ—) âˆ’(f â€²)âˆ’1(xâˆ—)
 
=

f â€²(y) âˆ’f â€²(x), y âˆ’x
 
> 0 âˆ€x Ì¸= y.
These two relations show that (f â€²)âˆ’1 is continuous and strictly monotone.
(III) Now we verify (4.15)â€“(4.18). First notice that the integrals exist in the
Riemann sense since f â€² is radially continuous by Proposition 4.3.8 and
f â€²âˆ’1 is continuous by step (II).
Ad (4.15). Let x, y âˆˆE, xâˆ—:= f â€²(x), yâˆ—:= f â€²(y). Since f is G-
diï¬€erentiable, we have âˆ‚f(x) = {xâˆ—} and so Proposition 4.4.1 yields
f âˆ—(xâˆ—) + f(x) = âŸ¨xâˆ—, xâŸ©.
(4.19)
This and an analogous formula with y and yâˆ—leads to
f âˆ—(yâˆ—) âˆ’f âˆ—(xâˆ—) = f(x) âˆ’f(y) âˆ’

f â€²(y), x âˆ’y
 
+

f â€²(y) âˆ’f â€²(x), x
 
(4.20)
â‰¥0 +

f â€²(y) âˆ’f â€²(x), x
 
=

yâˆ—âˆ’xâˆ—, (f â€²)âˆ’1(xâˆ—)
 
; (4.21)
here, the inequality sign follows from Theorem 4.1.3(a). Interchanging
xâˆ—and yâˆ—, we eventually obtain

yâˆ—âˆ’xâˆ—, (f â€²)âˆ’1(xâˆ—)
 
â‰¤f âˆ—(yâˆ—) âˆ’f âˆ—(xâˆ—) â‰¤

yâˆ—âˆ’xâˆ—, (f â€²)âˆ’1(yâˆ—)
 
.

4.4 Subdiï¬€erentials and Conjugate Functionals
75
This yields for each zâˆ—âˆˆEâˆ—,

(f âˆ—)â€²(xâˆ—), zâˆ— 
= lim
Ï„â†’0
1
Ï„

f âˆ—(xâˆ—+ Ï„zâˆ—) âˆ’f âˆ—(xâˆ—)

=

zâˆ—, (f â€²)âˆ’1(xâˆ—)
 
E =

(f â€²)âˆ’1(xâˆ—), zâˆ— 
Eâˆ—;
here, we exploited the continuity of the function Ï„ â†’

(f â€²)âˆ’1(xâˆ—+
Ï„zâˆ—), zâˆ— 
at Ï„ = 0.
Ad (4.18). By (4.19), we have
f âˆ—
f â€²(x)

+ f(x) =

f â€²(x), x
 
âˆ€x âˆˆE
which, with x := (f â€²)âˆ’1(o), implies (4.18).
Ad (4.16). This is the mean value formula established in Proposition 3.3.3.
Ad (4.17). The monotonicity of (f â€²)âˆ’1 and (4.15) entail that (f âˆ—)â€² is
monotone. Therefore (4.17) holds in analogy to (4.16).
âŠ“âŠ”
The formulas (4.17) and (4.18) will turn out to be crucial for calculating
the conjugate in connection with boundary value problems.
Equation (4.15) means that for all x âˆˆE(= Eâˆ—âˆ—) and all xâˆ—âˆˆEâˆ—we have
xâˆ—= f â€²(x)
â‡â‡’
x = (f â€²)âˆ’1(xâˆ—)
â‡â‡’
x = (f âˆ—)â€²(xâˆ—).
(4.22)
The simpler one of these equivalences, namely xâˆ—= f â€²(x) â‡â‡’x = (f âˆ—)â€²(xâˆ—),
will now be generalized to nondiï¬€erentiable convex functionals.
Proposition 4.4.4 Let f : E â†’R be proper and convex.
(i) There always holds
x âˆˆdom f, xâˆ—âˆˆâˆ‚f(x)
=â‡’
xâˆ—âˆˆdom f âˆ—, x âˆˆâˆ‚f âˆ—(xâˆ—).
(ii) If, in addition, E is reï¬‚exive and f is l.s.c., then
x âˆˆdom f, xâˆ—âˆˆâˆ‚f(x)
â‡â‡’
xâˆ—âˆˆdom f âˆ—, x âˆˆâˆ‚f âˆ—(xâˆ—).
Proof.
(i) If x âˆˆdom f and xâˆ—âˆˆâˆ‚f(x), then Proposition 4.4.1 gives f âˆ—(xâˆ—) =
âŸ¨xâˆ—, xâŸ©âˆ’f(x). Hence xâˆ—âˆˆdom f âˆ—. For each yâˆ—âˆˆEâˆ—, we obtain using
(4.13),
âŸ¨yâˆ—âˆ’xâˆ—, xâŸ©â‰¤

f(x) + f âˆ—(yâˆ—)

âˆ’

f(x) + f âˆ—(xâˆ—)

= f âˆ—(yâˆ—) âˆ’f âˆ—(xâˆ—)
and so x âˆˆâˆ‚f âˆ—(xâˆ—).
(ii) â‡=: By Proposition 2.2.3 and since xâˆ—âˆˆdom f âˆ—, we may apply (4.14)
with f âˆ—instead of f which gives âŸ¨xâˆ—, xâŸ©= f âˆ—(xâˆ—) + f âˆ—âˆ—(x) and so x âˆˆ
dom f âˆ—âˆ—. By Theorem 2.2.4 we have f âˆ—âˆ—= f. Hence applying (4.14) again,
we obtain xâˆ—âˆˆâˆ‚f(x).
âŠ“âŠ”

76
4 The Subdiï¬€erential of Convex Functionals
4.5 Further Calculus Rules
In this section, we establish computation rules for the subdiï¬€erential. The
following sum rule will be crucial for deriving optimality conditions (cf.
Remark 4.1.2).
Proposition 4.5.1 (Sum Rule) Let f0, f1, . . . , fn : E â†’R be proper and
convex. Assume there exists Â¯x âˆˆ(dom f0) âˆ©(int dom f1) âˆ©Â· Â· Â· âˆ©(int dom fn)
such that fi is continuous at Â¯x for i = 1, . . . , n. Then for each x âˆˆ(dom f0) âˆ©
(dom f1) âˆ©Â· Â· Â· âˆ©(dom fn), there holds
âˆ‚(f0 + f1 + Â· Â· Â· + fn)(x) = âˆ‚f0(x) + âˆ‚f1(x) + Â· Â· Â· + âˆ‚fn(x).
Proof. It is easy to see that (even without the continuity assumption) the
inclusion âŠ‡holds. We now verify the inclusion âŠ†for n = 1; for an arbitrary
n âˆˆN the assertion then follows by induction.
Let xâˆ—âˆˆâˆ‚(f0 + f1)(x) be given. Set p := f0 and deï¬ne q : E â†’R by
q(y) :=

âŸ¨xâˆ—, x âˆ’yâŸ©+ f1(y) âˆ’f1(x) âˆ’f0(x)
if y âˆˆdom f1,
+âˆ
otherwise.
Then all assumptions of the sandwich theorem (Theorem 1.5.2) are fulï¬lled
and this theorem guarantees the existence of yâˆ—
0 âˆˆEâˆ—and c âˆˆR such that
âˆ’q(y) â‰¤âŸ¨yâˆ—
0, yâŸ©+ c â‰¤p(y)
âˆ€y âˆˆE.
Since âˆ’q(x) = p(x), we have c = p(x) âˆ’âŸ¨yâˆ—
0, xâŸ©and so yâˆ—
0 âˆˆâˆ‚f0(x). For
yâˆ—
1 := xâˆ—âˆ’yâˆ—
0 we analogously obtain yâˆ—
1 âˆˆâˆ‚f1(x). Therefore xâˆ—= yâˆ—
0 + yâˆ—
1 âˆˆ
âˆ‚f0(x) + âˆ‚f1(x).
âŠ“âŠ”
Finally we characterize the subdiï¬€erential of a functional of the form
f(x) := max
sâˆˆS fs(x),
x âˆˆE.
(4.23)
We denote the directional G-derivative of fs at Â¯x by fs,G(Â¯x, Â·). We set
S(Â¯x) := {s âˆˆS | fs(Â¯x) = f(Â¯x)}.
Notice that if each fs is convex, then so is f. Recall that co âˆ—M denotes the
Ïƒ(Eâˆ—, E)-closed convex hull of M âŠ†Eâˆ—.
Proposition 4.5.2 (Maximum Rule) Let S be a compact Hausdorï¬€space.
For any s âˆˆS, let fs : E â†’R be convex on E and continuous at Â¯x âˆˆE.
Assume further that there exists a neighborhood U of Â¯x such that for every
z âˆˆU, the functional s â†’fs(z) is upper semicontinuous on S. Then the
functional f : E â†’R deï¬ned by (4.23) satisï¬es
fG(Â¯x, y) = sup
sâˆˆS(Â¯x)
fs,G(Â¯x, y)
âˆ€y âˆˆE,
(4.24)
âˆ‚f(Â¯x) = co âˆ— 
sâˆˆS(Â¯x)
âˆ‚fs(Â¯x)

.
(4.25)

4.5 Further Calculus Rules
77
Proof.
(I) We verify (4.24). Thus let y âˆˆE be given.
(Ia) If s âˆˆS(Â¯x), then
1
Ï„

fs(Â¯x + Ï„y) âˆ’fs(Â¯x)

â‰¤1
Ï„

f(Â¯x + Ï„y) âˆ’f(Â¯x)

and so fs,G(Â¯x, y) â‰¤fG(Â¯x, y) for each s âˆˆS(Â¯x).
(Ib) In view of step (Ia), (4.24) is veriï¬ed as soon as we showed that for each
Ïµ > 0 there exists s âˆˆS(Â¯x) such that
fG(Â¯x, y) âˆ’Ïµ â‰¤fs,G(Â¯x, y).
(4.26)
Since f is convex, we have fG(Â¯x, y) = infÏ„>0 1
Ï„

f(Â¯x + Ï„y) âˆ’f(Â¯x)

and so
fG(Â¯x, y) âˆ’Ïµ < 1
Ï„

f(Â¯x + Ï„y) âˆ’f(Â¯x)

âˆ€Ï„ > 0.
Now let Ï„ > 0 be ï¬xed. Then ÏµÏ„ := 1
Ï„

f(Â¯x + Ï„y) âˆ’f(Â¯x)

âˆ’fG(Â¯x, y) + Ïµ is
positive. By the deï¬nition of f, there exists s âˆˆS such that
1
Ï„ f(Â¯x + Ï„y) âˆ’ÏµÏ„ â‰¤1
Ï„ fs(Â¯x + Ï„y).
Therefore
fG(Â¯x, y) âˆ’Ïµ â‰¤1
Ï„

fs(Â¯x + Ï„y) âˆ’f(x)

.
(4.27)
In other words, the set SÏ„ of all s âˆˆS satisfying (4.27) is nonempty.
(Ic) Let Ï„0 > 0 be such that Â¯x + Ï„y âˆˆU for each Ï„ âˆˆ(0, Ï„0). Since s â†’
fs(Â¯x+Ï„y) is upper semicontinuous, the set SÏ„ is closed for each Ï„ âˆˆ(0, Ï„0).
(Id) We show that 0 < Ïƒ < Ï„ implies SÏƒ âŠ†SÏ„. Thus let s âˆˆSÏƒ be given.
Then
fG(Â¯x, y) âˆ’Ïµ â‰¤1
Ïƒ

fs(Â¯x + Ïƒy) âˆ’f(Â¯x)

.
Since Â¯x + Ïƒy =

1 âˆ’Ïƒ
Ï„

+ Ïƒ
Ï„

Â¯x + Ï„y

and fs is convex, we obtain
fG(Â¯x, y) âˆ’Ïµ â‰¤1
Ïƒ
&
1 âˆ’Ïƒ
Ï„

fs(Â¯x) + Ïƒ
Ï„ fs(Â¯x + Ï„y) âˆ’f(Â¯x)

â‰¤1
Ï„
&
fs(Â¯x + Ï„y) âˆ’f(Â¯x)

;
here, the second inequality follows from fs(Â¯x) â‰¤f(Â¯x). Therefore, s âˆˆSÏ„.
(Ie) In view of the above, the Cantor intersection theorem shows that the
intersection of all SÏ„, where Ï„ âˆˆ(0, Ï„0), is nonempty. If s is any element
of this intersection, then
Ï„

fG(Â¯x, y) âˆ’Ïµ

â‰¤fs(Â¯x + Ï„y) âˆ’f(Â¯x)
âˆ€Ï„ âˆˆ(0, Ï„0).
(4.28)
Recalling that fs is continuous at Â¯x and letting Ï„ â†“0, we deduce 0 â‰¤
fs(Â¯x) âˆ’f(Â¯x) and so s âˆˆS(Â¯x). Hence (4.28) holds with f(Â¯x) replaced by
fs(Â¯x) and from this we obtain (4.26) on dividing by Ï„ and letting Ï„ â†“0.

78
4 The Subdiï¬€erential of Convex Functionals
(II) We verify (4.25).
(IIa) It is easy to see that âˆ‚fs(Â¯x) âŠ†âˆ‚f(Â¯x) for each s âˆˆS(Â¯x). Since âˆ‚f(Â¯x) is
convex and Ïƒ(Eâˆ—, E)-closed, we conclude that
Q := co âˆ— 
sâˆˆS(Â¯x)
âˆ‚fs(Â¯x)

âŠ†âˆ‚f(Â¯x).
(IIb) Suppose there exists xâˆ—âˆˆâˆ‚f(Â¯x) \ Q. By the strong separation theorem
(Theorem 1.5.9) applied to Eâˆ—&
Ïƒ(Eâˆ—, E)

there exists z âˆˆE such that
âŸ¨xâˆ—, zâŸ©> sup
yâˆ—âˆˆQ
âŸ¨yâˆ—, zâŸ©.
(4.29)
We further have
fG(Â¯x, z) =
max
zâˆ—âˆˆâˆ‚f(Â¯x)âŸ¨zâˆ—, zâŸ©â‰¥âŸ¨xâˆ—, zâŸ©,
sup
yâˆ—âˆˆQ
âŸ¨yâˆ—, zâŸ©â‰¥sup
sâˆˆS(Â¯x)
sup
zâˆ—âˆˆâˆ‚fs(Â¯x)
âŸ¨zâˆ—, zâŸ©= sup
sâˆˆS(Â¯x)
fs,G(Â¯x, z).
In view of (4.29) we conclude that fG(Â¯x, z) > supsâˆˆS(Â¯x) fs,G(Â¯x, z) which
contradicts (4.24). Therefore âˆ‚f(Â¯x) = Q.
âŠ“âŠ”
Remark 4.5.3 If,inparticular,thesetS isï¬nite,thenitisacompactHausdorï¬€
space with respect to the discrete topology. For this topology, the function
s â†’fs(z) is continuous on S for any fs and every z âˆˆE.
4.6 The Subdiï¬€erential of the Norm
With z âˆˆE ï¬xed we consider the functional Ï‰z : E â†’R deï¬ned by
Ï‰z(x) := âˆ¥x âˆ’zâˆ¥
âˆ€x âˆˆE.
(4.30)
We simply write Ï‰ for Ï‰o, i.e., we set
Ï‰(x) := âˆ¥xâˆ¥
âˆ€x âˆˆE.
The results to be derived will reveal interesting properties of the norm func-
tional. In addition, they will later be applied to the problem of best approxi-
mation. Given A âŠ†E and z âˆˆE \ A, ï¬nd Â¯x âˆˆA satisfying
Ï‰z(Â¯x) = inf
xâˆˆA Ï‰z(x).
For this purpose, we now deduce suitable representations of the subdiï¬€er-
ential âˆ‚Ï‰z(Â¯x) and the directional H-derivative Ï‰z,H(Â¯x, Â·) of Ï‰z. Notice that Ï‰z
is continuous and convex. Deï¬ne
S(x) := {xâˆ—âˆˆEâˆ— âˆ¥xâˆ—âˆ¥â‰¤1, âŸ¨xâˆ—, xâŸ©= âˆ¥xâˆ¥}, x âˆˆE.

4.6 The Subdiï¬€erential of the Norm
79
Remark 4.6.1 The Hahnâ€“Banach theorem implies that S(x) Ì¸= âˆ…for each
x âˆˆE. Further, it is easy to see that
S(x) =

{xâˆ—âˆˆEâˆ— âˆ¥xâˆ—âˆ¥= 1, âŸ¨xâˆ—, xâŸ©= âˆ¥xâˆ¥}
if x Ì¸= o,
BEâˆ—
if x = o.
Proposition 4.6.2 The functional Ï‰z deï¬ned by (4.30) satisï¬es
âˆ‚Ï‰z(Â¯x) = S(Â¯x âˆ’z)
âˆ€Â¯x âˆˆE,
(4.31)
Ï‰z,H(Â¯x, y) = max{âŸ¨xâˆ—, yâŸ©
 xâˆ—âˆˆS(Â¯x âˆ’z) âˆ©ep S(o)}
âˆ€Â¯x, y âˆˆE.
(4.32)
Proof. We only consider the case Â¯x Ì¸= z which is important for the approxi-
mation problem; the veriï¬cation in the case Â¯x = z is left as an exercise.
Ad (4.31):
(Ia) Let xâˆ—âˆˆâˆ‚Ï‰z(Â¯x). Then we obtain
âŸ¨xâˆ—, xâˆ’Â¯xâŸ©â‰¤âˆ¥xâˆ’zâˆ¥âˆ’âˆ¥Â¯xâˆ’zâˆ¥âˆ€x âˆˆE, in particular âŸ¨xâˆ—, zâˆ’Â¯xâŸ©â‰¤âˆ’âˆ¥Â¯xâˆ’zâˆ¥.
Further we have
âŸ¨xâˆ—, Â¯x âˆ’zâŸ©= âŸ¨xâˆ—, 2Â¯x âˆ’zâŸ©âˆ’âŸ¨xâˆ—, Â¯xâŸ©â‰¤âˆ¥(2Â¯x âˆ’z) âˆ’zâˆ¥âˆ’âˆ¥Â¯x âˆ’zâˆ¥= âˆ¥Â¯x âˆ’zâˆ¥.
It follows that âŸ¨xâˆ—, Â¯x âˆ’zâŸ©= âˆ¥Â¯x âˆ’zâˆ¥.
(Ib) Now we show that âˆ¥xâˆ—âˆ¥= 1. Since
âŸ¨xâˆ—, xâŸ©= âŸ¨xâˆ—, x + Â¯xâŸ©âˆ’âŸ¨xâˆ—, Â¯xâŸ©â‰¤âˆ¥(x + Â¯x) âˆ’zâˆ¥âˆ’âˆ¥Â¯x âˆ’zâˆ¥â‰¤âˆ¥xâˆ¥
âˆ€x âˆˆE,
we conclude that âˆ¥xâˆ—âˆ¥â‰¤1. Recalling that Â¯x Ì¸= z, we set x2 :=
Â¯xâˆ’z
âˆ¥Â¯xâˆ’zâˆ¥.
Then (Ia) implies âŸ¨xâˆ—, x2âŸ©= 1. Further we have âˆ¥x2âˆ¥= 1 and so âˆ¥xâˆ—âˆ¥= 1.
(II) If xâˆ—âˆˆS(Â¯x âˆ’z), then we immediately obtain
âŸ¨xâˆ—, x âˆ’Â¯xâŸ©= âŸ¨xâˆ—, x âˆ’zâŸ©âˆ’âŸ¨xâˆ—, Â¯x âˆ’zâŸ©â‰¤âˆ¥x âˆ’zâˆ¥âˆ’âˆ¥Â¯x âˆ’zâˆ¥
and so xâˆ—âˆˆâˆ‚Ï‰z(Â¯x).
Ad (4.32):
By Proposition 4.1.7 we have
Ï‰z,H(Â¯x, y) = max{âŸ¨xâˆ—, yâŸ©
 xâˆ—âˆˆep S(Â¯x âˆ’z)}
âˆ€Â¯x, y âˆˆE.
We show that S(Â¯x âˆ’z) is an extremal subset of S(o); then Lemma 1.7.6
implies that ep S(Â¯x âˆ’z) = S(Â¯x âˆ’z) âˆ©ep S(o) and the assertion follows. Thus,
let xâˆ—, yâˆ—âˆˆS(o), Î» âˆˆ(0, 1), and Î»xâˆ—+ (1 âˆ’Î»)yâˆ—âˆˆS(Â¯x âˆ’z). Then
âŸ¨Î»xâˆ—, Â¯x âˆ’zâŸ©+ âŸ¨(1 âˆ’Î»)yâˆ—, Â¯x âˆ’zâŸ©= âˆ¥Â¯x âˆ’zâˆ¥.
Since âŸ¨xâˆ—, Â¯x âˆ’zâŸ©â‰¤âˆ¥xâˆ—âˆ¥Â· âˆ¥Â¯x âˆ’zâˆ¥â‰¤âˆ¥Â¯x âˆ’zâˆ¥and analogously for yâˆ—, we
deduce that âŸ¨xâˆ—, Â¯x âˆ’zâŸ©= âˆ¥Â¯x âˆ’zâˆ¥and analogously for yâˆ—. Therefore we have
xâˆ—, yâˆ—âˆˆS(Â¯x âˆ’z).
âŠ“âŠ”

80
4 The Subdiï¬€erential of Convex Functionals
Remark 4.6.3 We indicate the relationship to the duality mapping of E,
which is the multifunction J : E â‡’Eâˆ—deï¬ned by
J(x) := âˆ‚j(x),
where j(x) := 1
2âˆ¥xâˆ¥2,
x âˆˆE.
Similarly to the proof of (4.31), it can be shown that J(x) = âˆ¥xâˆ¥S(x) for any
x âˆˆE (see Exercise 4.8.8). This is also an immediate consequence of (4.31)
and a chain rule to be established below (Corollary 7.4.6).
Application: The Maximum Norm
Now we want to apply Proposition 4.6.2 to
E := C(T), with norm âˆ¥xâˆ¥âˆ:= max
tâˆˆT |x(t)|,
where T is a compact Hausdorï¬€space.
Recall that C(T) denotes the vector space of all continuous functions x :
T â†’R. Also recall that the dual space

C(T)
âˆ—is norm isomorphic to, and
so can be identiï¬ed with, the vector space M(T) of all ï¬nite regular signed
Borel measures Âµ on T, with norm âˆ¥Âµâˆ¥:= |Âµ|(T) := Âµ+(T) + Âµâˆ’(T) (see, for
instance, Elstrodt [60]). Here, Âµ+ and Âµâˆ’denote the positive and the negative
variation of Âµ, respectively. The isomorphism between xâˆ—âˆˆ

C(T)
âˆ—and the
associated Âµ âˆˆM(T) is given by
âŸ¨xâˆ—, xâŸ©=

T
x(t) dÂµ(t)
âˆ€x âˆˆC(T).
The signed measure Âµ âˆˆM(T) is said to be concentrated on the Borel set
B âŠ†T if |Âµ|(T \ B) = 0. Now let z âˆˆC(T) be ï¬xed. For Â¯x âˆˆC(T), we set
T +(Â¯x) := {t âˆˆT
 Â¯x(t) âˆ’z(t) = âˆ¥Â¯x âˆ’zâˆ¥âˆ},
T âˆ’(Â¯x) := {t âˆˆT
 Â¯x(t) âˆ’z(t) = âˆ’âˆ¥Â¯x âˆ’zâˆ¥âˆ},
T(Â¯x)
:= T +(Â¯x) âˆªT âˆ’(Â¯x).
As announced, we consider the functional
Ï‰z(x) := âˆ¥x âˆ’zâˆ¥âˆ, x âˆˆC(T).
(4.33)
Proposition 4.6.4 The functional Ï‰z deï¬ned by (4.33) satisï¬es
âˆ‚Ï‰z(Â¯x) =

Âµ âˆˆM(T)
 âˆ¥Âµâˆ¥= 1, Âµ+ resp. Âµâˆ’is concentrated
on T +(Â¯x) resp. on T âˆ’(Â¯x)

âˆ€Â¯x âˆˆC(T),
(4.34)
Ï‰z,H(Â¯x, y) = max
tâˆˆT (Â¯x)

sgn

Â¯x(t) âˆ’z(t)

y(t)

âˆ€Â¯x, y âˆˆC(T).
(4.35)

4.6 The Subdiï¬€erential of the Norm
81
Proof. Ad (4.34). In view of Proposition 4.6.2 it will do to show that S(Â¯xâˆ’z)
equals the right-hand side of (4.34).
(I) Let Âµ be an element of the latter. Then it follows that

T

Â¯x(t) âˆ’z(t)

dÂµ(t) =

T

Â· Â· Â·

dÂµ+(t) âˆ’

T

Â· Â· Â·

dÂµâˆ’(t)
=

T +(Â¯x)

Â· Â· Â·

dÂµ+(t) âˆ’

T âˆ’(Â¯x)

Â· Â· Â·

dÂµâˆ’(t)
= âˆ¥Â¯x âˆ’zâˆ¥âˆ

Âµ+(T) + Âµâˆ’(T)

= âˆ¥Â¯x âˆ’zâˆ¥âˆ.
We also have âˆ¥Âµâˆ¥= 1. Therefore Âµ âˆˆS(Â¯x âˆ’z).
(II) Now let Âµ âˆˆS(Â¯x âˆ’z). Then âˆ¥Âµâˆ¥= 1 and
âˆ¥Â¯x âˆ’zâˆ¥âˆ=

T

Â¯x(t) âˆ’z(t)

dÂµ+(t) âˆ’

T

Â¯x(t) âˆ’z(t)

dÂµâˆ’(t)
â‰¤âˆ¥Â¯x âˆ’zâˆ¥âˆ

Âµ+(T) + Âµâˆ’(T)

= âˆ¥Â¯x âˆ’zâˆ¥âˆ,
which implies

T

Â¯x(t) âˆ’z(t)

dÂµ+(t) = âˆ¥Â¯x âˆ’zâˆ¥âˆÂµ+(T),
(4.36)

T

Â¯x(t) âˆ’z(t)

dÂµâˆ’(t) = âˆ’âˆ¥Â¯x âˆ’zâˆ¥âˆÂµâˆ’(T).
Assume there exists a Borel set B âŠ†T satisfying B âˆ©T +(Â¯x) = âˆ…and
Âµ+(B) > 0. Then it follows that

T

Â¯x(t) âˆ’z(t)

dÂµ+(t) =

T \T +(Â¯x)

Â· Â· Â·

dÂµ+(t) +

T +(Â¯x)

Â· Â· Â·

dÂµ+(t)
< âˆ¥Â¯x âˆ’zâˆ¥âˆ
#
Âµ+
T \ T +(Â¯x)

+ Âµ+
T +(Â¯x)
$
;
(4.37)
here the sign < holds since Âµ+(T \T +(Â¯x)) â‰¥Âµ+(B) > 0. But the relations
(4.36) and (4.37) are contradictory. Hence Âµ+ is concentrated on T +(Â¯x).
The argument for Âµâˆ’is analogous.
Ad (4.35). For t âˆˆT let Ïµt denote the Dirac measure on T, i.e., for each Borel
set B âŠ†T we have
Ïµt(B) :=

1
if t âˆˆB,
0
if t âˆˆT \ B.
It is well known (see, for instance, KÂ¨othe [115]) that
ep S(o) = {Ïµt | t âˆˆT} âˆª{âˆ’Ïµt | t âˆˆT}.

82
4 The Subdiï¬€erential of Convex Functionals
This together with (4.31) and (4.34) gives
S(Â¯x âˆ’z) âˆ©ep S(o) = {Ïµt | t âˆˆT +(Â¯x)} âˆª{âˆ’Ïµt | t âˆˆT âˆ’(Â¯x)}.
Applying (4.32), we ï¬nally obtain
Ï‰H(Â¯x, y) = max
tâˆˆT (Â¯x)

T +(Â¯x)
y(s) dÏµt(s), âˆ’

T âˆ’(Â¯x)
y(s) dÏµt(s)
'
= max

{y(t) | t âˆˆT +(Â¯x)} âˆª{âˆ’y(t) | t âˆˆT âˆ’(Â¯x)}

,
and the latter is equal to the right-hand side of (4.35).
âŠ“âŠ”
We now consider the special case E := C[a, b], where a < b. A function Â¯x âˆˆ
C[a, b] is called peaking function if there exists tâˆ—âˆˆ[a, b] such that |Â¯x(tâˆ—)| >
|Â¯x(t)| for each t Ì¸= tâˆ—. In this case, tâˆ—is called peak point of Â¯x.
Proposition 4.6.5 Let Ï‰ be the maximum norm on C[a, b], where a < b, and
let Â¯x âˆˆC[a, b]. Then:
(a) Ï‰ is H-diï¬€erentiable at Â¯x if and only if Â¯x is a peaking function. If tâˆ—is the
peak point of Â¯x, then one has
âŸ¨Ï‰â€²(Â¯x), yâŸ©= sgn

Â¯x(tâˆ—)

y(tâˆ—)
âˆ€y âˆˆC[a, b].
(4.38)
(b) Ï‰ is nowhere F-diï¬€erentiable on C[a, b].
Proof. (a) We shall utilize the derivative of the function Î¾ â†’|Î¾| at Î¾ âˆˆR\{0}:
lim
hâ†’0
|Î¾ + h| âˆ’|Î¾|
h
= sgn(Î¾)
âˆ€Î¾ Ì¸= 0.
(I) Let Ï‰ be H-diï¬€erentiable at Â¯x. Take tâˆ—âˆˆ[a, b] with Ï‰(Â¯x) = |Â¯x(tâˆ—)|.
Now let y âˆˆC[a, b] and Ï„ Ì¸= 0. Then
Ï‰(Â¯x + Ï„y) âˆ’Ï‰(Â¯x) â‰¥|Â¯x(tâˆ—) + Ï„y(tâˆ—)| âˆ’|Â¯x(tâˆ—)|.
Dividing by Ï„, this implies, respectively,
âŸ¨Ï‰â€²(Â¯x), yâŸ©â‰¥sgn(Â¯x(tâˆ—)) y(tâˆ—)
(letting Ï„ â†“0),
âŸ¨Ï‰â€²(Â¯x), yâŸ©â‰¤sgn(Â¯x(tâˆ—)) y(tâˆ—)
(letting Ï„ â†‘0).
Hence (4.38) holds. It remains to show that tâˆ—is unique. Assume,
to the contrary, that with some tâˆ—Ì¸= tâˆ—we also had Ï‰(Â¯x) = |Â¯x(tâˆ—)|.
According to what has already been shown, it follows that
âŸ¨Ï‰â€²(Â¯x), yâŸ©= sgn

Â¯x(tâˆ—)

y(tâˆ—)
âˆ€y âˆˆC[a, b].
(4.39)

4.7 Diï¬€erentiable Norms
83
Choose y âˆˆC[a, b] such that y(tâˆ—) = 0 and y(tâˆ—) = Â¯x(tâˆ—). Then (4.38)
and (4.39) are contradictory. Hence Â¯x is a peaking function.
(II) Now let Â¯x be a peaking function with peak point tâˆ—. Then T(Â¯x) = {tâˆ—}
and so (4.35) passes into
Ï‰H(Â¯x, y) = sgn

Â¯x(tâˆ—)

y(tâˆ—).
Hence the functional Ï‰H(Â¯x, Â·) is linear and continuous and so is a
H-derivative, i.e., (4.38) holds.
(b) Assume, to the contrary, that Ï‰ is F-diï¬€erentiable at some Â¯x âˆˆC[a, b].
Then Ï‰ is also H-diï¬€erentiable at Â¯x (Proposition 3.4.2). According to (a),
Â¯x is a peaking function with a peak point tâˆ—, and (4.38) holds true. Let
(tn) be a sequence in [a, b] such that tn Ì¸= tâˆ—for each n and tn â†’tâˆ—as
n â†’âˆ. Since tâˆ—is a peak point of Â¯x and so Â¯x(tâˆ—) Ì¸= 0, we may assume
that Â¯x(tn) Ì¸= 0 for each n. Let Ï•n : [a, b] â†’[0, 1] be a continuous function
satisfying Ï•n(tn) = 1 and Ï•n(t) = 0 for each t in a neighborhood of tâˆ—
(depending on n). Further let
yn(t) := 2 sgn

Â¯x(tn)

|Â¯x(tn) âˆ’Â¯x(tâˆ—)| Ï•n(t)
âˆ€t âˆˆ[a, b].
Then
âˆ¥ynâˆ¥âˆ= |yn(tn)| = 2|Â¯x(tn) âˆ’Â¯x(tâˆ—)|.
(4.40)
It follows that
âˆ¥Â¯x + ynâˆ¥âˆâ‰¥|Â¯x(tn)+yn(tn)| = âˆ¥Â¯xâˆ¥âˆ+ |Â¯x(tn) âˆ’Â¯x(tâˆ—)| = âˆ¥Â¯xâˆ¥âˆ+ 1
2âˆ¥ynâˆ¥âˆ
and so
Ï‰(Â¯x + yn) âˆ’Ï‰(Â¯x)
âˆ¥ynâˆ¥âˆ
â‰¥1
2
âˆ€n.
(4.41)
On the other hand, from (4.38) and yn(tâˆ—) = 0 we obtain âŸ¨Ï‰â€²(Â¯x), ynâŸ©= 0.
Since Ï‰â€²(Â¯x) is assumed to be an F-derivative and âˆ¥ynâˆ¥âˆâ†’0 as n â†’âˆ
(see (4.40)), we must have
lim
nâ†’âˆ
Ï‰(Â¯x + yn) âˆ’Ï‰(Â¯x) âˆ’0
âˆ¥ynâˆ¥âˆ
= 0.
But this contradicts (4.41).
âŠ“âŠ”
4.7 Diï¬€erentiable Norms
Let again E be a normed vector space and z âˆˆE. Notice that, except for
the trivial case E = {o}, the functional Ï‰z : x â†’âˆ¥x âˆ’zâˆ¥, x âˆˆE, cannot be
G-diï¬€erentiable at z since Ï„ â†’|Ï„|, Ï„ âˆˆR, is not diï¬€erentiable at Ï„ = 0. For
points diï¬€erent from z, Proposition 4.1.8 and (4.31) immediately yield

84
4 The Subdiï¬€erential of Convex Functionals
Proposition 4.7.1 For each Â¯x Ì¸= z the following statements are equivalent:
(a) Ï‰z is G-diï¬€erentiable at Â¯x.
(b) Ï‰z is H-diï¬€erentiable at Â¯x.
(c) S(Â¯x âˆ’z) consists of exactly one element.
If one, and so each, of these statements holds true, then S(Â¯x âˆ’z) = {Ï‰â€²
z(Â¯x)},
hence
âˆ¥Ï‰â€²
z(Â¯x)âˆ¥= 1,
âŸ¨Ï‰â€²
z(Â¯x), Â¯x âˆ’zâŸ©= âˆ¥Â¯x âˆ’zâˆ¥.
(4.42)
Geometrical Interpretation
Let Â¯x âˆˆE, Â¯x Ì¸= o. By Corollary 1.5.5, the point Â¯x is a support point of the
ball B(o, âˆ¥Â¯xâˆ¥), i.e., it admits a supporting hyperplane.
Lemma 4.7.2 Let Â¯x âˆˆE, Â¯x Ì¸= o.
(i) If H is a supporting hyperplane of B(o, âˆ¥Â¯xâˆ¥) at Â¯x, then there exists xâˆ—âˆˆ
Eâˆ—such that H = [xâˆ—= âˆ¥Â¯xâˆ¥].
(ii) If xâˆ—âˆˆEâˆ—, xâˆ—Ì¸= o, then the following statements are equivalent:
(a) [xâˆ—= âˆ¥Â¯xâˆ¥] is a supporting hyperplane of B(o, âˆ¥Â¯xâˆ¥) at Â¯x.
(b) [xâˆ—= 1] is a supporting hyperplane of B(o, 1) at
Â¯x
âˆ¥Â¯xâˆ¥.
(c) xâˆ—âˆˆS(Â¯x).
Proof. (i) Let H = [yâˆ—= Î²], where yâˆ—âˆˆEâˆ—, yâˆ—Ì¸= o, and Î² âˆˆR. We may
assume that âŸ¨yâˆ—, yâŸ©â‰¤Î² for each y âˆˆB(o, âˆ¥Â¯xâˆ¥) (if âŸ¨yâˆ—, yâŸ©â‰¥Î², we replace
yâˆ—and Î² with âˆ’yâˆ—and âˆ’Î², respectively). If we had Î² â‰¤0, then âŸ¨yâˆ—, yâŸ©â‰¤0
for each y âˆˆE and so yâˆ—= o, which is not the case. Therefore Î² > 0. Set
xâˆ—:= âˆ¥Â¯xâˆ¥
Î² yâˆ—. Then we have
y âˆˆH
â‡â‡’
âŸ¨yâˆ—, yâŸ©= Î²
â‡â‡’
y âˆˆ[xâˆ—= âˆ¥Â¯xâˆ¥].
(ii) We only verify (a) =â‡’(c), the remaining implications are immediately
clear. So assume that (a) holds. Then âŸ¨xâˆ—, Â¯xâŸ©= âˆ¥Â¯xâˆ¥and âŸ¨xâˆ—, yâŸ©â‰¤âˆ¥Â¯xâˆ¥for
each y âˆˆB(o, âˆ¥Â¯xâˆ¥). (Choose y := o to see that we cannot have âŸ¨xâˆ—, yâŸ©â‰¥
âˆ¥Â¯xâˆ¥for each y âˆˆB(o, âˆ¥Â¯xâˆ¥).) It follows that
âˆ¥Â¯xâˆ¥= sup{âŸ¨xâˆ—, yâŸ©| y âˆˆB(o, âˆ¥Â¯xâˆ¥)} = âˆ¥xâˆ—âˆ¥âˆ¥Â¯xâˆ¥.
Here the second equation holds according to the deï¬nition of âˆ¥xâˆ—âˆ¥. We
thus obtain âˆ¥xâˆ—âˆ¥= 1. Hence xâˆ—âˆˆS(Â¯x).
âŠ“âŠ”
Roughly speaking, the lemma says that S(Â¯x) contains â€œas manyâ€ elements
as there are supporting hyperplanes of B(o, 1) at
Â¯x
âˆ¥Â¯xâˆ¥. This gives rise to Deï¬-
nition 4.7.3.
Deï¬nition 4.7.3 The normed vector space E is said to be smooth if B(o, 1)
possesses exactly one supporting hyperplane at each boundary point (in other
words, if S(x) consists of exactly one element for each x Ì¸= o).

4.7 Diï¬€erentiable Norms
85
o
o
Â¯x
Â¯x
Fig. 4.3
B(o, 1)
o
x
y
1
2(x + y)
â‰¥Î´(Ïµ, x)
Fig. 4.4
Proposition 4.7.1 (with z = o) and Lemma 4.7.2 immediately yield:
Proposition 4.7.4 The following assertions are equivalent:
(a) âˆ¥Â· âˆ¥is G-diï¬€erentiable at each nonzero point.
(b) âˆ¥Â· âˆ¥is H-diï¬€erentiable at each nonzero point.
(c) E is smooth.
Example 4.7.5 Figure 4.3 shows B(o, 1) in R2 for the Euclidean norm and for
the maximum norm. The Euclidean norm is G-diï¬€erentiable at each nonzero
point of R2 while the maximum norm is not G-diï¬€erentiable at the corner
points of B(o, 1). The same holds true in Rn for n > 2.
We now reï¬ne the investigation.
Deï¬nition 4.7.6 The normed vector space E is said to be locally uniformly
convex if the following holds (Fig. 4.4):
âˆ€Ïµ âˆˆ(0, 2]
âˆ€x âˆˆE, âˆ¥xâˆ¥= 1
âˆƒÎ´(Ïµ, x) > 0
âˆ€y âˆˆE :
âˆ¥yâˆ¥= 1, âˆ¥x âˆ’yâˆ¥â‰¥Ïµ
=â‡’
âˆ¥1
2(x + y)âˆ¥â‰¤1 âˆ’Î´(Ïµ, x).
If Î´(Ïµ, x) can be chosen to be independent of x, then E is said to be uniformly
convex.
It is clear that with respect to the maximum norm, Rn for n â‰¥2 is not
locally uniformly convex. However, we have the following positive results.

86
4 The Subdiï¬€erential of Convex Functionals
Example 4.7.7 If E is a Hilbert space, then E is uniformly convex with
respect to the norm generated by the inner product. In fact, the parallelogram
identity reads
 1
2(x + y)
2 = 1
2
x
2 +
y
2
âˆ’1
4
x âˆ’y
2.
Hence, given Ïµ > 0, we obtain for all x, y âˆˆE satisfying âˆ¥x âˆ’yâˆ¥â‰¥Ïµ,
 1
2 (x + y)
2 â‰¤1 âˆ’Ïµ2
4 â‰¤

1 âˆ’Ïµ2
8
2
,
i.e., we may choose Î´(Ïµ, x) := Ïµ2
8 which is independent of x. In particular, Rn
is uniformly convex with respect to the Euclidean norm.
Example 4.7.8 For any measure space (X, A, Âµ) and each p âˆˆ(1, +âˆ), the
Lebesgue space Lp(X, A, Âµ) is uniformly convex (Theorem of Clarkson). We
verify this for p â‰¥2; for 1 < p < 2 see, for instance, Cioranescu [32].
(I) We ï¬rst show that for arbitrary a, b âˆˆR and p â‰¥2 we have
|a + b|p + |a âˆ’b|p â‰¤2pâˆ’1(|a|p + |b|p).
(4.43)
Let Î± > 0, Î² > 0, and set c :=
!
Î±2 + Î²2. Then 0 < Î±
c < 1 and 0 < Î²
c < 1,
hence
Î±
c
p
+
Î²
c
p
â‰¤
Î±
c
2
+
Î²
c
2
= 1,
and so Î±p + Î²p â‰¤cp = (Î±2 + Î²2)p/2. We deduce that
|a + b|p + |a âˆ’b|p â‰¤

|a + b|2 + |a âˆ’b|2p/2 = 2p/2
|a|2 + |b|2p/2. (4.44)
Since 2
p + pâˆ’2
p
= 1, the HÂ¨older inequality (applied to p
2 and
p
pâˆ’2) yields
|a2Â·1|+|b2Â·1| â‰¤

a2p/2 +

b2p/22/p
Â·(1+1)
pâˆ’2
p
=

|a|p+|b|p2/pÂ·2
pâˆ’2
p .
This together with (4.44) gives (4.43).
(II) Now we show that Lp(X, A, Âµ) is uniformly convex. For all f, g âˆˆ
Lp(X, A, Âµ) the inequality (4.43) implies
 1
2(f + g)
p
p â‰¤1
2
f
p
p +
g
p
p

âˆ’1
2p
f âˆ’g
p
p.
Now we can argue as in Example 4.7.7.
Locally uniformly convex spaces have a nice convergence property. To de-
scribe it, we introduce the following concept. The norm âˆ¥Â·âˆ¥of a Banach space
E is said to be a Kadec norm if xn
w
âˆ’â†’x and âˆ¥xnâˆ¥â†’âˆ¥xâˆ¥as n â†’âˆimplies
xn â†’x as n â†’âˆ.

4.7 Diï¬€erentiable Norms
87
Lemma 4.7.9 The norm of a locally uniformly convex Banach space is a
Kadec norm.
Proof. Let xn
w
âˆ’â†’x and âˆ¥xnâˆ¥â†’âˆ¥xâˆ¥. The conclusion is obvious if x = o. So
let x Ì¸= o and set y :=
x
âˆ¥xâˆ¥, yn :=
xn
âˆ¥xnâˆ¥which makes sense for all n suï¬ƒciently
large. It follows that yn + y
w
âˆ’â†’2y. Hence (yn + y) considered as a sequence
in Eâˆ—âˆ—is bounded (Banachâ€“Steinhaus theorem). More precisely, we have
2 = âˆ¥2yâˆ¥â‰¤lim inf
nâ†’âˆâˆ¥yn + yâˆ¥â‰¤lim sup
nâ†’âˆâˆ¥yn + yâˆ¥â‰¤lim
nâ†’âˆâˆ¥ynâˆ¥+ âˆ¥yâˆ¥= 2
and so limnâ†’âˆâˆ¥yn +yâˆ¥= 2. Since E is locally uniformly convex, we conclude
that limnâ†’âˆâˆ¥yn âˆ’yâˆ¥= 0 and so (since âˆ¥xnâˆ¥â†’âˆ¥xâˆ¥) we ï¬nally obtain
âˆ¥xn âˆ’xâˆ¥â†’0.
âŠ“âŠ”
Proposition 4.7.10 Let E be reï¬‚exive and Eâˆ—locally uniformly convex.
Then the norm functional Ï‰ is continuously diï¬€erentiable on E \ {o}.
Proof. (I) Let x âˆˆE, x Ì¸= o. We show that S(x) contains exactly one
element. Assume that xâˆ—
1, xâˆ—
2 âˆˆS(x), i.e., âˆ¥xâˆ—
i âˆ¥= 1 and âŸ¨xâˆ—
i , xâŸ©= âˆ¥xâˆ¥for
i = 1, 2. We then have
2 = âˆ¥xâˆ—
1âˆ¥2 + âˆ¥xâˆ—
2âˆ¥2 =
(
xâˆ—
1 + xâˆ—
2, x
âˆ¥xâˆ¥
)
â‰¤âˆ¥xâˆ—
1 + xâˆ—
2âˆ¥Â· 1
and so âˆ¥1
2(xâˆ—
1 + xâˆ—
2)âˆ¥â‰¥1. Since Eâˆ—is locally uniformly convex, we
conclude that xâˆ—
1 = xâˆ—
2 (otherwise we could choose Î´(Ïµ, x) > 0 for Ïµ :=
âˆ¥xâˆ—
1 âˆ’xâˆ—
2âˆ¥).
(II) By step (I) and Proposition 4.7.1 we know that Ï‰ is G-diï¬€erentiable
at each nonzero point. Now we show that xn â†’x implies Ï‰â€²(xn)
w
âˆ’â†’
Ï‰â€²(x) as n â†’âˆ. Thus let xn â†’x. Since S(xn) = {Ï‰â€²(xn)}, we have
âˆ¥Ï‰â€²(xn)âˆ¥= 1 for each n. Since E is reï¬‚exive, some subsequence (Ï‰â€²(xnj))
of (Ï‰â€²(xn)) is weakly convergent to some yâˆ—âˆˆEâˆ—as j â†’âˆ. For each
y âˆˆE we thus obtain
âŸ¨yâˆ—, yâŸ©= lim
jâ†’âˆ

Ï‰â€²(xnj), y
 
â‰¤lim
jâ†’âˆâˆ¥Ï‰â€²(xnj)âˆ¥Â· âˆ¥yâˆ¥= âˆ¥yâˆ¥
and so âˆ¥yâˆ—âˆ¥â‰¤1. Moreover, we have
âŸ¨yâˆ—, xâŸ©= lim
jâ†’âˆ

Ï‰â€²(xnj), xnj
 
=
(4.42) lim
jâ†’âˆâˆ¥xnjâˆ¥= âˆ¥xâˆ¥.
Therefore yâˆ—âˆˆS(x) and step (I) tells us that yâˆ—= Ï‰â€²(x). Since each
weakly convergent subsequence of (Ï‰â€²(xn)) has the same limit Ï‰â€²(x), we
conclude that
Ï‰â€²(xn)
w
âˆ’â†’Ï‰â€²(x).
(4.45)

88
4 The Subdiï¬€erential of Convex Functionals
(III) Now let xn â†’x. We then have
âˆ¥Ï‰â€²(xn)âˆ¥= âˆ¥xnâˆ¥â†’âˆ¥xâˆ¥= âˆ¥Ï‰â€²(x)âˆ¥.
This together with (4.45) gives Ï‰â€²(xn) â†’Ï‰â€²(x) by Lemma 4.7.9.
âŠ“âŠ”
Example 4.7.11 The space Lp := Lp(X, A, Âµ), where 1 < p < +âˆ, is reï¬‚ex-
ive and the dual space can be identiï¬ed with Lq, where 1
p + 1
q = 1. Moreover,
by Example 4.7.8, Lq is uniformly convex. Proposition 4.7.10 therefore im-
plies that the norm Ï‰ := âˆ¥Â· âˆ¥p is continuously diï¬€erentiable away from zero.
Explicitly we have
Ï‰â€²(x) = sgn(x)
âˆ¥xâˆ¥pâˆ’1
p
|x|pâˆ’1
âˆ€x âˆˆLp \ {o}.
This is easily veriï¬ed by showing that the right-hand side is an element of
S(x).
Example 4.7.5 showed that the diï¬€erentiability properties of the norm may
change by passing to an equivalent norm. In this connection, the following deep
result is of great importance; concerning its proof we refer to Cioranescu [32],
Deville et al. [50], or Diestel [51].
Theorem 4.7.12 (Renorming Theorem) If E
is a
reï¬‚exive Banach
space, then there exists an equivalent norm on E such that E and Eâˆ—are both
locally uniformly convex.
Deï¬nition 4.7.13 The Banach space E is said to be FrÃ©chet smooth if it
admits an equivalent norm that is F-diï¬€erentiable on E \ {o}.
Recall that by Corollary 4.3.4 the norm functional is F-diï¬€erentiable if and
only if it is continuously diï¬€erentiable. Hence Theorem 4.7.12 together with
Proposition 4.7.10 leads to:
Proposition 4.7.14 If E is a reï¬‚exive Banach space, then there exists an
equivalent norm on E that is continuously diï¬€erentiable on E \ {o}, and the
same holds true for the associated norm on Eâˆ—. In particular, every reï¬‚exive
Banach space is FrÃ©chet smooth.
For later use we present the following result; for a proof we refer to Deville
et al. [50] and Phelps [165].
Proposition 4.7.15 Every FrÃ©chet smooth Banach space is an Asplund
space.

4.8 Bibliographical Notes and Exercises
89
4.8 Bibliographical Notes and Exercises
The theory of the subdiï¬€erential and the conjugate of convex functionals
as well as its various applications originated in the work of Moreau and
Rockafellar in the early 1960s (see Moreau [148] and Rockafellar [177]). The
now classic text on the subject in ï¬nite-dimensional spaces is Rockafellar [180].
Concerning ï¬nite-dimensional spaces, see also Bazaraa et al. [11], Borwein
and Lewis [18], Elster et al. [59], Hiriart-Urruty and LemarÃ©chal [88,89], and
Rockafellar and Wets [189] (comprehensive monograph).
In the inï¬nite-dimensional case, we recommend Aubin [6] (application to
mathematical economics), Barbu and Precupanu [9] (application to control
problems), Ekeland and Temam [58] (application to variational problems
involving partial diï¬€erential equations), Ioï¬€e and Tikhomirov [101] (ap-
plication to the calculus of variations and control problems), Pallaschke
and Rolewicz [156] (abstract approach with many concrete applications),
Pshenichnyi [170] (application to control problems), Schirotzek [196] (ap-
plication to the calculus of variations), and Zeidler [221] (comprehensive
monograph with many applications). For applications of the conjugation to
density functionals in quantum physics see Eschrig [62].
The results on Asplund spaces in Sect. 4.3 are mainly taken from
Phelps [165]. Theorem 4.3.18 is essentially due to Preiss and ZajÃ­Äek [167],
our presentation follows Phelps [165]. Theorem 4.3.19 was established by
Asplund [3]. The famous renorming result of Theorem 4.7.12 is due to
Kadec [108] and Troyanski [208]. Concerning diï¬€erentiability properties of
convex functionals, especially of the norm functional, see also Beauzamy [13],
Cioranescu [32], Deville et al. [50], Diestel [51], Sundaresan [205], and Ya-
mamuro [216]. For applications to approximation theory see Braess [27],
Krabs [112], and Laurent [118].
Exercise 4.8.1 Let Î¦ : E â‡’F be a multifunction between Banach spaces E
and F. Verify the following:
(a) Î¦ is upper semicontinuous if and only if for any open set V âŠ†F the set
{x âˆˆE | Î¦(x) âŠ†V } is open.
(b) Î¦ is lower semicontinuous if and only if for any open set V âŠ†F the set
{x âˆˆE | Î¦(x) âˆ©V Ì¸= âˆ…} is open.
Exercise 4.8.2 Let f : E â†’R be proper and convex, and continuous on the
nonempty set int domf. Show that f is G-diï¬€erentiable at Â¯x âˆˆint domf if
and only if there exists a selection Ï• : E â†’Eâˆ—of âˆ‚f which is norm-to-weak*
continuous at Â¯x (cf. Proposition 4.3.3).
Exercise 4.8.3 Prove Proposition 4.3.5.

90
4 The Subdiï¬€erential of Convex Functionals
Exercise 4.8.4 Verify Proposition 4.3.7.
Exercise 4.8.5 Verify the necessity part of Lemma 4.3.11.
Exercise 4.8.6 Prove Lemma 4.3.17.
Exercise 4.8.7 Prove Proposition 4.4.1.
Exercise 4.8.8 Show that the duality mapping J : E â‡’Eâˆ—satisï¬es J(x) =
âˆ¥xâˆ¥S(x) for any x âˆˆE (cf. Remark 4.6.3).
Exercise 4.8.9 Let E be a Banach space and assume that the duality map-
ping J : E â‡’Eâˆ—is linear, i.e., xâˆ—âˆˆJ(x), yâˆ—âˆˆJ(y), and Î» âˆˆR imply
xâˆ—+ yâˆ—âˆˆJ(x + y) and Î»xâˆ—âˆˆJ(Î»x). Show the following:
(a) E is a Hilbert space.
(b) J is single-valued and satisï¬es âŸ¨J(x), yâŸ©= (y | x) for all x, y âˆˆE, i.e., J is
the norm isomorphism of E onto Eâˆ—according to the Riesz representation
theorem.
Exercise 4.8.10 Let L be a linear subspace of the normed vector space E,
let f : E â†’R be proper and convex, and let Â¯x âˆˆLâˆ©dom f. Denote by âˆ‚Lf(Â¯x)
the subdiï¬€erential of f|L (the restriction of f to L) at Â¯x. Verify the following
assertions (cf. Singer [199]):
(a) For any xâˆ—âˆˆep(âˆ‚Lf(Â¯x)) there exists yâˆ—âˆˆep(âˆ‚f(Â¯x)) such that yâˆ—|L = xâˆ—.
(b) If dim L = n, then for any xâˆ—âˆˆep(âˆ‚Lf(Â¯x)) there exist yâˆ—
1, . . . , yâˆ—
n+1 âˆˆ
ep(âˆ‚f(Â¯x)) and Î»1, . . . , Î»n+1 â‰¥0 such that
n+1
	
i=1
Î»i = 1
and
n+1
	
i=1
Î»i yâˆ—
i (x) = xâˆ—(x)
âˆ€x âˆˆL.
Hint: By a Theorem of CarathÃ©odory, any point of a compact convex
subset C of Rn is the convex combination of at most n+1 extreme points
of C.

5
Optimality Conditions for Convex Problems
5.1 Basic Optimality Conditions
We consider the following basic convex optimization problem:
(P1) Minimize f(x) subject to x âˆˆM,
which we also formally write f(x) âˆ’â†’min, x âˆˆM. We assume that
f : E â†’R is a proper convex functional,
M is a nonempty convex subset of dom f.
Theorem 4.1.3 shows that under this assumption, fG(Â¯x, Â·) exists as an R-valued
functional.
The point Â¯x âˆˆM is called a global minimizer of f on M, or brieï¬‚y a global
solution of (P1), if f(Â¯x) â‰¤f(x) for any x âˆˆM. Moreover, Â¯x âˆˆM is called a
local minimizer of f on M, or brieï¬‚y a local solution of (P1), if there exists a
neighborhood U of Â¯x in E such that f(Â¯x) â‰¤f(x) for any x âˆˆM âˆ©U.
Proposition 5.1.1 The following statements are equivalent:
(a) Â¯x is a global solution of (P1).
(b) Â¯x is a local solution of (P1).
(c) fG(Â¯x, x âˆ’Â¯x) â‰¥0 for all x âˆˆM.
Proof. (a) =â‡’(b) is clear.
(b) =â‡’(c): If (b) holds, then for some neighborhood U of Â¯x, we have f(y) âˆ’
f(Â¯x) â‰¥0 for each y âˆˆM âˆ©U. Now let x âˆˆM. Since M is convex, we see that
y := Â¯x + Ï„(x âˆ’Â¯x) = Ï„x + (1 âˆ’Ï„)Â¯x âˆˆM
âˆ€Ï„ âˆˆ(0, 1).
Further, if Ï„ âˆˆ(0, 1) is suï¬ƒciently small, we also have y âˆˆU and so
1
Ï„

f

Â¯x + Ï„(x âˆ’Â¯x)

âˆ’f(Â¯x)

â‰¥0.

92
5 Optimality Conditions for Convex Problems
Letting Ï„ â†“0, the assertion follows.
(c) =â‡’(a): Theorem 4.1.3 shows that fG(Â¯x, x âˆ’Â¯x) â‰¤f(x) âˆ’f(Â¯x) for any
x âˆˆM. Hence (c) implies (a).
âŠ“âŠ”
Condition (c) is called variational inequality (as x varies over M). Some-
times a variational inequality passes into a variational equation.
Corollary 5.1.2 Assume that Â¯x âˆˆint M and f : M â†’R is G-diï¬€erentiable
at Â¯x. Then the following conditions are equivalent:
(a) f(Â¯x) = minxâˆˆM f(x)
(minimum problem).
(b)

f â€²(Â¯x), y
 
= 0
âˆ€y âˆˆE (variational equation).
(c) f â€²(Â¯x) = o
(operator equation).
Proof. By Proposition 5.1.1, (a) is equivalent to
âŸ¨f â€²(Â¯x), x âˆ’Â¯xâŸ©â‰¥0
âˆ€x âˆˆM.
(5.1)
Since the implications (b) =â‡’(5.1) and (b) â‡â‡’(c) are obvious, it remains
to show that (5.1) implies (b). Thus let y âˆˆE be given. Since Â¯x is an interior
point of M, we have x := Â¯x + Ï„y âˆˆM whenever Ï„ âˆˆR is such that |Ï„| is
suï¬ƒciently small. Hence for these Ï„ we deduce from (5.1) that Ï„

f â€²(Â¯x), y
 
â‰¥0.
Therefore (b) holds.
âŠ“âŠ”
5.2 Optimality Under Functional Constraints
We consider the following convex optimization problem:
(P2) Minimize f(x)
subject to gi(x) â‰¤0 (i = 1, . . . , m), x âˆˆA,
which of course means
minimize f(x) on M := {x âˆˆE | gi(x) â‰¤0 (i = 1, . . . , m), x âˆˆA}.
In this connection, the assumptions are:
(A) f, g1, . . . , gm : E â†’R are proper convex functionals,
A is a nonempty convex subset of D := dom f âˆ©dom g1 âˆ©Â· Â· Â· âˆ©dom gm.
Our aim is to characterize points Â¯x âˆˆM that minimize f under the func-
tional constraints gi(x) â‰¤0 (i = 1, . . . , m) and the residual constraint x âˆˆA.
We therefore consider the statement
(Min 2) Â¯x âˆˆM is a global solution of (P2).
We deï¬ne functionals *L : D Ã— Rm+1
+
â†’R and L : D Ã— Rm
+ â†’R by

5.2 Optimality Under Functional Constraints
93
*L(x; Î», Âµ1, . . . , Âµm) := Î»f(x) +
m
	
i=1
Âµigi(x),
L(x; Âµ1, . . . , Âµm)
:= f(x) +
m
	
i=1
Âµigi(x).
The functionals *L and L are called Lagrange functionals associated with (P2).
Furthermore, the point (Â¯x, Â¯Âµ) âˆˆA Ã— Rm
+, where Â¯Âµ := (Â¯Âµ1, . . . , Â¯Âµm), is called
saddle point of L with respect to A Ã— Rm
+ if
L(Â¯x, Âµ) â‰¤L(Â¯x, Â¯Âµ) â‰¤L(x, Â¯Âµ)
âˆ€(x, Âµ) âˆˆA Ã— Rm
+.
We consider the following statements:
(*L) âˆƒ(Â¯Î», Â¯Âµ1, . . . , Â¯Âµm) âˆˆRm+1
+
\ {o} :
*L(Â¯x; Â¯Î», Â¯Âµ1, . . . , Â¯Âµm) = min
xâˆˆA
*L(x; Â¯Î», Â¯Âµ1, . . . , Â¯Âµm),
Â¯Âµi gi(Â¯x) = 0
(i = 1, . . . , m).
(L) âˆƒ(Â¯Âµ1, . . . , Â¯Âµm) âˆˆRm
+ :
L(Â¯x; Â¯Âµ1, . . . , Â¯Âµm) = min
xâˆˆA L(x; Â¯Âµ1, . . . , Â¯Âµm),
Â¯Âµi gi(Â¯x) = 0
(i = 1, . . . , m).
(SP) âˆƒÂ¯Âµ âˆˆRm
+ : (Â¯x, Â¯Âµ) is a saddle point of L with respect to A Ã— Rm
+.
Finally we consider the Slater condition
âˆƒx0 âˆˆA : gi(x0) < 0 for i = 1, . . . , m.
(5.2)
Theorem 5.2.1 (Global Kuhnâ€“Tucker Theorem) Let the assumptions
(A) be satisï¬ed.
(a) There always holds
(SP)
â‡â‡’
(L)
=â‡’
(Min 2)
=â‡’
(*L).
(b) If the Slater condition (5.2) is satisï¬ed, then there holds
(SP)
â‡â‡’
(L)
â‡â‡’
(Min 2)
â‡â‡’
(*L).
Proof. (a) (SP) â‡â‡’(L) =â‡’(Min 2): Exercise 5.6.1.
(Min 2) =â‡’(*L): Deï¬ne
K :=

âˆ’

f(x) âˆ’f(Â¯x), g1(x), . . . , gm(x)
  x âˆˆA

.

94
5 Optimality Conditions for Convex Problems
Since the functions f, g1, . . . , gm are convex, K is a convex subset of Rm+1.
Furthermore, (Min 2) implies K âˆ©int Rm+1
+
= âˆ…. By Corollary 1.5.4, there
exists Â¯Âµ := (Â¯Î», Â¯Âµ1, . . . , Â¯Âµm) âˆˆRm+1 satisfying
Â¯Âµ Ì¸= o,
(Â¯Âµ| y) â‰¤0 âˆ€y âˆˆK,
(Â¯Âµ| z) â‰¥0 âˆ€z âˆˆRm+1
+
.
The assertion now follows immediately.
(b) It suï¬ƒces to show that (*L) implies (L). Assume that (*L) holds with Â¯Î» = 0.
Then we have (Â¯Âµ1, . . . , Â¯Âµm) Ì¸= o and so, by (5.2), Â¯Âµi gi(x0) < 0 for at
least one i âˆˆ{1, . . . , m}. On the other hand, the minimum property of (*L)
entails
0 =
m
	
i=1
Â¯Âµi gi(Â¯x) â‰¤
m
	
i=1
Â¯Âµi gi(x)
âˆ€x âˆˆA,
which is contradictory. Hence Â¯Î» Ì¸= 0 and we may (replacing Â¯Âµi by Â¯Âµi / Â¯Î» if
necessary) assume that Â¯Î» = 1. Therefore, (L) holds.
âŠ“âŠ”
Remark 5.2.2 (a) Roughly speaking, Theorem 5.2.1 states that the mini-
mization of f under functional and residual side conditions can be replaced
by the minimization of the Lagrange functional L or *L under the residual
side condition x âˆˆA alone, the functional side conditions being integrated
into the Lagrange functional.
(b) If Â¯Î» = 0, then the functional f to be minimized does not appear in the
optimality conditions. In this case, the conditions are not well suited for
detecting possible minimizers. A condition ensuring that Â¯Î» Ì¸= 0, and so
(*L) â‡â‡’(L), is called regularity condition. Theorem 5.2.1(b) shows that
the Slater condition is a regularity condition. A more thorough study of
regularity conditions shows that these are generally conditions on the con-
straint functionals (as is the Slater condition). Therefore regularity condi-
tions are also called constraint qualiï¬cations.
We now establish local optimality conditions for (Min 2) by using subdif-
ferentials. Consider the following statements.
(J) âˆƒ(Â¯Î», Â¯Âµ1, . . . , Â¯Âµm) âˆˆRm+1
+
\ {o} :
o âˆˆÂ¯Î»âˆ‚f(Â¯x) + Â¯Âµ1âˆ‚g1(Â¯x) + Â· Â· Â· + Â¯Âµmâˆ‚gm(Â¯x) + âˆ‚Î´A(Â¯x),
Â¯Âµi gi(Â¯x) = 0
(i = 1, . . . , m).
(KKT)
âˆƒ(Â¯Âµ1, . . . , Â¯Âµm) âˆˆRm
+ :
o âˆˆâˆ‚f(Â¯x) + Â¯Âµ1âˆ‚g1(Â¯x) + Â· Â· Â· + Â¯Âµmâˆ‚gm(Â¯x) + âˆ‚Î´A(Â¯x),
Â¯Âµi gi(Â¯x) = 0
(i = 1, . . . , m).
The conditions (J) and (KKT) are the
(Fritz) John conditions and the
Karushâ€“Kuhnâ€“Tucker conditions, respectively.

5.2 Optimality Under Functional Constraints
95
Theorem 5.2.3 (Local Johnâ€“Karushâ€“Kuhnâ€“Tucker Theorem) In
addition to the assumptions (A), let the functionals f, g1, . . . , gm be con-
tinuous at some point of A âˆ©int D.
(a) There always holds (KKT) =â‡’(Min 2) =â‡’(J).
(b) If the Slater condition (5.2) is satisï¬ed, then there holds (KKT) â‡â‡’
(Min 2) â‡â‡’(J).
Proof. See Exercise 5.6.2.
Remark 5.2.4 (a) Since âˆ’âˆ‚Î´A(Â¯x) = {xâˆ—âˆˆEâˆ—| âŸ¨xâˆ—, Â¯xâŸ©= min
xâˆˆAâŸ¨xâˆ—, xâŸ©}, the
John condition (J) is equivalent to
âˆƒ(Â¯Î», Â¯Âµ1, . . . , Â¯Âµm) âˆˆRm+1
+
\ {o}
âˆƒxâˆ—âˆˆâˆ‚f(Â¯x)
âˆƒyâˆ—
i âˆˆâˆ‚gi(Â¯x) (i = 1, . . . , m) :

Â¯Î» xâˆ—+ Â¯Âµ1 yâˆ—
1 + Â· Â· Â· + Â¯Âµm yâˆ—
m

(Â¯x) = min
xâˆˆA

Â¯Î» xâˆ—+ Â¯Âµ1 yâˆ—
1 + Â· Â· Â· + Â¯Âµm yâˆ—
m

(x),
Â¯Âµi gi(Â¯x) = 0 (i = 1, . . . , m).
(b) If f is continuous at a point of A âˆ©int dom f, then
f(Â¯x) = min
xâˆˆA f(x)
â‡â‡’
âˆƒxâˆ—âˆˆâˆ‚f(Â¯x) : âŸ¨xâˆ—, Â¯xâŸ©= min
xâˆˆAâŸ¨xâˆ—, xâŸ©.
This follows from Theorem 5.2.3(b) by choosing m = 1, g1(x) := âˆ’1 if
x âˆˆD, g1(x) := +âˆif x âˆˆE \ D.
(c) If f is continuous at a point of A âˆ©int dom f and G-diï¬€erentiable at Â¯x,
then
f(Â¯x) = min
xâˆˆA f(x)
â‡â‡’

f â€²(Â¯x), x âˆ’Â¯x
 
â‰¥0 âˆ€x âˆˆA.
If, in addition, Â¯x âˆˆint A (in particular, if A = E), then
f(Â¯x) = min
xâˆˆA f(x)
â‡â‡’

f â€²(Â¯x), y
 
= 0 âˆ€y âˆˆE
â‡â‡’
f â€²(Â¯x) = o.
This follows from (b) above noting that now âˆ‚f(Â¯x) = {f â€²(Â¯x)} by Proposi-
tion 4.1.8.
Remark 5.2.4(b) and Proposition 5.1.1 give the following result.
Proposition 5.2.5 Let f : E â†’R be a continuous convex functional, let A be
a nonempty convex subset of E, and let Â¯x âˆˆA. Then the following statements
are equivalent:
(a) f(Â¯x) = minxâˆˆA f(x).
(b) âˆƒxâˆ—âˆˆâˆ‚f(Â¯x) : âŸ¨xâˆ—, Â¯xâŸ©= minxâˆˆAâŸ¨xâˆ—, xâŸ©.
(c) âˆ€x âˆˆA : fG(Â¯x, x âˆ’Â¯x) â‰¥0.

96
5 Optimality Conditions for Convex Problems
5.3 Application to Approximation Theory
Let A be a nonempty subset of E and z âˆˆE. Recall that an element Â¯x âˆˆA
is said to be a best approximation of z with respect to A, or a projection of z
onto A, if
âˆ¥Â¯x âˆ’zâˆ¥= min
xâˆˆA âˆ¥x âˆ’zâˆ¥.
We write projA(z) for the set (possibly empty) of all projections of z onto A,
i.e., we put
projA(z) := {Â¯x âˆˆA | âˆ¥Â¯x âˆ’zâˆ¥= dA(z)},
where dA denotes the distance function. This deï¬nes the multifunction projA :
E â‡’E, called the projector associated with the set A. It is clear that z âˆˆA
implies projA(z) = {z}. We now assume that
A âŠ†E is nonempty and convex, and z âˆˆE \ A.
Our aim is to characterize projA(z). This can be done by applying the pre-
ceding results to the functional
f(x) := âˆ¥x âˆ’zâˆ¥,
x âˆˆE.
(5.3)
Best Approximation in a Hilbert Space
Proposition 5.3.1 Let E be a Hilbert space with inner product (x | y). Then
one has
Â¯x âˆˆprojA(z)
â‡â‡’
(z âˆ’Â¯x | x âˆ’Â¯x) â‰¤0
âˆ€x âˆˆA.
Proof. See Exercise 5.6.3.
âŠ“âŠ”
Remark 5.3.2 Recall that, by the Cauchyâ€“Schwarz inequality, the formula
cos Î±x := (z âˆ’Â¯x | x âˆ’Â¯x)
âˆ¥z âˆ’Â¯xâˆ¥âˆ¥x âˆ’Â¯xâˆ¥
deï¬nes an angle Î±x for any x âˆˆA, x Ì¸= Â¯x. Proposition 5.3.1 thus says that
Â¯x is a projection of z onto A if and only if Î±x is obtuse (see Fig. 5.1, where
E = R2).
If A is a linear subspace of E, then
AâŠ¥:= {y âˆˆE | (y|Ëœx) = 0
âˆ€Ëœx âˆˆA}
denotes the orthogonal complement of A. As an immediate consequence of
Proposition 5.3.1 we have:
Corollary 5.3.3 Let E be a Hilbert space and A a linear subspace of E. Then
Â¯x âˆˆprojA(z) if and only if z âˆ’Â¯x âˆˆAâŠ¥(see Fig. 5.2, where E = R3).

5.3 Application to Approximation Theory
97
A
z
Â¯x
x
Î±x
Fig. 5.1
z
x
Â¯x
A
Fig. 5.2
Best Approximation in a Normed Vector Space
We want to characterize best approximations in an arbitrary normed vector
space. From Propositions 4.6.2 and 5.2.5 we immediately obtain:
Proposition 5.3.4 (Characterization of Best Approximations) If
E
is a normed vector space, the following statements are equivalent:
(a) Â¯x âˆˆprojA(z).
(b) âˆƒxâˆ—âˆˆS(Â¯x âˆ’z) : âŸ¨xâˆ—, Â¯xâŸ©= min
xâˆˆAâŸ¨xâˆ—, xâŸ©.
(c) âˆ€x âˆˆA : max{âŸ¨yâˆ—, x âˆ’Â¯xâŸ©
 yâˆ—âˆˆS(Â¯x âˆ’z) âˆ©ep S(o)} â‰¥0.
Best Approximation in C(T )
Now we apply the above results to
E := C(T), with norm âˆ¥xâˆ¥âˆ:= max
tâˆˆT |x(t)|,
where T is a compact Hausdorï¬€space. We consider the functional
Ï‰z(x) := âˆ¥x âˆ’zâˆ¥âˆ, x âˆˆC(T).
(5.4)
Concerning the terminology, we refer to Sect. 4.6.
Combining Propositions 4.6.4 and 5.3.4(a)â‡”(c), we obtain the follow-
ing characterization of best approximations in C(T). Notice that in the
Kolmogorov condition the signum operation can now be omitted.

98
5 Optimality Conditions for Convex Problems
Proposition 5.3.5 Let A be a nonempty convex subset of C(T), let z âˆˆ
C(T) \ A, and let Â¯x âˆˆA. Then the following statements are equivalent:
(a) Â¯x âˆˆprojA(z).
(b) âˆ€x âˆˆA : maxtâˆˆT (Â¯x)

Â¯x(t) âˆ’z(t)

x(t) âˆ’Â¯x(t)

â‰¥0
(Kolmogorov condi-
tion).
We leave it to the reader to formulate the corresponding characterization
following from Proposition 5.2.5(a)â‡”(b).
As a special case, we now choose T = [a, b]. Recall that each (positive)
Borel measure Î½ on [a, b] is regular and can be represented by a nondecreasing
right continuous function Ïˆ : [a, b] â†’R such that

[a,b]
x(t) dÎ½(t) =

[a,b]
x(t) dÏˆ(t)
âˆ€x âˆˆC[a, b],
the integral on the right-hand side being a Riemannâ€“Stieltjes integral. In this
connection, we have
Ïˆ(x) = Î½

(a, x]

âˆ€x âˆˆ(a, b],
Ïˆ(a) = 0.
Moreover, for each Borel set B âŠ†[a, b] we have
Î½(B) = inf
 âˆ
	
i=1

Ïˆ(bi) âˆ’Ïˆ(ai)
  B âŠ‚
âˆ

i=1
(ai, bi]
'
.
(5.5)
It follows that the Borel measure Î½ is concentrated on the Borel set B âŠ†[a, b]
if and only if the associated function Ïˆ is constant except for jumps at the
points t âˆˆB.
Let Âµ âˆˆM[a, b] be given. Applying what has just been said about Î½ to
Âµ+ and Âµâˆ’, we obtain nondecreasing right continuous functions Ï•+ and Ï•âˆ’
on [a, b]. Then the function Ï• := Ï•+ âˆ’Ï•âˆ’is right continuous and of bounded
variation on [a, b], and we have

[a,b]
x(t) dÂµ(t) =

[a,b]
x(t) dÏ•(t)
âˆ€x âˆˆC[a, b].
Recall that T(Â¯x) := {t âˆˆT | |Â¯x(t) âˆ’z(t)| = âˆ¥Â¯x âˆ’zâˆ¥âˆ}. Now we can establish
the following:
Proposition 5.3.6 (Classical Chebyshev Approximation) Let
A
de-
note the set of (the restrictions to [a, b] of) all polynomials of degree at most
n, where n âˆˆN. Further let z âˆˆC[a, b] \ A. If Â¯x âˆˆA is a best approximation
of z with respect to A, then the set T(Â¯x) contains at least n + 2 points.
Proof. According to Propositions 4.6.4 and 5.2.5, and by what has been said
above, there exists a right continuous function Ï• of bounded variation on [a, b]
that is constant except for jumps on T(Â¯x) (Fig. 5.3) and satisï¬es

5.4 Existence of Minimum Points and the Ritz Method
99
âˆ¥Â¯x âˆ’zâˆ¥âˆ
âˆ’âˆ¥Â¯x âˆ’zâˆ¥âˆ
a
t1
t2
t
Ï•
Â¯x âˆ’z
b
Fig. 5.3

[a,b]
x(t) dÏ•(t) = 0
âˆ€x âˆˆA.
(5.6)
The latter result follows from the fact that âŸ¨xâˆ—, Â¯xâŸ©= minxâˆˆAâŸ¨xâˆ—, xâŸ©is
equivalent to âŸ¨xâˆ—, Â¯xâŸ©= 0 since in the present case A is a linear subspace of
C[a, b]. Now suppose that T(Â¯x) contains only m elements t1, . . . , tm, where
m < n + 2. We may assume that a < t1 < t2 < Â· Â· Â· < tm â‰¤b. For k âˆˆ
{1, . . . , m} deï¬ne
x(t) :=
m
+
i=1
iÌ¸=k
(t âˆ’ti), t âˆˆ[a, b].
Then x is (the restriction to [a, b] of) a polynomial of degree m âˆ’1 and so
belongs to A. In view of (5.6), we obtain
0 =

[a,b]
x(t) dÏ•(t) =
m
	
i=1
x(ti)

Ï•(ti) âˆ’Ï•(ti âˆ’0)

= x(tk)

Ï•(tk) âˆ’Ï•(tk âˆ’0)

.
As x(tk) Ì¸= 0, it follows that Ï• is continuous at tk, which is a contradiction.
âŠ“âŠ”
5.4 Existence of Minimum Points and the Ritz Method
In this section and in Sect. 5.5 we digress from the main road of these lectures,
brieï¬‚y discussing the existence of minimizers of
f : M â†’R,
where M is a nonempty subset of a normed vector space E. We start with a
deï¬nition.
Deï¬nition 5.4.1 A sequence (xn) in M is said to be a minimizing sequence
for f if limnâ†’âˆf(xn) = infxâˆˆM f(x).

100
5 Optimality Conditions for Convex Problems
It is clear that a minimizing sequence for f always exists but it need not be
convergent. If it happens to be convergent, the limit may fail to be a minimizer
of f. The starting point for existence results is a generalization of a well-known
Weierstrass theorem.
Proposition 5.4.2 Let M âŠ†E be (weakly) sequentially compact and f :
M â†’R (weakly) sequentially lower semicontinuous. Then:
(a) There exists Â¯x âˆˆM satisfying f(Â¯x) = minxâˆˆM f(x).
(b) Every minimizing sequence for f contains a subsequence that (weakly) con-
verges to a minimizer of f on M.
Proof. Let (xn) be a minimizing sequence for f. Since M is (weakly) sequen-
tially compact, some subsequence (xnj) of (xn) is (weakly) convergent to some
Â¯x âˆˆM. Since f is (weakly) sequentially l.s.c., it follows that
f(Â¯x) â‰¤lim inf
jâ†’âˆf(xnj) = lim
nâ†’âˆf(xn) = inf
xâˆˆM f(x).
âŠ“âŠ”
Concerning the assumptions of Proposition 5.4.2, observe that sequential
compactness of M is too restrictive for most applications. In general, even
weak sequential compactness is not appropriate. We tackle this problem in
the following way:
1. We assume that E is a reï¬‚exive Banach space. Then by the Eberleinâ€“
Å mulian Theorem (Theorem 1.6.7), each bounded, sequentially closed sub-
set M is weakly sequentially compact.
2. In order to get rid of boundedness which is still too restrictive, we replace
this hypothesis on M by an hypothesis on f to be deï¬ned now.
Deï¬nition 5.4.3 The functional f
:
M
â†’
R is said to be coercive
if for any sequence (xn) in M satisfying limnâ†’âˆâˆ¥xnâˆ¥= +âˆone has
lim supnâ†’âˆf(xn) = +âˆ.
We consider the following assumptions:
(A1) E is a reï¬‚exive Banach space,
M is a nonempty, weakly sequentially closed subset of E,
f : M â†’R is weakly sequentially l.s.c.,
either M is bounded or f is coercive.
Theorem 5.4.4 Under the assumptions (A1), the following holds:
(a) There exists Â¯x âˆˆM such that f(Â¯x) = minxâˆˆM f(x).
(b) Each minimizing sequence for f contains a subsequence that weakly con-
verges to a minimizer of f on M.
Proof. (I) As discussed above, if M is bounded, the assertion is a consequence
of Proposition 5.4.2 and the Eberleinâ€“Å mulian Theorem.

5.4 Existence of Minimum Points and the Ritz Method
101
(II) Assume now that M is unbounded and f is coercive. Choose some x0 âˆˆM
and set M0 := {x âˆˆM | f(x) â‰¤f(x0)}. Notice that
inf
xâˆˆM f(x) = inf
xâˆˆM0 f(x).
(5.7)
Since M is weakly sequentially closed and f is weakly sequentially l.s.c. on
M, the set M0 is weakly sequentially closed. Moreover, since f is coercive,
M0 is bounded. By Proposition 5.4.2(a), f has a minimizer on M0 which
by (5.7) is also a minimizer of f on M. This proves (a). Concerning (b),
notice that each minimizing sequence for f in M is eventually in M0 so
that Proposition 5.4.2(b) applies with M replaced by M0.
âŠ“âŠ”
The example f(x) = ex, x âˆˆR, shows that a minimizer may fail to exist
if M is unbounded and f is not coercive.
Corollary 5.4.5 Let E be a ï¬nite-dimensional Banach space and M a non-
empty closed subset of E. Then projM(z) is nonempty for any z âˆˆE.
Proof. This follows immediately by applying Theorem 5.4.4 to f(x) := âˆ¥xâˆ’zâˆ¥,
x âˆˆE.
âŠ“âŠ”
Now we pass from (A1) to assumptions that are easier to verify:
(A2) E is a reï¬‚exive Banach space,
M is a nonempty, convex, and closed subset of E,
f : D â†’R (where D âŠ†E is open and contains M) is strictly convex
and G-diï¬€erentiable on M,
either M is bounded or f is coercive on M.
Theorem 5.4.6 Under the assumptions (A2), the functional f has precisely
one minimizer Â¯x on M, and each minimizing sequence for f on M is weakly
convergent to Â¯x.
Proof. (I) First we show that the strict convexity of f entails that f has at
most one minimizer on M. Suppose, to the contrary, that x1 and x2 are
minimizers of f on M with x1 Ì¸= x2 and f(x1) = f(x2) =: a. Then
f
 1
2x1 + 1
2x2

< 1
2f(x1) + 1
2f(x2) = a,
which is a contradiction.
(II) By Corollary 1.6.6, M is weakly sequentially closed. By Propositions 1.7.3
and 4.1.9, f is weakly sequentially l.s.c. Hence the assumptions (A1) are
satisï¬ed so that Theorem 5.4.4 applies. By statement (b) of that theorem,
all weakly convergent subsequences of a minimizing sequence (xn) for f
have the same limit Â¯x; hence the entire sequence (xn) is weakly convergent
to Â¯x.
âŠ“âŠ”

102
5 Optimality Conditions for Convex Problems
With a given bâˆ—âˆˆEâˆ—, we now consider the following statements:
f(Â¯x) âˆ’âŸ¨bâˆ—, Â¯xâŸ©= min
xâˆˆE

f(x) âˆ’âŸ¨bâˆ—, xâŸ©

(minimum problem),
(5.8)
âŸ¨f â€²(Â¯x) âˆ’bâˆ—, yâŸ©= 0
âˆ€y âˆˆE
(variational equation),
(5.9)
f â€²(Â¯x) = bâˆ—
(operator equation).
(5.10)
We specify the assumptions:
(A3) E is a reï¬‚exive Banach space, f : E â†’R is G-diï¬€erentiable,
f â€² is uniformly monotone (with constants c > 0 and Î³ > 1).
Theorem 5.4.7 If (A3) is satisï¬ed, then for each bâˆ—âˆˆEâˆ—the following
holds:
(a) The problems (5.8)â€“(5.10) are mutually equivalent and have precisely one
solution Â¯x âˆˆE.
(b) Each minimizing sequence (xn) for f âˆ’bâˆ—is convergent to Â¯x, and one has
the error estimate
c
Î³ âˆ¥xn âˆ’Â¯xâˆ¥Î³ â‰¤(f âˆ’bâˆ—)(xn) âˆ’(f âˆ’bâˆ—)(Â¯x).
(5.11)
Proof. (a) Set g := f âˆ’bâˆ—. Then g is G-diï¬€erentiable with gâ€²(x) = f â€²(x) âˆ’bâˆ—
for any x âˆˆE and so gâ€² is also uniformly monotone with constants c and Î³.
(I) The equivalence of (5.8) and (5.9) follows from Corollary 5.1.2. The
equivalence of (5.9) and (5.10) is obvious.
(II) Existence and uniqueness. By Proposition 4.3.9, g is strictly convex
and
g(y) âˆ’g(x) â‰¥âŸ¨gâ€²(x), y âˆ’xâŸ©+ c
Î³ âˆ¥y âˆ’xâˆ¥Î³
âˆ€x, y âˆˆE.
(5.12)
We deduce that
g(y) âˆ’g(o) â‰¥âˆ¥yâˆ¥

âˆ’âˆ¥gâ€²(x)âˆ¥+ c
Î³ âˆ¥yâˆ¥Î³âˆ’1
.
The term in parentheses is positive if âˆ¥yâˆ¥is large enough, hence g is
coercive. By Theorem 5.4.6, g has precisely one minimizer Â¯x âˆˆE.
(b) We have gâ€²(Â¯x) = o. If (xn) is any minimizing sequence for g, then (5.12)
with x := Â¯x gives
c
Î³ âˆ¥xn âˆ’Â¯xâˆ¥Î³ â‰¤g(xn) âˆ’g(Â¯x) â†’0
as n â†’âˆ.
âŠ“âŠ”
Remark 5.4.8 Theorem 5.4.7, in particular, shows that under the assump-
tions (A3) the G-derivative f â€² is a bijective mapping of E onto Eâˆ—. This
observation closes the gap in the proof of Proposition 4.4.3.

5.4 Existence of Minimum Points and the Ritz Method
103
The Ritz Method
We now describe a method for constructing a minimizing sequence and so for
approximately calculating a minimizer. The basic idea is to replace the original
problem, which is placed in an inï¬nite-dimensional space, by a sequence of
ï¬nite-dimensional problems.
Suppose that E is an inï¬nite-dimensional normed vector space. A count-
able subset {zk | k âˆˆN} of E is called basis of E if ï¬nitely many zk are always
linearly independent and one has
E = cl

nâˆˆN
En,
where
En := span{z1, . . . , zn}.
Using transï¬nite induction, it is easy to prove:
Lemma 5.4.9 If E is separable, then E possesses a basis.
The Ritz method consists in replacing, for each n âˆˆN, the problems (5.8)
and (5.9) by the following n-dimensional problems:
f(Â¯xn) âˆ’âŸ¨bâˆ—, Â¯xnâŸ©= min
xnâˆˆEn

f(xn) âˆ’âŸ¨bâˆ—, xnâŸ©

(Ritz minimum problem),
(5.8a)
âŸ¨f â€²(Â¯xn) âˆ’bâˆ—, zkâŸ©= 0
âˆ€k = 1, . . . , n
(Ritz equations).
(5.9a)
For a given basis {zk | k âˆˆN} of E, each Â¯xn âˆˆEn is representable as
Â¯xn = n
j=1 Î¾jzj, where Î¾j âˆˆR. Hence, (5.9a) is a system of n equations (in
general nonlinear) for (Î¾1, . . . , Î¾n) âˆˆRn and so can be solved by numerical
methods. This yields a numerical approximation of Â¯xn. We shall not pursue
the numerical aspect. Rather we assume that the exact Â¯xn is known and ask
how it is related to a solution Â¯x of the original problems (5.8) and (5.9).
We shall give a convergence proof for the special case that f is a quadratic
functional of the form
f(x) := 1
2 a(x, x),
x âˆˆE.
(5.13)
In this connection, we make the following assumptions:
(A4) E is an inï¬nite-dimensional separable reï¬‚exive Banach space with basis
{zk | k âˆˆN}, a : E Ã— E â†’R is bilinear, symmetric, bounded, and
strongly positive, bâˆ—âˆˆEâˆ—.
Recall that a is said to be bounded if with some constant Îº > 0,
|a(x, y)| â‰¤Îº âˆ¥xâˆ¥âˆ¥yâˆ¥
âˆ€x, y âˆˆE,
(5.14)

104
5 Optimality Conditions for Convex Problems
and a is said to be strongly positive if with some constant c > 0,
a(x, x) â‰¥c âˆ¥xâˆ¥2
âˆ€x âˆˆE.
(5.15)
If (A4) holds, then by Example 4.3.6 the functional f deï¬ned by (5.13) is
continuously diï¬€erentiable, the derivative is given by âŸ¨f â€²(x), yâŸ©= a(x, y) for
all x, y âˆˆE, and f â€² is strongly monotone with constant c. The problems (5.8)
and (5.9) now pass, respectively, into
1
2 a(Â¯x, Â¯x) âˆ’âŸ¨bâˆ—, Â¯xâŸ©= min
xâˆˆE
 1
2 a(x, x) âˆ’âŸ¨bâˆ—, xâŸ©

,
(5.16)
a(Â¯x, y) âˆ’âŸ¨bâˆ—, yâŸ©= 0
âˆ€y âˆˆE.
(5.17)
The associated Ritz problems are
1
2 a(Â¯xn, Â¯xn) âˆ’âŸ¨bâˆ—, Â¯xnâŸ©= min
xnâˆˆEn
 1
2 a(xn, xn) âˆ’âŸ¨bâˆ—, xnâŸ©

,
(5.16a)
a(Â¯xn, zk) âˆ’âŸ¨bâˆ—, zkâŸ©= 0
âˆ€k = 1, . . . , n.
(5.17a)
Notice that the minimum problems (5.16) and (5.16a) are quadratic, the
variational equations (5.17) and (5.17a) are linear.
Theorem 5.4.10 If (A4) holds, then:
(a) The problems (5.16) and (5.17) are equivalent and possess precisely one
solution Â¯x âˆˆE.
(b) For each n âˆˆN, (5.16a) and (5.17a) are equivalent and possess precisely
one solution Â¯xn âˆˆEn.
(c) The sequence (Â¯xn) is minimizing for f âˆ’bâˆ—, converges to Â¯x as n â†’âˆ, and
satisï¬es
âˆ¥Â¯xn âˆ’Â¯xâˆ¥â‰¤Îº
c d(Â¯x, En)
âˆ€n âˆˆN.
Here, f, Îº, and c are as in (5.13), (5.14), and (5.15), respectively.
Proof. (I) Example 4.3.6 shows that, with f according to (5.13), the
assumptions (A3) are satisï¬ed. Therefore assertion (a) is a consequence
of Theorem 5.4.7. Analogously, applying Theorem 5.4.7 with E replaced
by En yields (b).
(II) Convergence. From (5.17) with y = yn and (5.17a) we see that
a(Â¯x âˆ’Â¯xn, yn) = 0
âˆ€yn âˆˆEn
(5.18)
and, in particular, a(Â¯x âˆ’Â¯xn, Â¯xn) = 0. This and (5.18) yield
a(Â¯x âˆ’Â¯xn, Â¯x âˆ’Â¯xn) = a(Â¯x âˆ’Â¯xn, Â¯x âˆ’yn)
âˆ€yn âˆˆEn.
Since a is strongly positive and bounded, we deduce
c âˆ¥Â¯x âˆ’Â¯xnâˆ¥2 â‰¤Îº âˆ¥Â¯x âˆ’Â¯xnâˆ¥âˆ¥Â¯x âˆ’ynâˆ¥
âˆ€yn âˆˆEn

5.5 Application to Boundary Value Problems
105
and so
âˆ¥Â¯x âˆ’Â¯xnâˆ¥â‰¤Îº
c
inf
ynâˆˆEn âˆ¥Â¯x âˆ’ynâˆ¥= Îº
c d(Â¯x, En).
Since En âŠ†En+1 for all n and 
n En is dense in E, we have d(Â¯x, En) â†’0
as n â†’âˆ. Hence Â¯xn â†’Â¯x as n â†’âˆ. This also shows that the sequence
(Â¯xn) is minimizing for f âˆ’bâˆ—as the latter functional is continuous.
âŠ“âŠ”
5.5 Application to Boundary Value Problems
Our aim in this section is to apply Theorems 5.4.7 and 5.4.10 to a boundary
value problem. We start by introducing some notation. Let G be a bounded
region in RN, with boundary âˆ‚G and closure G = Gâˆªâˆ‚G. Recall that a region
is a nonempty open connected set. We set
Ck(G) := set of all continuous functions u : G â†’R with continuous
partial derivatives up to and including order k on G such that
the partial derivatives can be continuously extended to G.
Câˆ
c (G) := set of all continuous functions u : G â†’R having continuous
partial derivatives of arbitrary order on G and vanishing
outside a compact subset of G (that depends on u).
In particular, C(G) := C0(G) denotes the set of all continuous functions
on G. We write x = (x1, . . . , xN) for the independent variable ranging over G
and we denote by Di diï¬€erentiation with respect to the ith coordinate, where
i = 1, . . . , N. Let p âˆˆ(1, +âˆ) be ï¬xed. We consider the Lebesgue space Lp(G)
with norm
âˆ¥uâˆ¥p :=

G
|u|p dx
1/p
and the Sobolev spaces
W1,p(G) :=

u âˆˆLp(G)
 Diu exists in Lp(G) for i = 1, . . . , N

,
W1,p
0 (G) := closure of Câˆ
c (G) in W1,p(G).
In this connection, Diu now denotes the generalized derivative of u with
respect to the ith coordinate. By deï¬nition, Diu is an element of Lp(G) that
satisï¬es the integration-by-parts formula

G

Diu

v dx = âˆ’

G
u

Div

dx
âˆ€v âˆˆCâˆ
c (G).
(5.19)
The norm in W1,p(G) is given by
âˆ¥uâˆ¥1,p :=


G

|u|p +
N
	
i=1
|Diu|p
dx
1/p
.

106
5 Optimality Conditions for Convex Problems
On W1,p
0 (G), the following norm âˆ¥Â· âˆ¥1,p,0 is equivalent to âˆ¥Â· âˆ¥1,p :
âˆ¥uâˆ¥1,p,0 :=


G
N
	
i=1
|Diu|p dx
1/p
.
W1,p(G) and W1,p
0 (G) are separable reï¬‚exive Banach spaces. In particular,
W1,2(G) and W1,2
0 (G) are Hilbert spaces with respect to the inner product
(u | v)1,2 :=

G

uv +
N
	
i=1
Diu Div

dx.
We start with the following classical boundary value problem. Given g âˆˆ
C(G), ï¬nd u âˆˆC2(G) satisfying
âˆ’
N
	
i=1
Di

|Diu|pâˆ’2Diu

= g on G,
u = 0 on âˆ‚G.
(5.20)
For p = 2 this is the famous Dirichlet problem or the ï¬rst boundary value
problem for the Poisson equation. Observe that for p > 2 the problem is
nonlinear. Since the problem may fail to have a solution unless the function
g and the boundary âˆ‚G are suï¬ƒciently smooth, we pass to a generalized
problem. This is obtained heuristically by multiplying the diï¬€erential equation
in (5.20) by v âˆˆCâˆ
c (G) and applying the integration-by-parts formula (5.19):

G
N
	
i=1
|Diu|pâˆ’2Diu Div dx =

G
gv dx
âˆ€v âˆˆCâˆ
c (G).
(5.21)
Conversely, if u âˆˆC2(G) satisï¬es (5.21) and u = 0 on âˆ‚G, then u is also a
solution of (5.20).
The generalized boundary value problem associated with (5.20) now reads
as follows. Given g âˆˆLq(G), where 1
p + 1
q = 1, ï¬nd u âˆˆW1,p
0 (G) such that

G
N
	
i=1
|Diu|pâˆ’2Diu Div dx =

G
gv dx
âˆ€v âˆˆW1,p
0 (G).
(5.22)
In this connection, recall that Câˆ
c (G) is dense in W1,p
0 (G) and that the
elements of W1,p
0 (G) have vanishing generalized boundary values. In view of
the above discussion, it is reasonable to say that a solution of (5.22) is a
generalized solution of (5.20).
Parallel to (5.22) we also consider the variational problem

5.5 Application to Boundary Value Problems
107

G

1
p
N
	
i=1
|Diu|p âˆ’gu

dx âˆ’â†’min,
u âˆˆW1,p
0 (G).
(5.23)
The following result ensures, in particular, that under weak assumptions
problem (5.20) has a generalized solution.
Proposition 5.5.1 Let G be a bounded region in RN and let p âˆˆ[2, +âˆ).
Then for any g âˆˆLq(G), where 1
p + 1
q = 1, the problems (5.22) and (5.23) are
equivalent and have precisely one solution u âˆˆW1,p
0 (G).
Before verifying this result, we establish two inequalities.
Lemma 5.5.2 Let N âˆˆN, p â‰¥2, and r > 0 be given.
(a) There exists c1 > 0 (depending on N and r) such that

 N
	
i=1
|xi|
r
â‰¤c1
N
	
i=1
|xi|r
âˆ€(x1, . . . , xN) âˆˆRN.
(5.24)
(b) There exists c2 > 0 (depending on p) such that
(|Î±|pâˆ’2Î± âˆ’|Î²|pâˆ’2Î²)(Î± âˆ’Î²) â‰¥c2|Î± âˆ’Î²|p
âˆ€Î±, Î² âˆˆR.
(5.25)
Proof. (a) First let r â‰¥1. Then âˆ¥xâˆ¥r :=
N
i=1 |xi|r1/r deï¬nes a norm on
RN. Since all norms on RN are equivalent, there exists c1 > 0 such that
âˆ¥xâˆ¥1 â‰¤c1/r
1
âˆ¥xâˆ¥r for each x âˆˆRN. This proves (5.24) if r â‰¥1. If 0 < r < 1,
then argue similarly with âˆ¥Â· âˆ¥s, where s := 1/r.
(b) First assume that 0 â‰¤Î² â‰¤Î±. Then
Î±pâˆ’1âˆ’Î²pâˆ’1 = (pâˆ’1)
 Î±âˆ’Î²
0
(t+Î²)pâˆ’2 dt â‰¥(pâˆ’1)
 Î±âˆ’Î²
0
tpâˆ’2 dt=(Î±âˆ’Î²)pâˆ’1,
which implies (5.25) in this case. Now let Î² â‰¤0 â‰¤Î±. Then (5.24) shows
that Î±pâˆ’1+|Î²|pâˆ’1 â‰¥c(Î±+|Î²|)pâˆ’1 and again (5.25) follows. The remaining
cases can be reduced to the two considered.
âŠ“âŠ”
Proof of Proposition 5.5.1. Our aim is to show that Theorem 5.4.7 applies to
E := W1,p
0 (G),
f(u) :=

G
1
p
N
	
i=1
|Diu|p dx,
bâˆ—(u) :=

G
gu dx,
u âˆˆE.
(I) First observe that the Sobolev space E is a reï¬‚exive Banach space.
(II) It is clear that the integral deï¬ning f(u) exists for any u âˆˆE.

108
5 Optimality Conditions for Convex Problems
(III) We show that f is G-diï¬€erentiable on E. Recall that
fG(u, v) = âˆ‚
âˆ‚Ï„ f(u + Ï„v)

Ï„=0.
We show that partial diï¬€erentiation by Ï„ and integration over G can be
exchanged. For ï¬xed u, v âˆˆE, consider the function
Î³(x, Ï„) := 1
p
N
	
i=1
|Diu + Ï„Div|p,
x âˆˆG,
Ï„ âˆˆ(âˆ’1, 1).
Notice that
âˆ‚
âˆ‚Ï„ Î³(x, Ï„) = 1
p
N
	
i=1
|Diu + Ï„Div|pâˆ’2(Diu + Ï„Div) Â· Div
and so
 âˆ‚
âˆ‚Ï„ Î³(x, Ï„)
 â‰¤1
p
N
	
i=1
|Diu + Ï„Div|pâˆ’1 Â· |Div|
â‰¤
(5.24)
c
N
	
i=1

|Diu|pâˆ’1 + |Div|pâˆ’1
Â· |Div|.
(5.26)
Under the last sum sign, the ï¬rst factor is in Lq(G) (notice that (pâˆ’1)q =
p) and the second factor is in Lp(G). Hence the HÂ¨older inequality shows
that the right-hand side of (5.26) is integrable over G and so is the
left-hand side. Therefore, measure theory tells us that we may write
fG(u, v) =

G
âˆ‚
âˆ‚Ï„ Î³(x, Ï„)

Ï„=0dx =

G
N
	
i=1
|Diu|pâˆ’2Diu Â· Div dx.
(5.27)
The function v â†’fG(u, v) is linear, and the following estimate using
the HÂ¨older inequality shows that it is also continuous
|fG(u, v)| â‰¤
N
	
i=1

G
|Diu|(pâˆ’1)qdx
1/q
Â·

G
|Div|pdx
1/p
â‰¤c âˆ¥vâˆ¥E;
here, c is independent of v. Hence f is G-diï¬€erentiable on E, the G-
derivative being given by (5.27).
(IV) We show that f â€² is uniformly monotone. Let u, *u âˆˆE be given. Then

f â€²(u) âˆ’f â€²(*u), u âˆ’*u
 
=

G
N
	
i=1

|Diu|pâˆ’2Diu âˆ’|Di*u|pâˆ’2Di*u
 
Diu âˆ’Di*u

dx
â‰¥c

G
N
	
i=1
|Diu âˆ’Di*u|p dx = c âˆ¥u âˆ’*uâˆ¥p
1,p,0 â‰¥Ëœc âˆ¥u âˆ’*uâˆ¥p
1,p.

5.5 Application to Boundary Value Problems
109
In this connection, the ï¬rst inequality holds by Lemma 5.5.2(b) and the
second follows from the equivalence of the two norms on E.
(V) In view of the above, the generalized boundary value problem (5.22) is
equivalent to the variational equation âŸ¨f â€²(u) âˆ’bâˆ—, vâŸ©= 0 for all v âˆˆE.
Hence the assertion is a consequence of Theorem 5.4.7.
âŠ“âŠ”
In the special case p = 2 we now apply the Ritz method to the problems
(5.22) and (5.23). In other words, setting
E := W1,2
0 (G),
a(u, v) :=

G
N
	
i=1
Diu Div dx,
âŸ¨bâˆ—, vâŸ©:=

G
gv dx,
(5.28)
we consider the problems (cf. (5.16) and (5.17))
1
2 a(Â¯u, Â¯u) âˆ’âŸ¨bâˆ—, Â¯uâŸ©= min
uâˆˆE
 1
2 a(u, u) âˆ’âŸ¨bâˆ—, uâŸ©

,
(5.29)
a(Â¯u, v) âˆ’âŸ¨bâˆ—, vâŸ©= 0
âˆ€v âˆˆE,
(5.30)
as well as the associated Ritz problems corresponding to a basis {zk | k âˆˆN}
of E (cf. (5.16a) and (5.17a)),
1
2 a(Â¯un, Â¯un) âˆ’âŸ¨bâˆ—, Â¯unâŸ©= min
unâˆˆEn
 1
2 a(un, un) âˆ’âŸ¨bâˆ—, unâŸ©

,
(5.29a)
a(Â¯un, zk) âˆ’âŸ¨bâˆ—, zkâŸ©= 0
âˆ€k = 1, . . . , n.
(5.30a)
For all u, v âˆˆE we have the following estimates:
|a(u, v)| â‰¤
N
	
i=1

G
|Diu Div| dx â‰¤
N
	
i=1
âˆ¥Diuâˆ¥2 Â· âˆ¥Divâˆ¥2 â‰¤Nâˆ¥uâˆ¥1,2 Â· âˆ¥vâˆ¥1,2,
|âŸ¨bâˆ—, vâŸ©| â‰¤âˆ¥gâˆ¥2 Â· âˆ¥vâˆ¥2 â‰¤âˆ¥gâˆ¥2 Â· âˆ¥vâˆ¥1,2,
a(u, u) = âˆ¥uâˆ¥2
1,2,0 â‰¥c âˆ¥uâˆ¥2
1,2.
In the ï¬rst two lines, we applied the HÂ¨older (or Cauchyâ€“Schwarz) inequality.
The inequality in the third line is the PoincarÃ©â€“Friedrichs inequality (which
leads to the equivalence of the norms âˆ¥Â· âˆ¥1,2,0 and âˆ¥Â· âˆ¥1,2 on E). The above
estimates show that the assumptions (A4) of Sect. 5.4 are satisï¬ed. As a con-
sequence of Theorem 5.4.10 we therefore obtain:
Proposition 5.5.3 With the notation of (5.28), the following holds:
(a) The problems (5.29) and (5.30) are equivalent and possess precisely one
solution Â¯u âˆˆE.
(b) For each n âˆˆN, (5.29a) and (5.30a) are equivalent and possess precisely
one solution Â¯un âˆˆEn.
(c) The sequence (Â¯un) satisï¬es
âˆ¥Â¯un âˆ’Â¯uâˆ¥1,2 â‰¤N
c d(Â¯u, En)
âˆ€n âˆˆN.
In particular, (Â¯un) converges to Â¯u as n â†’âˆ.

110
5 Optimality Conditions for Convex Problems
5.6 Bibliographical Notes and Exercises
Concerning the subject of this chapter, we refer to the Bibliographical Notes
at the end of Chap. 4. The optimality conditions for convex optimization prob-
lems are due to John [105], and Kuhn and Tucker [114], with Karush [109] as
an early (rather late perceived) predecessor.
The presentation in Sect. 5.5 was strongly inï¬‚uenced by Zeidler [221]. More
results on the approximation problem in function spaces oï¬€er, among others,
Braess [27], Holmes [91], Krabs [112], and Laurent [118].
A result analogous to Theorem 5.4.10 holds under the more general as-
sumptions (A3) (if, in addition, E is inï¬nite dimensional and separable); see,
for instance, Zeidler [221] or Schirotzek [196]. The theory of monotone oper-
ators provides an important generalization concerning both the solvability of
variational equations (or inequalities) and the convergence of an approxima-
tion method, the Galerkin method. For this and many substantial applications
we recommend the comprehensive monograph by Zeidler [223,224]. Concern-
ing the numerical analysis of the Ritz and Galerkin methods we refer to
Atkinson and Han [4], and GroÃŸmann and Roos [81].
Standard references on the theory of Sobolev spaces are Adams [1] and
Ziemer [228].
Exercise 5.6.1 Prove the implications (SP) â‡â‡’(L) =â‡’(Min 2) of Theo-
rem 5.2.1(a).
Exercise 5.6.2 Verify Theorem 5.2.3.
Hint: To see that (Min 2) implies (J), consider the functional p : E â†’R
deï¬ned by
p(x) :=
*L(x; Â¯Î», Â¯Âµ1, . . . , Â¯Âµm) + Î´A(x)
if x âˆˆD,
+âˆ
if x âˆˆE \ D
Exercise 5.6.3 Prove Proposition 5.3.1.
Exercise 5.6.4 UsingProposition5.2.5(a)â‡”(b),formulateandverifyacharac-
terization of best approximation in C(T), where T is a compact Hausdorï¬€space.
Exercise 5.6.5 Let E be a Hilbert space and T : E â†’E be a continuous
linear self-adjoint operator. Deï¬ne f(x) :=
1
2(Tx | x) for all x âˆˆE. Show
that any local maximizer or minimizer Â¯x of f over {x âˆˆE | âˆ¥xâˆ¥= 1} is an
eigenvector of T with associated eigenvalue Î» = 2f(Â¯x).
Exercise 5.6.6 Let A be a convex subset of an n-dimensional subspace of E
and let f : E â†’R be continuous at Â¯x âˆˆA. Show that Â¯x minimizes f over
A if and only if for any i = 1, . . . , n + 1 there exist xâˆ—
i âˆˆâˆ‚f(Â¯x) and Î»i â‰¥0
satisfying
n+1
	
i=1
Î»i = 1
and
n+1
	
i=1
Î»iâŸ¨xâˆ—
i , Â¯xâŸ©= min
xâˆˆA
n+1
	
i=1
Î»iâŸ¨xâˆ—
i , xâŸ©.
Hint: Recall Exercise 4.8.10.

6
Duality of Convex Problems
The idea of duality in convex optimization theory is, roughly speaking, the
following. With a given optimization problem, called primal problem in this
context, one associates another problem, called dual problem, in such a way
that there is a close relationship between the two problems. The motivation
is that the dual problem may be easier to solve than the primal one (which is
sometimes really the case) or that at least the dual problem furnishes addi-
tional information about the primal one.
6.1 Duality in Terms of a Lagrange Function
Assume that
A âŠ†E is a nonempty convex set,
f, g1, . . . , gm : A â†’R are convex functionals,
M := {x âˆˆA | gi(x) â‰¤0 (i = 1, . . . , m)}, Â¯x âˆˆM.
We continue studying the minimization of f on M (cf. Sect. 5.2). We set
Î± := inf
xâˆˆM f(x).
(6.1)
Further we deï¬ne the Lagrange functional L : A Ã— Rm
+ â†’R by
L(x, q) := f(x) +
m
	
i=1
qi gi(x)
âˆ€x âˆˆA âˆ€q = (q1, . . . , qm) âˆˆRm
+.
(6.2)
We then have
sup
qâˆˆRm
+
L(x, q) =

f(x)
if x âˆˆM,
+âˆ
if x âˆˆA \ M

112
6 Duality of Convex Problems
and so we obtain
Î± = inf
xâˆˆA
sup
qâˆˆRm
+
L(x, q).
(6.3)
Parallel to (6.3) we now consider
Î² := sup
qâˆˆRm
+
inf
xâˆˆA
L(x, q).
(6.4)
The original minimization problem, which is described by (6.1) and so by
(6.3), is called primal problem. The associated problem described by (6.4) is
called dual problem. We say that Â¯x âˆˆA is a solution of the primal problem
(6.3) if Â¯x âˆˆM and f(Â¯x) = Î±, thus if
sup
qâˆˆRm
+
L(Â¯x, q) = inf
xâˆˆA
sup
qâˆˆRm
+
L(x, q).
Analogously, Â¯q âˆˆRm
+ is said to be a solution of the dual problem (6.4) if
inf
xâˆˆA L(x, Â¯q) = sup
qâˆˆRm
+
inf
xâˆˆA
L(x, q).
Theorem 6.1.1 establishes relationships between the two problems. In this
connection, we again need the Slater condition (cf. (5.2))
âˆƒx0 âˆˆA : gi(x0) < 0 for i = 1, . . . , m.
(6.5)
Theorem 6.1.1 (Lagrange Duality) Assume that the space E is reï¬‚exive,
the subset A is nonempty, closed, and convex, and the functionals f, g1, . . . , gm
are l.s.c. and convex. Assume further that the Slater condition (6.5) is satis-
ï¬ed. Then:
(i)
One has Î± = Î², and the dual problem (6.4) has a solution Â¯q âˆˆRm
+.
(ii) For Â¯x âˆˆM, the following statements are equivalent:
(a) Â¯x is a solution of the primal problem (6.3).
(b) The Lagrange function L has a saddle point (Â¯x, Â¯q) with respect to
A Ã— Rm
+.
(iii) If (b) holds, then Â¯q is a solution of the dual problem (6.4), and one has
Â¯qi gi(Â¯x) = 0 for i = 1, . . . , m.
Theorem 6.1.1 will follow from Theorem 6.1.3 below.
Remark 6.1.2
(a) Comparing Theorem 6.1.1 with Theorem 5.2.1, we see that the â€œdual vari-
ableâ€ q is nothing else than the Lagrange multiplier vector, i.e., we have
qi = Âµi for i = 1, . . . , m.
(b) If the Slater condition is not satisï¬ed, a duality gap may occur which
means that we have Î± > Î². A trivial example is E = R, A = [âˆ’1, +âˆ),
f(x) = âˆ’x, g(x) = 1, where we have Î± = +âˆand Î² = âˆ’âˆ. An example

6.1 Duality in Terms of a Lagrange Function
113
with ï¬nite and diï¬€erent optimal values will be given below in a somewhat
diï¬€erent context (Example 6.1.7).
Now we replace the Lagrange functional L of (6.2) by an arbitrary func-
tional L : A Ã— B â†’R and consider
Î± := inf
xâˆˆA
sup
qâˆˆB
L(x, q)
(primal problem),
(6.6)
Î² := sup
qâˆˆB
inf
xâˆˆA
L(x, q)
(dual problem).
(6.7)
Theorem 6.1.3 (General Duality Theorem) Assume that E, F are ref-
lexive Banach spaces, that A âŠ†E and B âŠ†F are nonempty, closed, and
convex, and that L : A Ã— B â†’R satisï¬es
x â†’L(x, q) is l.s.c. and convex on A for each q âˆˆB,
q â†’âˆ’L(x, q) is l.s.c. and convex on B for each x âˆˆA.
Then:
(i)
One has Î± â‰¥Î² (weak duality).
(ii) For (Â¯x, Â¯q) âˆˆA Ã— B, the following statements are equivalent:
(a) Â¯x is a solution of (6.6), Â¯q is a solution of (6.7), and one has Î± = Î²
(strong duality).
(b) (Â¯x, Â¯q) is a saddle point of L with respect to A Ã— B.
(iii) Assume, in addition, that either A is bounded or L(x, q0) â†’+âˆas
âˆ¥xâˆ¥â†’+âˆ, x âˆˆA, for some q0 âˆˆB. Assume further that Î± < +âˆ.
Then the primal problem (6.6) has a solution Â¯x âˆˆA and one has Î± = Î².
(iv) Assume, in addition, that either B is bounded or âˆ’L(x0, q) â†’+âˆas
âˆ¥qâˆ¥â†’+âˆ, q âˆˆB, for some x0 âˆˆA. Assume further that Î² > âˆ’âˆ.
Then the dual problem (6.7) has a solution Â¯q âˆˆB and one has Î± = Î².
Remarks on the Proof of Theorem 6.1.3. The proof consists of two main
steps. First, the result is veriï¬ed under the additional assumption that A and
B are bounded. In this case, Neumannâ€™s minimax theorem can be applied,
which in turn is proved with the aid of Brouwerâ€™s ï¬xed point theorem. Sec-
ond, the general case is reduced to the ï¬rst one. If, say, A is unbounded, then
replace A by An := {x âˆˆA | âˆ¥xâˆ¥â‰¤n} and L by Ln(x, q) := L(x, q) + 1
nâˆ¥xâˆ¥2.
The proof can be found, e.g., in Zeidler [221].
âŠ“âŠ”
Proof of Theorem 6.1.1. Set F := Rm, B := Rm
+, and notice that the Slater
condition (6.5) implies
L(x0, q) = f(x0)+
m
	
i=1
qi gi(x0) â†’âˆ’âˆas âˆ¥qâˆ¥â†’+âˆ, q âˆˆRm
+.
âŠ“âŠ”
In view of Theorem 6.1.3, we can set up a general dualization principle.

114
6 Duality of Convex Problems
General Dualization Principle
Given the minimum problem f(x) â†’min, x âˆˆM, ï¬nd sets A, B and a func-
tion L : A Ã— B â†’R such that
inf
xâˆˆM f(x) = inf
xâˆˆA
sup
qâˆˆB
L(x, q)
and consider the following dual problem:
sup
qâˆˆB
inf
xâˆˆA
L(x, q).
Special Case
Here, we apply the dualization principle to problems of the form
Î± := inf
xâˆˆE

f(x) + h(Tx âˆ’a)

.
(6.8)
Below we shall see that the problem of linear optimization is of this form.
In connection with problem (6.8) we make the following assumptions:
(A) E and F are reï¬‚exive Banach spaces,
f : E â†’R and h : F â†’R are proper, convex, and l.s.c.,
T : E â†’F is linear and continuous, a âˆˆF.
We set
A := dom f, B := dom hâˆ—,
L(x, q) := f(x) + âŸ¨q, Tx âˆ’aâŸ©âˆ’hâˆ—(q)
âˆ€x âˆˆA âˆ€q âˆˆB.
(6.9)
It will turn out that
Î± = inf
xâˆˆA
sup
qâˆˆB
L(x, q).
(6.10)
By the general dualization principle, the dual to (6.10) and so to (6.8) is
Î² := sup
qâˆˆB
inf
xâˆˆA
L(x, q).
(6.11)
This will be shown to coincide with
Î² = sup
qâˆˆB

âˆ’f âˆ—(âˆ’T âˆ—q) âˆ’hâˆ—(q) âˆ’âŸ¨q, aâŸ©

.
(6.12)
Notice that hâˆ—denotes the conjugate of the functional h while T âˆ—denotes the
adjoint of the operator T.
Proposition 6.1.4 Under the assumptions (A), the problem dual to (6.8) is
(6.12). Hence all statements of Theorem 6.1.3 hold for (6.8) and (6.12).

6.1 Duality in Terms of a Lagrange Function
115
Proof.
(I) By Theorem 2.2.4, we have h = hâˆ—âˆ—and so
h(Tx âˆ’a) = hâˆ—âˆ—(Tx âˆ’a) = sup
qâˆˆF âˆ—

âŸ¨q, Tx âˆ’aâŸ©âˆ’hâˆ—(q)

,
which entails
Î± = inf
xâˆˆE
sup
qâˆˆF âˆ—

f(x) + âŸ¨q, Tx âˆ’aâŸ©âˆ’hâˆ—(q)

= inf
xâˆˆA
sup
qâˆˆB

. . .

,
and the latter term equals (6.10).
(II) We obtain
inf
xâˆˆA L(x, q) = âˆ’sup
xâˆˆA

âˆ’âŸ¨T âˆ—q, xâŸ©âˆ’f(x) + hâˆ—(q) + âŸ¨q, aâŸ©

= âˆ’f âˆ—(âˆ’T âˆ—q) âˆ’hâˆ—(q) âˆ’âŸ¨q, aâŸ©,
which shows that (6.11) coincides with (6.12).
âŠ“âŠ”
Example 6.1.5 We now apply Proposition 6.1.4 to the problem of linear
optimization which is
Î± := inf{âŸ¨c, xâŸ©| x âˆˆPE, Tx âˆ’a âˆˆPF }.
(6.13)
We make the following assumptions:
(ËœA) E and F are reï¬‚exive Banach spaces,
PE and PF are closed convex cones in E and F, respectively,
T : E â†’F is linear and continuous, c âˆˆEâˆ—, a âˆˆF.
Setting
f(x) :=

âŸ¨c, xâŸ©
if x âˆˆPE,
+âˆ
otherwise, h(b) :=

0
if b âˆˆPF ,
+âˆ
otherwise,
(6.14)
we see that problem (6.13) is of the form (6.8). Hence the dual problem is
(6.12), with f and h according to (6.14). In Exercise 6.5.1 it is shown that
this dual problem is equivalent to
Î² = sup{âŸ¨q, aâŸ©| q âˆˆâˆ’P â—¦
F , c âˆ’T âˆ—q âˆˆâˆ’P â—¦
E}.
(6.15)
Recall that P â—¦
E denotes the negative polar cone to PE. By Proposition 6.1.4
we have the following result.
Corollary 6.1.6 Under the assumptions (ËœA), all assertions of Theorem 6.1.3
apply to the problems (6.13) and (6.15).

116
6 Duality of Convex Problems
Example 6.1.7 We show that, in the situation of Corollary 6.1.6, a duality
gap with ï¬nite optimal values may occur (cf. Remark 6.1.2). Let E = F := R3,
Tx := (0, x3, x1)âŠ¤for x = (x1, x2, x3)âŠ¤âˆˆR3, c := (0, 0, 1)âŠ¤, and a :=
(0, âˆ’1, 0)âŠ¤. Equip R3 with the Euclidean norm âˆ¥Â· âˆ¥2. Further let PE = PF :=
K, where
K := {(x1, x2, x3)âŠ¤âˆˆR3 | x1 â‰¥0, x2 â‰¥0, 2x1x2 â‰¥x2
3}.
It is easy to see that with z0 := (1, 1, 0)âŠ¤, we have
K = {x âˆˆR3 | zâŠ¤
0 x â‰¥âˆ¥z0âˆ¥2 âˆ¥xâˆ¥2 cos(Ï€/4)}.
Hence K consists of all vectors x whose angle with the vector z0 is not greater
than Ï€/4. Observe that K is a closed convex cone (â€œice cream coneâ€) and that
Kâ—¦= âˆ’K. Further we have T âˆ—q = (q3, 0, q2)âŠ¤for q = (q1, q2, q3)âŠ¤âˆˆR3. Thus
the problems (6.13) and (6.15) read, respectively,
Î± = inf{x3 | x âˆˆK, (0, x3 âˆ’1, x1)âŠ¤âˆˆK},
Î² = sup{âˆ’q2 | q âˆˆK, (âˆ’q3, 0, 1 âˆ’q2)âŠ¤âˆˆK}.
It follows that Î± = 0 and Î² = âˆ’1. Notice that the primal problem and the
dual problem have inï¬nitely many solutions.
Exercise 6.5.5 presents an example where the optimal values of the primal
and the dual problem coincide but the primal problem has no solution.
6.2 Lagrange Duality and GÃ¢teaux Diï¬€erentiable
Functionals
Let w âˆˆEâˆ—. With f(x) := âˆ’âŸ¨w, xâŸ©, x âˆˆE, and a := o, the primal problem
(6.8) and the dual problem (6.12), respectively, read as follows:
Î± := inf
xâˆˆE

h(Tx) âˆ’âŸ¨w, xâŸ©

,
(6.16)
Î² := sup
qâˆˆB

âˆ’f âˆ—(âˆ’T âˆ—q) âˆ’hâˆ—(q)

.
We have
f âˆ—(âˆ’T âˆ—q) = sup
xâˆˆE

âŸ¨âˆ’T âˆ—q, xâŸ©+ âŸ¨w, xâŸ©

=

0
if w = T âˆ—q,
+âˆ
otherwise.
The assumptions in Proposition 6.2.1 will entail that B := dom hâˆ—= F âˆ—.
Setting
K := {q âˆˆF âˆ—| w = T âˆ—q},
(6.17)
we thus see that the problem dual to (6.16) is
Î² = sup
qâˆˆK

âˆ’hâˆ—(q)

.
(6.18)

6.2 Lagrange Duality and GÃ¢teaux Diï¬€erentiable Functionals
117
Proposition 6.2.1 Assume that:
E and F are reï¬‚exive Banach spaces, h : F â†’R is G-diï¬€erentiable,
hâ€² : F â†’F âˆ—is uniformly monotone with constants c > 0 and Î³ > 1,
T : E â†’F is linear and isometric (i.e., âˆ¥Txâˆ¥= âˆ¥xâˆ¥âˆ€x âˆˆE).
Then:
(a) Problem (6.16) has precisely one solution Â¯x âˆˆE, problem (6.18) has pre-
cisely one solution Â¯q âˆˆK, and one has Î± = Î².
(b) x = Â¯x is also the unique solution of

hâ€²(Tx), Ty
 
= âŸ¨w, yâŸ©
âˆ€y âˆˆE,
(6.19)
and q = Â¯q is also the unique solution of

(hâ€²)âˆ’1(q), p âˆ’q
 
â‰¥0
âˆ€p âˆˆK.
(6.20)
(c) One has Â¯q = hâ€²(T Â¯x).
(d) The following error estimates hold for Î± and Â¯x:
âˆ’hâˆ—(q) â‰¤Î± â‰¤h(Tx) âˆ’âŸ¨w, xâŸ©
âˆ€x âˆˆE âˆ€q âˆˆK,
(6.21)
c
Î³ âˆ¥x âˆ’Â¯xâˆ¥Î³ â‰¤h(Tx) âˆ’âŸ¨w, xâŸ©+ hâˆ—(q)
âˆ€x âˆˆE âˆ€q âˆˆK.
(6.22)
Proof.
(I) Setting g(x) := h(Tx), x âˆˆE, we obtain gâ€²(x) = T âˆ—hâ€²(Tx), x âˆˆE, and

gâ€²(y) âˆ’gâ€²(x), y âˆ’x
 
=

hâ€²(Ty) âˆ’hâ€²(Tx), Ty âˆ’Tx
 
â‰¥câˆ¥Ty âˆ’Txâˆ¥Î³ = câˆ¥y âˆ’xâˆ¥Î³.
(6.23)
Hence by Theorem 5.4.7, the problem g(x) âˆ’âŸ¨w, xâŸ©â†’min, x âˆˆE, and
so (6.16) has precisely one solution Â¯x âˆˆE; this is also the unique solution
of

gâ€²(Â¯x) âˆ’w, y
 
= 0 for any y âˆˆE and so of (6.19).
(II) We show that Â¯q := hâ€²(T Â¯x) is the unique solution of (6.18). By (6.19), we
obtain âŸ¨Â¯q, TyâŸ©= âŸ¨w, yâŸ©for all y âˆˆE and so T âˆ—Â¯q = w which means that
Â¯q âˆˆK. The Young inequality implies
h(Tx) + hâˆ—(q) â‰¥âŸ¨q, TxâŸ©= âŸ¨T âˆ—q, xâŸ©= âŸ¨w, xâŸ©
âˆ€(x, q) âˆˆE Ã— K,
and it follows that Î± â‰¥Î². Since {Â¯q} = âˆ‚h(T Â¯x), we further obtain by
Proposition 4.4.1,
h(T Â¯x) + hâˆ—(Â¯q) = âŸ¨Â¯q, T Â¯xâŸ©= âŸ¨w, Â¯xâŸ©.
We thus conclude that Î± = Î² and Â¯q is a solution of (6.18).

118
6 Duality of Convex Problems
(III) The element Â¯q is the only solution of (6.18) because K is a convex set
and hâˆ—is a strictly convex functional (cf. Theorem 5.4.6). Concerning
the latter, recall that (hâˆ—)â€² = (hâ€²)âˆ’1 by Proposition 4.4.3, notice that
(hâ€²)âˆ’1 is strictly monotone and apply Proposition 4.3.5 to hâˆ—.
(IV) By Remark 5.2.4(c) (cf. also Proposition 5.2.5), q âˆˆK is a solution of
(6.18) if and only if

(hâˆ—)â€²(q), pâˆ’q
 
â‰¥0 for all p âˆˆK which is equivalent
to (6.20).
(V) It is left as Exercise 6.5.2 to verify (d).
âŠ“âŠ”
6.3 Duality of Boundary Value Problems
We adopt the notation introduced at the beginning of Sect. 5.5. Consider the
classical boundary value problem
Au(x) = g(x) âˆ€x âˆˆG,
u(x) = 0 âˆ€x âˆˆâˆ‚G,
(6.24)
where A denotes the linear second-order diï¬€erential operator deï¬ned by
Au(x) := âˆ’
N
	
i,j=1
Di

aij(x) Dju(x)

.
Recall that A is said to be strongly elliptic if there exists a constant c > 0
such that
N
	
i,j=1
aij(x) yiyj â‰¥c
N
	
i=1
y2
i
âˆ€x âˆˆG
âˆ€(y1, . . . , yN) âˆˆRN.
Set
E := W1,2
0 (G).
Then the generalized problem associated with (6.24) reads as follows. Find
u âˆˆE satisfying

G
N
	
i,j=1
aij(x)Dju(x) Div(x) dx =

G
g(x) v(x) dx
âˆ€v âˆˆE.
(6.25)
Heuristically, this is obtained from the classical problem by multiplying the
diï¬€erential equation of (6.24) by v âˆˆCâˆ
c (G) and partial integration (cf.
Sect. 5.5). Parallel to (6.25) we consider the following minimum problem:
Î± := inf
uâˆˆE

G
â›
â1
2
N
	
i,j=1
aij(x)Diu(x) Dju(x) âˆ’g(x) u(x)
â
â dx.
(6.26)

6.3 Duality of Boundary Value Problems
119
Our aim is to apply Proposition 6.2.1. In this connection, notice that we now
denote the â€œprimal variableâ€ by u instead of x, while we go on denoting the
â€œdual variableâ€ by q. The assumptions in Proposition 6.3.1 will ensure that
(6.26) is a convex problem of the form f(u) â†’min, u âˆˆE, and (6.25) is the
equivalent variational equation

f â€²(u), v
 
= 0 for all v âˆˆE (Corollary 5.1.2).
Moreover, below we shall show that the problem dual to (6.26) is
Î² := sup
qâˆˆK
â›
ââˆ’

G
1
2
N
	
i,j=1
a(âˆ’1)
ij
(x) qi(x) qj(x) dx
â
â .
(6.27)
Here,

a(âˆ’1)
ij
(x)

denotes the inverse of the matrix

aij(x)

. Further, we set
F := L2
N(G) := L2(G) Ã— Â· Â· Â· Ã— L2(G)



N-times
,
âˆ¥qâˆ¥2 :=
 N
	
i=1

G
qi(x)
2 dx
 1
2
âˆ€q = (q1, . . . , qN) âˆˆF,
K :=
0
q âˆˆF âˆ—

G
N
	
i=1
qi(x) Div(x) dx =

G
g(x) v(x) dx
âˆ€v âˆˆE
1
,
Tu(x) :=

D1u(x), . . . , DNu(x)

âˆ€x âˆˆG âˆ€u âˆˆE,
âŸ¨w, uâŸ©:=

G
g(x) u(x) dx
âˆ€u âˆˆE,
h(v) := 1
2

G
N
	
i,j=1
aij(x) vi(x) vj(x) dx
âˆ€v âˆˆF.
Proposition 6.3.1 Assumethat,for i, j = 1, . . . , N,thefunctions aij : G â†’R
are continuous, bounded, and symmetric (i.e., aij = aji). Further assume
that the diï¬€erential operator A is strongly elliptic, with the constant c > 0.
Let g âˆˆL2(G) be given. Then:
(a) The problem (6.26) has precisely one solution Â¯u âˆˆE, the problem (6.27)
has precisely one solution Â¯q âˆˆK, and one has Î± = Î².
(b) The problems (6.25) and (6.26) are equivalent and so Â¯u is also the unique
solution of (6.25).
(c) For i = 1, . . . , N, one has Â¯qj = N
i=1 aij DiÂ¯u.
(d) The following error estimates hold for Î± and Â¯u:
âˆ’hâˆ—(q) â‰¤Î± â‰¤h(Tu) âˆ’âŸ¨w, uâŸ©
âˆ€u âˆˆE âˆ€q âˆˆK,
c
2âˆ¥u âˆ’Â¯uâˆ¥2
1,2,0 â‰¤h(Tu) âˆ’âŸ¨w, uâŸ©+ hâˆ—(q)
âˆ€u âˆˆE âˆ€q âˆˆK.

120
6 Duality of Convex Problems
Proof. We show that Proposition 6.2.1 applies.
(I) Notice that T : E â†’F is linear and isometric. The HÂ¨older inequality
shows that w âˆˆEâˆ—. Moreover, we obtain

hâ€²(v), r
 
= âˆ‚
âˆ‚Ï„ h(v + Ï„r)

Ï„=0 =

G
N
	
i,j=1
aij vi rj dx
âˆ€v, r âˆˆF,
(6.28)
which implies that hâ€² is strongly monotone (as A is strongly elliptic).
(II) By Proposition 4.4.3 we have
hâˆ—(q) = hâˆ—(o) +
 1
0

q, (hâ€²)âˆ’1(Ï„q)
 
dÏ„
âˆ€q âˆˆF âˆ—,
(6.29)
hâˆ—(o) = âˆ’h

(hâ€²)âˆ’1(o)

.
Since hâ€²(o) = o, it follows that hâˆ—(o) = âˆ’h(o) = 0. Let Ï„ âˆˆ[0, 1] and
q âˆˆF âˆ—be given. By the bijectivity of hâ€² there exists v âˆˆF satisfying
v = (hâ€²)âˆ’1(Ï„q). In view of (6.28), we conclude that
Ï„ qj(x) = (Ï„q)j(x) =
N
	
i=1
aij(x) vi(x)
for almost all x âˆˆG
and so
vi(x) =
N
	
j=1
a(âˆ’1)
ij
(x)Ï„ qj(x)
for almost all x âˆˆG and i = 1, . . . , N.
Inserting this for the ith coordinate of (hâ€²)âˆ’1(Ï„q) into (6.29), we obtain
hâˆ—(q) =
 1
0
â›
â

G
N
	
i,j=1
qi a(âˆ’1)
ij
Ï„ qj dx
â
â dÏ„ =

G
1
2
N
	
i,j=1
a(âˆ’1)
ij
qi qj dx.
(6.30)
Finally we have
K = {q âˆˆF âˆ—| âŸ¨q, TvâŸ©F = âŸ¨w, vâŸ©E âˆ€v âˆˆE} = {q âˆˆF âˆ—| T âˆ—q = w}.
The assertions now follow from Proposition 6.2.1.
âŠ“âŠ”
Remark 6.3.2 [Smooth Data] If the boundary âˆ‚G as well as the functions
aij and g are suï¬ƒciently smooth, then the solution Â¯u of (6.25) and (6.26) is
an element of C2(G) and so is also a classical solution of (6.24). Set
R := {u âˆˆC2(G)
 u = o on âˆ‚G},
S := {v âˆˆC2(G)
 Av = g on G}.

6.3 Duality of Boundary Value Problems
121
Since R âŠ†E and Â¯u âˆˆR, we have Î± = infuâˆˆR
"
G

Â· Â· Â·

dx (cf. (6.26)) and so
Î± = inf
uâˆˆR

h(Tu) âˆ’âŸ¨w, uâŸ©

.
(6.31)
Deï¬ne
Q :=
0
(q1, . . . , qN) âˆˆF âˆ— qi =
N
	
j=1
aijDjv for i = 1, . . . , N, v âˆˆS
1
.
If q âˆˆQ, then
âˆ’
N
	
i=1
Diqi = Av = g
(6.32)
and so q âˆˆK; the latter follows by multiplying (6.32) by Ëœv âˆˆCâˆ
c (G) and
partial integration. Moreover, we have
Â¯q = hâ€²(T Â¯u) =
N
	
i,j=1
aijDiÂ¯u âˆˆQ;
here, the second equality follows by Proposition 6.3.1(c). In view of (6.27), we
thus obtain Î² = sup
qâˆˆQ

âˆ’hâˆ—(q)

. From (6.30) we deduce that for q âˆˆQ we have
hâˆ—(q) = h(Tv) with some v âˆˆS so that we ï¬nally obtain
Î² = sup
vâˆˆS

âˆ’h(Tv)

= âˆ’inf
vâˆˆS h(Tv).
(6.33)
Hence for smooth data, the statements of Proposition 6.3.1 hold with Î± and
Î² according to (6.31) and (6.33), respectively. In this connection, we have the
error estimates
âˆ’h(Tv) â‰¤Î± â‰¤h(Tu) âˆ’âŸ¨w, uâŸ©
âˆ€u âˆˆR âˆ€v âˆˆS,
(6.34)
c
2âˆ¥u âˆ’Â¯uâˆ¥2
1,2,0 â‰¤h(Tu) âˆ’âŸ¨w, uâŸ©+ h(Tv)
âˆ€u âˆˆR âˆ€v âˆˆS.
(6.35)
By applying the Ritz method to (6.33), a sequence (v(n)) in S is obtained
which can be used in (6.34) to successively improve the lower bound for Î±
according to Î± â‰¥âˆ’h

Tv(n)
. This is the Treï¬€tz method. Notice that the
elements u âˆˆR and v âˆˆS only need to satisfy the boundary condition or the
diï¬€erential equation.
Example 6.3.3 Consider the diï¬€erential operator A = âˆ’âˆ†= âˆ’N
i=1 DiDi.
Then for u âˆˆC2(G), we have the boundary value problem
âˆ’âˆ†u = g on G,
u = o on âˆ‚G
According to (6.31), the associated minimum problem is

122
6 Duality of Convex Problems
Î± = inf

G
1
2
n
	
i=1

Diu
2 âˆ’gu

dx
 u = o on âˆ‚G
'
and according to (6.34), the dual problem is
Î² = sup

âˆ’

G
1
2
N
	
i=1

Div
2 dx
 âˆ’âˆ†v = g on G
'
.
6.4 Duality in Terms of Conjugate Functions
In this section we present another approach to duality, which we ï¬rst explain
in a special case.
Example 6.4.1 As in Example 6.1.5 and with the same notation, we consider
the problem of linear optimization
Î± := inf{âŸ¨c, xâŸ©| x âˆˆPE , Tx âˆ’a âˆˆPF }.
We now perturb the constraint Tx âˆ’a âˆˆPF by a linear parameter b, i.e., we
pass to the perturbed problem
S(b) := inf{âŸ¨c, xâŸ©| x âˆˆPE , Tx âˆ’a âˆ’b âˆˆPF }.
The original problem is Î± = S(o). Again we formalize the above procedure.
Setting
Ëœf(x) :=

âŸ¨c, xâŸ©
if x âˆˆPE ,
+âˆ
if x âˆˆE \ PE ,
h(Ë†b) :=

0
if Ë†b âˆˆPF ,
+âˆ
if Ë†b âˆˆF \ PF ,
f(x) := Ëœf(x) + h(Tx âˆ’a),
x âˆˆE,
M(x, b) := Ëœf(x) + h(Tx âˆ’a âˆ’b)
âˆ€x âˆˆE âˆ€b âˆˆF,
we have
S(b) = inf
xâˆˆE M(x, b)
âˆ€b âˆˆF,
f(x) = M(x, o)
âˆ€x âˆˆE,
Î± = S(o) = inf
xâˆˆE f(x).
The functional M : E Ã— F â†’R can be interpreted as a perturbation of f.

6.4 Duality in Terms of Conjugate Functions
123
Now we consider a more general setting. Let the following problem be
given
Î± := inf
xâˆˆE f(x),
(6.36)
where f : E â†’R. Choose another normed vector space F and a functional
M : E Ã— F â†’R such that f(x) = M(x, o) for each x âˆˆE and consider the
following problems:
S(b) := inf
xâˆˆE M(x, b), b âˆˆF
(perturbed problem),
(6.37)
âˆ’Ë†S(v) := sup
qâˆˆF âˆ—

âˆ’M âˆ—(v, q)

, v âˆˆEâˆ—
(problem dual to (6.37)),
(6.38)
Î² := âˆ’Ë†S(o) = sup
qâˆˆF âˆ—

âˆ’M âˆ—(o, q)

(problem dual to (6.36)).
(6.39)
Deï¬nition 6.4.2 The functional S : F â†’R deï¬ned by (6.37) is called value
functional or marginal functional. The problems (6.36) and (6.39) are said to
be stable if âˆ‚S(o) Ì¸= âˆ…and âˆ‚Ë†S(o) Ì¸= âˆ…, respectively.
We make the following assumptions:
(A1) E and F are normed vector spaces, f : E â†’R is proper, convex, and
l.s.c., M : E Ã— F â†’R is proper, convex, and l.s.c., M(x, o) = f(x) âˆ€
x âˆˆE,
there exist x0 âˆˆE and q0 âˆˆF âˆ—satisfying f(x0) < +âˆand M âˆ—(o, q0) <
+âˆ.
It turns out that, under the above assumptions, the duality between the
problems (6.36) and (6.39) can be completely characterized by means of the
value functional S and the perturbation M. Theorem 6.4.3 is one of the central
results of duality theory.
Theorem 6.4.3 Under the assumptions (A1), the following holds:
(i)
One has âˆ’âˆ< Î² â‰¤Î± < +âˆ.
(ii)
The following statements are equivalent:
(a) Problem (6.36) has a solution and Î± = Î².
(b) Problem (6.39) is stable.
(iii) The following statements are equivalent:
(aâ€²) Problem (6.39) has a solution and Î± = Î².
(bâ€²) Problem (6.36) is stable.
(iv) If Î± = Î², then
âˆ‚Ë†S(o) = solution set of (6.36),
âˆ‚S(o) = solution set of (6.39).
(v)
The following statements are equivalent:
(aâ€²â€²) x âˆˆE is a solution of (6.36), q âˆˆF âˆ—is a solution of (6.39), and
Î± = Î².

124
6 Duality of Convex Problems
(bâ€²â€²) M(x, o) + M âˆ—(o, q) = 0.
(câ€²â€²) (o, q) âˆˆâˆ‚M(x, o).
Proof.
(I) First recall that (E Ã— F)âˆ—can and will be identiï¬ed with Eâˆ—Ã— F âˆ—ac-
cording to

(v, q), (x, b)
 
= âŸ¨v, xâŸ©+ âŸ¨q, bâŸ©
âˆ€(x, b) âˆˆE Ã— F âˆ€(v, q) âˆˆEâˆ—Ã— F âˆ—.
Using this, we have
M âˆ—(v, q) = sup
xâˆˆE
bâˆˆF

âŸ¨v, xâŸ©+ âŸ¨q, bâŸ©âˆ’M(x, b)

.
(6.40)
Furthermore, we obtain
Sâˆ—(q) = sup
bâˆˆF

âŸ¨q, bâŸ©âˆ’S(b)

= sup
bâˆˆF
sup
xâˆˆE

âŸ¨q, bâŸ©âˆ’M(x, b)

= sup
xâˆˆE
bâˆˆF

âŸ¨q, bâŸ©âˆ’M(x, b)

= M âˆ—(o, q)
(6.41)
and so
Sâˆ—âˆ—(o) = sup
qâˆˆF âˆ—

o âˆ’Sâˆ—(q)

= sup
qâˆˆF âˆ—

âˆ’M âˆ—(o, q)

= Î².
(6.42)
(II) From (6.39) and (6.38) we see that
âˆ’Î² = inf
qâˆˆF âˆ—M âˆ—(o, q),
(6.43)
Ë†S(v) = inf
qâˆˆF âˆ—M âˆ—(v, q),
v âˆˆEâˆ—.
(6.44)
Recalling that the dual of F âˆ—[Ïƒ(F âˆ—, F)] and Eâˆ—[Ïƒ(Eâˆ—, E)] can be identi-
ï¬ed with F and E, respectively, and comparing the relationship between
(6.37) and (6.38), we conclude that the problem dual to (6.44) is
âˆ’Ë†Ë†S(b) := sup
xâˆˆE

âˆ’M âˆ—âˆ—(x, b)

= sup
xâˆˆE

âˆ’M(x, b)

,
b âˆˆF.
Therefore, the problem dual to (6.40) and so to (6.39) is
âˆ’Ë†Ë†S(o) = sup
xâˆˆE

âˆ’M(x, o)

= inf
xâˆˆE M(x, o) = Î±,
which is the primal problem.
(III) It is left as an exercise to show that S is convex.
(IV) Ad (i). The hypotheses imply that Î± < +âˆand Î² > âˆ’âˆ. Applying the
Young inequality to M, we obtain
M(x, o) + M âˆ—(o, q) â‰¥âŸ¨o, xâŸ©+ âŸ¨q, oâŸ©= 0

6.4 Duality in Terms of Conjugate Functions
125
which, by passing to the inï¬mum over all (x, q) âˆˆEÃ—F âˆ—, yields Î±âˆ’Î² â‰¥0.
Ad (v). This follows by applying Proposition 4.4.1 to M.
Ad (iv). Assume that Î± = Î². Then it follows that
q is a solution of (6.39) â‡â‡’âˆ’Sâˆ—(q)
=
(6.41) âˆ’M âˆ—(o, q)
=
(6.39) Î² = Î± = S(o)
â‡â‡’q âˆˆâˆ‚S(o);
here, the last equivalence holds by Proposition 4.4.1. According to
step (II), the problem dual to (6.39) is just the original problem (6.36).
Therefore, in analogy to the above, we have
x is a solution of (6.36) â‡â‡’x âˆˆâˆ‚Ë†S(o).
Ad (iii). (aâ€²) =â‡’(bâ€²): By (iv), (aâ€²) implies that âˆ‚S(o) Ì¸= âˆ…and so (6.36)
is stable.
(bâ€²) =â‡’(aâ€²): Let v âˆˆâˆ‚S(o). It follows from Proposition 4.4.1 that
S(o) = âŸ¨v, oâŸ©âˆ’Sâˆ—(v) â‰¤Sâˆ—âˆ—(o).
On the other hand, we have Sâˆ—âˆ—â‰¤S. Hence Î± = S(o) = Sâˆ—âˆ—(o) = Î²; here
the last equation is a consequence of (6.42). Moreover, v is a solution of
(6.39) by (iv).
Ad (ii). This follows from (iii) and step (II).
âŠ“âŠ”
Theorem 6.4.3 reveals the importance of the stability concept. Lemma 6.4.4
provides a suï¬ƒcient condition for stability.
Lemma 6.4.4 Let the assumptions (A1) be fulï¬lled.
(a) If b â†’M(x1, b) is continuous at b = o for some x1 âˆˆE, then the primal
problem (6.36) is stable.
(b) If v â†’M âˆ—(v, q1) is continuous at v = o for some q1 âˆˆF âˆ—, then the dual
problem (6.39) is stable.
Proof.
(a) By assumption, there exist a number k > 0 and a neighborhood U of o in
F such that
S(b) = inf
xâˆˆE M(x, b) â‰¤M(x1, b) â‰¤k
âˆ€b âˆˆU.
Since the functional S is also convex (cf. the remark in step (III) of the
proof of Theorem 6.4.3), it is continuous at o by Theorem 1.4.1, therefore
âˆ‚S(o) Ì¸= âˆ…by Proposition 4.1.6.
(b) This is proved analogously.
âŠ“âŠ”

126
6 Duality of Convex Problems
Special Case
Now we make the following assumptions:
(A2) f : E â†’R and h : F â†’R are proper, convex, and l.s.c.,
T : E â†’F is linear and continuous, a âˆˆF,
there exist x0 âˆˆE and q0 âˆˆF âˆ—such that f(x0), h(Tx0 âˆ’a), f âˆ—(T âˆ—q0),
and hâˆ—(âˆ’q0) are all < +âˆ.
As in (6.8) we consider the problem
Î± := inf
xâˆˆE

f(x) + h(Tx âˆ’a)

.
(6.45)
We set (cf. Example 6.4.1 with f instead of Ëœf)
M(x, b) := f(x) + h(Tx âˆ’a âˆ’b)
(6.46)
to obtain Î± = infxâˆˆE M(x, o). This gives the following associated problems:
S(b) := inf
xâˆˆE M(x, b)
(perturbed problem),
(6.47)
âˆ’Ë†S(v) := sup
qâˆˆF âˆ—

âˆ’M âˆ—(v, q)

(problem dual to (6.47)),
(6.48)
Î² := âˆ’Ë†S(o) = sup
qâˆˆF âˆ—

âˆ’M âˆ—(o, q)

(problem dual to (6.45)).
(6.49)
A simple calculation shows that
âˆ’M âˆ—(v, q) = âŸ¨q, aâŸ©âˆ’f âˆ—(T âˆ—q + v) âˆ’hâˆ—(âˆ’q)
and so
Î² = sup
qâˆˆF âˆ—

âŸ¨q, aâŸ©âˆ’f âˆ—(T âˆ—q) âˆ’hâˆ—(âˆ’q)

.
(6.50)
We associate with (6.45) the Lagrange functional
L1(x, q) := f(x) âˆ’âŸ¨q, Tx âˆ’aâŸ©âˆ’hâˆ—(âˆ’q),
x âˆˆA, q âˆˆB,
where
A := dom f, B := {q âˆˆF âˆ—| hâˆ—(âˆ’q) < +âˆ}.
Notice that L1(x, q) = L(x, âˆ’q), where L denotes the corresponding Lagrange
functional in (6.9).
Theorem 6.4.5 Let the assumptions (A2) be fulï¬lled:
(i) With (6.36) replaced by (6.45), with (6.39) replaced by (6.50) and with M
according to (6.46), the statements (i)â€“(iv) of Theorem 6.4.3 hold.

6.4 Duality in Terms of Conjugate Functions
127
(ii) [Modiï¬cation of Theorem 6.4.3(v)] The following statements are equiva-
lent:
(aâ€²â€²â€²) x âˆˆE is a solution of (6.45), q âˆˆF âˆ—is a solution of (6.50), and
Î± = Î².
(bâ€²â€²â€²) (x, q) is a saddle point of L1 with respect to A Ã— B.
(câ€²â€²â€²) T âˆ—q âˆˆâˆ‚f(x) and âˆ’q âˆˆâˆ‚h(Tx âˆ’a).
Proof. See Exercise 6.5.3.
âŠ“âŠ”
Lemma 6.4.4 immediately implies the following result.
Lemma 6.4.6 Let the assumptions (A2) be fulï¬lled:
(a) If h is continuous at Tx0 âˆ’a, then the problem (6.45) is stable.
(b) If f âˆ—is continuous at T âˆ—q0, then the problem (6.50) is stable.
Corollary 6.4.7 Let the assumptions (A2) be fulï¬lled. In addition, assume
that h is continuous at Tx0 âˆ’a. Then one has
inf
xâˆˆE

f(x) + h(Tx âˆ’a)

= max
qâˆˆF âˆ—

âŸ¨q, aâŸ©âˆ’f âˆ—(T âˆ—q) âˆ’hâˆ—(âˆ’q)

.
(6.51)
Proof. By Lemma 6.4.6, the problem (6.45) is stable. Hence the assertion
follows from Theorem 6.4.5 (cf. Theorem 6.4.3(iii)).
âŠ“âŠ”
We further specialize the setting. Let A be a nonempty convex subset
of E. Set f := Î´A and so f âˆ—(q) = supxâˆˆAâŸ¨q, xâŸ©. Moreover, let F :=E, T := idE,
and a := o. Applying Corollary 6.4.7 to these data, we obtain:
Corollary 6.4.8 Assume that A is a nonempty convex subset of E, h is
proper, convex, l.s.c., and continuous at a point of A. Then one has
inf
xâˆˆA h(x) = max
qâˆˆEâˆ—

inf
xâˆˆAâŸ¨q, xâŸ©âˆ’hâˆ—(q)

.
(6.52)
Application
Let E be a Hilbert space with scalar product (v|u). We identify Eâˆ—with E.
Moreover, let S : E â†’Rn be linear and continuous, and let c âˆˆRn. We
consider the problem
h(u) := 1
2âˆ¥uâˆ¥2 â†’min,
u âˆˆE,
Su = c.
(6.53)
Assume that the set
A := {u âˆˆE | Su = c}
is nonempty. By Corollary 6.4.8 we have
inf
uâˆˆA
1
2âˆ¥uâˆ¥2 = max
vâˆˆE

inf
uâˆˆA(v|u) âˆ’hâˆ—(v)

.
(6.54)

128
6 Duality of Convex Problems
We evaluate the dual problem, i.e., the right-hand side of (6.54):
Ad infuâˆˆA(v|u). For Q := {o} âŠ†Rn we have Qâ—¦= Rn, and Sâˆ—(Rn), as a ï¬nite-
dimensional linear subspace of E(= Eâˆ—), is Ïƒ(Eâˆ—, E)-closed. By Lemma 2.4.1
we therefore obtain
Sâˆ—(Rn) =

Sâˆ’1{o}
â—¦= {v âˆˆE | (v|u) = 0 âˆ€u âˆˆker S} =:

ker S
âŠ¥.
(6.55)
(I) If v Ì¸âˆˆ

ker S
âŠ¥, then there exists u0 âˆˆE such that Su0 =o and (v|u0)=1.
Let u1 âˆˆA. Since S is linear, we have u := Î±u0 + u1 âˆˆA for each Î± âˆˆR.
It follows that
(v|u) = Î± + (v|u1) â†’âˆ’âˆ
as Î± â†’âˆ’âˆ
and so infuâˆˆA(v|u) = âˆ’âˆ.
(II) If v âˆˆ

ker S
âŠ¥, then by (6.55), there exists a âˆˆRn satisfying Sâˆ—a = v,
and we obtain
inf
uâˆˆA(v|u) = inf
uâˆˆA(Sâˆ—a|u) = inf
uâˆˆA(a|Su) = (a|c),
(6.56)
and this holds for each a âˆˆRn.
Ad hâˆ—(v). We immediately obtain
hâˆ—(v) = sup
uâˆˆE

(v|u) âˆ’1
2(u|u)

= 1
2(v|v) = 1
2âˆ¥vâˆ¥2;
concerning the second equality, notice that
0 â‰¤1
2(v âˆ’u|v âˆ’u) = 1
2(v|v) âˆ’(v|u) + 1
2(u|u)
âˆ€u, v âˆˆE.
With the above, (6.54) passes into
inf
uâˆˆA
1
2âˆ¥uâˆ¥2 = max
aâˆˆRn

(a|c) âˆ’1
2âˆ¥Sâˆ—aâˆ¥2



=:Ï•(a)

.
(6.57)
Since Ï• : Rn â†’R is concave and diï¬€erentiable, we have
Ï•(a0) = max
aâˆˆRn Ï•(a)
â‡â‡’
Ï•â€²(a0) = o
â‡â‡’
(h|c) âˆ’(h|SSâˆ—a0) = 0
âˆ€h âˆˆRn
â‡â‡’
SSâˆ—a0 = c.
Hence we have deduced the following result: If a0 âˆˆRn is a solution of
SSâˆ—a0 = c (which is a linear equation in Rn), then v0 := Sâˆ—a0 is a solution
of the right-hand side of (6.54).
We leave it as Exercise 6.5.6 to show that u0 := v0 is a solution of the primal
problem infuâˆˆA 1
2âˆ¥uâˆ¥2.

6.5 Bibliographical Notes and Exercises
129
Example 6.4.9 Consider a dynamical system described by
Ë™x(t) = Fx(t) + bu(t),
t âˆˆ[0, 1].
(6.58)
In this connection, x : [0, 1] â†’Rn is the phase function and u : [0, 1] â†’R is
the control function. The (n, n)-matrix F and the vector b âˆˆRn are given. We
search a control function u that moves the system from x(0) = o to x(1) = c
(where c âˆˆRn is given) under minimal consumption of energy. We assume
that the energy needed for any control function u is
h(u) := 1
2
 1
0
u2(t)dt.
We solve the problem in the Hilbert space E := L2[0, 1] so that we have
h(u) =
1
2âˆ¥uâˆ¥2. Each solution x âˆˆL2[0, 1] of (6.58) satisfying x(0) = o is
representable as
x(t) =
 t
0
Ï†(t âˆ’Ï„)bu(Ï„) dÏ„,
t âˆˆ[0, 1];
here, Ï† denotes the fundamental matrix associated with (6.58). The operator
S : L2[0, 1] â†’Rn deï¬ned by
Su :=
 1
0
Ï†(1 âˆ’Ï„)bu(Ï„) dÏ„,
is linear and continuous, and the end condition x(1) = c is equivalent to
Su = c. Hence, according to what has been said above, the solution of the
problem is u0 = Sâˆ—a0, where a0 âˆˆRn is the solution of SSâˆ—a0 = c.
6.5 Bibliographical Notes and Exercises
Principal contributions to duality theory were obtained by Fenchel [65],
Moreau [147], BrÃ¸ndsted [28], and Rockafellar [178, 180]. In particular,
Theorem 6.4.3 is due to Fenchel [66] and Rockafellar [179]. Example 6.1.7 is
adapted from Ky Fan [64]. The presentation in Sect. 6.3 essentially follows
Zeidler [221]. The application at the end of Sect. 6.4 is taken from Luen-
berger [127]. In addition to the references in the Bibliographical Notes at the
end of Chap. 4, we recommend Stoer and Witzgall [201] (ï¬nite-dimensional
spaces) and GÂ¨opfert [76] (applications in locally convex spaces).
Exercise 6.5.1 Show that, with the notation and the assumptions of
Example 6.1.5, the problem dual to (6.8) can be written as (6.15).
Exercise 6.5.2 Verify assertion (d) of Proposition 6.2.1.
Exercise 6.5.3 Prove Theorem 6.4.5.

130
6 Duality of Convex Problems
Exercise 6.5.4 Consider Problem (6.13) with E = PE := Rn and F :=
C[a, b] with the maximum norm. Further let PF be the cone of nonnegative
functions in C[a, b]. Then (6.13) is a linear semi-inï¬nite optimization problem.
It is placed in a ï¬nite-dimensional space but has inï¬nitely many side conditions
of the form Tx(t) â‰¥a(t) for all t âˆˆ[a, b]. In this case, E is reï¬‚exive but F
is not. Check which assertions of the theory developed above still hold (cf.
Krabs [112]).
Exercise 6.5.5 Consider the following linear semi-inï¬nite problem (cf.
Exercise 6.5.4):
Minimize f(x1, x2) := x2
subject to (x1, x2) âˆˆR2,
t2x1 + x2 â‰¥t
âˆ€t âˆˆ[0, 1].
Show that the values of the primal problem and the dual problem coincide,
the dual problem has a solution, but the primal problem has no solution.
Exercise 6.5.6 Verify that u0 := v0 = Sâˆ—a0, where a0 âˆˆRn solves SSâˆ—a0 =c,
is a solution of the primal problem (6.53).

7
Derivatives and Subdiï¬€erentials of Lipschitz
Functionals
7.1 Preview: Derivatives and Approximating Cones
The aim of this section is to give, in an informal discussion, the motivation
for the following sections.
Let f : E â†’R be proper, let A âŠ†E, and let Â¯x âˆˆA. We consider the
following statement:
(Min) Â¯x is a local minimizer of f on A.
There are two basic approaches to necessary conditions for (Min), which
we call method of tangent directions and method of penalty functions.
Method of Tangent Directions
(I) Suppose that f and A are convex. Then (Min) can be characterized by a
variational inequality (see Proposition 5.1.1):
(Min)
â‡â‡’
fG(Â¯x, y) â‰¥0
âˆ€y âˆˆA âˆ’Â¯x.
(7.1)
(II) Suppose now that f and/or A is not convex. In order to be able to argue
similarly as in the convex case, we have to identify â€œadmissibleâ€ directions,
i.e., directions y âˆˆE that appropriately approximate the set A locally at Â¯x.
The set
Tr(A, Â¯x) := {y âˆˆE | âˆƒÏ„k â†“0 âˆ€k âˆˆN : Â¯x + Ï„ky âˆˆA},
which turns out to be a cone, is called cone of radial directions to A at Â¯x
(Fig. 7.1). If (Min) holds and if y âˆˆTr(A, Â¯x), then for some sequence Ï„k â†“0,
we have
1
Ï„k

f(Â¯x + Ï„ky) âˆ’f(Â¯x)

â‰¥0
âˆ€k âˆˆN.

132
7 Derivatives and Subdiï¬€erentials of Lipschitz Functionals
Â¯x
Â¯x + Ï„ky
A
y âˆˆTr(A, Â¯x)
Fig. 7.1
We therefore consider the upper directional G-derivative
f G(Â¯x, y) := lim sup
Ï„â†“0
1
Ï„

f(Â¯x + Ï„y) âˆ’f(Â¯x)

.
Using this, we conclude that
(Min)
=â‡’
f G(Â¯x, y) â‰¥0
âˆ€y âˆˆTr(M, Â¯x).
(7.2)
In other words, as a necessary optimality condition we again obtain a varia-
tional inequality. This condition is useful as long as Tr(A, Â¯x) contains â€œenoughâ€
elements. However, if for example M is the kernel of a mapping h : D â†’F,
i.e., if
A := ker h := {x âˆˆD | h(x) = o},
(7.3)
then in general we will have Tr(A, Â¯x) = {o}. Since there always holds
f G(Â¯x, o) = 0, the optimality condition in (7.2) is trivially satisï¬ed for each
Â¯x âˆˆA and so is not suitable for identifying possible solutions of (Min). There-
fore we look for ï¬ner local approximations of A at Â¯x.
Let again A be an arbitrary subset of E and Â¯x âˆˆA. The set
T(A, Â¯x) := {y âˆˆE | âˆƒÏ„k â†“0 âˆƒyk â†’y âˆ€k âˆˆN : Â¯x + Ï„kyk âˆˆA},
which is also a cone, is called contingent cone to A at Â¯x (Fig. 7.2). In analogy
to (7.2), we obtain
(Min)
=â‡’
f H(Â¯x, y) â‰¥0
âˆ€y âˆˆT(A, Â¯x),
(7.4)
where now the upper directional H-derivative
f H(Â¯x, y) := lim sup
Ï„â†“0, zâ†’y
1
Ï„

f(Â¯x + Ï„z) âˆ’f(Â¯x)

is the adequate local approximation of f at Â¯x. Since Tr(A, Â¯x) âŠ†T(A, Â¯x), the
optimality condition in (7.4) is stronger than that in (7.2).

7.1 Preview: Derivatives and Approximating Cones
133
 
 
y âˆˆT(A, Â¯x)
yk
Â¯x + Ï„kyk
Â¯x
A
Fig. 7.2
So far, we have not imposed any diï¬€erentiability hypotheses on the functional
f. From (7.2) and (7.4) we immediately deduce the following conditions:
(a) If f is G-diï¬€erentiable at Â¯x, then
(Min)
=â‡’
âŸ¨f â€²(Â¯x), yâŸ©â‰¥0
âˆ€y âˆˆTr(A, Â¯x).
(7.5)
If, in addition, A is convex, then A âˆ’Â¯x âŠ‚Tr(A, Â¯x) and we obtain (cf. (7.1))
(Min)
=â‡’
âŸ¨f â€²(Â¯x), yâŸ©â‰¥0
âˆ€y âˆˆA âˆ’Â¯x.
(7.6)
(b) If f is H-diï¬€erentiable at Â¯x, then
(Min)
=â‡’
âŸ¨f â€²(Â¯x), yâŸ©â‰¥0
âˆ€y âˆˆT(A, Â¯x).
(7.7)
The above shows that necessary conditions for (Min) can be obtained by
choosing local approximations of the functional f by a (directional) deriva-
tive and of the set A by a cone provided these approximations â€œï¬t together.â€
(III) Let A be as in (7.3), with a mapping h : D â†’F. Our aim now is to
derive a necessary condition for (Min) in terms of h. If h is F-diï¬€erentiable
in a neighborhood of Â¯x, hâ€² is continuous at Â¯x, and hâ€²(Â¯x) is surjective, then a
well-known theorem of Lyusternik says that
T(ker h, Â¯x) = ker hâ€²(Â¯x),
(7.8)
i.e., y âˆˆT(ker h, Â¯x) if and only if hâ€²(Â¯x)y = o (see Fig. 7.3, where E = Rn).
This will follow below from a more general result (see Theorem 11.4.2).
If, in addition, the functional f is H-diï¬€erentiable at Â¯x, then we obtain
from (7.7) and (7.8) the following condition:
(Min)
=â‡’
#
âˆ€y âˆˆE : hâ€²(Â¯x)y = o =â‡’

âˆ’f â€²(Â¯x), y
 
â‰¤0.
$
Applying the generalized Farkas lemma of Proposition 2.4.2 to [Â· Â· Â· ], where
T := hâ€²(Â¯x), u := âˆ’f â€²(Â¯x), and Q := {o}, we see that (Min) implies the existence

134
7 Derivatives and Subdiï¬€erentials of Lipschitz Functionals
âˆ‡h(Â¯x)
y
ker h
Â¯x
Fig. 7.3
of v âˆˆF âˆ—satisfying T âˆ—v = u, i.e.,

v, hâ€²(Â¯x)y
 
=

âˆ’f â€²(Â¯x), y
 
for all y âˆˆE
and so
f â€²(Â¯x) + v â—¦hâ€²(Â¯x) = o.
(7.9)
Hence as a necessary condition for (Min), we obtain a Lagrange multiplier
rule, the Lagrange â€œmultiplierâ€ being the functional v âˆˆF âˆ—.
(IV) We again consider (Min), where now A is of the form
A = {x âˆˆE | gi(x) â‰¤0, i = 1, . . . , m}
(7.10)
with certain functionals g1, . . . , gm. In this case we want to obtain optimality
conditions in terms of f and these functionals. Therefore, in view of say (7.4),
we want to characterize (a suï¬ƒciently large subset of) T(A, Â¯x) in terms of
g1, . . . , gm. Similarly to (III) this will be achieved under appropriate diï¬€er-
entiability assumptions. A multiplier rule is then obtained with the aid of a
suitable nonlinear substitute for the generalized Farkas lemma.
Method of Penalty Functions
The idea of this method is to replace the constrained minimum problem
f(x) â†’min,
x âˆˆA,
by a free minimum problem
f(x) + p(x) â†’min,
x âˆˆE,
where the penalty function p is such that p(x) > 0 if x âˆˆE \ A, i.e., leaving
the set A is â€œpenalized.â€
(I) Let A be a convex set and f a convex functional that is continuous at
some point of A. Then the indicator functional Î´A is an appropriate penalty
function. In fact, we have
(Min) â‡â‡’(f + Î´A)(Â¯x) = min
xâˆˆE(f + Î´A)(x) â‡â‡’o âˆˆâˆ‚(f + Î´A)(Â¯x),

7.2 Upper Convex Approximations and Locally Convex Functionals
135
and the sum rule (Proposition 4.5.1) implies
(Min) â‡â‡’o âˆˆâˆ‚f(Â¯x) + âˆ‚Î´A(Â¯x) â‡â‡’o âˆˆâˆ‚f(Â¯x) + (A âˆ’Â¯x)â—¦.
The cone N(A, Â¯x) := T(A, Â¯x)â—¦is called normal cone to A at Â¯x. Since A is
convex, we have T(A, Â¯x) = R+(A âˆ’Â¯x) and so N(A, Â¯x) = (A âˆ’Â¯x)â—¦. Thus the
above equivalence can be written as
(Min) â‡â‡’o âˆˆâˆ‚f(Â¯x) + N(A, Â¯x).
(7.11)
Assume now that A is given by (7.10). Then for a further exploitation of
(7.11) we need a representation of N(A, Â¯x) in terms of gi.
(II) In a theory involving locally L-continuous (nonconvex) functionals, the
indicator functional is not suitable as a penalty function. In this case, the L-
continuous functional p := Î» dA, where Î» > 0 is suï¬ƒciently large, will turn out
to serve this purpose. Here, as in the convex case, a possible subdiï¬€erential
mapping âˆ‚âˆ—f : E â‡’Eâˆ—should at least have the following properties:
If Â¯x is a local minimizer of f on E, then o âˆˆâˆ‚âˆ—f(Â¯x),
âˆ‚âˆ—(f + g)(Â¯x) âŠ†âˆ‚âˆ—f(Â¯x) + âˆ‚âˆ—g(Â¯x).
Then it follows that
(Min) =â‡’o âˆˆâˆ‚âˆ—f(Â¯x) + âˆ‚âˆ—(Î»dA)(Â¯x) âŠ†âˆ‚âˆ—f(Â¯x) + Nâˆ—(A, Â¯x),
where Nâˆ—(A, Â¯x) denotes the Ïƒ(Eâˆ—, E)-closure of 
Î»â‰¥0 âˆ‚âˆ—(Î»dA)(Â¯x).
(III) If A is given by (7.10), then we wish to describe Nâˆ—(A, Â¯x) in terms of
the functionals g1, . . . , gm.
(IV) Finally, analogous investigations are to be done for nonconvex non-
Lipschitz functionals.
7.2 Upper Convex Approximations and Locally
Convex Functionals
We start carrying out the program indicated in Sect. 7.1.
Deï¬nition 7.2.1 Let f : E â†’R be proper and let Â¯x âˆˆdom f.
(a) The functional Ï• : E â†’R is called radial upper convex approximation of
f at Â¯x if Ï• is proper, sublinear, and satisï¬es
f G(Â¯x, y) â‰¤Ï•(y)
âˆ€y âˆˆE.
(b) The functional Ï• : E â†’R is called upper convex approximation of f at Â¯x
if Ï• is proper, sublinear, and satisï¬es
f H(Â¯x, y) â‰¤Ï•(y)
âˆ€y âˆˆE \ {o}.

136
7 Derivatives and Subdiï¬€erentials of Lipschitz Functionals
We write
UCr(f, Â¯x) := set of all radial upper convex approximations of f at Â¯x,
UC(f, Â¯x) := set of all upper convex approximations of f at Â¯x.
Since f G(Â¯x, Â·) â‰¤f H(Â¯x, Â·), we always have UC(f, Â¯x) âŠ†UCr(f, Â¯x) (notice
that f G(Â¯x, o) = o = Ï•(o)).
Proposition 7.2.2 If f : E â†’R is proper and locally L-continuous at Â¯x âˆˆ
dom f, then f H(Â¯x, y) = f G(Â¯x, y) for any y âˆˆE and so UC(f, Â¯x) = UCr(f, Â¯x).
Proof. See Exercise 7.5.1.
âŠ“âŠ”
Remark 7.2.3 There is a close relationship to quasidiï¬€erentiable functionals.
The proper functional f : E â†’R is said to be quasidiï¬€erentiable at Â¯x âˆˆdom f
if fG(Â¯x, Â·) exists on E and there exist nonempty convex Ïƒ(Eâˆ—, E)-compact
subsets âˆ‚f(Â¯x) and âˆ‚f(Â¯x) of Eâˆ—such that
fG(Â¯x, y) =
min
uâˆˆâˆ‚f(Â¯x)
âŸ¨u, yâŸ©+ max
vâˆˆâˆ‚f(Â¯x)âŸ¨v, yâŸ©
âˆ€y âˆˆE.
Now let f : E â†’R be quasidiï¬€erentiable at Â¯x âˆˆdom f and set
Ï•u(y) := max{âŸ¨u + v, yâŸ©| v âˆˆâˆ‚f(Â¯x)}
âˆ€y âˆˆE,
Ïˆv(y) := max{âŸ¨u âˆ’v, yâŸ©| u âˆˆâˆ’âˆ‚f(Â¯x)}
âˆ€y âˆˆE.
Then obviously
Ï•u âˆˆUCr(f, Â¯x)
âˆ€u âˆˆâˆ‚f(Â¯x)
and
Ïˆv âˆˆUCr(âˆ’f, Â¯x)
âˆ€v âˆˆâˆ‚f(Â¯x).
Deï¬nition 7.2.4 describes a special class of functionals admitting (radial)
upper convex approximations.
Deï¬nition 7.2.4 Let f : E â†’R be proper and let Â¯x âˆˆdom f. The functional
f is said to be
â€“ locally convex at Â¯x if fG(Â¯x, Â·) exists and is sublinear as a mapping of E to
R,
â€“ regularly locally convex at Â¯x if fH(Â¯x, Â·) exists and is sublinear as a mapping
of E to R.
See Exercise 7.5.2 for an example of a functional that is locally convex but
not regularly locally convex.
Proposition 7.2.5 Let f1, f2 : E â†’R be proper and set f := f1+f2. Further
let Â¯x âˆˆ(int domf1) âˆ©(int domf2) and assume that f1 is continuous at Â¯x and
convex:
(a) If f2 is G-diï¬€erentiable at Â¯x, then f is locally convex at Â¯x and fG(Â¯x, Â·) =
f1,H(Â¯x, Â·) + f â€²
2(Â¯x) âˆˆUCr(f, Â¯x).

7.2 Upper Convex Approximations and Locally Convex Functionals
137
(b) If f2 is H-diï¬€erentiable at Â¯x, then f is regularly locally convex at Â¯x and
fH(Â¯x, Â·) = f1,H(Â¯x, Â·) + f â€²
2(Â¯x) âˆˆUC(f, Â¯x).
Proof. By Theorem 4.1.3 we have f1,H(Â¯x, Â·) âˆˆUC(f1, Â¯x), and by Remark 3.2.3
it follows that f â€²
2(Â¯x) âˆˆUCr(f2, Â¯x) or f â€²
2(Â¯x) âˆˆUC(f2, Â¯x), respectively. This
veriï¬es the assertions.
âŠ“âŠ”
Remark 7.2.6 By Proposition 7.2.5, each functional that is G-diï¬€erentiable
at Â¯x is locally convex there. Moreover, each continuous convex functional
as well as each functional that is H-diï¬€erentiable at Â¯x is regularly locally
convex. Notice that the proposition also describes regularly locally convex
functionals that are neither convex nor G-diï¬€erentiable; consider, e.g., f(x) :=
|x| + x3, x âˆˆR, at Â¯x = 0.
We want to derive a maximum rule for the directional G-derivative. For
i = 1, . . . , m let fi : E â†’R and set
f(x) :=
max
i=1....,m fi(x),
x âˆˆE.
(7.12)
Let Â¯x âˆˆE, I := {1, . . . , m}, and I(Â¯x) := {i âˆˆI | fi(Â¯x) = f(Â¯x)}.
Proposition 7.2.7 (Maximum Rule) Assume that Â¯x âˆˆ
iâˆˆI int(dom fi),
that fi is continuous at Â¯x for each i âˆˆI, and that fi,G(Â¯x, Â·) exists for each
i âˆˆI(Â¯x). Then, with f as in (7.12), the directional G-derivative fG(Â¯x, Â·) exists
and one has
fG(Â¯x, y) = max
iâˆˆI(Â¯x) fi,G(Â¯x, y),
y âˆˆE.
(7.13)
An analogous result holds with fG, fi,G replaced by fH, fi,H, respectively.
Proof.
(I) First we show that the directional G-derivative fG(Â¯x, Â·), whenever it
exists, depends on the functions fi for i âˆˆI(Â¯x) only. Let y âˆˆE be
given. If i âˆˆI \ I(Â¯x), then the continuity of fi and f imply that there
exists Ï„i > 0 such that fi(Â¯x + Ï„y) < f(Â¯x + Ï„y) for each Ï„ âˆˆ[0, Ï„i]. Let
Ï„0 := min{Ï„i | i âˆˆI \ I(Â¯x)}. For any Ï„ âˆˆ(0, Ï„0) we have
Ï„ âˆ’1
f(Â¯x + Ï„y) âˆ’f(Â¯x)

= max
iâˆˆI(Â¯x) Ï„ âˆ’1
fi(Â¯x + Ï„y) âˆ’f(Â¯x)

= max
iâˆˆI(Â¯x) Ï„ âˆ’1
fi(Â¯x + Ï„y) âˆ’fi(Â¯x)

.
(7.14)
Hence we may assume that I(Â¯x) = I.
(II) For each i âˆˆI

= I(Â¯x)

we obtain
lim inf
Ï„â†“0
Ï„ âˆ’1
f(Â¯x + Ï„y) âˆ’f(Â¯x)

â‰¥lim
Ï„â†“0 Ï„ âˆ’1
fi(Â¯x + Ï„y) âˆ’fi(Â¯x)

= (fi)G(Â¯x, y).
(7.15)

138
7 Derivatives and Subdiï¬€erentials of Lipschitz Functionals
We now show that
lim sup
Ï„â†“0
Ï„ âˆ’1
f(Â¯x + Ï„y) âˆ’f(Â¯x)

â‰¤max
iâˆˆI fi,G(Â¯x, y).
This and (7.15) verify (7.13). Assume that
lim sup
Ï„â†“0
Ï„ âˆ’1
f(Â¯x + Ï„y) âˆ’f(Â¯x)

> max
iâˆˆI fi,G(Â¯x, y).
Then we ï¬nd Ïµ > 0 and a sequence Ï„k â†“0 such that
Ï„ âˆ’1
k

f(Â¯x + Ï„ky) âˆ’f(Â¯x)

â‰¥max
iâˆˆI fi,G(Â¯x, y) + Ïµ
âˆ€k âˆˆN .
For a subsequence (Ï„kÎ½) of (Ï„k) we have f(Â¯x + Ï„kÎ½y) = fj(Â¯x + Ï„kÎ½y) with
a ï¬xed index j. It follows that
fj,G(Â¯x, y) = lim
Î½â†’âˆÏ„ âˆ’1
kÎ½

fj(Â¯x + Ï„kÎ½y) âˆ’fj(Â¯x)

â‰¥max
iâˆˆI fi,G(Â¯x, y) + Ïµ,
which is a contradiction.
(III) For fH(Â¯x, Â·) see Exercise 7.5.3.
âŠ“âŠ”
Proposition 7.2.8 Assume that Â¯x âˆˆ
iâˆˆI int(dom fi), each fi is continuous
at Â¯x, and fi is (regularly) locally convex at Â¯x for each i âˆˆI(Â¯x). Then the
functional f deï¬ned by (7.12) is (regularly) locally convex at Â¯x.
Proof. This follows immediately from Proposition 7.2.7.
âŠ“âŠ”
Proposition 7.2.8 applies, in particular, to the maximum of a ï¬nite number of
continuous GÃ¢teaux diï¬€erentiable (resp. Hadamard diï¬€erentiable) functionals.
Notice that such a maximum functional in general is not GÃ¢teaux diï¬€eren-
tiable (resp. Hadamard diï¬€erentiable).
Proposition 4.1.6 stimulates us to deï¬ne a subdiï¬€erential for locally convex
functionals.
Deï¬nition 7.2.9 If f : E â†’R is locally convex at Â¯x âˆˆdom f, then
âˆ‚âˆ—f(Â¯x) := {xâˆ—âˆˆEâˆ—| âŸ¨xâˆ—, yâŸ©â‰¤fG(Â¯x, y) âˆ€y âˆˆE}
is called locally convex subdiï¬€erential of f at Â¯x.
If f is convex, then by Proposition 4.1.6 we have âˆ‚âˆ—f(Â¯x) = âˆ‚f(Â¯x). Notice
that if fG(Â¯x, y) = âˆ’âˆfor some y âˆˆE, then âˆ‚âˆ—f(Â¯x) is empty.
Proposition 7.2.10 If f : E â†’R is locally convex at Â¯x âˆˆdom f, then the
following assertions are equivalent:
(a) âˆ‚âˆ—f(Â¯x) is nonempty.
(b) fG(Â¯x, Â·) is lower semicontinuous at y = o.

7.3 The Subdiï¬€erentials of Clarke and Michelâ€“Penot
139
Proof.
(a) =â‡’(b): Let xâˆ—âˆˆâˆ‚âˆ—f(Â¯x). Further let k < fG(Â¯x, o) = 0. Since xâˆ—is
continuous, there exists a neighborhood W of zero in E such that k < âŸ¨xâˆ—, yâŸ©â‰¤
fG(Â¯x, y) for each y âˆˆW.
(b) =â‡’(a): By assumption there exists a neighborhood V of zero in E such
that âˆ’1 â‰¤fG(Â¯x, y) for each y âˆˆV . Now let z âˆˆE be given. Then Î·z âˆˆV
for some Î· > 0. Since p := fG(Â¯x, Â·) is positively homogeneous, it follows that
âˆ’âˆ< âˆ’1
Î· â‰¤fG(Â¯x, z) = p(z). Hence p is proper and sublinear. Moreover, let
q(y) := 1 for y âˆˆV and q(y) := +âˆfor y âˆˆE \ V . Then q is proper, convex,
and continuous at zero. We further have âˆ’q(y) â‰¤p(y) for each y âˆˆE. The
sandwich theorem (Theorem 1.5.2) thus implies that there exists xâˆ—âˆˆâˆ‚âˆ—f(Â¯x).
âŠ“âŠ”
The locally convex subdiï¬€erential is an appropriate tool for detecting min-
imizers as is the convex subdiï¬€erential (cf. Remark 4.1.2). The following result
is an immediate consequence of the deï¬nitions.
Proposition 7.2.11 If f : E â†’R is locally convex at Â¯x âˆˆdom f and Â¯x is a
local minimizer of f, then o âˆˆâˆ‚âˆ—f(Â¯x).
7.3 The Subdiï¬€erentials of Clarke and Michelâ€“Penot
Convention. Throughout this section, we assume that D âŠ†E is open, Â¯x âˆˆD
and f : D â†’R.
Here, we present two intrinsic constructions for upper convex approxima-
tions. For comparison, recall that
f H(Â¯x, y) := lim sup
Ï„â†“0
zâ†’y
1
Ï„

f(Â¯x + Ï„z) âˆ’f(Â¯x)

.
Deï¬nition 7.3.1 If y âˆˆE, then
f â—¦(Â¯x, y) := lim sup
Ï„â†“0
xâ†’Â¯x
1
Ï„

f(x + Ï„y) âˆ’f(x)

(7.16)
is called Clarke directional derivative of f at Â¯x in the direction y and
f â™¦(Â¯x, y) := sup
zâˆˆE
lim sup
Ï„â†“0
1
Ï„

f(Â¯x + Ï„y + Ï„z) âˆ’f(Â¯x + Ï„z)

(7.17)
is called Michelâ€“Penot directional derivative of f at Â¯x in the direction y.
Theorem 7.3.2 Let f be locally L-continuous around Â¯x with constant Î» > 0.
Then:
(a) f â—¦(Â¯x, Â·) and f â™¦(Â¯x, Â·) are sublinear and (globally) L-continuous with con-
stant Î» on E and satisfy
f H(Â¯x, y) â‰¤f â™¦(Â¯x, y) â‰¤f â—¦(Â¯x, y) â‰¤Î»âˆ¥yâˆ¥
âˆ€y âˆˆE.
(7.18)
In particular, f â—¦(Â¯x, Â·) and f â™¦(Â¯x, Â·) are ï¬nite upper convex approximations
of f at Â¯x.

140
7 Derivatives and Subdiï¬€erentials of Lipschitz Functionals
(b) For any y âˆˆE one has
f â—¦(Â¯x, âˆ’y) = (âˆ’f)â—¦(Â¯x, y),
f â™¦(Â¯x, âˆ’y) = (âˆ’f)â™¦(Â¯x, y).
Proof.
(a)(Ia) The third inequality of (7.18) holds. Let y âˆˆE be ï¬xed. By assump-
tion, we have
1
Ï„

f(x + Ï„y) âˆ’f(x)

â‰¤1
Ï„ Î»âˆ¥Ï„yâˆ¥= Î»âˆ¥yâˆ¥
whenever âˆ¥x âˆ’Â¯xâˆ¥and Ï„ > 0 are small. Hence f â—¦(Â¯x, y) â‰¤Î»âˆ¥yâˆ¥.
(Ib) The second inequality of (7.18) holds. Fix y âˆˆE. Further let Ïµ > 0
be given. For each z âˆˆE there exists Î´(z) > 0 such that (consider
x := Â¯x + Ï„z)
1
Ï„

f(Â¯x + Ï„y + Ï„z) âˆ’f(Â¯x + Ï„z)

< f â—¦(Â¯x, y) + Ïµ
âˆ€Ï„ âˆˆ(0, Î´(z)).
This implies
lim sup
Ï„â†“0
1
Ï„

f(Â¯x + Ï„y + Ï„z) âˆ’f(Â¯x + Ï„z

â‰¤f â—¦(Â¯x, y) + Ïµ,
which holds for each z âˆˆE. We conclude that f â™¦(Â¯x, y) â‰¤f â—¦(Â¯x, y) + Ïµ.
Letting Ïµ â†“0, the assertion follows.
(Ic) The ï¬rst inequality of (7.18) holds. Let y âˆˆE be ï¬xed. Further let
Ïµ > 0 be given. For all suï¬ƒciently small Ï„ > 0 and all z âˆˆE such that
âˆ¥y âˆ’zâˆ¥is suï¬ƒciently small, we have
1
Ï„

f(Â¯x + Ï„z) âˆ’f(Â¯x)

= 1
Ï„

f

Â¯x + Ï„y + Ï„(z âˆ’y)

âˆ’f

Â¯x + Ï„(z âˆ’y)

+ 1
Ï„

f

Â¯x + Ï„(z âˆ’y)

âˆ’f(Â¯x)

â‰¤1
Ï„

f

Â¯x + Ï„y + Ï„(z âˆ’y)

âˆ’f

Â¯x + Ï„(z âˆ’y)

+ Î»âˆ¥z âˆ’yâˆ¥
â‰¤f â™¦(Â¯x, y) + Ïµ + Î»âˆ¥z âˆ’yâˆ¥.
Letting Ï„ â†“0, z â†’y, and ï¬nally Ïµ â†“0, the ï¬rst inequality follows.
(IIa) f â—¦(Â¯x, Â·) is sublinear. It is obvious that f â—¦(Â¯x, Â·) is positively homoge-
neous. We show that it is subadditive. Let y1, y2 âˆˆE. We have
1
Ï„
&
f

x + Ï„(y1 + y2)

âˆ’f(x)

= 1
Ï„
&
f

(x + Ï„y2
  
=:Ë†xâ†’Â¯x
) + Ï„y1

âˆ’f(x + Ï„y2
  
Ë†xâ†’Â¯x
)

+ 1
Ï„
&
f(x + Ï„y2) âˆ’f(x)

.
Passing on both sides to the limit superior for Ï„ â†“0 and x â†’Â¯x, we
obtain
f â—¦(Â¯x, y1 + y2) â‰¤f â—¦(Â¯x, y1) + f â—¦(Â¯x, y2).

7.3 The Subdiï¬€erentials of Clarke and Michelâ€“Penot
141
(IIb) f â™¦(Â¯x, Â·) is sublinear. Again we can restrict ourselves to showing sub-
additivity. Let y1, y2 âˆˆE. Let Ïµ > 0 be given. For all Ï„ > suï¬ƒciently
small we obtain
1
Ï„

f

Â¯x + Ï„(y1 + y2) + Ï„z

âˆ’f

Â¯x + Ï„(y2 + z)

â‰¤f â™¦(Â¯x, y1) + Ïµ
2
âˆ€z âˆˆE,
1
Ï„

f

Â¯x + Ï„y2 + Ï„z

âˆ’f

Â¯x + Ï„z)

â‰¤f â™¦(Â¯x, y2) + Ïµ
2
âˆ€z âˆˆE.
Adding these inequalities, we get
1
Ï„

f
Â¯x+Ï„(y1+y2)+Ï„z
âˆ’f
Â¯x+Ï„z
â‰¤f â™¦(Â¯x, y1)+f â™¦(Â¯x, y2)+Ïµ
âˆ€z âˆˆE,
and ï¬nally f â™¦(Â¯x, y1 + y2) â‰¤f â™¦(Â¯x, y1) + f â™¦(Â¯x, y2).
(IIIa) f â—¦(Â¯x, Â·) is L-continuous. Let y1, y2 âˆˆE. If Ï„ > 0 is small and x is close
to Â¯x, we obtain
f(x + Ï„y1) âˆ’f(x) =
&
f(x + Ï„y2) âˆ’f(x)

+
&
f(x + Ï„y1) âˆ’f(x + Ï„y2)

â‰¤
&
f(x + Ï„y2) âˆ’f(x)

+ Ï„Î»âˆ¥y1 âˆ’y2âˆ¥
and so
f â—¦(Â¯x, y1) â‰¤f â—¦(Â¯x, y2) + Î»âˆ¥y1 âˆ’y2âˆ¥.
By an analogous estimate with y1 and y2 interchanged, we see that
|f â—¦(Â¯x, y1) âˆ’f â—¦(Â¯x, y2)| â‰¤Î»âˆ¥y1 âˆ’y2âˆ¥.
(IIIb) Analogously, the L-continuity of f â™¦(Â¯x, Â·) is veriï¬ed.
(b)(IVa) We immediately obtain
f â—¦(Â¯x, âˆ’y) = lim sup
Ï„â†“0
xâ†’Â¯x
1
Ï„
&
f(x âˆ’Ï„y) âˆ’f(x)

= lim sup
Ï„â†“0
Ë†xâ†’Â¯x
1
Ï„
&
(âˆ’f)(Ë†x + Ï„y) âˆ’(âˆ’f)(Ë†x)

= (âˆ’f)â—¦(Â¯x, y);
in this connection, Ë†x stands for x âˆ’Ï„y.
(IVb) For any z âˆˆE we have
lim sup
Ï„â†“0
1
Ï„
&
f(Â¯x âˆ’Ï„y + Ï„z) âˆ’f(Â¯x + Ï„z)

= lim sup
Ï„â†“0
&
(âˆ’f)(Â¯x + Ï„y + Ï„(z âˆ’y)) âˆ’(âˆ’f)(Â¯x + Ï„(z âˆ’y)

.
Taking the supremum over z and z âˆ’y, respectively, gives the second
statement of (b).
âŠ“âŠ”

142
7 Derivatives and Subdiï¬€erentials of Lipschitz Functionals
f
Ï€
x
f â™¦(Ï€, Â·)
= f â—¦(Ï€, Â·)
f H(Ï€, Â·)
y
Fig. 7.4
Example 7.3.3 Let E := R, f(x) := |x| âˆ’| sin x|, and Â¯x := Ï€. Then we have
f H(Ï€, y) =

2y
if y < 0,
0
if y â‰¥0,
f â™¦(Ï€, y) = f â—¦(Ï€, y) =

0
if y < 0,
2y
if y â‰¥0.
We see that of the three directional derivatives, the functional f H(Ï€, Â·) is the
best local approximation of f at Ï€ but it is not convex (Fig. 7.4).
Recall (see Proposition 4.1.6) that if f is convex, then
âˆ‚f(Â¯x) = {xâˆ—âˆˆEâˆ— âŸ¨xâˆ—, yâŸ©â‰¤fG(Â¯x, y) âˆ€y âˆˆE}.
In the nonconvex case, we now give the following:
Deï¬nition 7.3.4 If f is locally L-continuous around Â¯x, then
âˆ‚â—¦f(Â¯x) := {xâˆ—âˆˆEâˆ—| âŸ¨xâˆ—, yâŸ©â‰¤f â—¦(Â¯x, y) âˆ€y âˆˆE}
is called Clarke subdiï¬€erential, or Clarke generalized gradient, of f at Â¯x and
âˆ‚â™¦f(Â¯x) := {xâˆ—âˆˆEâˆ—| âŸ¨xâˆ—, yâŸ©â‰¤f â™¦(Â¯x, y) âˆ€y âˆˆE}
is called Michelâ€“Penot subdiï¬€erential of f at Â¯x.
Proposition 7.3.5 If f is locally L-continuous around Â¯x, then for any Ïƒ âˆˆR
one has
âˆ‚â—¦(Ïƒf)(Â¯x) = Ïƒâˆ‚â—¦f(Â¯x)
and
âˆ‚â™¦(Ïƒf)(Â¯x) = Ïƒâˆ‚â™¦f(Â¯x).

7.3 The Subdiï¬€erentials of Clarke and Michelâ€“Penot
143
Proof. We consider âˆ‚â—¦f; for âˆ‚â™¦f the proof is analogous. If Ïƒ â‰¥0, the formula
follows immediately from (Ïƒf)â—¦(Â¯x, Â·) = Ïƒf â—¦(Â¯x, Â·). Thus it remains to verify it
for Ïƒ = âˆ’1. We have
âˆ‚â—¦(âˆ’f)(Â¯x) = {xâˆ—âˆˆEâˆ—| âŸ¨xâˆ—, yâŸ©â‰¤(âˆ’f)â—¦(Â¯x, y) âˆ€y âˆˆE}
= {xâˆ—âˆˆEâˆ—| âŸ¨xâˆ—, âˆ’zâŸ©â‰¤f â—¦(Â¯x, z) âˆ€z âˆˆE}
= âˆ’âˆ‚â—¦f(Â¯x).
Here the second equation holds by Theorem 7.3.2(b) and with z := âˆ’y.
âŠ“âŠ”
The importance of the subdiï¬€erentials introduced above reveals:
Proposition 7.3.6 If f is locally L-continuous around Â¯x and Â¯x is a local
minimizer or a local maximizer of f, then o âˆˆâˆ‚â—¦f(Â¯x) and o âˆˆâˆ‚â™¦f(Â¯x).
Proof. If Â¯x is a local minimizer of f, then for any y âˆˆE we obtain
0 â‰¤lim inf
Ï„â†“0
1
Ï„

f(Â¯x + Ï„y) âˆ’f(Â¯x)

â‰¤lim sup
Ï„â†“0
1
Ï„

f(Â¯x + Ï„y) âˆ’f(Â¯x)

â‰¤f â—¦(Â¯x, y).
(7.19)
The deï¬nition of âˆ‚â—¦f(Â¯x) now shows that o âˆˆâˆ‚â—¦f(Â¯x). If Â¯x is a local maximizer
of f, then Â¯x is a local minimizer of âˆ’f and so o âˆˆâˆ‚â—¦(âˆ’f)(Â¯x) = âˆ’âˆ‚â—¦f(Â¯x) (the
latter by Proposition 7.3.5). The proof for âˆ‚â™¦f is analogous.
âŠ“âŠ”
We establish further properties of the subdiï¬€erentials.
Proposition 7.3.7 Let f be locally L-continuous around Â¯x with constant Î» > 0.
Then:
(a) The subdiï¬€erentials âˆ‚â—¦f(Â¯x) and âˆ‚â™¦f(Â¯x) are nonempty, convex, and
Ïƒ(Eâˆ—, E)-compact, and satisfy
âˆ‚â™¦f(Â¯x) âŠ†âˆ‚â—¦f(Â¯x) âŠ†BEâˆ—(o, Î»).
(b) One has
f â—¦(Â¯x, y) = max{âŸ¨xâˆ—, yâŸ©| xâˆ—âˆˆâˆ‚â—¦f(Â¯x)}
âˆ€y âˆˆE,
f â™¦(Â¯x, y) = max{âŸ¨xâˆ—, yâŸ©| xâˆ—âˆˆâˆ‚â™¦f(Â¯x)}
âˆ€y âˆˆE.
Proof. Taking Theorem 7.3.2(a) into consideration, the assertions follow as
those of Proposition 4.1.6(b).
âŠ“âŠ”
Observe that, beside the lower semicontinuity, it is the sublinearity of
f â—¦(Â¯x, Â·) and f â™¦(x, Â·) that ensures the nonemptyness of the respective subdif-
ferential. If we choose, say, f H(Â¯x, Â·) instead, we obtain for the function f of
Example 7.3.3,
{xâˆ—âˆˆEâˆ—| âŸ¨xâˆ—, yâŸ©â‰¤f H(Ï€, y)
âˆ€y âˆˆE} = âˆ….

144
7 Derivatives and Subdiï¬€erentials of Lipschitz Functionals
Proposition 7.3.8 If f : E â†’R is locally L-continuous on E, then:
(a) The functional (x, y) â†’f â—¦(x, y) is upper semicontinuous on E Ã— E.
(b) Let (xk) and (xâˆ—
k) be sequences in E and Eâˆ—, respectively, such that xâˆ—
k âˆˆ
âˆ‚â—¦f(xk) for all k âˆˆN. Assume that (xk) converges to Â¯x âˆˆE as k â†’âˆ
and that xâˆ—âˆˆEâˆ—is a Ïƒ(Eâˆ—, E)-cluster point of (xâˆ—
k). Then one has xâˆ—âˆˆ
âˆ‚â—¦f(Â¯x). (That is, graph(âˆ‚â—¦f) is a normâ€“weakâˆ—closed subset of E Ã— Eâˆ—.)
(c) The subdiï¬€erential mapping âˆ‚â—¦f : E â‡’Eâˆ—is norm-to-weakâˆ—upper semi-
continuous.
Proof.
(a) Let (xk) and (yk) be sequences converging to Â¯x âˆˆE and Â¯y âˆˆE, respec-
tively. By deï¬nition of f â—¦, for each k there exist zk âˆˆE and Ï„k > 0 such
that âˆ¥zk âˆ’xkâˆ¥+ Ï„k < 1
k and
f â—¦(xk, yk) âˆ’1
k â‰¤f(zk + Ï„kyk) âˆ’f(zk)
Ï„k
= f(zk + Ï„kÂ¯y) âˆ’f(zk)
Ï„k
+ f(zk + Ï„kyk) âˆ’f(zk + Ï„kÂ¯y)
Ï„k
â‰¤f(zk + Ï„kÂ¯y) âˆ’f(zk)
Ï„k
+ Î»âˆ¥yk âˆ’Â¯yâˆ¥;
in the last term, Î» > 0 denotes a Lipschitz constant of f near Â¯x. By letting
k â†’âˆ, the deï¬nition of the upper limit gives lim supkâ†’âˆf â—¦(xk, yk) â‰¤
f â—¦(Â¯x, Â¯y). Hence f â—¦is u.s.c. at (Â¯x, Â¯y).
(b) Let y âˆˆE be given. Some subsequence of (âŸ¨xâˆ—
k, yâŸ©), again denoted (âŸ¨xâˆ—
k, yâŸ©),
satisï¬es âŸ¨xâˆ—
k, yâŸ©â†’âŸ¨xâˆ—, yâŸ©as k â†’âˆ. By the deï¬nition of âˆ‚â—¦f we have
âŸ¨xâˆ—
k, yâŸ©â‰¤f â—¦(xk, y) for all k. Letting k â†’âˆ, we conclude from (a) that
âŸ¨xâˆ—, yâŸ©â‰¤f â—¦(Â¯x, y). Since y âˆˆE was arbitrary, we obtain xâˆ—âˆˆâˆ‚â—¦f(Â¯x).
(c) The proof is analogous to that of Proposition 4.3.2(a). (Notice that by
Proposition 7.3.7(a), the multifunction âˆ‚â—¦f is locally bounded at any
Â¯x âˆˆE.)
âŠ“âŠ”
Statement (b) of Proposition 7.3.8 will be crucial for deriving a chain rule
in Sect. 7.4 as well as a multiplier rule in Sect. 12.4. Now we establish rela-
tionships between the various notions. Recall the convention at the beginning
of this section.
Proposition 7.3.9
(a) If fG(Â¯x, Â·) exists and is sublinear on E, then f â™¦(Â¯x, y) = fG(Â¯x, y) for each
y âˆˆE. In particular, if f is G-diï¬€erentiable at Â¯x, then âˆ‚â™¦f(Â¯x) = {f â€²(Â¯x)}.
(b) If f is locally L-continuous around Â¯x and G-diï¬€erentiable at Â¯x, then
f â€²(Â¯x) âˆˆâˆ‚â—¦f(Â¯x).

7.3 The Subdiï¬€erentials of Clarke and Michelâ€“Penot
145
(c) If f is strictly H-diï¬€erentiable at Â¯x, then f is locally L-continuous around Â¯x
and f â—¦(Â¯x, y) = âŸ¨f â€²(Â¯x), yâŸ©for each y âˆˆE and âˆ‚â™¦f(Â¯x) = âˆ‚â—¦f(Â¯x) = {f â€²(Â¯x)}.
(d) If D is convex and f is convex and locally L-continuous around Â¯x, then
f â™¦(Â¯x, y) = f â—¦(Â¯x, y) = fH(Â¯x, y) for each y âˆˆE and âˆ‚â™¦f(Â¯x) = âˆ‚â—¦f(Â¯x) =
âˆ‚f(Â¯x).
Proof.
(a) It is clear that fG(Â¯x, Â·) â‰¤f â™¦(Â¯x, Â·). We show the reverse inequality. For
each y âˆˆE we have
f â™¦(Â¯x, y)
â‰¤sup
zâˆˆE

lim sup
Ï„â†“0
1
Ï„

f(Â¯x + Ï„y + Ï„z) âˆ’f(Â¯x)

+lim sup
Ï„â†“0
1
Ï„

f(Â¯x) âˆ’f(Â¯x + Ï„z)

= sup
zâˆˆE

fG(Â¯x, y + z) âˆ’fG(Â¯x, z)

â‰¤fG(Â¯x, y);
here, the last inequality holds because fG(Â¯x, Â·) is subadditive. The second
statement follows immediately from the deï¬nition of âˆ‚â™¦f(Â¯x).
(b) If y âˆˆE, then
âŸ¨f â€²(Â¯x), yâŸ©= lim
Ï„â†“0
1
Ï„
&
f(Â¯x+Ï„y)âˆ’f(Â¯x)

â‰¤lim sup
Ï„â†“0
xâ†’Â¯x
1
Ï„
&
f(x+Ï„y)âˆ’f(x)

=f â—¦(Â¯x, y)
and so f â€²(Â¯x) âˆˆâˆ‚â—¦f(Â¯x).
(c) By Proposition 3.2.4, f is locally L-continuous around Â¯x and strictly G-
diï¬€erentiable at Â¯x. We therefore have
âŸ¨f â€²(Â¯x), yâŸ©= lim
Ï„â†’0
xâ†’Â¯x
1
Ï„
&
f(x + Ï„y) âˆ’f(x)

= f â—¦(Â¯x, y)
âˆ€y âˆˆE
and so âˆ‚â—¦f(Â¯x) = {f â€²(Â¯x)} = âˆ‚â™¦f(Â¯x).
(d) Let Î´ > 0. Then
f â—¦(Â¯x, y) =
inf
Ïµâˆˆ(0,Ïµ0)
sup
Ï„âˆˆ(0,Ïµ)
xâˆˆB(Â¯x,Î´Ïµ)
1
Ï„
&
f(x + Ï„y) âˆ’f(x)

=
inf
Ïµâˆˆ(0,Ïµ0)
sup
xâˆˆB(Â¯x,Î´Ïµ)
1
Ïµ
&
f(x + Ïµy) âˆ’f(x)

;
(7.20)
here the ï¬rst equation is a consequence of the deï¬nition of the limit su-
perior, and the second holds by Theorem 4.1.3(a) because f is convex.
Denoting the Lipschitz constant of f around Â¯x by Î», we further obtain
1
Ïµ
&
f(x + Ïµy) âˆ’f(x)

âˆ’
&
f(Â¯x + Ïµy) âˆ’f(Â¯x)

â‰¤1
Ïµ
f(x + Ïµy) âˆ’f(Â¯x + Ïµy)
 +
f(Â¯x) âˆ’f(x)

â‰¤2Î´Î»,

146
7 Derivatives and Subdiï¬€erentials of Lipschitz Functionals
provided âˆ¥xâˆ’Â¯xâˆ¥< Î´Ïµ and Ïµ is suï¬ƒciently small. With this estimate, (7.20)
passes into
f â—¦(Â¯x, y) â‰¤
inf
Ïµâˆˆ(0,Ïµ0)
1
Ïµ
&
f(Â¯x + Ïµy) âˆ’f(Â¯x)

+ 2Î´Î»
= fG(Â¯x, y) + 2Î´Î» = fH(Â¯x, y) + 2Î´Î»;
here the second equation holds by Proposition 4.1.8. Since Î´ > 0 was
arbitrary, it follows that f â—¦(Â¯x, y) â‰¤fH(Â¯x, y). Since the reverse inequality
always holds, we obtain f â—¦(Â¯x, y) = fH(Â¯x, y) and so âˆ‚â—¦f(Â¯x) = âˆ‚f(Â¯x). The
assertion concerning f â™¦(Â¯x, Â·) and âˆ‚â™¦f(Â¯x) follows from this and (a) since
by Theorem 4.1.3(d), fH(Â¯x, Â·) and so fG(Â¯x, Â·) exists and is sublinear.
âŠ“âŠ”
Remark 7.3.10
(a) Proposition 7.3.9 shows that the Michelâ€“Penot subdiï¬€erential is a gener-
alization of the G-derivative while the Clarke subdiï¬€erential generalizes
the strict H-derivative.
(b) Since we always have âˆ‚â™¦f(Â¯x) âŠ†âˆ‚â—¦f(Â¯x) (Proposition 7.3.7) and the in-
clusion may be proper (see Example 7.3.11), the necessary optimality
condition o âˆˆâˆ‚â™¦f(Â¯x) (Proposition 7.3.6) is in general stronger than the
condition o âˆˆâˆ‚â—¦f(Â¯x).
Example 7.3.11 Let E := R and f(x) := x2 sin 1
x for x Ì¸= 0, f(0) := 0.
Then f is locally L-continuous and diï¬€erentiable at 0, with f â€²(0) = 0. By
Proposition 7.3.9 we have f â™¦(0, y) = 0 for each y âˆˆR and âˆ‚â™¦f(0) = {0}. On
the other hand, we obtain f â—¦(0, y) = |y| for each y âˆˆR and so âˆ‚â—¦f(0) = [âˆ’1, 1].
Notice that f is not strictly diï¬€erentiable at 0.
Recall that a locally L-continuous function f : Rn â†’R is diï¬€erentiable
almost everywhere, i.e., outside a set â„¦f of n-dimensional Lebesgue measure
zero (Theorem of Rademacher, see, for instance, Evans and Gariepy [63]).
Theorem 7.3.12 If f : Rn â†’R is locally L-continuous around Â¯x and S âŠ†Rn
has n-dimensional Lebesgue measure zero, then one has
âˆ‚â—¦f(Â¯x) = co

lim
kâ†’âˆf â€²(xk)
 xk â†’Â¯x, xk /âˆˆâ„¦f âˆªS}.
For a proof of Theorem 7.3.12 we refer to Clarke [36].
7.4 Subdiï¬€erential Calculus
The following notion will serve to reï¬ne certain computation rules for the
subdiï¬€erentials.
Deï¬nition 7.4.1 The functional f : D â†’R is called regular (in the sense of
Clarke) at Â¯x if fG(Â¯x, Â·) and f â—¦(Â¯x, Â·) both exist and coincide.

7.4 Subdiï¬€erential Calculus
147
Remark 7.4.2
(a) If f is regular at Â¯x, then together with f â—¦(Â¯x, Â·) the functional fG(Â¯x, Â·)
is sublinear and so the two functionals also coincide with f â™¦(Â¯x, Â·)
(Proposition 7.3.9).
(b) Let the functional f : D â†’R be locally L-continuous around Â¯x. Then it
is regular at Â¯x if it is strictly H-diï¬€erentiable or if D and f are convex
(Proposition 7.3.9).
Concerning the following computation rules, compare Proposition 4.5.1.
Proposition 7.4.3 (Sum Rule) Let f0, f1, . . . , fn : D â†’R be locally L-
continuous around Â¯x:
(a) One has
âˆ‚â—¦
 n
	
i=0
fi

(Â¯x) âŠ†
n
	
i=0
âˆ‚â—¦fi(Â¯x)
and
âˆ‚â™¦
 n
	
i=0
fi

(Â¯x) âŠ†
n
	
i=0
âˆ‚â™¦fi(Â¯x).
(7.21)
(b) If f1, . . . , fn are strictly H-diï¬€erentiable at Â¯x, then (7.21) holds with equal-
ity in both cases.
(c) If f0, f1, . . . , fn are regular at Â¯x, then
n
i=0
fi is regular at Â¯x and (7.21)
holds with equality in both cases.
Proof.
(a) We verify the statement for the Clarke subdiï¬€erential, leaving the veri-
ï¬cation for the Michelâ€“Penot subdiï¬€erential as Exercise 7.5.4. Moreover,
we conï¬ne ourselves to the case n = 1; the general case then follows by
induction. Since by Proposition 7.3.7, we have f â—¦
i (Â¯x, y) = max{âŸ¨v, yâŸ©| v âˆˆ
âˆ‚â—¦fi(Â¯x)} for i = 0, 1, we conclude that:
â€“ The support functional of âˆ‚â—¦(f0 + f1)(Â¯x) is (f0 + f1)â—¦(Â¯x, Â·).
â€“ The support functional of âˆ‚â—¦f0(Â¯x) + âˆ‚â—¦f1(Â¯x) is f â—¦
0 (Â¯x, Â·) + f â—¦
1 (Â¯x, Â·).
From the deï¬nition of the Clarke directional derivative we easily obtain
(f0 + f1)â—¦(Â¯x, y) â‰¤f â—¦
0 (Â¯x, y) + f â—¦
1 (Â¯x, y)
âˆ€y âˆˆE.
(7.22)
Hence the assertion follows by the HÂ¨ormander theorem (Theorem 2.3.1(c)).
(b) The assumption implies that the functional f1 + Â· Â· Â· + fn is also strictly
H-diï¬€erentiable. Therefore it suï¬ƒces to consider the case n = 1. It is easy
to show that
(f0 + f1)â—¦(Â¯x, y) = f â—¦
0 (Â¯x, y) + âŸ¨f â€²
1(Â¯x), yâŸ©= f â—¦
0 (Â¯x, y) + f â—¦
1 (Â¯x, y)
âˆ€y âˆˆE.
This together with (a) yields the assertion for the Clarke subdiï¬€erential.
Again the proof is analogous for the Michelâ€“Penot subdiï¬€erential.

148
7 Derivatives and Subdiï¬€erentials of Lipschitz Functionals
(c) By assumption we obtain
(f0 + f1)G(Â¯x, y)
= f0,G(Â¯x, y) + f1,G(Â¯x, y) = f â—¦
0 (Â¯x, y) + f â—¦
1 (Â¯x, y)
â‰¥
(7.22)
(f0 + f1)â—¦(Â¯x, y).
On the other hand, we always have (f0 + f1)â—¦(Â¯x, y) â‰¥(f0 + f1)G(Â¯x, y).
Therefore f0 + f1 is regular at Â¯x. Moreover, by what has just been shown
we see that
(f0 + f1)â—¦(Â¯x, y) = f â—¦
0 (Â¯x, y) + f â—¦
1 (Â¯x, y)
âˆ€y âˆˆE.
From this, the assertion again follows by the HÂ¨ormander theorem since
the left-hand side is the support functional of âˆ‚â—¦(f0+f1)(Â¯x) and the right-
hand side is the support functional of âˆ‚â—¦f0(Â¯x) + âˆ‚â—¦f1(Â¯x). Remark 7.4.2(a)
completes the proof.
âŠ“âŠ”
Next we establish a mean value theorem. If x, y âˆˆE and A âŠ†Eâˆ—, we write
[x, y] := {(1 âˆ’Ï„)x + Ï„y | Ï„ âˆˆ[0, 1]},
(x, y) := {(1 âˆ’Ï„)x + Ï„y | Ï„ âˆˆ(0, 1)},
âŸ¨A, xâŸ©:= {âŸ¨xâˆ—, xâŸ©| xâˆ—âˆˆA}.
Theorem 7.4.4 (Mean Value Theorem) Assume that f : D â†’R is loc-
ally L-continuous and [x, y] âŠ†D. Then there exists z âˆˆ(x, y) satisfying
f(y) âˆ’f(x) âˆˆâŸ¨âˆ‚â—¦f(z), y âˆ’xâŸ©.
(7.23)
Proof.
(I) For Î» âˆˆ[0, 1] let xÎ» := x + Î»(y âˆ’x). Deï¬ne Ï•, Ïˆ : [0, 1] â†’R by
Ï•(Î») := Ïˆ(Î») + Î»

f(x) âˆ’f(y)

,
Ïˆ(Î») := f(xÎ»).
Since Ï•(0) = Ï•(1) = f(x), the continuous function Ï• attains a local
minimum or a local maximum at some Î»0 âˆˆ(0, 1). Therefore 0 âˆˆâˆ‚â—¦Ï•(Î»0)
(Proposition 7.3.6). By Propositions 7.3.5 and 7.4.3 we obtain
0 âˆˆâˆ‚â—¦Ïˆ(Î»0) +

f(x) âˆ’f(y)

.
(7.24)
(II) We show that
âˆ‚â—¦Ïˆ(Î») âŠ†âŸ¨âˆ‚â—¦f(xÎ»), y âˆ’xâŸ©
âˆ€Î» âˆˆ(0, 1).
(7.25)
Observe that Ïˆ is L-continuous on (0, 1) so that âˆ‚â—¦Ïˆ makes sense. Also
notice that the two sets in (7.25) are closed convex subsets of R and so
are intervals. Hence it suï¬ƒces to prove that
max

aâˆ‚â—¦Ïˆ(Î»)

â‰¤max

aâŸ¨âˆ‚â—¦f(xÎ»), y âˆ’xâŸ©

for a = Â±1.

7.4 Subdiï¬€erential Calculus
149
This is veriï¬ed as follows:
max

aâˆ‚â—¦Ïˆ(Î»)

= Ïˆâ—¦(Î», a) = lim sup
Ï„â†“0
Î»â€²â†’Î»
1
Ï„

Ïˆ(Î»â€² + Ï„a) âˆ’Ïˆ(Î»â€²)

= lim sup
Ï„â†“0
Î»â€²â†’Î»
1
Ï„
&
f

x + (Î»â€² + Ï„a)(y âˆ’x)

âˆ’f

x + Ï„(y âˆ’x)

â‰¤lim sup
Ï„â†“0
zâ†’xÎ»
1
Ï„
&
f

z + Ï„a(y âˆ’x)

âˆ’f(z)

= f â—¦(xÎ», a(y âˆ’x)) = maxâŸ¨âˆ‚â—¦f(xÎ»), a(y âˆ’x)âŸ©.
In view of (7.24) and (7.25) the proof is complete on setting z := xÎ»0.
âŠ“âŠ”
Finally we establish a chain rule. We consider the composite function
g â—¦h : E â†’R, where
h : E â†’Rn,
g : Rn â†’R,
(g â—¦h)(x) := g

h(x)

,
x âˆˆE.
(7.26)
We identify

Rnâˆ—with Rn, put h = (h1, . . . , hn) with hi : E â†’R, and deï¬ne
for any a âˆˆRn,
ha(x) := âŸ¨a, h(x)âŸ©Rn,
x âˆˆE.
(7.27)
Recall that coâˆ—A denotes the Ïƒ(Eâˆ—, E)-closed convex hull of the set A âŠ†Eâˆ—.
Theorem 7.4.5 (Chain Rule) Let g and h be as in (7.26). Assume that h
is locally L-continuous around Â¯x âˆˆE and g is locally L-continuous around
h(Â¯x). Then:
(a) The composite function g â—¦h is locally L-continuous around Â¯x, and there
holds
âˆ‚â—¦(g â—¦h)(Â¯x) âŠ†coâˆ—{âˆ‚â—¦ha(Â¯x) | a âˆˆâˆ‚â—¦g

h(Â¯x)

}.
(7.28)
(b) If, in addition, g is regular at h(Â¯x), any hi is regular at Â¯x, and any a âˆˆ
âˆ‚â—¦g

h(Â¯x)

has nonnegative components, then (7.28) holds as equality and
g â—¦h is regular at Â¯x.
Proof.
(I) Set f := g â—¦h. It is easy to see that f is locally L-continuous around Â¯x.
(II) Denote the set on the right-hand side of the inclusion (7.28) by M.
The sets âˆ‚â—¦f(Â¯x) and M are nonempty, convex, and Ïƒ(Eâˆ—.E)-compact.
Therefore (7.28) holds if and only if the associated support functions
satisfy Ïƒâˆ‚â—¦f(Â¯x) â‰¤ÏƒM. By Proposition 7.3.7, we have Ïƒâˆ‚â—¦f(Â¯x) = f â—¦(Â¯x, Â·).
Hence the theorem is veriï¬ed if we can show that
f â—¦(Â¯x, y) â‰¤ÏƒM(y)
âˆ€y âˆˆE.
(7.29)

150
7 Derivatives and Subdiï¬€erentials of Lipschitz Functionals
(III) To verify (7.29), let y âˆˆE be given. We shall construct elements a âˆˆ
âˆ‚â—¦g

h(Â¯x)

and yâˆ—âˆˆâˆ‚â—¦ha(Â¯x) satisfying
f â—¦(Â¯x, y) â‰¤âŸ¨yâˆ—, yâŸ©.
(7.30)
Choose sequences Ï„k â†“0 and xk â†’Â¯x such that
lim
kâ†’âˆ
1
Ï„k

f(xk + Ï„ky) âˆ’f(xk)

= f â—¦(Â¯x, y).
By the mean value theorem (Theorem 7.4.4) there exist zk âˆˆ[h(xk),
h(xk + Ï„ky)] and ak âˆˆâˆ‚â—¦g(zk) satisfying
1
Ï„k

f(xk + Ï„ky) âˆ’f(xk)

= 1
Ï„k
#
g

h(xk + Ï„ky)

âˆ’g

h(xk)
$
=
2
ak, 1
Ï„k

h(xk + Ï„ky) âˆ’h(xk)
3
Rn.
(7.31)
Let Î» be a local Lipschitz constant of g at h(Â¯x). Since zk â†’h(Â¯x) as
k â†’âˆ, we conclude that for k suï¬ƒciently large, Î» is also a Lipschitz
constant of g at zk and so âˆ¥akâˆ¥â‰¤Î» (Proposition 7.3.7(a)). A subse-
quence of the sequence (ak), again denoted (ak), is thus convergent to
some a âˆˆRn. Proposition 7.3.7(c) shows that a âˆˆâˆ‚â—¦g

h(Â¯x)

.
(IV) Again by the mean value theorem there exist yk âˆˆ[xk, xk + Ï„ky] and
yâˆ—
k âˆˆâˆ‚â—¦ha(yk) such that
2
a, 1
Ï„k

h(xk + Ï„ky) âˆ’h(xk)
3
Rn = âŸ¨yâˆ—
k, yâŸ©.
(7.32)
As above it follows that the sequences (yâˆ—
k) and (âŸ¨yâˆ—
k, yâŸ©) are bounded
in Eâˆ—and R, respectively. Let again denote (âŸ¨yâˆ—
k, yâŸ©) a convergent sub-
sequence and let yâˆ—âˆˆEâˆ—be a Ïƒ(Eâˆ—, E)-cluster point of (yâˆ—
k). Then
âŸ¨yâˆ—
k, yâŸ©â†’âŸ¨yâˆ—, yâŸ©as k â†’âˆand yâˆ—âˆˆâˆ‚â—¦ha(Â¯x) by Proposition 7.3.7(c).
(V) Combining (7.31) and (7.32) we obtain
1
Ï„k

f(xk + Ï„ky) âˆ’f(xk)

=
2
ak âˆ’a, 1
Ï„

h(xk + Ï„ky) âˆ’h(xk)
3
Rn + âŸ¨yâˆ—
k, yâŸ©.
Since h is locally L-continuous around Â¯x and xk
â†’
Â¯x, the term
Ï„ âˆ’1
k

h(xk +Ï„ky)âˆ’h(xk)

is bounded. Moreover, we have ak â†’a. There-
fore we obtain
f â—¦(Â¯x, y) = lim
kâ†’âˆ
1
Ï„k

f(xk + Ï„ky) âˆ’f(xk)

= âŸ¨yâˆ—, yâŸ©,
which proves (a). The veriï¬cation of (b) is left as Exercise 7.5.5.
âŠ“âŠ”

7.4 Subdiï¬€erential Calculus
151
We consider the special case that g is strictly H-diï¬€erentiable at h(Â¯x).
Recall that Dig, where i = 1, . . . , n, denotes the partial derivative of g with
respect to the ith variable.
Corollary 7.4.6 Let g and h be as in (7.26). Assume that h is locally L-
continuous around Â¯x âˆˆE and g is strictly H-diï¬€erentiable at h(Â¯x). Then the
composite function g â—¦h is locally L-continuous around Â¯x, and there holds
âˆ‚â—¦(g â—¦h)(Â¯x) âŠ†
n
	
i=1
Dig

h(Â¯x)

âˆ‚â—¦hi(Â¯x).
(7.33)
In particular, if n = 1, then
âˆ‚â—¦(g â—¦h)(Â¯x) = gâ€²
h(Â¯x)

âˆ‚â—¦h(Â¯x).
(7.34)
Proof.
(I) By Proposition 7.3.9(c) we have âˆ‚â—¦g

h(Â¯x)

= {gâ€²
h(Â¯x)

} and so, with
a = gâ€²
h(Â¯x)

,
ha(x) =
n
	
i=1
Dig

h(Â¯x)

hi(x),
x âˆˆE.
The inclusion (7.33) now follows by applying Theorem 7.4.5 and
Propositions 7.3.5 and 7.4.3. The coâˆ—operation is superï¬‚uous here
since with each âˆ‚â—¦hi(Â¯x) the set on the right-hand side of (7.33) is
Ïƒ(Eâˆ—, E)-compact and convex.
(II) Now let n = 1. Deï¬ne Î³ : E â†’R by
Î³(y) := max{gâ€²
h(Â¯x)

âŸ¨xâˆ—, yâŸ©| xâˆ—âˆˆâˆ‚â—¦h(Â¯x)}.
For any y âˆˆE we have
Î³(y) = gâ€²
h(Â¯x)

hâ—¦(Â¯x, y) = lim sup
Ï„â†“0
xâ†’Â¯x
1
Ï„ gâ€²
h(Â¯x)

h(x + Ï„y) âˆ’h(x)

= lim sup
Ï„â†“0
xâ†’Â¯x
1
Ï„
#
g

h(x + Ï„y)

âˆ’g

h(x)
$
= (g â—¦h)â—¦(Â¯x, y).
Here, the ï¬rst equation holds by Proposition 7.3.7(b) and the third
is a consequence of the strict H-diï¬€erentiability of g. The assertion
(7.34) follows because Î³ is the support function of gâ€²
h(Â¯x)

âˆ‚â—¦h(Â¯x) and
(g â—¦h)â—¦(Â¯x, Â·) is the support function of âˆ‚â—¦(g â—¦h)(Â¯x).
âŠ“âŠ”
Given a ï¬nite family of functionals fi : D â†’R, i âˆˆI, we consider the
maximum functional f : D â†’R deï¬ned by
f(x) := max{fi(x) | i âˆˆI},
x âˆˆD.
(7.35)

152
7 Derivatives and Subdiï¬€erentials of Lipschitz Functionals
Let Â¯x âˆˆD. As in Sect. 7.2 we set
I(Â¯x) := {i âˆˆI | fi(Â¯x) = f(Â¯x)}.
Proposition 7.4.7 (Maximum Rule) Let I be a ï¬nite set and for all i âˆˆI
let fi : D â†’R be locally L-continuous around Â¯x. Then the functional f deï¬ned
by (7.35) satisï¬es
âˆ‚â—¦f(Â¯x) âŠ†co{âˆ‚â—¦fi(Â¯x) | i âˆˆI(Â¯x)}
and
âˆ‚â™¦f(Â¯x) âŠ†co{âˆ‚â™¦fi(Â¯x) | i âˆˆI(Â¯x)}.
(7.36)
If, in addition, fi is regular at Â¯x for any i âˆˆI(Â¯x), then the ï¬rst inclusion in
(7.36) holds with equality and f is regular at Â¯x.
Proof. We verify (7.36) for the Michelâ€“Penot subdiï¬€erential, leaving the proof
for the Clarke subdiï¬€erential as Exercise 7.5.6.
(I)
As in the proof of Proposition 7.2.7 it can be shown that for i âˆˆI \ I(Â¯x)
the functional fi does not contribute to f â™¦(Â¯x, Â·).
(II) Let y âˆˆE be given. Choose sequences (zn) in E and (Ï„n) in (0, +âˆ) such
that Ï„n â†“0 and
1
Ï„n

f(Â¯x + Ï„ny + Ï„nzn) âˆ’f(Â¯x + Ï„nzn)

â†’f â™¦(Â¯x, y)
as n â†’âˆ.
Without loss of generality we may assume that for suitable subsequences,
again denoted (zn) and (Ï„n), we have for some i âˆˆI(Â¯x),
f(Â¯x + Ï„ny + Ï„nzn) = fi(Â¯x + Ï„ny + Ï„nzn).
It follows that
f â™¦
i (Â¯x, y) â‰¥lim sup
nâ†’âˆ
1
Ï„n

fi(Â¯x + Ï„ny + Ï„nzn) âˆ’fi(Â¯x + Ï„nzn)

â‰¥lim sup
nâ†’âˆ
1
Ï„n

f(Â¯x + Ï„ny + Ï„nzn) âˆ’f(Â¯x + Ï„nzn)

= f â™¦(Â¯x, y)
and so f â™¦(Â¯x, Â·)
â‰¤
f â™¦
i (Â¯x, Â·)
â‰¤
maxiâˆˆI(Â¯x) f â™¦
i (Â¯x, Â·). Since f â™¦(Â¯x, Â·) is the
support functional of âˆ‚â™¦f(Â¯x) (Proposition 7.3.7) and so equals Î´âˆ—
âˆ‚â™¦f(Â¯x)
(Example 2.2.5), we conclude that, setting M := co{âˆ‚â™¦fi(Â¯x) | i âˆˆI(Â¯x)},
we have
Î´âˆ—
âˆ‚â™¦f(Â¯x) â‰¤max
iâˆˆI(Â¯x) Î´âˆ—
âˆ‚â™¦fi(Â¯x) = Î´âˆ—
M;
here the equality sign is easily veriï¬ed. By Proposition 7.3.7 the set M is
nonempty, convex, and Ïƒ(Eâˆ—, E)-compact and so Î´M is proper, convex, and
l.s.c. Hence Theorem 2.2.4 gives Î´M = Î´âˆ—âˆ—
M â‰¤Î´âˆ—âˆ—
âˆ‚â™¦f(Â¯x)) = Î´âˆ‚â™¦f(Â¯x), and we
conclude that âˆ‚â™¦f(Â¯x) âŠ†M.
âŠ“âŠ”

7.5 Bibliographical Notes and Exercises
153
7.5 Bibliographical Notes and Exercises
(Radial) upper convex approximations were introduced and studied by
Neustadt [150] and Pshenichnyi [168] (see also Scheï¬„er [190] and Scheï¬„er
and Schirotzek [192]). (Regularly) locally convex functionals are considered
by Ioï¬€e and Tikhomirov [101]. Demyanov and Rubinov [47, 48] studied qua-
sidiï¬€erentiable functionals in detail (see also Luderer et al. [126] and the
literature cited therein).
Clarkeâ€™s doctoral thesis [33] marks a breakthrough in that it gives, for
Lipschitz functions on Rn, the ï¬rst intrinsic (nonaxiomatic) approach to
generalized directional derivatives. The characterization of âˆ‚â—¦f(Â¯x) given in
Theorem 7.3.12 is Clarkeâ€™s original deï¬nition in the ï¬nite-dimensional case.
A remarkable generalization of this characterization to Banach spaces with a
Î²-smooth norm is due to Preiss [166].
Clarke [36] systematically elaborated his concept in normed vector spaces.
The mean value theorem (Theorem 7.4.4) is due to Lebourg [119]. For further
results of this kind see Hiriart-Urruty [86], Penot [163], and Studniarski [202,
203]. A mean value theorem in terms of radial upper convex approximations
that encompasses Lebourgâ€™s mean value theorem is due to Scheï¬„er [191]. For
applications of Clarkeâ€™s directional derivative and subdiï¬€erential to various
problems we refer to Clarke [36], Clarke et al. [39], Loewen [123], MÂ¨akelÂ¨a and
NeittaanmÂ¨aki [149], Panagiotopoulos [157], Papageorgiou and Gasinski [158],
and the references in these books. The Michelâ€“Penot directional derivative
and subdiï¬€erential (see [129,130]) are considered, among others, by Borwein
and Lewis [18] and Ioï¬€e [99].
Exercise 7.5.1 Prove Proposition 7.2.2.
Hint: Compare the proof of Lemma 3.1.2.
Exercise 7.5.2 Deï¬ne f : R2 â†’R by f(x1, x2) := 0 if x1 â‰¥0 and
f(x1, x2) := 1 otherwise. Show that f is locally convex but not regularly
locally convex at Â¯x := (0, 0).
Exercise 7.5.3 Prove Proposition 7.2.7 for the directional H-derivative.
Exercise 7.5.4 Verify Proposition 7.4.3 for the Michelâ€“Penot subdiï¬€erential.
Exercise 7.5.5 Verify assertion (b) of Theorem 7.4.5.
Exercise 7.5.6 Prove Proposition 7.4.7 for the Clarke subdiï¬€erential.
Hint: Deï¬ne g : Rn â†’R and h : E â†’Rn by
g(z1, . . . , zn) := max{z1, . . . , zn},
h(x) :=

f1(x), . . . , fn(x)

.
Observe that f = g â—¦h and apply Theorem 7.4.5.

8
Variational Principles
8.1 Introduction
Convention. In this chapter, unless otherwise speciï¬ed, assume that E is a
Banach space and f : E â†’R is proper, l.s.c., and bounded below.
The theory of generalized directional derivatives and subdiï¬€erentials con-
sidered so far for both convex and nonconvex functionals is essentially based on
separation and so on convexity arguments; consider, e.g., the proofs of the sum
rules (Propositions 4.5.1 and 7.4.3) and the maximum rule (Proposition 7.4.7),
where the crucial tool is the sandwich theorem, the HÂ¨ormander theorem, and
the biconjugation theorem, respectively. These tools were applicable since the
derivative-like objects constructed are convex. It turns out that a correspond-
ing theory not enforcing convexity and working beyond the Lipschitz case
requires quite diï¬€erent tools. In the following we establish variational prin-
ciples as well as extremal principles, which have proved to be adequate for
treating lower semicontinuous functionals. (To be precise, Clarkeâ€™s multiplier
rule for Lipschitz functionals to be derived in Sect. 12.4 also hinges on a vari-
ational principle.)
First we explain the idea of variational principles. It is clear that a func-
tional f as above may fail to have a global minimizer. However, since f is
bounded below, there are points that â€œalmostâ€ minimize f, i.e., for each Ïµ > 0
there exists Â¯x âˆˆE satisfying
f(Â¯x) â‰¤inf
xâˆˆE f(x) + Ïµ.
Ekeland [56] showed that for each such Â¯x and each Î» > 0 there exists a
point z âˆˆE that actually minimizes the slightly perturbed functional
Ï•(y) := f(y) + Ïµ
Î»âˆ¥z âˆ’yâˆ¥,
y âˆˆE,
and is such that âˆ¥z âˆ’Â¯xâˆ¥â‰¤Î». This ï¬rst variational principle has remarkable
applications in quite diï¬€erent areas of nonlinear analysis (see the references
at the end of this chapter).

156
8 Variational Principles
A drawback of Ekelandâ€™s variational principle is that the perturbed func-
tional Ï• is not diï¬€erentiable at y = z even if the original functional f
is diï¬€erentiable on all of E. The ï¬rst to overcome this drawback were
Borwein and Preiss [19] who established a smooth variational principle. Mean-
while several smooth variational principles have been derived. We present
below a smooth variational principle due to Loewen and Wang [125] from
which the mentioned variational principles will then be deduced in a uni-
ï¬ed way.
8.2 The Loewenâ€“Wang Variational Principle
We write infE f for infxâˆˆE f(x). Recall the notion of a minimizing sequence.
Deï¬nition 8.2.1
(a) A point Â¯x âˆˆE is said to be a strict minimizer of f if f(Â¯x) < f(x) for
each x âˆˆE, x Ì¸= Â¯x.
(b) A point Â¯x âˆˆE is said to be a strong minimizer of f if f(Â¯x) = infE f and
each minimizing sequence for f is convergent to Â¯x.
It is clear that each strong minimizer of f is also a strict minimizer. But
the converse is false. For example, the point Â¯x = 0 is a strict but not a strong
minimizer of the function f(x) := x2eâˆ’x on R; notice that each sequence (xn)
tending to +âˆas n â†’âˆis a minimizing sequence for f.
Recall that diam(A) := sup{âˆ¥x âˆ’yâˆ¥| x, y âˆˆA} denotes the diameter of
the set A âŠ†E.
Remark 8.2.2 For Ïµ > 0 let
Î£Ïµ(f) := {x âˆˆE | f(x) â‰¤inf
E f + Ïµ}.
It is left as Exercise 8.5.1 to show that the functional f has a strong minimizer
on E if and only if
inf {diam

Î£Ïµ(f)
  Ïµ > 0} = 0.
Now we construct a perturbation Ïâˆof f. The data involved will be spec-
iï¬ed in Theorem 8.2.3. Let Ï : E â†’[0, +âˆ) be such that
Ï(o) = 0,
Î· := sup{âˆ¥xâˆ¥| x âˆˆE, Ï(x) < 1} < +âˆ
(8.1)
and set
Ïâˆ(x) :=
âˆ
	
n=0
Âµn Ï

(n + 1)(x âˆ’zn)

.
(8.2)

8.2 The Loewenâ€“Wang Variational Principle
157
Theorem 8.2.3 (Loewenâ€“Wang) Let Ïµ > 0 and let Â¯x âˆˆE be such that
f(Â¯x) < infE f + Ïµ. Assume further that Ï : E â†’[0, +âˆ) is a continuous
function satisfying (8.1) and that (Âµn) is a decreasing sequence in (0, 1) with
âˆ
n=0 Âµn < +âˆ. Then there exists a sequence (zn) in E converging to some
z âˆˆE such that, with Ïâˆaccording to (8.2), the following holds:
(a) Ï(Â¯x âˆ’z) < 1.
(b) f(z) + ÏµÏâˆ(z) â‰¤f(Â¯x).
(c) z is a strong minimizer of f + ÏµÏâˆon E. In particular,
f(z) + ÏµÏâˆ(z) < f(x) + ÏµÏâˆ(x)
âˆ€x âˆˆE \ {z}.
(8.3)
Proof.
(I) Set z0 := Â¯x, f0 := f. By induction, zn+1 can be chosen (see below) and
fn+1, Dn can be deï¬ned for n = 0, 1, . . . in the following way:
fn+1(x) := fn(x) + ÏµÂµn Ï

(n + 1)(x âˆ’zn)

,
x âˆˆE,
(8.4)
fn+1(zn+1) â‰¤Âµn+1
2
fn(zn) +

1 âˆ’Âµn+1
2

inf
E fn+1 â‰¤fn(zn),
(8.5)
Dn :=
0
x âˆˆE
 fn+1(x) â‰¤fn+1(zn+1) + ÂµnÏµ
2
1
.
(8.6)
We show that zn+1 can be chosen according to (8.5). Note that
infE fn+1 â‰¤fn+1(zn) = fn(zn). If this inequality is strict, then by
the deï¬nition of the inï¬mum there exists zn+1 âˆˆE such that
fn+1(zn+1) < inf
E fn+1 + Âµn+1
2

fn(zn) âˆ’inf
E fn+1

.
If equality holds, then choose zn+1 := zn. In either case, (8.5) is satis-
ï¬ed.
(II) Since fn+1 is l.s.c., the set Dn is closed. Moreover Dn is nonempty as
zn+1 âˆˆDn. Since Âµn âˆˆ(0, 1) and fn+1 â‰¥fn, (8.5) implies
fn+1(zn+1) âˆ’inf
E fn+1 â‰¤Âµn+1
2

fn(zn) âˆ’inf
E fn+1

â‰¤fn(zn) âˆ’inf
E fn.
(8.7)
(III) We have Dn âŠ†Dnâˆ’1 for n = 1, 2 . . . In fact, if x âˆˆDn, then Âµnâˆ’1 > Âµn
and (8.5) yield
fn(x) â‰¤fn+1(x) â‰¤fn+1(zn+1) + ÂµnÏµ
2
â‰¤fn(zn) + Âµnâˆ’1Ïµ
2
and so x âˆˆDnâˆ’1.
(IV) We show that diam(Dn) â†’0 as n â†’âˆ. Since fnâˆ’1 â‰¤fn, (8.5) with
n replaced by n âˆ’1 implies
fn(zn) âˆ’inf
E fn â‰¤Âµn
2

fnâˆ’1(znâˆ’1) âˆ’inf
E fn

â‰¤Âµn
2

fnâˆ’1(znâˆ’1) âˆ’inf
E fnâˆ’1

< ÂµnÏµ
2 .
(8.8)

158
8 Variational Principles
The last < follows from (8.7) and f0(z0)âˆ’infE f0 = f(Â¯x)âˆ’infE f < Ïµ.
Now let x âˆˆDn. By the deï¬nitions of Dn and fn+1 we obtain
ÂµnÏµ Ï

(n + 1)(x âˆ’zn)

â‰¤fn+1(zn+1) âˆ’fn(x) + ÂµnÏµ
2
â‰¤fn+1(zn+1) âˆ’inf
E fn + ÂµnÏµ
2 .
This inequality together with fn+1(zn+1) â‰¤fn(zn) (see (8.5)) and (8.8)
shows that
Ï

(n + 1)(x âˆ’zn)

< 1
âˆ€n = 0, 1, . . .
(8.9)
The hypothesis (8.1) therefore implies
(n + 1)âˆ¥x âˆ’znâˆ¥â‰¤Î·
(8.10)
and so diam(Dn) â‰¤
2Î·
n+1 â†’0 as n â†’âˆ.
(V) In view of (III) and (IV), Cantorâ€™s intersection theorem applies to (Dn)
ensuring that âˆ
n=0 Dn contains exactly one point, say z. For each n
we have zn+1 âˆˆDn and z âˆˆDn. Hence âˆ¥zn+1 âˆ’zâˆ¥â†’0 as n â†’âˆ.
Moreover, setting x = z and n = 0 in (8.9), we see that Ï(z âˆ’Â¯x) < 1.
This veriï¬es (a).
(VI) Next we show that f(z) + ÏµÏâˆ(z) â‰¤fn(zn) for each n. Let
%Dn := {x âˆˆE | fn+1(x) â‰¤fn+1(zn+1)}
for n = 1, 2, . . .
Since fn+1 â‰¥fn but fn+1(zn+1) â‰¤fn(zn) (see (8.5)), we have %Dn âŠ†
%Dnâˆ’1. Moreover, each %Dn is a nonempty closed subset of Dn. Therefore
âˆ
n=1 %Dn = {z}. This together with fn+1(zn+1) â‰¤fn(zn) implies
fk(z) â‰¤fk(zk) â‰¤fn(zn) â‰¤f0(z0) = f(Â¯x)
âˆ€k > n.
From (8.4) we get
fk(x) = f(x) + Ïµ
kâˆ’1
	
j=0
ÂµjÏ

(j + 1)(x âˆ’zj)

,
x âˆˆE.
(8.11)
Recalling (8.2), we conclude that
f(z) + ÏµÏâˆ(z) = lim
kâ†’âˆfk(z) â‰¤fn(zn) â‰¤f(Â¯x).
(8.12)
This was claimed above and this also veriï¬es (b).
(VII) Let Ëœf := f + ÏµÏâˆ. We show that Î£ÂµnÏµ/2( Ëœf) âŠ†Dn for each n. Thus let
x âˆˆÎ£ÂµnÏµ/2( Ëœf). Then
fn+1(x)
â‰¤
(8.11)
Ëœf(x) â‰¤Ëœf(z) + ÂµnÏµ
2
â‰¤
(8.12)
fn+1(zn+1) + ÂµnÏµ
2
and so indeed x âˆˆDn.

8.2 The Loewenâ€“Wang Variational Principle
159
(VIII) Since the sequence (Âµn) is decreasing, the sequence of the closed sets
Î£ÂµnÏµ/2( Ëœf) is decreasing with respect to inclusion and so (V) and (VII)
give âˆ
n=0 Î£ÂµnÏµ/2( Ëœf) = {z}. Hence z is a minimizer of Ëœf. By (IV) and
(VII) we have
lim
nâ†’âˆdiam

Î£ÂµnÏµ/2( Ëœf)

= 0.
Hence Remark 8.2.2 ï¬nally tells us that z is even a strong minimizer
of Ëœf.
âŠ“âŠ”
As a ï¬rst corollary to Theorem 8.2.3 we derive a Banach space variant of
Ekelandâ€™s variational principle, with the additional property that the mini-
mizer of the perturbed functional is strong.
Theorem 8.2.4 (Ekeland) Let Ïµ > 0 and let Â¯x âˆˆE be such that f(Â¯x) <
infE f + Ïµ. Then for any Î» > 0 there exists z âˆˆE such that:
(a) âˆ¥Â¯x âˆ’zâˆ¥< Î».
(b) z is a strong minimizer of the functional x â†’f(x) + Ïµ
Î»âˆ¥x âˆ’zâˆ¥on E.
In particular,
f(z) < f(x) + Ïµ
Î»âˆ¥x âˆ’zâˆ¥
âˆ€x âˆˆE \ {z}.
(8.13)
Proof. Set
Ï(x) := âˆ¥xâˆ¥
Î» ,
Âµn :=
1
2n+1(n + 1).
By Theorem 8.2.3 there exist a sequence (zn) and a point z in E such that,
in particular, (8.3) holds true, i.e., for each x Ì¸= z we have
f(z) < f(x) + Ïµ

Ïâˆ(x) âˆ’Ïâˆ(z)

= f(x) + Ïµ
Î»
âˆ
	
n=0
1
2n+1 (âˆ¥x âˆ’znâˆ¥âˆ’âˆ¥z âˆ’znâˆ¥)
â‰¤f(x) + Ïµ
Î»
âˆ
	
n=0
1
2n+1 âˆ¥x âˆ’zâˆ¥= f(x) + Ïµ
Î»âˆ¥x âˆ’zâˆ¥.
(8.14)
This veriï¬es (8.13). Now let (xn) be a minimizing sequence for Ï•(x) := f(x)+
Ïµ
Î»âˆ¥x âˆ’zâˆ¥, i.e., Ï•(xn) â†’infE Ï• = f(z) as n â†’âˆ. Then (8.14) shows that
(xn) is a minimizing sequence for f + ÏµÏâˆ. By Theorem 8.2.3(c) we conclude
that xn â†’z. Hence z is a strong minimizer of Ï•.
âŠ“âŠ”
Corollary 8.2.5 Let Ïµ > 0 and let Â¯x âˆˆE be such that f(Â¯x) < infE f + Ïµ.
Assume that f is G-diï¬€erentiable. Then there exists z âˆˆB(Â¯x, âˆšÏµ) satisfying
f(z) < inf
E f + Ïµ
and
âˆ¥f â€²(z)âˆ¥< âˆšÏµ.
Proof. See Exercise 8.5.2.
âŠ“âŠ”

160
8 Variational Principles
The corollary states that near an â€œalmost minimumâ€ point of f we can ï¬nd
an â€œalmost criticalâ€ point. In particular, there exists a minimizing sequence
(xk) of f such that the sequence (f â€²(xk)) converges to zero.
Corollary 8.2.6 Let A be a closed subset of E, let f : A â†’R be l.s.c. and
bounded below. Let Ïµ > 0 and let Â¯x âˆˆA be such that f(Â¯x) < infA f + Ïµ. Then
for any Î» > 0 there exists z âˆˆA such that:
(a) âˆ¥Â¯x âˆ’zâˆ¥< Î».
(b) z is a strong minimizer of the functional x â†’f(x) + Ïµ
Î»âˆ¥x âˆ’zâˆ¥on A.
In particular,
f(z) < f(x) + Ïµ
Î»âˆ¥x âˆ’zâˆ¥
âˆ€x âˆˆA \ {z}.
(8.15)
Proof. See Exercise 8.5.3.
âŠ“âŠ”
Here, we give a geometric application of Ekelandâ€™s variational principle.
In view of this, recall that by Corollary 1.5.5, every boundary point of a closed
convex set M âŠ†E is a support point provided M has interior points. Without
the latter condition, the existence of support points cannot be guaranteed.
However, the following result due to Bishop and Phelps [15] ensures that M
contains support points with respect to certain Bishopâ€“Phelps cones. In this
connection, M is not assumed to be convex or to have interior points. In
Fig. 8.1, the point y is a support point of M âŠ†R2 with respect to the Bishopâ€“
Phelps cone K(xâˆ—, Î±) while z is not.
Proposition 8.2.7 Let E be a Banach space and M be a closed subset of E.
Suppose that xâˆ—âˆˆEâˆ—\ {o} is bounded on M. Then for every Î± > 0 there
exists y âˆˆM such that
M âˆ©

y + K(xâˆ—, Î±)

= {y}.
Proof. See Exercise 8.5.4.
âŠ“âŠ”
y
z
y + K(xâˆ—, Î±)
z + K(xâˆ—, Î±)
M
Fig. 8.1

8.3 The Borweinâ€“Preiss Variational Principle
161
8.3 The Borweinâ€“Preiss Variational Principle
Now we deduce the smooth variational principle of Borwein and Preiss, again
with a strong minimizer.
Theorem 8.3.1 (Borweinâ€“Preiss) Let Ïµ > 0 and let Â¯x âˆˆE be such that
f(Â¯x) < infE f + Ïµ. Further let Î» > 0 and p â‰¥1. Then there exist a sequence
(Î½n) in (0, 1) with âˆ
n=0 Î½n = 1 and a sequence (zn) in E converging to some
z âˆˆE such that the following holds:
(a) âˆ¥z âˆ’Â¯xâˆ¥< Î».
(b) f(z) â‰¤infE f + Ïµ.
(c) z is a strong minimizer of f + ÏµÏâˆon E, where
Ïâˆ(x) := 1
Î»p
âˆ
	
n=0
Î½nâˆ¥x âˆ’znâˆ¥p.
(8.16)
Proof. We set
Ï(x) := âˆ¥xâˆ¥p
Î»p ,
Âµn :=
1
2n+1(n + 1)Ïƒ ,
where Ïƒ :=
âˆ
	
n=0
(n + 1)pâˆ’1
2n+1
.
(8.17)
Then there exists a sequence (zn) converging to some z as in Theorem 8.2.3.
The perturbation functional according to (8.2) here is given by (8.16), where
Î½n := (n + 1)pâˆ’1
2n+1Ïƒ
.
It is left as Exercise 8.5.5 to show that these data meet the assertions.
âŠ“âŠ”
Remark 8.3.2 If, under the assumptions of Theorem 8.3.1 and with p > 1,
the norm functional Ï‰(x) := âˆ¥xâˆ¥, x âˆˆE, is Î²-diï¬€erentiable on E \ {o} for
some bornology Î², then the perturbation functional Ïâˆdeï¬ned by (8.16) is
Î²-diï¬€erentiable on all of E and satisï¬es
Ïâ€²
âˆ(x) = p
Î»Ïƒ
âˆ
	
n=0
(n + 1)pâˆ’1
2n+1

x âˆ’zn
Î»

pâˆ’1
Ï‰â€²(x âˆ’zn)
âˆ€x Ì¸= zn, n âˆˆN,
Ïâ€²
âˆ(zn) = 0
âˆ€n âˆˆN,
âˆ¥Ïâ€²
âˆ(x)âˆ¥â‰¤p
Î»Ïƒ
âˆ
	
n=0
(n + 1)pâˆ’1
2n+1
1
(n + 1)pâˆ’1 = p
Î»Ïƒ
âˆ€x âˆˆE.
The estimation follows with the aid of (8.10), where by (8.17) we have Î· = Î»
and âˆ¥Ï‰â€²(z âˆ’zn)âˆ¥= 1 (Proposition 4.7.1).
If E is a Hilbert space, the perturbation functional Ïâˆin Theorem 8.3.1
can be simpliï¬ed.

162
8 Variational Principles
Theorem 8.3.3 Assume that E is a Hilbert space. Let Ïµ > 0 and let Â¯x âˆˆE
be such that f(Â¯x) < infE f + Ïµ. Then for any Î» > 0 there exist y, z âˆˆE such
that the following holds:
(a) âˆ¥z âˆ’Â¯xâˆ¥< Î»,
âˆ¥z âˆ’yâˆ¥< Î».
(b) f(z) â‰¤infE f + Ïµ.
(c) z is a strong minimizer of the functional x â†’f(x) +
Ïµ
Î»2 âˆ¥x âˆ’yâˆ¥2 on E.
Proof. We set
Ï(x) := âˆ¥xâˆ¥2
Î»2 ,
Âµn :=
1
2n+1(n + 1)2 .
Then there exists a sequence (zn) converging to some z as in Theorem 8.2.3.
The perturbation functional is
Ïâˆ(x) = 1
Î»2
âˆ
	
n=0
âˆ¥x âˆ’znâˆ¥2
2n+1
.
Now deï¬ne
y :=
âˆ
	
n=0
zn
2n+1 ,
c :=
âˆ
	
n=0
âˆ¥znâˆ¥2
2n+1 âˆ’âˆ¥yâˆ¥2.
A direct calculation using the inner product shows that for each x âˆˆE,
Ïâˆ(x) = 1
Î»2
âˆ
	
n=0
âˆ¥xâˆ¥2 âˆ’2(x | zn) + âˆ¥znâˆ¥2
2n+1
= 1
Î»2

âˆ¥xâˆ¥2 âˆ’2(x | y) +
âˆ
	
n=0
âˆ¥znâˆ¥2
2n+1

= 1
Î»2 âˆ¥x âˆ’yâˆ¥2 + c
Î»2 .
Noting that c/Î»2 is constant, the assertions follow from Theorem 8.2.3, except
for the estimate âˆ¥z âˆ’yâˆ¥< Î». The latter is obtained as follows (observe that
c is positive). Since
f(z) + Ïµ
Î»2 âˆ¥z âˆ’yâˆ¥2 â‰¤f(z) + ÏµÏâˆ(z) â‰¤f(Â¯x) < inf
E f + Ïµ,
we have
Ïµ
Î»2 âˆ¥z âˆ’yâˆ¥2 < inf
E f âˆ’f(z) + Ïµ â‰¤Ïµ,
which completes the proof.
âŠ“âŠ”
8.4 The Devilleâ€“Godefroyâ€“Zizler Variational Principle
We prepare the next result. If g : E â†’R is bounded, we write
âˆ¥gâˆ¥âˆ:= sup{|g(x)| | x âˆˆE}.
A functional b : E â†’R is said to be a bump functional if b is bounded and
the set supp(b) := {x âˆˆE | b(x) Ì¸= 0} is nonempty and bounded.

8.4 The Devilleâ€“Godefroyâ€“Zizler Variational Principle
163
Lemma 8.4.1 Let E be a FrÃ©chet smooth Banach space and âˆ¥Â·âˆ¥be an equiv-
alent norm on E that is F-diï¬€erentiable on E \ {o}. Then E admits a bump
functional b : E â†’R that is L-continuous, continuously diï¬€erentiable, and
such that
b(E) âŠ†[0, 1],
b(x) = 0 if âˆ¥xâˆ¥â‰¥1,
b(o) = 1.
(8.18)
Proof. Let Ï• : R â†’R be a continuously diï¬€erentiable function satisfying
Ï•(R) âŠ†[0, 1],
Ï•(t) = 0 if t â‰¤1 and if t â‰¥3,
Ï•(2) = 1.
Choose x0 âˆˆE such that âˆ¥x0âˆ¥= 2 and set
b(x) := Ï•(âˆ¥5x + x0âˆ¥),
x âˆˆE.
Together with Ï• and âˆ¥Â· âˆ¥, the functional b is L-continuous. Moreover, by
Corollary 4.3.4 the norm functional is continuously diï¬€erentiable on E \ {o}
and so b is continuously diï¬€erentiable on E; in this connection notice that
in a neighborhood of the critical point x = âˆ’(1/5)x0 the function Ï• is zero.
Obviously (8.18) holds.
âŠ“âŠ”
We make the following assumptions:
(A1) E is a Banach space, Y is a Banach space (with norm âˆ¥Â·âˆ¥Y ) of bounded
continuous real-valued functions on E.
(A2) âˆ¥gâˆ¥âˆâ‰¤âˆ¥gâˆ¥Y for any g âˆˆY .
(A3) For any g âˆˆY and z âˆˆE, the function gz : E â†’R deï¬ned by gz(x) :=
g(x + z) satisï¬es gz âˆˆY and âˆ¥gzâˆ¥Y = âˆ¥gâˆ¥Y .
(A4) For any g âˆˆY and Î± âˆˆR, the function x â†’g(Î±x) is an element of Y .
(A5) E admits a bump functional b âˆˆY .
Theorem 8.4.2 (Devilleâ€“Godefroyâ€“Zizler [49]) If
the
assumptions
(A1)â€“(A5) are satisï¬ed, then the set G of all g âˆˆY such that f + g attains a
strong minimum on E is a dense GÎ´ subset of Y .
Proof. Given g âˆˆY , deï¬ne
S(g, Î±) := {x âˆˆE; | g(x) â‰¤inf
E g + Î±},
Uk := {g âˆˆY | âˆƒÎ± > 0 : diam S(f + g, Î±) < 1
k }.
We will show that each Uk is open and dense in Y and that âˆ©âˆ
k=1Uk = G:
(I) We show that each Uk is open. Let g âˆˆUk be given and let Î± be an
associated positive number. Then for any h âˆˆY satisfying âˆ¥g âˆ’hâˆ¥Y <
Î±/3 we have âˆ¥g âˆ’hâˆ¥âˆ< Î±/3. If x âˆˆS(f + h, Î±/3), then
(f + h)(x) â‰¤inf
E (f + h) + Î±
3 .

164
8 Variational Principles
It follows that
(f + g)(x) â‰¤(f + h)(x) + âˆ¥g âˆ’hâˆ¥âˆâ‰¤inf
E (f + h) + Î±
3 + âˆ¥g âˆ’hâˆ¥âˆ
â‰¤inf
E (f + g) + Î±
3 + 2âˆ¥g âˆ’hâˆ¥âˆâ‰¤inf
E (f + g) + Î±.
Hence S(f + h, Î±/3) âŠ†S(f + g, Î±) and so h âˆˆUk.
(II) Next we show that each Uk is dense in Y .
(IIa) Let g âˆˆY and Ïµ > 0 be given. It suï¬ƒces to ï¬nd h âˆˆY such that
âˆ¥hâˆ¥Y < Ïµ and diam S(f + g + h, Î±) < 1/k for some Î± > 0. We may
assume that the functional b of (A5) satisï¬es âˆ¥bâˆ¥Y < Ïµ. By (A3) we may
further assume that b(o) > 0 and by (A4) that supp(b) âŠ†B(o, 1/(2k)).
Set Î± := b(o)/2, choose Â¯x âˆˆE such that
(f + g)(Â¯x) < inf
E (f + g) + b(o)
2
and deï¬ne h : E â†’R by h(x) := âˆ’b(x âˆ’Â¯x). Then (A3) implies that
h âˆˆY and âˆ¥hâˆ¥Y = âˆ¥bâˆ¥Y < Ïµ.
(IIb) We show that
S(f + g + h, Î±) âŠ†B(Â¯x, 1/(2k)).
(8.19)
Let âˆ¥x âˆ’Â¯xâˆ¥> 1/(2k). Since supp(h) âŠ†B(Â¯x, 1/(2k)), we have h(x) = 0.
It follows that
(f + g + h)(x) = (f + g)(x) â‰¥inf
E (f + g) > (f + g)(Â¯x) âˆ’Î±
= (f + g + h)(Â¯x) + b(o) âˆ’b(o)/2 â‰¥inf
E (f + g + h) + Î±
and so x /âˆˆS(f + g + h, Î±). This veriï¬es (8.19). By what has been said
in step (IIa) we can now conclude that Uk is dense in Y .
(IIc) The Baire category theorem now implies that âˆ©âˆ
k=1Uk is dense in Y .
(III) Finally we show that âˆ©âˆ
k=1Uk = G. It is left as Exercise 8.5.6 to verify
that G âŠ†âˆ©âˆ
k=1Uk. Now let g âˆˆâˆ©âˆ
k=1Uk be given. We will show that f +g
attains a strong minimum on E. Given k âˆˆN choose Î±k > 0 such that
diam S(f +g, Î±k) < 1/k. Since each set S(f +g, Î±k) is closed, the Cantor
intersection theorem shows that âˆ©âˆ
k=1S(f + g, Î±k) consists of exactly
one point Â¯x, which obviously is a minimizer of f + g. Now let (xn) be a
sequence in E satisfying limnâ†’âˆ(f+g)(xn) = infE(f+g). For any k âˆˆN
there exists k0 such that k â‰¥k0 implies (f + g)(xn) â‰¤infE(f + g) + Î±k
and so xn âˆˆS(f + g, Î±k). We conclude that
âˆ¥xn âˆ’Â¯xâˆ¥â‰¤diam S(f + g, Î±k) < 1
k
âˆ€n â‰¥k0.

8.4 The Devilleâ€“Godefroyâ€“Zizler Variational Principle
165
Hence xn â†’Â¯x as n â†’âˆ. Therefore, Â¯x is a strong minimizer of f + g
and so g âˆˆG.
âŠ“âŠ”
As a consequence of Theorem 8.4.2 we derive:
Theorem 8.4.3 Let E be a Banach space admitting a continuously diï¬€er-
entiable bump functional b such that âˆ¥bâˆ¥âˆand âˆ¥bâ€²âˆ¥âˆare ï¬nite. Further let
f : E â†’R be proper, l.s.c., and bounded below. Then there exits a constant
Î± > 0 (depending only on E) such that for all Ïµ âˆˆ(0, 1) and for any x0 âˆˆE
satisfying
f(x0) < inf
E f + Î±Ïµ2,
(8.20)
there exist a continuously diï¬€erentiable function g : E â†’R and y0 âˆˆE such
that:
(a) y0 is a strong minimizer of f + g.
(b) max{âˆ¥gâˆ¥âˆ, âˆ¥gâ€²âˆ¥âˆ} < Ïµ.
(c) âˆ¥y0 âˆ’x0âˆ¥< Ïµ.
Proof. Let Y be the vector space of all continuously diï¬€erentiable functions
g : E â†’R such that âˆ¥gâˆ¥âˆand âˆ¥gâ€²âˆ¥âˆare ï¬nite. Equipped with the norm
âˆ¥gâˆ¥Y := max{âˆ¥gâˆ¥âˆ, âˆ¥gâˆ¥âˆ}, Y is a Banach space. A construction analogous
to that in the proof of Lemma 8.4.1 allows us to assume that b satisï¬es (8.18),
in particular âˆ¥bâˆ¥âˆ= 1. Deï¬ne
Î± :=
1
4 max{âˆ¥bâ€²âˆ¥âˆ, 1}
and
h(x) := f(x) âˆ’2Î±Ïµ2b
x âˆ’x0
Ïµ

, x âˆˆE.
By Theorem 8.4.2 there exist k âˆˆY and y0 âˆˆE such that h + k attains a
strong minimum at y0 and
âˆ¥kâˆ¥âˆâ‰¤Î±Ïµ2/2,
âˆ¥kâ€²âˆ¥âˆâ‰¤Î±Ïµ2/2 â‰¤Ïµ/2.
(8.21)
We have
h(x0) = f(x0) âˆ’2Î±Ïµ2 < inf
E f âˆ’Î±Ïµ2,
h(y) â‰¥inf
E f
whenever âˆ¥y âˆ’x0âˆ¥â‰¥Ïµ.
If (c) would not hold, the above estimate would give
inf
E f + k(y0) â‰¤(h + k)(y0) â‰¤(h + k)(x0) < inf
E f âˆ’Î±Ïµ2 + k(x0)
and so k(y0) < k(x0) âˆ’Î±Ïµ2, which is a contradiction to (8.21). Hence (c) is
veriï¬ed. Finally set
g(x) := k(x) âˆ’2Î±Ïµ2b
x âˆ’x0
Ïµ

,
x âˆˆE.
It is easy to see that (a) and (b) also hold.
âŠ“âŠ”

166
8 Variational Principles
8.5 Bibliographical Notes and Exercises
Some references have already been given in the text. For various applications
of Ekelandâ€™s variational principle we refer to Ekeland [57], Figueiredo [69],
Pallaschke [155], and Penot [162]. Vector-valued variants of Ekelandâ€™s vari-
ational principle have been obtained by GÂ¨opfert et al. [78]. Concerning the
smooth variational principle of Deville, Godefroy, and Zizler see also Deville
et al. [50]. The proof given here follows Borwein and Zhu [24]. This book
also contains further variational principles, many applications, and additional
references.
Borwein and Preiss [19] show that a result analogous to Theorem 8.3.3
holds in any reï¬‚exive Banach space with a Kadec norm and with Ïâˆ(x) =
1
Î»p âˆ¥x âˆ’yâˆ¥p for any given p > 1. Recall that on each reï¬‚exive Banach
space there exists an equivalent norm that is locally uniformly convex
(Theorem 4.7.12), and each locally uniformly convex norm is a Kadec norm
(Lemma 4.7.9). In particular, on each Hilbert space the norm generated by
the inner product is (locally) uniformly convex (Example 4.7.7) and so is the
initial norm on Lp for 1 < p < +âˆ(Example 4.7.11).
Exercise 8.5.1 Verify Remark 8.2.2.
Exercise 8.5.2 Prove Corollary 8.2.5.
Exercise 8.5.3 Verify Corollary 8.2.6.
Exercise 8.5.4 Verify Proposition 8.2.7.
Hint: Apply Ekelandâ€™s variational principle to the functional f := âˆ’xâˆ—
âˆ¥xâˆ—âˆ¥+Î´M
and with appropriate choices of Ïµ and Î».
Exercise 8.5.5 Elaborate the details of the proof of Theorem 8.3.1.
Exercise 8.5.6 Show that, with the assumptions and the notation of
Theorem 8.4.2, one has G âŠ†âˆ©âˆ
k=1Uk.

9
Subdiï¬€erentials of Lower Semicontinuous
Functionals
9.1 FrÃ©chet Subdiï¬€erentials: First Properties
In this section we study another kind of derivative-like concepts.
Deï¬nition 9.1.1 Assume that E is a Banach space, f : E â†’R is proper
and l.s.c., and Â¯x âˆˆdom f.
(a) The functional f is said to be FrÃ©chet subdiï¬€erentiable (F-subdiï¬€erenti-
able) at Â¯x if there exists xâˆ—âˆˆEâˆ—, the F-subderivative of f at Â¯x, such that
lim inf
yâ†’o
f(Â¯x + y) âˆ’f(Â¯x) âˆ’âŸ¨xâˆ—, yâŸ©
âˆ¥yâˆ¥
â‰¥0.
(9.1)
(b) The functional f is said to be viscosity subdiï¬€erentiable at Â¯x if there
exist xâˆ—âˆˆEâˆ—, the viscosity subderivative of f at Â¯x, and a C1-function
g : E â†’R such that gâ€²(Â¯x) = xâˆ—and f âˆ’g attains a local minimum at Â¯x.
If, in particular,
g(x) = âŸ¨xâˆ—, x âˆ’Â¯xâŸ©âˆ’Ïƒâˆ¥x âˆ’Â¯xâˆ¥2
with some positive constant Ïƒ, then xâˆ—is called proximal subgradient of
f at Â¯x. The sets
âˆ‚F f(Â¯x) := set of all F-subderivatives of f at Â¯x,
âˆ‚V f(Â¯x) := set of all viscosity subderivatives of f at Â¯x,
âˆ‚P f(Â¯x) := set of all proximal subgradients of f at Â¯x
are called FrÃ©chet subdiï¬€erential (F-subdiï¬€erential), viscosity subdiï¬€eren-
tial, and proximal subdiï¬€erential of f at Â¯x, respectively.
Remark 9.1.2 Observe that the function g in Deï¬nition 9.1.1(b) can always
be chosen such that (f âˆ’g)(Â¯x) = 0 (cf. Fig. 9.1).
We study the relationship between the diï¬€erent notions.

168
9 Subdiï¬€erentials of Lower Semicontinuous Functionals
f
g
Â¯x
xâˆ—
Fig. 9.1
Proposition 9.1.3 Assume that E is a Banach space, f : E â†’R is proper
and l.s.c., and Â¯x âˆˆdom f. Then âˆ‚V f(Â¯x) âŠ†âˆ‚F f(Â¯x).
Proof. See Exercise 9.8.1.
âŠ“âŠ”
Remark 9.1.4 Notice that âˆ‚F f(Â¯x) and âˆ‚V f(Â¯x) can be deï¬ned as above for
any proper, not necessarily l.s.c. functional f. However, if âˆ‚F f(Â¯x) (in parti-
cular, âˆ‚V f(Â¯x)) is nonempty, then in fact f is l.s.c. at Â¯x (see Exercise 9.8.2).
The next result is an immediate consequence of the deï¬nition of the vis-
cosity F-subdiï¬€erential and Proposition 9.1.3.
Proposition 9.1.5 (Generalized Fermat Rule) If the proper l.s.c. func-
tional f : E â†’R attains a local minimum at Â¯x, then o âˆˆâˆ‚V f(Â¯x) and in
particular o âˆˆâˆ‚F f(Â¯x).
We shall now show that we even have âˆ‚V f(Â¯x) = âˆ‚F f(Â¯x) provided E is a
FrÃ©chet smooth Banach space. We start with an auxiliary result.
Lemma 9.1.6 Let E be a FrÃ©chet smooth Banach space and âˆ¥Â·âˆ¥be an equiva-
lent norm on E that is F-diï¬€erentiable on E\{o}. Then there exist a functional
d : E â†’R+ and a number Î± > 1 such that:
(a) d is bounded, L-continuous on E and continuously diï¬€erentiable on E\{o}.
(b) âˆ¥xâˆ¥â‰¤d(x) â‰¤Î±âˆ¥xâˆ¥if âˆ¥xâˆ¥â‰¤1 and d(x) = 2 if âˆ¥xâˆ¥â‰¥1.
Proof. Let b : E â†’R be the bump functional of Lemma 8.4.1. Deï¬ne d : E â†’
R+ by d(o) := 0 and
d(x) :=
2
s(x),
where
s(x) :=
âˆ
	
n=0
b(nx)
for x Ì¸= o.

9.1 FrÃ©chet Subdiï¬€erentials: First Properties
169
We show that d has the stated properties:
Ad (b). First notice that the series deï¬ning s is locally a ï¬nite sum. In fact,
if Â¯x Ì¸= o, then we have
b(nx) = 0
âˆ€x âˆˆB(Â¯x, âˆ¥Â¯xâˆ¥/2)
âˆ€n â‰¥2âˆ¥Â¯xâˆ¥.
(9.2)
Moreover, s(x) â‰¥b(o) = 1 for any x Ì¸= o. Hence d is well deï¬ned. We have
d(E) âŠ†[0, 2]
and
d(x) = 2 whenever âˆ¥xâˆ¥â‰¥1.
Further it is clear that
[x Ì¸= o and b(nx) Ì¸= 0]
=â‡’
n < 1/âˆ¥xâˆ¥
(9.3)
and so, since 0 â‰¤b â‰¤1, we conclude that s(x) â‰¤1 + 1/âˆ¥xâˆ¥. Hence d(x) â‰¥
2âˆ¥xâˆ¥/(1+âˆ¥xâˆ¥), which shows that d(x) â‰¥âˆ¥xâˆ¥whenever âˆ¥xâˆ¥â‰¤1. Since b(o) = 1
and b is continuous at o, there exists Î· > 0 such that b(x) â‰¥1/2 whenever
âˆ¥xâˆ¥â‰¤Î·. Let x âˆˆE and m â‰¥1 be such that Î·/(m + 1) < âˆ¥xâˆ¥â‰¤Î·/m.
It follows that
s(x) â‰¥
m
	
n=1
b(nx) â‰¥m + 1
2
>
Î·
2âˆ¥xâˆ¥
and so d(x) < (4/Î·)âˆ¥xâˆ¥whenever âˆ¥xâˆ¥â‰¤Î·. This and the boundedness of d
imply that d(x)/âˆ¥xâˆ¥is bounded on E \ {o}. This veriï¬es (b).
Ad (a). Since by (9.2) the sum deï¬ning s is locally ï¬nite, the functional d is
continuously diï¬€erentiable on E \ {o}. For any x Ì¸= o we have
dâ€²(x) = âˆ’2

 âˆ
	
n=0
nbâ€²(nx)
 
 âˆ
	
n=0
b(nx)
âˆ’2
= âˆ’(d(x))2
2
âˆ
	
n=0
nbâ€²(nx).
Since b is L-continuous, Î» := sup{âˆ¥bâ€²(x)âˆ¥| x âˆˆE} is ï¬nite and we obtain for
any x Ì¸= o,

âˆ
	
n=0
nbâ€²(nx)
 â‰¤Î»
[âˆ¥xâˆ¥âˆ’1]
	
n=0
n â‰¤Î»

1 +
1
âˆ¥xâˆ¥
2
;
here the ï¬rst inequality holds by (9.3). This estimate together with (b) yields
âˆ¥dâ€²(x)âˆ¥â‰¤Î» max{Î±, 2}2(âˆ¥xâˆ¥+ 1)2,
showing that dâ€² is bounded on B(o, 1) \ {o}. Since dâ€² is zero outside B(o, 1),
it follows that dâ€² is bounded on E \ {o}. Hence d is L-continuous on E. This
veriï¬es (a).
âŠ“âŠ”
Now we can supplement Proposition 9.1.3.
Theorem 9.1.7 Let E be a FrÃ©chet smooth Banach space, f : E â†’R be a
proper l.s.c. functional, and Â¯x âˆˆdom f. Then âˆ‚V f(Â¯x) = âˆ‚F f(Â¯x).

170
9 Subdiï¬€erentials of Lower Semicontinuous Functionals
Proof. In view of Proposition 9.1.3 it remains to show that âˆ‚F f(Â¯x) âŠ†âˆ‚V f(Â¯x).
Thus let xâˆ—âˆˆâˆ‚F f(Â¯x). Replacing f with the functional Ëœf : E â†’R deï¬ned by
Ëœf(y) := sup{f(Â¯x + y) âˆ’f(Â¯x) âˆ’âŸ¨xâˆ—, yâŸ©, âˆ’1},
y âˆˆE,
we have o âˆˆâˆ‚F Ëœf(o). We show that o âˆˆâˆ‚V Ëœf(o). Notice that Ëœf(Â¯x) = 0 and Ëœf is
bounded below. By (9.1) we obtain
lim inf
yâ†’o
Ëœf(y)
âˆ¥yâˆ¥â‰¥0.
(9.4)
Deï¬ne Ï : R+ â†’R by Ï(t) := inf{ Ëœf(y) | âˆ¥yâˆ¥â‰¤t}. Then Ï is nonincreasing,
Ï(0) = 0 and Ï â‰¤0. This and (9.4) give
lim
tâ†’0
Ï(t)
t
= 0.
(9.5)
Deï¬ne Ï1 and Ï2 on (0, +âˆ) by
Ï1(t) :=
 et
t
Ï(s)
s ds,
Ï2(t) :=
 et
t
Ï1(s)
s
ds.
Since Ï is nonincreasing, we have
Ï1(et) =
 e2t
et
Ï(s)
s ds â‰¥Ï(e2t)
 e2t
et
1
sds = Ï(e2t).
(9.6)
Since Ï1 is also nonincreasing, we obtain analogously Ï1(et) â‰¤Ï2(t) â‰¤0. This
and (9.5) yield
lim
tâ†“0
Ï2(t)
t
= lim
tâ†“0
Ï1(t)
t
= lim
tâ†“0
Ï(t)
t
= 0.
(9.7)
Now deï¬ne Ëœg : E â†’R by Ëœg(x) := Ï2(d(x)) for x Ì¸= o and Ëœg(o) := 0, where d
denotes the functional in Lemma 9.1.6. Recall that d(x) Ì¸= 0 whenever x Ì¸= o.
Since Ï1 is continuous on (0, +âˆ) and so Ï2 is continuously diï¬€erentiable on
(0, +âˆ), the chain rule implies that Ëœg is continuously diï¬€erentiable on E \{o}
with derivative
Ëœgâ€²(x) = Ï1

ed(x)

âˆ’Ï1

d(x)

d(x)
Â· dâ€²(x),
x Ì¸= o.
The properties of d and (9.7) further imply that limxâ†’o âˆ¥Ëœgâ€²(x)âˆ¥= 0. There-
fore it follows as a consequence of the mean value theorem that Ëœg is also
F-diï¬€erentiable at o with Ëœgâ€²(o) = o, and Ëœgâ€² is continuous at o. Since Ï is non-
increasing, we have Ï2(t) â‰¤Ï1(t) â‰¤Ï(t); here, the second inequality follows
analogously as (9.6) and the ï¬rst is a consequence of the second. Let âˆ¥xâˆ¥â‰¤1.
Then âˆ¥xâˆ¥â‰¤d(x), and since Ï2 is nonincreasing (as Ï1 is nonincreasing), we
obtain

9.1 FrÃ©chet Subdiï¬€erentials: First Properties
171
( Ëœf âˆ’Ëœg)(x) = Ëœf(x) âˆ’Ï2(d(x)) â‰¥Ëœf(x) âˆ’Ï2(âˆ¥xâˆ¥) â‰¥Ëœf(x) âˆ’Ï(âˆ¥xâˆ¥) â‰¥0.
Since 0 = ( Ëœf âˆ’Ëœg)(o), we see that Ëœf âˆ’Ëœg attains a local minimum at o. Hence
o âˆˆâˆ‚V Ëœf(o) and so xâˆ—âˆˆâˆ‚V f(Â¯x).
âŠ“âŠ”
Remark 9.1.8 Let E, f, and Â¯x be as in Theorem 9.1.7. Further let xâˆ—âˆˆ
âˆ‚V f(Â¯x), which by Theorem 9.1.7 is equivalent to xâˆ—âˆˆâˆ‚F f(Â¯x). Then there
exists a concave C1 function g : E â†’R such that gâ€²(Â¯x) = xâˆ—and f âˆ’g attains
a local minimum at Â¯x (cf. Fig. 9.1); see Exercise 9.8.4.
In order to have both the limit deï¬nition and the viscosity deï¬nition of
F-subderivatives at our disposal, we shall in view of Theorem 9.1.7 assume
that E is a FrÃ©chet smooth Banach space and we denote the common F-
subdiï¬€erential of f at Â¯x by âˆ‚F f(Â¯x).
The relationship to classical concepts is established in Proposition 9.1.9.
In this connection recall that
âˆ‚P f(Â¯x) âŠ†âˆ‚F f(Â¯x).
(9.8)
Proposition 9.1.9 Assume that E is a FrÃ©chet smooth Banach space and
f : E â†’R is proper and l.s.c.
(a) If the directional G-derivative fG(Â¯x, Â·) of f at Â¯x âˆˆdom f exists on E, then
for any xâˆ—âˆˆâˆ‚F f(Â¯x) (provided there exists one),
âŸ¨xâˆ—, yâŸ©â‰¤fG(Â¯x, y)
âˆ€y âˆˆE.
If, in particular, f is G-diï¬€erentiable at Â¯x âˆˆdom f, then âˆ‚F f(Â¯x) âŠ†
{f â€²(Â¯x)}.
(b) If f âˆˆC1(U), where U âŠ†E is nonempty and open, then âˆ‚F f(x) = {f â€²(x)}
for any x âˆˆU.
(c) If f âˆˆC2(U), where U âŠ†E is nonempty and open, then âˆ‚P f(x) =
âˆ‚F f(x) = {f â€²(x)} for any x âˆˆU.
(d) If f is convex, then âˆ‚P f(x) = âˆ‚F f(x) = âˆ‚f(x) for any x âˆˆdom f.
(e) If f is locally L-continuous on E, then âˆ‚F f(x) âŠ†âˆ‚â—¦f(x) for any x âˆˆE.
Proof.
(a) Let xâˆ—âˆˆâˆ‚F f(Â¯x) be given. Then there exist a C1 function g and a number
Ïµ > 0 such that gâ€²(Â¯x) = xâˆ—and for each x âˆˆB(Â¯x, Ïµ) we have
(f âˆ’g)(x) â‰¥(f âˆ’g)(Â¯x)
âˆ€x âˆˆB(Â¯x, Ïµ).
(9.9)
Now let y âˆˆE. Then for each Ï„ > 0 suï¬ƒciently small we have Â¯x + Ï„y âˆˆ
B(Â¯x, Ïµ) and so
1
Ï„

f(Â¯x + Ï„y) âˆ’f(Â¯x)

â‰¥1
Ï„

g(Â¯x + Ï„y) âˆ’g(Â¯x)

.
Letting Ï„ â†“0 it follows that fG(Â¯x, y) â‰¥âŸ¨gâ€²(Â¯x), yâŸ©= âŸ¨xâˆ—, yâŸ©. If f is
G-diï¬€erentiable at Â¯x, then by linearity the latter inequality passes into
f â€²(Â¯x) = xâˆ—.

172
9 Subdiï¬€erentials of Lower Semicontinuous Functionals
(b) It is obvious that f â€²(x) âˆˆâˆ‚F f(x) for each x âˆˆU. This and (a) imply
âˆ‚F f(x) = {f â€²(x)} for each x âˆˆU.
(c) By Proposition 3.5.1 we have f â€²(x) âˆˆâˆ‚P f(x), which together with (a)
and (9.8) veriï¬es the assertion.
(d) It is evident that âˆ‚f(Â¯x) âŠ†âˆ‚P f(Â¯x) âŠ†âˆ‚F f(Â¯x) for each Â¯x âˆˆdom f. Now
let xâˆ—âˆˆâˆ‚F f(Â¯x) be given. As in the proof of (a) let g and Ïµ be such that
(9.9) holds. Further let x âˆˆE. If Ï„ âˆˆ(0, 1) is suï¬ƒciently small, then
(1 âˆ’Ï„)Â¯x + Ï„x âˆˆB(Â¯x, Ïµ) and we obtain using the convexity of f,
(1âˆ’Ï„)f(Â¯x)+Ï„f(x) â‰¥f

(1âˆ’Ï„)Â¯x+Ï„x

â‰¥
(9.9)
f(Â¯x)+g

(1âˆ’Ï„)Â¯x+Ï„x

âˆ’g(Â¯x).
It follows that
f(x) âˆ’f(Â¯x) â‰¥g

Â¯x + Ï„(x âˆ’Â¯x)

âˆ’g(Â¯x)
Ï„
.
Letting Ï„ â†“0, we see that f(x) âˆ’f(Â¯x) â‰¥âŸ¨gâ€²(Â¯x), x âˆ’Â¯xâŸ©= âŸ¨xâˆ—, x âˆ’Â¯xâŸ©. Since
x âˆˆE was arbitrary, we conclude that xâˆ—âˆˆâˆ‚f(Â¯x).
(e) See Exercise 9.8.5.
âŠ“âŠ”
In Sect. 9.5 we shall establish the relationship between the FrÃ©chet subdif-
ferential and the Clarke subdiï¬€erential.
9.2 Approximate Sum and Chain Rules
Convention. Throughout this section, we assume that E is a FrÃ©chet smooth
Banach space, and âˆ¥Â· âˆ¥is a norm on E that is F-diï¬€erentiable on E \ {o}.
Recall that we write Ï‰Â¯x(x) := âˆ¥x âˆ’Â¯xâˆ¥, and in particular Ï‰(x) := âˆ¥xâˆ¥,
x âˆˆE.
One way to develop subdiï¬€erential analysis for l.s.c. functionals is to
start with sum rules. It is an easy consequence of the deï¬nition of the
F-subdiï¬€erential that we have
âˆ‚F f1(Â¯x) + âˆ‚F f2(Â¯x) âŠ†âˆ‚F (f1 + f2)(Â¯x).
But the reverse inclusion
âˆ‚F (f1 + f2)(Â¯x) âŠ†âˆ‚F f1(Â¯x) + âˆ‚F f2(Â¯x)
(9.10)
does not hold in general.

9.2 Approximate Sum and Chain Rules
173
Example 9.2.1 Let f1(x) := |x| and f2(x) := âˆ’|x| for x âˆˆR. Then âˆ‚F (f1 +
f2)(0) = {0} but since âˆ‚F f2(0) = âˆ…(see Exercise 9.8.3), we have âˆ‚F f1(0) +
âˆ‚F f2(0) = âˆ….
Yet what we usually need is just (9.10). For instance, if Â¯x is a local mini-
mizer of the proper l.s.c. function f on the closed subset M of E, then Â¯x is a
local minimizer of f + Î´M on all of E, which implies
o âˆˆâˆ‚F (f + Î´M)(Â¯x).
(9.11)
Now we would like to conclude that o âˆˆâˆ‚F f(Â¯x)+âˆ‚F Î´M(Â¯x) which (9.10) would
ensure. In a special case we do obtain an exact sum rule.
Proposition 9.2.2 Let f1, f2 : E â†’R be proper and l.s.c. If f1 is F-
diï¬€erentiable at Â¯x, then
âˆ‚F (f1 + f2)(Â¯x) = f â€²
1(Â¯x) + âˆ‚F f2(Â¯x).
Proof. See Exercise 9.8.6.
âŠ“âŠ”
In the general case we at least obtain, among others, an approximate, or
fuzzy, sum rule of the following form. If xâˆ—âˆˆâˆ‚F (f1 + f2)(Â¯x), then for each
Ïƒ(Eâˆ—, E)-neighborhood V of zero in Eâˆ—there exist x1 and x2 close to Â¯x such
that fi(xi) is close to fi(Â¯x) for i = 1, 2 and
xâˆ—âˆˆâˆ‚F f1(x1) + âˆ‚F f2(x2) + V.
We establish several approximate sum rules, which are then applied to
derive a general mean value theorem as well as multiplier rules for constrained
optimization problems involving lower semicontinuous data. The ï¬rst result
is nonlocal, meaning that there is no reference point Â¯x.
Theorem 9.2.3 (Nonlocal Approximate Sum Rule) Let f1, . . . ,fn :Eâ†’
R be proper, l.s.c., bounded below, and such that
lim
Ïâ†“0 inf
0 n
	
i=1
fi(yi)
 diam{y1, . . . , yn} â‰¤Ï
1
< +âˆ.
Then for any Ïµ > 0 there exist xi âˆˆE and xâˆ—
i âˆˆâˆ‚F fi(xi), i = 1, . . . , n,
satisfying
diam{x1, . . . , xn} Â· max{1, âˆ¥xâˆ—
1âˆ¥, . . . , âˆ¥xâˆ—
nâˆ¥} < Ïµ,
(9.12)
n
	
i=1
fi(xi) < lim
Ïâ†“0 inf
0 n
	
i=1
fi(yi)
 diam{y1, . . . , yn} â‰¤Ï
1
+ Ïµ,
(9.13)

n
	
i=1
xâˆ—
i
 â‰¤Ïµ.
(9.14)

174
9 Subdiï¬€erentials of Lower Semicontinuous Functionals
Proof.
(I) For each positive real number Îº let
Ï•Îº(y1, . . . , yn) :=
n
	
i=1
fi(yi) + Îº
n
	
i,j=1
âˆ¥yi âˆ’yjâˆ¥2
and
Î±Îº := inf
En Ï•Îº.
We show that
Î±Îº â‰¤Î² := lim
Ïâ†“0 inf
0 n
	
i=1
fi(yi)
 diam{y1, . . . , yn} â‰¤Ï
1
âˆ€Îº > 0.
Assume, to the contrary, that for some Îº we had
Î² < Î±Îº â‰¤
n
	
i=1
fi(yi) + Îº
n
	
i,j=1
âˆ¥yi âˆ’yjâˆ¥2
âˆ€(y1, . . . , yn) âˆˆEn.
By the deï¬nition of Î², for each suï¬ƒciently large Î½
âˆˆN we ï¬nd
(z1, . . . , zn) âˆˆEn satisfying
n
	
i=1
fi(zi) < Î±Îº
and
diam{z1, . . . , zn} â‰¤1
Î½
and so
n
	
i=1
fi(zi) + Îº
n
	
i,j=1
âˆ¥zi âˆ’zjâˆ¥2 â‰¤
n
	
i=1
fi(zi) + Îºn(n âˆ’1)
2Î½2
.
If Î½ is large enough, the right-hand side, and so the left-hand side, of
the last inequality is smaller than Î±Îº, but this contradicts the deï¬nition
of Î±Îº. Thus we have shown that the generalized sequence (Î±Îº)Îº>0 is
bounded (above). Since it is also increasing, the limit Î± := limÎºâ†’âˆÎ±Îº
exists.
(II) Observe that En with the Euclidean product norm is also a FrÃ©chet
smooth Banach space. By the Borweinâ€“Preiss variational principle
(Theorem 8.3.1 and Remark 8.3.2) applied to Ï•Îº for Îº = 1, . . . , n (with
p = 2 and Î» > 0 suï¬ƒciently large), there exist a C1-function ÏˆÎº and a
point (z1,Îº, . . . , zn,Îº) âˆˆEn such that Ï•Îº + ÏˆÎº attains a local minimum
at (z1,Îº, . . . , zn,Îº) and that
âˆ¥Ïˆâ€²(z1,Îº, . . . , zn,Îº)âˆ¥< Ïµ
n,
Ï•k(z1,Îº, . . . , zn,Îº) < inf
En Ï•Îº + 1
Îº â‰¤Î± + 1
Îº.
(9.15)

9.2 Approximate Sum and Chain Rules
175
For each Îº > 0 deï¬ne Î³Îº : E â†’R by
Î³Îº(y1, . . . , yn) := âˆ’ÏˆÎº(y1, . . . , yn) âˆ’Îº
n
	
i,j=1
âˆ¥yi âˆ’yjâˆ¥2.
Then Î³Îº is a C1-function satisfying
n
	
i=1
fi(yi) âˆ’Î³Îº(y1, . . . , yn) = Ï•Îº(y1, . . . , yn) + ÏˆÎº(y1, . . . , yn).
(9.16)
Since for each i = 1, . . . , n the function
y â†’Ï•Îº(z1,Îº, . . . , ziâˆ’1, Îº, y, zi+1, Îº, . . . , zn,Îº)
+ ÏˆÎº(z1,Îº, . . . , ziâˆ’1, Îº, y, zi+1, Îº, . . . , zn,Îº)
attains a local minimum at y = zi,Îº, we conclude from (9.16) that
xâˆ—
i,Îº := Di Î³k(z1,Îº, . . . , zn,Îº) âˆˆâˆ‚F fi(zi,Îº)
for i = 1, . . . , n.
Summing over i and recalling the deï¬nition of Î³Îº gives
n
	
i=1
xâˆ—
i,Îº = âˆ’
n
	
i=1
Di ÏˆÎº(z1,Îº, . . . , zn,Îº) âˆ’2Îº
n
	
i,j=1
(Ï‰2)â€²(zi,Îº âˆ’zj,Îº).
For symmetry reasons the double sum over i, j vanishes. Moreover, by
(9.15) we have âˆ¥âˆ’n
i=1 Di ÏˆÎº(z1,Îº, . . . , zn,Îº)âˆ¥â‰¤Ïµ. It follows that

n
	
i=1
xâˆ—
i,Îº
 â‰¤Ïµ.
(9.17)
(III) By the deï¬nition of Î±Îº and Ï•Îº we conclude that
Î±Îº/2 â‰¤Ï•Îº/2(z1,Îº, . . . , zn,Îº)
= Ï•Îº(z1,Îº, . . . , zn,Îº) âˆ’Îº
2
n
	
i=1
âˆ¥zi,Îº âˆ’zj,Îºâˆ¥2
â‰¤
(9.15)
Î±Îº + 1
Îº âˆ’Îº
2
n
	
i,j=1
âˆ¥zi,Îº âˆ’zj,Îºâˆ¥2.
(9.18)
Rearranging we obtain
Îº
n
	
i,j=1
âˆ¥zi,Îº âˆ’zj,Îºâˆ¥2 â‰¤2(Î±Îº âˆ’Î±Îº/2 + 1
Îº)
and so limÎºâ†’âˆÎº n
i,j=1 âˆ¥zi,Îº âˆ’zj,Îºâˆ¥2
=
0. Hence limÎºâ†’âˆdiam
{z1,Îº, . . . , zn,Îº} = 0 and, recalling (9.17), we conclude that
lim
Îºâ†’âˆdiam{z1,Îº, . . . , zn,Îº} Â· max{âˆ¥xâˆ—
1,Îº, . . . , âˆ¥xâˆ—
n,Îºâˆ¥} = 0.

176
9 Subdiï¬€erentials of Lower Semicontinuous Functionals
(IV) We now obtain
Î± â‰¤Î² â‰¤lim inf
Îºâ†’âˆ
n
	
i=1
fi(zi,Îº) = lim inf
Îºâ†’âˆÏ•Îº(z1,Îº, . . . , zn,Îº)
â‰¤
(9.15)
Î±.
Therefore we have Î± = Î². In view of (9.15), the assertion follows by
setting xi := zi,Îº and xâˆ—
i := xâˆ—
i,Îº for i = 1, . . . , n, with Îº suï¬ƒciently
large.
âŠ“âŠ”
As an immediate application of Theorem 9.2.3 we obtain a remarkable
density result.
Proposition 9.2.4 Let f : E â†’R be proper and l.s.c. Then Dom(âˆ‚F f) is
dense in dom f.
Proof. Let Â¯x âˆˆdom f and Î· > 0 be given. Since f is l.s.c. at Â¯x, there exists
Ïµ > 0 such that f(x) > f(Â¯x) âˆ’1 for all x âˆˆB(Â¯x, Ïµ). We may assume that
Ïµ < Î·. The functionals f1, f2 deï¬ned by
f1(x) :=

f(x)
if x âˆˆB(Â¯x, Ïµ),
+âˆ
otherwise,
f2(x) :=

0
if x = Â¯x,
+âˆ
otherwise
satisfy the hypotheses of Theorem 9.2.3. Hence for i = 1, 2 there exist xi âˆˆE
and xâˆ—
i âˆˆâˆ‚F fi(xi) such that
âˆ¥x1 âˆ’x2âˆ¥< Ïµ,
o âˆˆxâˆ—
1 + xâˆ—
2 + BEâˆ—(o, Ïµ),
f1(x1) + f2(x2) < f1(Â¯x) + f2(Â¯x) + Ïµ = f(Â¯x) + Ïµ.
The last inequality shows that x2 = Â¯x. Hence x1 âˆˆËšB(Â¯x, Ïµ), and since
f1 coincides with f on B(Â¯x, Ïµ), we obtain âˆ‚F f1(x1) = âˆ‚F f(x1). Moreover,
âˆ‚F f2(Â¯x) = {o}. Therefore xâˆ—
1 âˆˆâˆ‚F f(x1) and we have âˆ¥x1 âˆ’Â¯xâˆ¥< Î·.
âŠ“âŠ”
Now we turn to local approximate sum rules. In this connection, we shall
assume that, for some Î· > 0, the reference point Â¯x has the following property:
n
	
i=1
fi(Â¯x) â‰¤lim
Ïâ†“0 inf
0 n
	
i=1
fi(yi)
 âˆ¥y0 âˆ’Â¯xâˆ¥â‰¤Î·, diam{y0, y1, . . . , yn} â‰¤Ï
1
.
(9.19)
We ï¬rst give a suï¬ƒcient condition for (9.19).
Lemma 9.2.5 Let fi : E â†’R be proper and l.s.c. Assume that Â¯x âˆˆ
âˆ©n
i=1dom fi is a local minimizer of n
i=1 fi and that one of the following con-
ditions (a) and (b) is satisï¬ed:
(a) All but one of fi are uniformly continuous in a neighborhood of Â¯x.
(b) The restriction of at least one fi to a neighborhood of Â¯x has compact level
sets.
Then (9.19) holds.
Proof. See Exercise 9.8.7
âŠ“âŠ”

9.2 Approximate Sum and Chain Rules
177
Theorem 9.2.6 (Strong Local Approximate Sum Rule) Assume that
f1, . . . , fn : E â†’R are proper and l.s.c., let Â¯x âˆˆâˆ©n
i=1dom fi, and assume
that there exists Î· > 0 such that (9.19) holds. Then for any Ïµ > 0 there exist
xi âˆˆB(Â¯x, Ïµ) and xâˆ—
i âˆˆâˆ‚F fi(xi), i = 1, . . . , n, satisfying
|fi(xi) âˆ’fi(Â¯x)| < Ïµ,
i = 1, . . . , n,
(9.20)
diam{x1, . . . , xn} Â· max{âˆ¥xâˆ—
1âˆ¥, . . . , âˆ¥xâˆ—
nâˆ¥} < Ïµ,
(9.21)

n
	
i=1
xâˆ—
i
 < Ïµ.
(9.22)
Proof. Obviously we may assume that Î· < min{Ïµ, 1}. Since each fi is l.s.c.,
we may further assume that
fi(x) > fi(Â¯x) âˆ’Ïµ/n
âˆ€x âˆˆB(Â¯x, Î·), i = 1, . . . , n.
(9.23)
In view of (9.19), for Ïµ1 := Î·2/(32n2) there exists Ï âˆˆ(0, Î·) such that
n
	
i=1
fi(Â¯x) â‰¤inf
0 n
	
i=1
fi(yi)+Î´B(Â¯x,Î·)(y0)
 âˆ¥yiâˆ’yjâˆ¥â‰¤Ï âˆ€i, j = 0, 1, . . . , n
1
+Ïµ1.
(9.24)
For i = 1, . . . , n let
Ëœfi(x) := fi(x) + âˆ¥x âˆ’Â¯xâˆ¥2 + Î´B(Â¯x,Î·)(x),
x âˆˆE.
Then Ëœfi is l.s.c., bounded below, and satisï¬es
r := lim
Ïâ†“0 inf
0 n
	
i=1
Ëœfi(yi)
 diam{y1, . . . , yn} â‰¤Ï
1
â‰¤
n
	
i=1
fi(Â¯x) < +âˆ.
Applying Theorem 9.2.3 to Ëœfi and Ïµ2 âˆˆ(0, min{Ï, Ïµ1}), we obtain xi and
yâˆ—
i âˆˆâˆ‚F Ëœfi(xi), i = 1, . . . , n, such that
n
	
i=1
Ëœfi(xi) < r + Ïµ2,
(9.25)
diam{x1, . . . , xn} Â· {âˆ¥yâˆ—
1âˆ¥, . . . , âˆ¥yâˆ—
nâˆ¥} < Ïµ2,
(9.26)

n
	
i=1
yâˆ—
i
 < Ïµ2.
(9.27)
Observe that (9.25) implies xi âˆˆB(Â¯x, Î·). Moreover, from (9.24) and (9.26) we
deduce that

178
9 Subdiï¬€erentials of Lower Semicontinuous Functionals
n
	
i=1

fi(Â¯x) + âˆ¥xi âˆ’Â¯xâˆ¥2
âˆ’Ïµ1 â‰¤
n
	
i=1
Ëœfi(xi) < r + Ïµ2
â‰¤
n
	
i=1
Ëœfi(Â¯x) + Ïµ2 =
n
	
i=1
fi(Â¯x) + Ïµ2
and so
n
	
i=1
âˆ¥xi âˆ’Â¯xâˆ¥2 â‰¤Ïµ1 + Ïµ2 < 2Ïµ1.
(9.28)
Deï¬ne xâˆ—
i := yâˆ—
i âˆ’(Ï‰2
Â¯x)â€²(xi). It follows that
xâˆ—
i âˆˆâˆ‚F Ëœf(xi) âˆ’âˆ‚F Ï‰2
Â¯x(xi) âŠ†âˆ‚F
 Ëœf âˆ’Ï‰2
Â¯x

(xi)
= âˆ‚F

fi + Î´B(Â¯x,Î·)

(xi) = âˆ‚F fi(xi);
here the latter equation holds because by (9.28) the point xi is in the interior
of B(Â¯x, Î·). From (9.25), (9.27), and
(Ï‰2
Â¯x)â€²(xi)
 â‰¤Ïµ/(2n) we obtain (9.21) and
(9.22). Finally, the estimate
fi(xi)
â‰¤
(9.25)
fi(Â¯x) +
	
jÌ¸=i

fj(Â¯x) âˆ’fj(xj)

+ Ïµ2
<
(9.23) fi(Â¯x) + (n âˆ’1)Ïµ
n
+ Ïµ2 < fi(Â¯x) + Ïµ
together with (9.23) veriï¬es (9.20).
âŠ“âŠ”
Theorem 9.2.6 in conjunction with Lemma 9.2.5 is a necessary optimality
condition. It can also be interpreted as a strong approximate sum rule in that
it relates a local minimizer of n
i=1 fi to F-subderivatives xâˆ—
i of fi whose sum
is close to zero in the norm topology of Eâˆ—. The following weak rule relates
an F-subderivative xâˆ—of n
i=1 fi to F-subderivatives xâˆ—
i of fi whose sum is
close to xâˆ—in the weak* topology of Eâˆ—. Notice that in this result, condition
(9.19) can be omitted.
Theorem 9.2.7 (Weak Local Approximate Sum Rule) Assume
that
f1, . . . , fn : E â†’R are proper and l.s.c., let Â¯x âˆˆâˆ©n
i=1dom fi, and let
xâˆ—âˆˆâˆ‚F
n
i=1 fi

(Â¯x). Then for any Ïµ > 0 and any Ïƒ(Eâˆ—, E)-neighborhood
V of zero in Eâˆ—there exist xi âˆˆB(Â¯x, Ïµ) and xâˆ—
i âˆˆâˆ‚F fi(xi), i = 1, . . . , n,
satisfying
|fi(xi) âˆ’fi(Â¯x)| < Ïµ,
i = 1, . . . , n,
diam{x1, . . . , xn} Â· max{âˆ¥xâˆ—
1âˆ¥, . . . , âˆ¥xâˆ—
nâˆ¥} < Ïµ,
xâˆ—âˆˆ
n
	
i=1
xâˆ—
i + V.

9.2 Approximate Sum and Chain Rules
179
Proof. Let Ïµ and V be given. Then there exist y1, . . . , ym âˆˆE such that
{xâˆ—âˆˆEâˆ— |âŸ¨xâˆ—, ykâŸ©| â‰¤1, k = 1, . . . , m} âŠ†V.
Let L := span{Â¯x, y1, . . . , ym} and Ï :=

2 max{âˆ¥y1âˆ¥, . . . âˆ¥ymâˆ¥}
âˆ’1. Then we
have
LâŠ¥+ B(o, 2Ï) âŠ†V.
For xâˆ—there exists a C1-function g such that gâ€²(Â¯x) = xâˆ—and
n
i=1 fi

âˆ’g
attains a local minimum at Â¯x. Choose Ïµâ€² > 0 such that
âˆ¥x âˆ’Â¯xâˆ¥< Ïµâ€²
=â‡’
âˆ¥gâ€²(x) âˆ’gâ€²(Â¯x)âˆ¥< Ï.
(9.29)
We may assume that Ïµâ€² < min{Ïµ, Ï}. The functional
n
i=1 fi

âˆ’g+Î´L attains
a local minimum at Â¯x and Î´L has locally compact lower level sets. Hence by
Lemma 9.2.5 the (n + 2)-tuple (f1, . . . , fn, âˆ’g, Î´L) satisï¬es condition (9.19).
By Theorem 9.2.6 there exist xi âˆˆB(Â¯x, Ïµâ€²) for i = 1, . . . , n + 2 and xâˆ—
i âˆˆ
âˆ‚F fi(Â¯x) for i = 1, . . . , n as well as xâˆ—
n+1 := âˆ’gâ€²(xn+1) and xâˆ—
n+2 âˆˆâˆ‚F Î´L(xn+2)
satisfying
|fi(xi) âˆ’fi(Â¯x)| < Ïµâ€²,
i = 1, . . . , n,
|Î´L(xn+2) âˆ’Î´L(Â¯x)| < Ïµâ€²,
diam{x1, . . . , xn+2} Â· max{âˆ¥xâˆ—
1âˆ¥, . . . , âˆ¥xâˆ—
n+2âˆ¥} < Ïµâ€²,

n
	
i=1
xâˆ—
i âˆ’gâ€²(xn+1) + xâˆ—
n+2
 < Ïµâ€².
The inequality involving Î´L shows that xâˆ—
n+2 âˆˆL. Moreover, it is easy to see
that âˆ‚F Î´L(xn+2) = LâŠ¥. Since âˆ¥xn+1âˆ’Â¯xâˆ¥< Ïµâ€², (9.29) gives âˆ¥gâ€²(xn+1)âˆ’xâˆ—âˆ¥<Ï.
We conclude that

 n
	
i=1
xâˆ—
i + xâˆ—
n+2

âˆ’xâˆ—
â‰¤âˆ¥gâ€²(xn+1) âˆ’xâˆ—âˆ¥+

n
	
i=1
xâˆ—
i âˆ’gâ€²(xn+1) + xâˆ—
n+2
 < Ï + Ïµâ€² â‰¤2Ï,
which implies
xâˆ—âˆˆ
n
	
i=1
xâˆ—
i + LâŠ¥+ B(o, 2Ï) âŠ‚
n
	
i=1
xâˆ—
i + V.
âŠ“âŠ”
Finally we establish an approximate chain rule. For this, we need the
following concepts.

180
9 Subdiï¬€erentials of Lower Semicontinuous Functionals
Deï¬nition 9.2.8 Let T : E â†’F be a mapping between Banach spaces E
and F.
(a) T is said to be locally compact at Â¯x âˆˆE if there is a neighborhood U of Â¯x
such that T(C) is compact for any closed set C âŠ†U.
(b) For any yâˆ—âˆˆF âˆ—, the scalarization âŸ¨yâˆ—, TâŸ©: E â†’R of T is deï¬ned by
âŸ¨yâˆ—, TâŸ©(x) := âŸ¨yâˆ—, T(x)âŸ©,
x âˆˆE.
Recall that if g : F â†’R and T : E â†’F, then g â—¦T : E â†’R denotes the
composition of g and T.
Theorem 9.2.9 (Approximate Chain Rule) Assume that E and F are
FrÃ©chet smooth Banach spaces, g : F â†’R is proper and l.s.c., and T : E â†’F
is locally L-continuous and locally compact at Â¯x âˆˆdom f. Suppose that xâˆ—âˆˆ
âˆ‚F (g â—¦T)(Â¯x). Then for any Ïµ > 0 there exist x âˆˆBE(Â¯x, Ïµ), y âˆˆBF (T(Â¯x), Ïµ),
yâˆ—âˆˆâˆ‚F g(y), zâˆ—âˆˆËš
BF âˆ—(yâˆ—, Ïµ), and Ëœxâˆ—âˆˆâˆ‚F âŸ¨zâˆ—, TâŸ©(x) such that
|g(y) âˆ’g(T(Â¯x))| < Ïµ,
âˆ¥y âˆ’T(x)âˆ¥max{âˆ¥Ëœxâˆ—âˆ¥, âˆ¥yâˆ—âˆ¥, âˆ¥zâˆ—âˆ¥} < Ïµ,
âˆ¥xâˆ—âˆ’Ëœxâˆ—âˆ¥< Ïµ.
(9.30)
Proof. Let h : E â†’R be a C1 function such that hâ€²(Â¯x) = xâˆ—and g â—¦T âˆ’h
attains a local minimum at Â¯x. Deï¬ne
f1(u, y) := g(y) âˆ’h(u),
f2(u, y) := Î´graph T (u, y)
âˆ€(u, y) âˆˆE Ã— F (9.31)
and put f := f1 +f2. Then f attains a local minimum at (Â¯x, T(Â¯x)). Moreover,
since T is locally compact, condition (b) of Lemma 9.2.5 also holds. By that
lemma the hypothesis (9.19) of the approximate sum rule of Theorem 9.2.6
is satisï¬ed. Applying the latter theorem, we ï¬nd x, u âˆˆBE(Â¯x, Ïµ) such that
âˆ¥hâ€²(u) âˆ’xâˆ—âˆ¥< Ïµ/2 as well as y âˆˆBF (T(Â¯x), Ïµ) with |f(y) âˆ’f(T(Â¯x))| < Ïµ,
yâˆ—âˆˆâˆ‚F g(y) and
(Ëœxâˆ—, âˆ’zâˆ—) âˆˆâˆ‚F Î´graph T (x, T(x))
(9.32)
satisfying (9.30) and
âˆ¥(âˆ’hâ€²(u), yâˆ—) + (Ëœxâˆ—, âˆ’zâˆ—)âˆ¥< Ïµ/2.
(9.33)
From (9.32) we conclude that there is a C1 function Ëœh : E Ã— F â†’R such that
Ëœhâ€²(x, T(x)) = (Ëœxâˆ—, âˆ’zâˆ—) and Ëœh attains a local minimum 0 at (x, T(x)). The
latter means that for any u in a neighborhood of x we have
0 â‰¥Ëœh(u, T(u)) âˆ’Ëœh(x, T(x)) = âŸ¨Ëœxâˆ—, u âˆ’xâŸ©âˆ’âŸ¨zâˆ—, T(u) âˆ’T(x)âŸ©+ o(âˆ¥u âˆ’xâˆ¥).
This shows that Ëœxâˆ—âˆˆâˆ‚F âŸ¨zâˆ—, TâŸ©(x). Applying (9.33) we obtain
âˆ¥xâˆ—âˆ’Ëœxâˆ—âˆ¥â‰¤âˆ¥xâˆ—âˆ’hâ€²(u)âˆ¥+ âˆ¥hâ€²(u) âˆ’Ëœxâˆ—âˆ¥< Ïµ,
which completes the proof.
âŠ“âŠ”

9.3 Application to Hamiltonâ€“Jacobi Equations
181
9.3 Application to Hamiltonâ€“Jacobi Equations
Convention. Throughout this section, assume that E is a Hilbert space.
An equation of the form
f(x) + H

x, f â€²(x)

= 0
âˆ€x âˆˆE,
(9.34)
where H : E Ã— Eâˆ—â†’R is given, is called Hamiltonâ€“Jacobi equation for f.
Equations of this (and a more general) type play a fundamental role in the
calculus of variations and in optimal control theory. In this context, (9.34) may
fail to have a classical, i.e., continuously diï¬€erentiable, solution f : E â†’R.
It turns out that F-subdiï¬€erentials can be used to introduce an adequate
concept of generalized solutions. First, parallel to the F-subdiï¬€erential âˆ‚F (Â¯x),
we now consider the F-superdiï¬€erential of f at Â¯x deï¬ned by
âˆ‚Ff(Â¯x) := âˆ’âˆ‚F (âˆ’f)(Â¯x).
Deï¬nition 9.3.1
(a) A function f : E â†’R is said to be a viscosity supersolution of (9.34) if f
is lower semicontinuous and for any x âˆˆE and any xâˆ—âˆˆâˆ‚F f(x) one has
f(x) + H(x, xâˆ—) â‰¥0.
(b) A function f : E â†’R is said to be a viscosity subsolution of (9.34) if f is
upper semicontinuous and for any x âˆˆE and any xâˆ—âˆˆâˆ‚Ff(x) one has
f(x) + H(x, xâˆ—) â‰¤0.
(c) If f : E â†’R is both a viscosity supersolution and a viscosity subsolution
of (9.34), then f is said to be a viscosity solution of (9.34).
If f : E â†’R is continuously diï¬€erentiable, then âˆ‚F f(x) = âˆ‚Ff(x) =
{f â€²(x)} for every x âˆˆE (Proposition 9.1.9). Hence any classical solution of
(9.34) is also a viscosity solution, and any viscosity solution of (9.34) that is
continuously diï¬€erentiable is also a classical solution.
We consider the following condition on the function H:
|H(y, yâˆ—)âˆ’H(x, xâˆ—)| â‰¤Ï•(y âˆ’x, yâˆ—âˆ’xâˆ—)+c max{âˆ¥xâˆ—âˆ¥, âˆ¥yâˆ—âˆ¥} âˆ¥y âˆ’xâˆ¥. (9.35)
Theorem 9.3.2 (Comparison Theorem) Let H : E Ã— Eâˆ—â†’R be such
that, with some constant c > 0 and some continuous function Ï• : E Ã—Eâˆ—â†’R
satisfying Ï•(o, o) = 0, the condition (9.35) holds for any x, y âˆˆE and any
xâˆ—, yâˆ—âˆˆEâˆ—. If f is a viscosity subsolution of (9.34) and bounded above and
g is a viscosity supersolution of (9.34) and bounded below, then f â‰¤g.

182
9 Subdiï¬€erentials of Lower Semicontinuous Functionals
Proof. Let Ïµ > 0 be given. By Theorem 9.2.3 applied to f1 := g and f2 := âˆ’f,
there exist x, y âˆˆE and xâˆ—âˆˆâˆ‚F g(x), yâˆ—âˆˆâˆ‚Ff(y) satisfying
âˆ¥x âˆ’yâˆ¥< Ïµ,
âˆ¥xâˆ—âˆ¥âˆ¥x âˆ’yâˆ¥< Ïµ,
âˆ¥yâˆ—âˆ¥âˆ¥x âˆ’yâˆ¥< Ïµ,
g(x) âˆ’f(y) < inf
E (g âˆ’f) + Ïµ,
âˆ¥xâˆ—âˆ’yâˆ—âˆ¥â‰¤Ïµ.
From the properties of f and g we deduce
g(x) + H(x, xâˆ—) â‰¥0,
f(y) + H(y, yâˆ—) â‰¤0.
Combining the above inequalities as well as (9.35), we obtain
inf
E (g âˆ’f) > g(x) âˆ’f(y) âˆ’Ïµ â‰¥

H(y, yâˆ—) âˆ’H(x, xâˆ—)

âˆ’Ïµ
â‰¥âˆ’

Ï•(y âˆ’x, yâˆ—âˆ’xâˆ—) + c max{âˆ¥xâˆ—âˆ¥, yâˆ—âˆ¥} âˆ¥y âˆ’xâˆ¥

âˆ’Ïµ.
By the assumptions on Ï•, the right-hand side of the last inequality converges
to 0 as Ïµ â†’0. Therefore infE(g âˆ’f) â‰¥0.
âŠ“âŠ”
As an immediate consequence of Theorem 9.3.2 we have:
Corollary 9.3.3 Under the assumptions of Theorem 9.3.2, (9.34) has at most
one continuous bounded viscosity solution.
9.4 An Approximate Mean Value Theorem
Convention. Throughout this section, assume that E is a FrÃ©chet smooth
Banach space.
Theorem 9.4.1 (Approximate Mean Value Theorem) Let f : E â†’R
be proper and l.s.c. Further let a, b âˆˆE and Ï âˆˆR be such that a Ì¸= b,
f(a) âˆˆR, and Ï â‰¤f(b) âˆ’f(a). Then there exist a point c âˆˆ[a, b) as well as
sequences (xn) in E and (xâˆ—
n) in Eâˆ—satisfying
(xn, f(xn)) â†’(c, f(c)) as n â†’âˆ,
xâˆ—
n âˆˆâˆ‚F f(xn) âˆ€n âˆˆN,
lim inf
nâ†’âˆâŸ¨xâˆ—
n, c âˆ’xnâŸ©â‰¥0,
(9.36)
lim inf
nâ†’âˆâŸ¨xâˆ—
n, b âˆ’aâŸ©â‰¥Ï,
(9.37)
f(c) â‰¤f(a) + |Ï|.
(9.38)
Proof.
(I) Let zâˆ—âˆˆEâˆ—be such that âŸ¨zâˆ—, a âˆ’bâŸ©= Ï and set
g(x) := f(x) + âŸ¨zâˆ—, xâŸ©+ Î´[a,b](x),
x âˆˆE.
Then g attains its minimum on the compact set [a,b] at some c, and
we may assume that c âˆˆ[a, b) because g(b) â‰¥g(a). By the strong local

9.4 An Approximate Mean Value Theorem
183
approximate sum rule (Theorem 9.2.6) there exist sequences (xn), (yn),
(xâˆ—
n), and (yâˆ—
n) satisfying
(xn, f(xn)) â†’(c, f(c))
as n â†’âˆ,
yn âˆˆ[a, b]
âˆ€n,
yn â†’c
as n â†’âˆ,
xâˆ—
n âˆˆâˆ‚F f(xn),
yâˆ—
n âˆˆâˆ‚F Î´[a,b](yn)
âˆ€n,
âˆ¥xâˆ—
nâˆ¥Â· âˆ¥xn âˆ’ynâˆ¥< 1/n,
âˆ¥yâˆ—
nâˆ¥Â· âˆ¥xn âˆ’ynâˆ¥< 1/n
âˆ€n,
âˆ¥xâˆ—
n + zâˆ—+ yâˆ—
nâˆ¥< 1/n
âˆ€n.
Since yn â†’c, we have yn âˆˆ[a, b) if n is suï¬ƒciently large which we now
assume. Since Î´[a,b] is convex, Proposition 9.1.9 gives
âˆ‚F Î´[a,b](yn) = âˆ‚Î´[a,b](yn) = {yâˆ—âˆˆEâˆ—| âŸ¨yâˆ—, x âˆ’ynâŸ©â‰¤0
âˆ€x âˆˆ[a, b]}.
(9.39)
Since yâˆ—
n âˆˆâˆ‚F Î´[a,b](yn) and c âˆˆ[a, b), we see that lim supnâ†’âˆ(yâˆ—
n | c âˆ’
yn) â‰¤0. Using this, we obtain
lim inf
nâ†’âˆ(xâˆ—
n | c âˆ’xn) = lim inf
nâ†’âˆ(xâˆ—
n + u | c âˆ’xn)
= lim inf
nâ†’âˆ(âˆ’yâˆ—
n | c âˆ’yn) = âˆ’lim sup
nâ†’âˆ(yâˆ—
n | c âˆ’yn) â‰¥0,
which veriï¬es (9.36).
(II) We turn to (9.37). As yn âˆˆ[a, b) for all suï¬ƒciently large n, we have for
these n,
b âˆ’a = Î»n(b âˆ’yn),
where Î»n := âˆ¥b âˆ’aâˆ¥
âˆ¥b âˆ’ynâˆ¥.
It follows that
lim inf
nâ†’âˆâŸ¨xâˆ—
n + zâˆ—, b âˆ’aâŸ©= lim inf
nâ†’âˆ
&
Î»nâŸ¨xâˆ—
n + zâˆ—, b âˆ’ynâŸ©

= âˆ¥b âˆ’aâˆ¥
âˆ¥b âˆ’câˆ¥lim inf
nâ†’âˆâŸ¨âˆ’yâˆ—
n, b âˆ’ynâŸ©â‰¥0
(9.39)
,
which immediately implies (9.37).
(III) To verify (9.38), notice that g(c) â‰¤g(a) and so f(c) â‰¤f(a) + (u | a âˆ’c).
With some Î» âˆˆ(0, 1] we have c = Î»a + (1 âˆ’Î»)b and it follows that
f(c) â‰¤f(a) + (1 âˆ’Î»)(u | a âˆ’b) â‰¤f(a) + |Ï|.
âŠ“âŠ”
As an application we show:
Proposition 9.4.2 Let f : E â†’R be proper and l.s.c., let U be an open
convex subset of E such that U âˆ©dom f Ì¸= âˆ…. Then for any Î» > 0 the following
assertions are equivalent:

184
9 Subdiï¬€erentials of Lower Semicontinuous Functionals
(a) f is L-continuous on U with Lipschitz constant Î».
(b) sup{âˆ¥xâˆ—âˆ¥| xâˆ—âˆˆâˆ‚F f(x)} â‰¤Î» for any x âˆˆU.
Proof. (a) =â‡’(b): This is straightforward.
(b) =â‡’(a): Let a, b âˆˆU and Ï âˆˆR be such that a âˆˆdom f, a Ì¸= b, and
Ï â‰¤f(b) âˆ’f(a). Further let Ïµ > 0 be given. By Theorem 9.4.1 there exist
x âˆˆU and xâˆ—âˆˆâˆ‚F f(x) such that (see (9.37))
Ï â‰¤âŸ¨xâˆ—, b âˆ’aâŸ©+ Ïµ â‰¤Î»âˆ¥b âˆ’aâˆ¥+ Ïµ.
Since Ï â‰¤f(b) âˆ’f(a) and Ïµ > 0 are arbitrary, it follows that f(b) âˆ’f(a) â‰¤
Î»âˆ¥b âˆ’aâˆ¥and so, in particular, f(b) < +âˆ. Exchanging the roles of a and b,
we thus obtain |f(b) âˆ’f(a)| â‰¤Î»âˆ¥b âˆ’aâˆ¥.
âŠ“âŠ”
9.5 FrÃ©chet Subdiï¬€erential vs. Clarke Subdiï¬€erential
For a locally L-continuous functional we now deduce a representation of the
Clarke subdiï¬€erential in terms of FrÃ©chet subdiï¬€erentials.
Proposition 9.5.1 Let E be a FrÃ©chet smooth Banach space and let f : E â†’
R be locally L-continuous on E. Then for any Â¯x âˆˆE one has
âˆ‚â—¦f(Â¯x) = coâˆ—{xâˆ—âˆˆEâˆ—| âˆƒxk âˆˆE âˆƒxâˆ—
k âˆˆâˆ‚F f(xk) : xk â†’Â¯x, xâˆ—
k
wâˆ—
âˆ’âˆ’â†’xâˆ—}.
(9.40)
Proof. For convenience we write xâˆ—=âˆ—limkâ†’âˆxâˆ—
k if xâˆ—
k
wâˆ—
âˆ’âˆ’â†’xâˆ—. In view of
Theorem 2.3.1, it suï¬ƒces to show that the support functionals of the two sets
in (9.40) coincide, i.e.,
f â—¦(Â¯x, y) = sup{âŸ¨xâˆ—, yâŸ©| xâˆ—=âˆ—lim
kâ†’âˆxâˆ—
k, xâˆ—
k âˆˆâˆ‚F f(xk), xk â†’Â¯x}
âˆ€y âˆˆE.
Since âˆ‚F f(xk) âŠ†âˆ‚â—¦f(xk) by Proposition 9.1.9(e) and âˆ‚â—¦f is norm-to-weakâˆ—
u.s.c. by Proposition 7.3.8(c), we have
f â—¦(Â¯x, y) â‰¥sup{âŸ¨xâˆ—, yâŸ©| xâˆ—=âˆ—lim
kâ†’âˆxâˆ—
k, xâˆ—
k âˆˆâˆ‚F f(xk), xk â†’Â¯x}
âˆ€y âˆˆE.
It remains to verify that
f â—¦(Â¯x, y) â‰¤sup{âŸ¨xâˆ—, yâŸ©| xâˆ—=âˆ—lim
kâ†’âˆxâˆ—
k, xâˆ—
k âˆˆâˆ‚F f(xk), xk â†’Â¯x}
âˆ€y âˆˆE.
(9.41)
Let y âˆˆE be ï¬xed. Choose sequences zk â†’Â¯x and Ï„k â†“0 satisfying
f â—¦(Â¯x, y) = lim
kâ†’âˆ
f(zk + Ï„ky) âˆ’f(zk)
Ï„k
.
Now let Ïµ > 0. By Theorem 9.4.1, for each k there exist Ëœzk âˆˆ[zk, zk + Ï„ky),
xk âˆˆB(Ëœzk, ÏµÏ„k), and xâˆ—
k âˆˆâˆ‚F f(xk) such that

9.6 Multidirectional Mean Value Theorems
185
âŸ¨xâˆ—
k, yâŸ©â‰¥f(zk + Ï„ky) âˆ’f(zk)
Ï„k
âˆ’Ïµ.
(9.42)
If Î» > 0 denotes a Lipschitz constant of f around Â¯x, then xâˆ—
k âˆˆBEâˆ—(o, Î») for
each k (Proposition 7.3.7). Since BEâˆ—(o, Î») is weakâˆ—compact, we may assume
that (xâˆ—
k) is weakâˆ—convergent to some xâˆ—âˆˆBEâˆ—(o, Î»). By letting k â†’âˆ, we
conclude from (9.42) that
sup{âŸ¨xâˆ—, yâŸ©| xâˆ—=âˆ—lim
kâ†’âˆxâˆ—
k, xâˆ—
k âˆˆâˆ‚F f(xk), xk â†’Â¯x} â‰¥f â—¦(Â¯x, y) âˆ’Ïµ.
Since Ïµ > 0 and y âˆˆE are arbitrary, (9.41) follows.
âŠ“âŠ”
Remark 9.5.2 Proposition 9.5.1 may be considered as an inï¬nite-dimensional
analogue of Clarkeâ€™s Theorem 7.3.12. It shows that the Clarke subdiï¬€erential
is the convexiï¬cation of weakâˆ—limits of FrÃ©chet subdiï¬€erentials. In many ins-
tances, convexity is a very convenient property as it allows to use techniques of
convex analysis (cf. the remarks at the beginning of this chapter). However, as
already observed above, the Clarke subdiï¬€erential may be too coarse to detect
minimizers and so may be the smaller Michelâ€“Penot subdiï¬€erential (cf. Re-
mark 7.3.10, Example 7.3.11, and Exercise 9.8.3). The FrÃ©chet subdiï¬€erential
is qualiï¬ed as an appropriate derivative-like object not only by its â€œsmallness,â€
but also, in particular, by the rich calculus it admits. This will also allow to
derive multiplier rules in terms of FrÃ©chet subdiï¬€erentials in Chap. 12. But we
already know that the results are of an approximate nature. In Chap. 13 we
shall study derivative-like objects that admit exact results.
9.6 Multidirectional Mean Value Theorems
Convention. Throughout this section, E denotes a FrÃ©chet smooth Banach
space.
Let f : E â†’R be a G-diï¬€erentiable l.s.c. functional. As a special case of
the mean value inequality of Proposition 3.3.4 we obtain that for any x, y âˆˆE
there exists z âˆˆ(x, y) such that
f(y) âˆ’f(x) â‰¤âŸ¨f â€²(z), y âˆ’xâŸ©.
Given a compact convex set S âŠ†E, we pass to the inequality
min
ËœyâˆˆS f(Ëœy) âˆ’f(x) â‰¤âŸ¨f â€²(z), y âˆ’xâŸ©
âˆ€y âˆˆS.
(9.43)
We ï¬rst establish a multidirectional version of this inequality by showing that
for ï¬xed x the same element z can be chosen in (9.43) while the direction y
varies over S, provided E is ï¬nite dimensional.
If x âˆˆE and S âŠ†E, we write [x, S] := co({x} âˆªS).

186
9 Subdiï¬€erentials of Lower Semicontinuous Functionals
Proposition 9.6.1 Assume that S is a nonempty, bounded, closed, convex
subset of RN, x âˆˆRN, and f : RN â†’R is l.s.c. on RN and G-diï¬€erentiable
on a neighborhood of [x, S]. Then there exists z âˆˆ[x, S] satisfying (9.43).
Proof. Let U be an open neighborhood of [x, S] on which f is G-diï¬€erentiable.
Set
r := min
ËœyâˆˆS f(Ëœy) âˆ’f(x)
and deï¬ne g : U Ã— [0, 1] â†’R by
g(y, Ï„) := f(x + Ï„(y âˆ’x)) âˆ’rÏ„.
Since g is l.s.c. and [x, S] is compact, g attains its inï¬mum on S Ã— [0, 1] at
some (Ë†y, Ë†Ï„) âˆˆS Ã— [0, 1]. We show that (9.43) holds with
z :=

x + Ë†Ï„(Ë†y âˆ’x)
if Ë†Ï„ âˆˆ[0, 1),
x
if Ë†Ï„ = 1.
Now we distinguish three cases:
(I) Assume ï¬rst that Ë†Ï„ âˆˆ(0, 1). Then the function Ï„ â†’g(Ë†y, Ï„) attains its
inï¬mum on the interval [0, 1] at the interior point Ë†Ï„. It follows that
0 = âˆ‚
âˆ‚tg(Ë†y, Ï„)

Ï„=Ë†Ï„= âŸ¨f â€²(z), Ë†y âˆ’xâŸ©âˆ’r.
(9.44)
Analogously, the function y â†’g(y, Ë†Ï„) attains its inï¬mum over the set
S at Ë†y. Since the function is G-diï¬€erentiable, the necessary optimality
condition (7.6) in Sect. 7.1 implies that
0 â‰¤
( âˆ‚
âˆ‚y g(y, Ë†Ï„)

y=Ë†y, y âˆ’Ë†y
)
=

Ë†Ï„f â€²(z), y âˆ’Ë†y
 
âˆ€y âˆˆS
and so
âŸ¨f â€²(z), y âˆ’Ë†yâŸ©â‰¥0
âˆ€y âˆˆS.
(9.45)
Combining (9.44) and (9.45), we obtain
r â‰¤âŸ¨f â€²(z), Ë†y âˆ’xâŸ©+ âŸ¨f â€²(z), y âˆ’Ë†yâŸ©= âŸ¨f â€²(z), y âˆ’xâŸ©;
here y âˆˆS is arbitrary. Hence (9.43) is veriï¬ed in case Ë†Ï„ âˆˆ(0, 1).
(II) Now assume that Ë†Ï„ = 0 so that (Ë†y, 0) is a minimizer of g on S Ã— [0, 1].
It follows directly that
f(x) = g(Ë†y, 0) â‰¤g(y, Ï„) = f(x + Ï„(y âˆ’x)) âˆ’rÏ„
âˆ€(y, Ï„) âˆˆS Ã— (0, 1]
and so
r â‰¤lim
Ï„â†“0
f(x + Ï„(y âˆ’x)) âˆ’f(x)
Ï„
= âŸ¨f â€²(z), y âˆ’xâŸ©
âˆ€y âˆˆS,
which is equivalent to (9.43).

9.6 Multidirectional Mean Value Theorems
187
(III) Finally assume that Ë†Ï„ = 1. Then, in particular, we have g(Ë†y, 1) â‰¤
g(Ë†y, 0) = f(x) and on the other hand,
g(Ë†y, 1) = f(Ë†y) âˆ’r = f(Ë†y) âˆ’min
ËœyâˆˆS f(Ëœy) + f(x) â‰¥f(x).
Therefore, f(x) = g(Ë†y, 1) which means that f(x) is the minimum of g
on S Ã— [0, 1]. Since f(x) = g(y, 0) for any y âˆˆS, we see that any (y, 0) is
also a minimizer of g. Hence we can replace Ë†Ï„ = 1 with Ë†Ï„ = 0 and refer
to case (II).
âŠ“âŠ”
Now we establish a multidirectional mean value theorem in terms of F-
subdiï¬€erentials in arbitrary FrÃ©chet smooth Banach spaces.
Theorem 9.6.2 (Multidirectional Mean Value Theorem) Assume that
E is a FrÃ©chet smooth Banach space, S is a nonempty closed convex subset
of E, f : E â†’R is a l.s.c. functional, and x âˆˆdom f. Suppose that for some
Ï > 0, f is bounded below on [x, S] + B(o, Ï). Let r be such that
r < lim
Î·â†“0 inf{f(y) | y âˆˆS + B(o, Î·)} âˆ’f(x).
(9.46)
Then for any Ïµ > 0 there exist z âˆˆ[x, S] + B(o, Ïµ) and zâˆ—âˆˆâˆ‚F f(z) such that
f(z) < lim
Î·â†“0 inf{f(y) | y âˆˆ[x, S] + B(o, Î·)} + |r| + Ïµ,
(9.47)
r < âŸ¨zâˆ—, y âˆ’xâŸ©+ Ïµâˆ¥y âˆ’xâˆ¥
âˆ€y âˆˆS.
(9.48)
Proof.
(I) First we assume that (9.46) holds for r = 0 and we consider the case
r = 0. The functional Ëœf := f + Î´[x,S]+B(o,Ï) is bounded below on all
of E. By (9.46) there exists Î· âˆˆ(0, Ï/2) such that
f(x) < inf{f(y) | y âˆˆS + B(o, 2Î·)}.
Without loss of generality we may assume that Ïµ satisï¬es
0 < Ïµ < inf{f(y) | y âˆˆS + B(o, 2Î·)} âˆ’f(x)
and Ïµ < Î·.
(9.49)
By the nonlocal approximate sum rule (Theorem 9.2.3), applied to
f1 := Ëœf and f2 := Î´[x,S], there exist z âˆˆdom f âˆ©([x, S] + B(o, Ï)) and
u âˆˆ[x, S] such that
âˆ¥z âˆ’uâˆ¥< Ïµ,
zâˆ—âˆˆâˆ‚F f1(z) = âˆ‚F f(z)
as well as uâˆ—âˆˆâˆ‚F Î´[x,S](u) satisfying
max{âˆ¥zâˆ—âˆ¥, âˆ¥uâˆ—âˆ¥} Â· âˆ¥z âˆ’uâˆ¥< Ïµ,
(9.50)
f(z) < lim
Î·â†“0 inf{f(y) | y âˆˆ[x, S] + B(o, Î·)} + Ïµ â‰¤f(x) + Ïµ,
(9.51)
âˆ¥zâˆ—+ uâˆ—âˆ¥< Ïµ.
(9.52)

188
9 Subdiï¬€erentials of Lower Semicontinuous Functionals
Since [x, S] is a convex set, we have
uâˆ—âˆˆâˆ‚F Î´[x,S](u) = NF ([x, S], u) = N([x, S], u)
and so
âŸ¨uâˆ—, w âˆ’uâŸ©â‰¤0
âˆ€w âˆˆ[x, S].
(9.53)
From (9.52) and (9.53) we obtain
âŸ¨zâˆ—, w âˆ’uâŸ©= âŸ¨zâˆ—+ uâˆ—, w âˆ’uâŸ©âˆ’âŸ¨uâˆ—, w âˆ’uâŸ©
â‰¥âŸ¨zâˆ—+ uâˆ—, w âˆ’uâŸ©> âˆ’Ïµâˆ¥w âˆ’uâˆ¥
âˆ€w âˆˆ[x, S], w Ì¸= u.
(9.54)
We show that d(S, u) â‰¥Î·. If we had d(S, u) < Î·, it would follow that
âˆ¥Ëœy âˆ’uâˆ¥< Î· for some Ëœy âˆˆS, thus
âˆ¥Ëœy âˆ’zâˆ¥â‰¤âˆ¥Ëœy âˆ’uâˆ¥+ âˆ¥u âˆ’zâˆ¥
<
(9.50) Î· + Ïµ < 2Î·
and so d(S, z) < 2Î·. But then
f(z) â‰¥inf{f(y) | y âˆˆS + B(o, 2Î·)}
>
(9.49) f(x) + Ïµ,
which contradicts (9.51). Hence d(S, u) â‰¥Î·. Let u := x + Ë†Ï„(Ë†y âˆ’x) with
some Ë†Ï„ âˆˆ[0, 1] and Ë†y âˆˆS. Then
0 < Î· â‰¤âˆ¥Ë†y âˆ’uâˆ¥= (1 âˆ’Ë†Ï„)âˆ¥Ë†y âˆ’xâˆ¥
and so Ë†Ï„ < 1. Consider any y âˆˆS and set w := y + Ë†Ï„(Ë†y âˆ’y). Then
w Ì¸= u, otherwise it would follow that y = x which is contradictory
because x /âˆˆS (see (9.46)). Inserting this w into (9.54), we ï¬nally obtain
(9.48) with r = 0.
(II) Now we consider the general case (9.46). Equip EÃ—R with the Euclidean
product norm. Choose Ïµâ€² âˆˆ(0, Ïµ/2) such that
r + Ïµâ€² < lim
Î·â†“0 inf{f(y) | y âˆˆS + B(o, Î·)} âˆ’f(x).
Deï¬ne F : E Ã— R â†’R by F(y, Ï„) := f(y) âˆ’(r + Ïµâ€²)Ï„. Then F is l.s.c. on
E Ã—R and bounded below on [(x, 0), S Ã—{1}]+BEÃ—R(o, Ï). Furthermore
we have
0 < lim
Î·â†“0 inf{f(y) | y âˆˆS + B(o, Î·)} âˆ’(r + Ïµâ€²) âˆ’f(x)
= lim
Î·â†“0 inf{F(y, 1) | (y, 1) âˆˆ(S Ã— {1}) + BEÃ—R(o, Î·)} âˆ’F(x, 0).
Hence the special case (I) applies with f, x, and S replaced by F,
(x, 0), and S Ã—{1}, respectively. Consequently there exist (z, Ï„) âˆˆ[(x, 0),

9.6 Multidirectional Mean Value Theorems
189
S Ã— {1}] + BEÃ—R(o, Ïµ) and (zâˆ—, Ï„ âˆ—) âˆˆâˆ‚F F(z, Ï„) âŠ†âˆ‚F f(z) Ã— {âˆ’(r + Ïµâ€²)}
such that
f(z) = F(z, Ï„) + (r + Ïµâ€²)Ï„
< lim
Î·â†“0 inf{F(y, Ï„) | (y, Ï„) âˆˆ[(x, 0), S Ã— {1}]+BEÃ—R(o, Î·)}+Ïµâ€²+(r + Ïµâ€²)Ï„
â‰¤lim
Î·â†“0 inf{f(y) | y âˆˆ[x, S] + B(o, Î·)} + |r| + Ïµ,
and for any (y, 1) âˆˆS Ã— {1} we have
0 <

(zâˆ—, Ï„ âˆ—), (y, 1) âˆ’(x, 0)
 
+ Ïµâ€²âˆ¥(y âˆ’x, 1)âˆ¥
â‰¤âŸ¨zâˆ—, y âˆ’xâŸ©âˆ’(r + Ïµâ€²) + Ïµâ€²(âˆ¥y âˆ’xâˆ¥+ 1)
= âŸ¨zâˆ—, y âˆ’xâŸ©âˆ’r + Ïµâ€²âˆ¥y âˆ’xâˆ¥â‰¤âŸ¨zâˆ—, y âˆ’xâŸ©âˆ’r + Ïµâˆ¥y âˆ’xâˆ¥.
The proof is thus complete.
âŠ“âŠ”
Notice that the set S in Theorem 9.6.2 is not assumed to be bounded
(in this context, see Exercise 9.8.8).
To
prepare
the
next
result,
consider
a
G-diï¬€erentiable
functional
f : E â†’R such that f â€²(Â¯x) Ì¸= o for some Â¯x âˆˆE. Then Â¯x is not a local
minimizer of f. Hence for some r > 0 we have
inf
xâˆˆB(Â¯x,r) f(x) < f(Â¯x).
Theorem 9.6.3 generalizes this fact to the nondiï¬€erentiable case and at the
same time quantiï¬es the inequality.
Theorem 9.6.3 (Decrease Principle) Assume that f : E â†’R is l.s.c.
and bounded below, and Â¯x âˆˆE. Assume further that for some r > 0 and
Ïƒ > 0, one has
&
x âˆˆB(Â¯x, r) and xâˆ—âˆˆâˆ‚F f(x)

=â‡’âˆ¥xâˆ—âˆ¥> Ïƒ.
(9.55)
Then
inf
xâˆˆB(Â¯x,r) f(x) â‰¤f(Â¯x) âˆ’rÏƒ.
(9.56)
Proof. Obviously we may suppose that Â¯x âˆˆdom f. Let râ€² âˆˆ(0, r). Observe
that
inf
xâˆˆB(Â¯x,r) f(x) â‰¤lim
Î·â†“0
inf
yâˆˆB(Â¯x,Î·) f(y).
(9.57)
Let Ïµ âˆˆ(0, r âˆ’râ€²) and set
Ëœr := lim
Î·â†“0
inf
yâˆˆB(Â¯x,Î·) f(y) âˆ’f(Â¯x) âˆ’Ïµ.

190
9 Subdiï¬€erentials of Lower Semicontinuous Functionals
Applying Theorem 9.6.2 with S := B(Â¯x, râ€²) and x, r replaced by Â¯x, Ëœr, res-
pectively, we conclude that there exist z âˆˆB(Â¯x, râ€²) + B(o, Ïµ) âŠ†B(Â¯x, r) and
zâˆ—âˆˆâˆ‚F f(z) such that
Ëœr < âŸ¨zâˆ—, y âˆ’Â¯xâŸ©+ Ïµâˆ¥y âˆ’Â¯xâˆ¥
âˆ€y âˆˆB(Â¯x, râ€²).
(9.58)
By hypothesis (9.55) we have âˆ¥zâˆ—âˆ¥> Ïƒ. Hence there exists z0 âˆˆE satisfying
âˆ¥z0âˆ¥= 1 and âŸ¨zâˆ—, z0âŸ©> Ïƒ. Inserting y := âˆ’râ€²z0 + Â¯x into (9.58) yields
Ëœr < âˆ’râ€²âŸ¨zâˆ—, z0âŸ©+ râ€²Ïµ < âˆ’râ€²Ïƒ + râ€²Ïµ.
Recalling (9.57) and the deï¬nition of Ëœr, we further obtain
inf
B(Â¯x,r) f(x) < f(Â¯x) âˆ’râ€²Ïƒ + (râ€² + 1)Ïµ.
Letting râ€² â†‘r and so Ïµ â†“0 gives (9.56).
âŠ“âŠ”
Corollary 9.6.4 is a counterpart of Corollary 8.2.5 for a nondiï¬€erentiable
functional f.
Corollary 9.6.4 Let f : E â†’R be l.s.c. and bounded below. Assume that
Â¯x âˆˆE and Ïµ > 0 are such that f(Â¯x) < infE f + Ïµ. Then for any Î» > 0 there
exist z âˆˆB(Â¯x, Î») and zâˆ—âˆˆâˆ‚F f(z) satisfying
f(z) < inf
E f + Ïµ
and
âˆ¥zâˆ—âˆ¥< Ïµ
Î».
Proof. See Exercise 9.8.9.
âŠ“âŠ”
9.7 The FrÃ©chet Subdiï¬€erential of Marginal Functions
We now establish representations of the F-subdiï¬€erential of a marginal func-
tional of the form
f(x) := inf
yâˆˆF Ï•(x, y),
x âˆˆE.
(9.59)
The ï¬rst result will be crucial for deriving an implicit multifunction
theorem in Sect. 13.10. Recall that f(x) := lim infyâ†’x f(y) denotes the
lower semicontinuous closure of f
(see Exercise 1.8.11). Notice that
âˆ‚F f(x) âŠ†âˆ‚F f(x).
Proposition 9.7.1 Assume that E and F are FrÃ©chet smooth Banach spaces,
Ï• : EÃ—F â†’R is l.s.c., and f is deï¬ned by (9.59). Let x âˆˆE and xâˆ—âˆˆâˆ‚F f(x).
Then for any suï¬ƒciently small Ïµ > 0 there exist (xÏµ, yÏµ) âˆˆEÃ—F and (xâˆ—
Ïµ, yâˆ—
Ïµ ) âˆˆ
âˆ‚F Ï•(xÏµ, yÏµ) such that
âˆ¥x âˆ’xÏµâˆ¥< Ïµ,
|f(x) âˆ’f(xÏµ)| < Ïµ,
(9.60)
Ï•(xÏµ, yÏµ) < f(xÏµ) + Ïµ < f(xÏµ) + Ïµ,
(9.61)
âˆ¥xâˆ—
Ïµ âˆ’xâˆ—âˆ¥< Ïµ,
âˆ¥yâˆ—
Ïµ âˆ¥< Ïµ.
(9.62)

9.7 The FrÃ©chet Subdiï¬€erential of Marginal Functions
191
Proof. Let g : E â†’R be a C1 function such that gâ€²(x) = xâˆ—and for some
Ï âˆˆ(0, 1) one has
(f âˆ’g)(u) â‰¥(f âˆ’g)(x) = 0
âˆ€u âˆˆB(x, Ï).
Let Ïµ âˆˆ(0, Ï) and let Î± > 0 be the constant associated with E in the
smooth variational principle of Theorem 8.4.3. Choose a positive number Î· <
min{Ïµ/5,
!
Ïµ/(5Î±) such that the following holds:
f(u) â‰¥f(x) âˆ’Ïµ/5
âˆ€u âˆˆB(x, Î·),
|g(u) âˆ’g(Ë†u)| < Ïµ/5
whenever âˆ¥u âˆ’Ë†uâˆ¥< Î·,
âˆ¥gâ€²(u) âˆ’gâ€²(x)âˆ¥< Ïµ/2
âˆ€u âˆˆB(x, Î·).
Now choose Â¯u âˆˆB(x, Î·/2) close enough to x so that f(Â¯u) âˆ’g(Â¯u) < f(x) âˆ’
g(x) + Î±Î·2/8. Then there exists Â¯v âˆˆF satisfying
Ï•(Â¯u, Â¯v) âˆ’g(Â¯u) < f(Â¯u) âˆ’g(Â¯u) + Î±Î·2/8 < f(x) âˆ’g(x) + Î±Î·2/4
â‰¤
inf
uâˆˆB(x,Ï)
vâˆˆF

Ï•(u, v) âˆ’g(u)

+ Î±Î·2/4.
Applying Theorem 8.4.3 to the functional (u, v) â†’Ï•(u, v) âˆ’g(u), we ï¬nd
(xÏµ, yÏµ) âˆˆB((Â¯u, Â¯v), Î·/2) âŠ†B((x, Â¯v), Î·) and a C1 function h : E Ã— F â†’R such
that max{âˆ¥hâˆ¥âˆ, âˆ¥hâ€²âˆ¥âˆ} < Î· and the functional
(u, v) â†’Ï•(u, v) âˆ’g(u) + h(u, v),
(u, v) âˆˆE Ã— F,
attains its minimum at (xÏµ, yÏµ). It follows that

gâ€²(xÏµ) âˆ’h 1(xÏµ, yÏµ), âˆ’h 2(xÏµ, yÏµ)

âˆˆâˆ‚F Ï•(xÏµ, yÏµ).
Setting xâˆ—
Ïµ := gâ€²(xÏµ) âˆ’h 1(xÏµ, yÏµ) and yâˆ—
Ïµ := âˆ’h 2(xÏµ, yÏµ), we see that (9.62)
holds. We further have
Ï•(xÏµ, yÏµ) â‰¤Ï•(Â¯u, Â¯v) +

g(xÏµ) âˆ’g(Â¯u)

+ h(Â¯u, Â¯v) âˆ’h(xÏµ, yÏµ)
â‰¤f(x) + Î±Î·2 + |g(xÏµ) âˆ’g(Â¯u)| + 2âˆ¥hâˆ¥âˆ
< f(xÏµ) + Ïµ/5 + Î±Î·2 + |g(xÏµ) âˆ’g(Â¯u)| + 2âˆ¥hâˆ¥âˆ
â‰¤f(xÏµ) + Ïµ â‰¤f(xÏµ) + Ïµ,
which veriï¬es (9.61). This inequality together with f(xÏµ) â‰¤f(xÏµ) â‰¤Ï•(xÏµ, yÏµ)
shows that (9.60) also holds.
âŠ“âŠ”
The following result strengthens Proposition 9.7.1; it states that each xâˆ—âˆˆ
âˆ‚F f(x) (in particular, each xâˆ—âˆˆâˆ‚F f(x)) can be approximated by some uâˆ—âˆˆ
âˆ‚F,1Ï•(u, y), where u is close to x, for all y such that Ï•(x, y) is close to f(x).
Here, âˆ‚F,1Ï•(u, y) denotes the F-subdiï¬€erential of u â†’Ï•(u, y).

192
9 Subdiï¬€erentials of Lower Semicontinuous Functionals
Proposition 9.7.2 Assume that E is a FrÃ©chet smooth Banach space and F
is an arbitrary nonempty set. For each y âˆˆF let u â†’Ï•(u, y), u âˆˆE, be proper
and l.s.c. Let f : E â†’R be deï¬ned by (9.59), let x âˆˆE, and xâˆ—âˆˆâˆ‚F f(x).
Then there exist a nonnegative continuous function Î³ : [0, +âˆ) â†’R with
Î³(0) = 0 and a constant c > 0 such that for any suï¬ƒciently small Ïµ > 0,
any y âˆˆF, and any Ë†x âˆˆB(x, Ïµ) satisfying Ï•(Ë†x, y) < f(x) + Ïµ, there exist
u âˆˆB(x, câˆšÏµ) and uâˆ—âˆˆâˆ‚F,1Ï•(u, y) such that
Ï•(u, y) < f(x) + câˆšÏµ
and
âˆ¥uâˆ—âˆ’xâˆ—âˆ¥â‰¤Î³(Ïµ).
Proof. Since xâˆ—âˆˆâˆ‚F f(x), there exist Î´ âˆˆ(0, 1) and a C1 functional g : E â†’R
such that gâ€²(x) = xâˆ—and one has
0 = (f âˆ’g)(x) â‰¤(f âˆ’g)(u)
âˆ€u âˆˆB(x, 2Î´).
(9.63)
Moreover we may assume that Î´ is so small that g is L-continuous on B(x, 2Î´)
with Lipschitz constant Î» > 0 (cf. Propositions 3.2.4 and 3.4.2). Now let
Ïµ âˆˆ(0, Î´2) be given. Further let Ë†x be as in the theorem. It follows that
Ï•(Ë†x, y) âˆ’g(Ë†x) =

Ï•(Ë†x, y) âˆ’f(x)

+

f(x) âˆ’g(Ë†x)

< Ïµ +

g(x) âˆ’g(Ë†x)

â‰¤Ïµ + Î»âˆ¥x âˆ’Ë†xâˆ¥â‰¤(1 + Î»)Ïµ.
For any u âˆˆB(x, 2âˆšÏµ) we have Ï•(u, y)âˆ’g(u) â‰¥0 (which follows from (9.63)).
This and the foregoing estimate imply

Ï•(u, y) âˆ’g(u)

âˆ’

Ï•(Ë†x, y) âˆ’g(Ë†x)

â‰¥âˆ’(1 + Î»)Ïµ
âˆ€u âˆˆB(x, 2âˆšÏµ).
Applying Theorem 9.6.2 with S, x, and f replaced by B(x, âˆšÏµ), Ë†x, and
u â†’Ï•(u, y) âˆ’g(u), respectively, we conclude that there exist u âˆˆB(x, âˆšÏµ) +
B(o, âˆšÏµ) âŠ†B(x, 2âˆšÏµ) and uâˆ—âˆˆâˆ‚F,1Ï•(u, y) such that
Ï•(u,y)) < Ï•(Ë†x, y) +

g(u) âˆ’g(Ë†x)

+ Ïµ < f(x) + Î»âˆ¥u âˆ’Ë†xâˆ¥+ 2Ïµ
<f(x) + Î»(âˆ¥u âˆ’xâˆ¥+ âˆ¥x âˆ’Ë†xâˆ¥) + 2Ïµ â‰¤f(x) + (3Î» + 2)âˆšÏµ
and
âŸ¨uâˆ—âˆ’gâ€²(u), v âˆ’Ë†xâŸ©â‰¥âˆ’(1 + Î»)Ïµ
âˆ€v âˆˆB(Ë†x, âˆšÏµ);
(9.64)
in this connection notice that âˆ‚F,1

Ï•(u, y)âˆ’g(u)

= âˆ‚F,1Ï•(u, y)âˆ’{gâ€²(u)} and
employ Exercise 9.8.8. From (9.64) we conclude that âˆ¥uâˆ—âˆ’gâ€²(u)âˆ¥â‰¤(1+Î»)âˆšÏµ
and so
âˆ¥uâˆ—âˆ’xâˆ—âˆ¥â‰¤âˆ¥uâˆ—âˆ’gâ€²(u)âˆ¥+âˆ¥gâ€²(u)âˆ’gâ€²(x)âˆ¥â‰¤(1+Î»)âˆšÏµ+âˆ¥gâ€²(u)âˆ’gâ€²(x)âˆ¥â‰¤Î³(Ïµ),
where
Î³(Ïµ) := (1 + Î»)âˆšÏµ + sup{âˆ¥gâ€²(u) âˆ’gâ€²(x)âˆ¥| u âˆˆB(x, 2âˆšÏµ)}
âˆ€Ïµ â‰¥0.
Obviously, Î³ has the required properties. It remains to set c := 3Î» + 2.
âŠ“âŠ”

9.8 Bibliographical Notes and Exercises
193
9.8 Bibliographical Notes and Exercises
The concept of the FrÃ©chet subdiï¬€erential can be traced back to Bazaraa and
Goode [10]. It was developed by Kruger and Mordukhovich [113], Borwein
and StrÃ³jwas [20], Schirotzek [194], and others. Crucial progress in the study
of the FrÃ©chet subdiï¬€erential was possible after Deville et al. [50] had shown
that it coincides with the viscosity subdiï¬€erential in any FrÃ©chet smooth
Banach space and so in particular with the proximal subdiï¬€erential (see
Lemma 9.1.6 and Theorem 9.1.7). The concept of proximal subgradients is
due to Rockafellar [185].
The presentation of Chap. 9 owes much to Borwein and Zhu [23,
24].
As
these
authors,
we
took
the
nonlocal
approximate
sum
rule
(Theorem 9.2.3), which is due to Zhu [225], as starting point for the theory
of the F-subdiï¬€erential. Local approximate sum rules go back to Ioï¬€e [95].
Generalizations were obtained among others by Borwein and Ioï¬€e [17] and
Borwein and Zhu [22].
The approximate mean value inequality is originally due to Zagrodny [220],
its version in terms of F-subdiï¬€erentials was established by Loewen [124].
The simple proof of Theorem 9.4.1 via the nonlocal approximate sum rule is
adapted from Borwein and Zhu [23]. Zagrodny [220] also shows that Lebourgâ€™s
mean value theorem (Theorem 7.4.4) can be derived from Theorem 9.4.1.
The multidirectional mean value theorem is due to Clarke and Ledyaev [38].
It is a cornerstone in the subdiï¬€erential theory of Clarke et al. [39]. The
F-subdiï¬€erential version of Theorem 9.6.2 appeared in Zhuâ€™s paper [225],
the ï¬nite-dimensional version of Proposition 9.6.1 was taken from Clarke
et al. [39]. For further substantial results and applications in this direction
we also recommend [39] (inï¬nite-dimensional spaces) and Rockafellar and
Wets [189] (ï¬nite-dimensional spaces).
Proposition
9.7.1
is
due
to
Ledyaev
and
Zhu
[120, 121],
while
Proposition 9.7.2 is taken from Borwein and Zhu [24] who attribute it to
Ledyaev and Treiman.
Crandall and Lions [42] introduced the concept of a viscosity solution of the
Hamiltonâ€“Jacobi equation. Viscosity subsolutions and viscosity supersolutions
were ï¬rst studied by Crandall et al. [41]. Theorem 9.3.2 and its proof are due
to Borwein and Zhu [22]. For related comparison results as well as existence
theorems in terms of viscosity solutions see also Clarke et al. [39], Deville et
al. [50], and Subbotin [204].
Exercise 9.8.1 Verify Proposition 9.1.3.
Exercise 9.8.2 Verify Remark 9.1.4.

194
9 Subdiï¬€erentials of Lower Semicontinuous Functionals
Exercise 9.8.3
(a) Let f(x) := âˆ’|x|, x âˆˆR. Show that âˆ‚F f(0) = âˆ…but âˆ‚â™¦f(0) = âˆ‚â—¦f(0) =
[âˆ’1, 1].
(b) Let f(x) := âˆ’|x|3/2, x âˆˆR. Show that âˆ‚P f(0) = âˆ…but âˆ‚F f(0) = {f â€²(0)}.
(Hence the inclusion in (9.8) can be proper.)
Exercise 9.8.4 Verify Remark 9.1.8.
Hint (cf. Borwein and Zhu [23]): Let Î·(t) := âˆ’Ï2(Î±t) for t > 0 and Î·(0) := 0;
here Î± is as in Lemma 9.1.6 and Ï2 is as in the proof of Theorem 9.1.7. Notice
that Î· is diï¬€erentiable and put
Î³(t) :=
 t
0
Î²(s) ds, t â‰¥0,
where Î²(s) := sup
0â‰¤Ïƒâ‰¤s
Î·â€²(Ïƒ), s â‰¥0.
Show that the function g : E â†’R deï¬ned by
g(x) := f(Â¯x) + âŸ¨xâˆ—, x âˆ’Â¯xâŸ©âˆ’Î³(âˆ¥x âˆ’Â¯xâˆ¥),
x âˆˆE,
meets the requirement.
Exercise 9.8.5 Prove statement (e) of Proposition 9.1.9.
Exercise 9.8.6 Prove Proposition 9.2.2.
Exercise 9.8.7 Verify Lemma 9.2.5.
Exercise 9.8.8 We refer to Theorem 9.6.2:
(a) Show that in (9.48) the term Ïµâˆ¥y âˆ’xâˆ¥can be omitted if the set S is
bounded.
(b) Consider the example E = S := R and f(y) := ey to see that in general
the conclusion of Theorem 9.6.2 is false if the term Ïµâˆ¥y âˆ’xâˆ¥is omitted
from (9.48).
Exercise 9.8.9 Verify Corollary 9.6.4.

10
Multifunctions
10.1 The Generalized Open Mapping Theorem
In this section, let E and F be Banach spaces.
Given a multifunction Î¦ : E â‡’F (cf. Sect. 4.3), we write
Dom Î¦ := {x âˆˆE | Î¦(x) Ì¸= âˆ…},
domain of Î¦,
ker Î¦
:= {x âˆˆE | o âˆˆÎ¦(x)},
kernel of Î¦,
range Î¦:= 
xâˆˆE Î¦(x),
range of Î¦,
graph Î¦:= {(x, y) âˆˆE Ã— F | x âˆˆE, y âˆˆÎ¦(x)}, graph of Î¦,
Î¦âˆ’1(y):= {x âˆˆE | y âˆˆÎ¦(x)},
y âˆˆF,
inverse of Î¦.
The multifunction Î¦ is said to be closed or convex if graph Î¦ is closed or
convex, respectively. We call Î¦ closed-valued or bounded-valued if Î¦(x) is,
respectively, a closed or a bounded subset of F for any x âˆˆE. Notice that a
closed multifunction is closed-valued but the converse is not true.
Our aim in this section is to generalize the open mapping theorem from
continuous linear mappings to multifunctions. We prepare this with an aux-
iliary result. Let pE : E Ã— F â†’E denote the projection onto E deï¬ned by
pE(x, y) := x for each (x, y) âˆˆE Ã— F. Analogously deï¬ne pF : E Ã— F â†’F.
Lemma 10.1.1 If C is a closed convex subset of E Ã— F such that pE(C) is
bounded, then
int cl

pF (C)

= int

pF (C)

.
Proof. We may assume that C is nonempty. The assertion is veriï¬ed when we
have shown that int cl

pF (C)

âŠ†pF (C). Thus let y âˆˆint cl

pF (C)

be given.
We shall show that there exists x âˆˆC satisfying (x, y) âˆˆC. Let Ïµ > 0 be
such that B(y, 2Ïµ) âŠ†cl

pF (C)

. Choose (x0, y0) âˆˆC and deï¬ne a sequence

(xk, yk)

in C recursively in the following way. Assume that (xk, yk) is already

196
10 Multifunctions
deï¬ned. If yk = y, then set xk+1 := xk and yk+1 := yk. In this case, the element
x := xk meets the requirement. If yk Ì¸= y, then set
Î±k :=
Ïµ
âˆ¥yk âˆ’yâˆ¥,
zk := y + Î±k(y âˆ’yk).
Then zk âˆˆB(y, Ïµ) âŠ†cl

pF (C)

. Hence there exists (Ëœx, Ëœy) âˆˆC satisfying
âˆ¥Ëœy âˆ’zkâˆ¥â‰¤1
2âˆ¥yk âˆ’yâˆ¥. Now let
(xk+1, yk+1) :=
Î±k
1 + Î±k
(xk, yk) +
1
1 + Î±k
(Ëœx, Ëœy).
Since C is convex, we have (xk+1, yk+1) âˆˆC. It follows that
âˆ¥xk+1 âˆ’xkâˆ¥= âˆ¥Ëœx âˆ’xkâˆ¥
1 + Î±k
â‰¤diam pE(C)
Ïµ
âˆ¥yk âˆ’yâˆ¥,
(10.1)
âˆ¥yk+1 âˆ’yâˆ¥= âˆ¥Ëœy âˆ’zkâˆ¥
1 + Î±k
â‰¤1
2âˆ¥yk âˆ’yâˆ¥.
(10.2)
From (10.2) we conclude that âˆ¥yk âˆ’yâˆ¥â‰¤2âˆ’kâˆ¥y0 âˆ’yâˆ¥. Hence yk â†’y as
k â†’âˆ. This together with (10.1) shows that (xk) is a Cauchy sequence and
so is convergent to some x âˆˆE. Since C is closed, we have (x, y) âˆˆC.
âŠ“âŠ”
Now we can establish the announced result.
Theorem 10.1.2 (Generalized Open Mapping Theorem) Let E and F
be Banach spaces and Î¦ : E â‡’F be a closed convex multifunction. If
y âˆˆint range(Î¦), then y âˆˆint Î¦
ËšB(x, Ï)

for each x âˆˆÎ¦âˆ’1(y) and each Ï > 0.
Remark 10.1.3 Recall that a mapping T : E â†’F is said to be open if it
maps open subsets of E onto open subsets of F. The classical open mapping
theorem of Banach states that if T is continuous, linear, and surjective, then
T is open. We show that this follows from Theorem 10.1.2. Since T is contin-
uous and linear, the multifunction %T deï¬ned by %T(x) := {T(x)}, x âˆˆE, has
a closed and convex graph. Moreover, the surjectivity of T is equivalent to
o âˆˆint T(E) and so to o âˆˆint range %T. Hence applying Theorem 10.1.2 with
x = o and y = o, we conclude that o âˆˆint T(ËšBE) which is equivalent to T
being open. (Recall that ËšBE denotes the open unit ball of E.)
Proof of Theorem 10.1.2. We may and do assume that x = o, y = o (replace
Î¦ with Ëœx â†’Î¦(x âˆ’Ëœx) âˆ’y if necessary) and that Ï = 1. Set M := cl Î¦( 1
2ËšBE).
Then M is nonempty closed and convex. Let z âˆˆF. Since by assumption
range Î¦ is a neighborhood of zero, we have Î»z âˆˆrange Î¦ for some Î» > 0 and
so Î»z âˆˆÎ¦(xâ€²) for some xâ€² âˆˆE. Furthermore, for each Î± âˆˆ(0, 1) we obtain
Î±Î»z = Î±Î»z + (1 âˆ’Î±)o
âˆˆÎ±Î¦(xâ€²) + (1 âˆ’Î±)Î¦(o) âŠ†Î¦

Î±xâ€² + (1 âˆ’Î±)o

= Î¦(Î±xâ€²);

10.2 Systems of Convex Inequalities
197
here the inclusion âŠ†holds since graph Î¦ is convex. We conclude that Î±Î»z âˆˆ
Î¦( 1
2ËšBE) for suï¬ƒciently small Î± > 0. Since this holds for each z âˆˆF, it
follows that Î¦( 1
2ËšBE), and so M, is absorbing. Thus by Proposition 1.2.1, M
is a neighborhood of zero. Therefore, ÏËšBF âŠ†int M for some Ï > 0. Now let
C := graph(Î¦)âˆ©
 1
2BE Ã—F

. Then C is closed and convex and pE(C) âŠ†1
2BE.
Hence Lemma 10.1.1 implies that int cl pF (C) = int pF (C). Noting this and
pF (C) = Î¦
 1
2BE

, we ï¬nally obtain
ÏËšBF âŠ†int M âŠ†int cl Î¦( 1
2BE) = int pF (C) = int Î¦( 1
2BE) âŠ†int Î¦(ËšBE).
âŠ“âŠ”
10.2 Systems of Convex Inequalities
Let G be a normed vector space and P be a convex cone in G. Recall that we
denote by â‰¤P the preorder generated by P, i.e., for all u, v âˆˆG we set (see
Sect. 1.5)
u â‰¤P v
:â‡â‡’
v âˆˆu + P.
Now let E be another normed vector space, let K be a convex subset of E,
and let S : K â†’G. Generalizing the notion of a convex functional, we say
that the mapping S is P-convex if for all x, y âˆˆK and all Î» âˆˆ(0, 1) we have
S

Î»x + (1 âˆ’Î»)y

â‰¤P Î»S(x) + (1 âˆ’Î»)S(y),
in other words, if we have
Î»S(x) + (1 âˆ’Î»)S(y) âˆˆS

Î»x + (1 âˆ’Î»)y

+ P.
Consider the following assumptions:
(A) E, G, and H are normed vector spaces, K âŠ†E is nonempty and convex.
P âŠ†G is a convex cone with int(P) Ì¸= âˆ…, Q âŠ†H is a closed convex cone.
S : K â†’G is P-convex, T : K â†’H is Q-convex.
Furthermore let
C := {(y, z) âˆˆG Ã— H | âˆƒx âˆˆK : y âˆ’Sx âˆˆint P, z âˆ’Tx âˆˆQ}.
We shall utilize the condition
âˆƒÂ¯y âˆˆG : (Â¯y, o) âˆˆint C.
(10.3)
We establish a theorem of the alternative for convex mappings.
Proposition 10.2.1 If (A) and (10.3) are satisï¬ed, then precisely one of the
following statements is true:
(a) âˆƒx âˆˆK :
Sx âˆˆâˆ’int P, Tx âˆˆâˆ’Q.
(b) âˆƒu âˆˆP â—¦\ {o}
âˆƒv âˆˆQâ—¦
âˆ€x âˆˆK :
âŸ¨u, SxâŸ©+ âŸ¨v, TxâŸ©â‰¤0.

198
10 Multifunctions
Proof. It is obvious that (a) and (b) cannot hold simultaneously. Assuming
now that (a) is not satisï¬ed, we have to show that (b) holds. It is easy to see
that the set C is convex. Moreover, (10.3) implies int C Ì¸= âˆ…, and since (a)
does not hold, we have (o, o) /âˆˆC. Hence (o, o) and C can be separated by a
closed hyperplane, i.e., there exists (u, v) âˆˆGâˆ—Ã— Hâˆ—such that âŸ¨u, vâŸ©Ì¸= o and
âŸ¨u, yâŸ©+ âŸ¨v, zâŸ©â‰¤0
âˆ€(y, z) âˆˆC.
(10.4)
Now let x âˆˆK, p âˆˆint P, q âˆˆQ, Î± > 0, and Î² > 0. It follows that (Sx +
Î±p, Tx + Î²q) âˆˆC and so by (10.4),
âŸ¨u, SxâŸ©+ Î±âŸ¨u, pâŸ©+ âŸ¨v, TxâŸ©+ Î²âŸ¨v, qâŸ©â‰¤0.
(10.5)
Letting Î± â†“0 and Î² â†“0, we obtain âŸ¨u, SxâŸ©+ âŸ¨v, TxâŸ©â‰¤0. Moreover, letting
Î± â†’+âˆand Î² â†’+âˆin (10.5), we get âŸ¨u, pâŸ©â‰¤0 and âŸ¨v, qâŸ©â‰¤0, respectively.
Since this holds for all p âˆˆint P and all q âˆˆQ, it follows that u âˆˆ(int P)â—¦= P â—¦
and v âˆˆQâ—¦. Assume that u = o. Then (10.4) implies âŸ¨v, zâŸ©â‰¤0 for each
(y, z) âˆˆC. By virtue of (10.3), there exists a neighborhood W of zero in F
such that {Â¯y} Ã— W âŠ†C. Hence we obtain âŸ¨v, zâŸ©â‰¤0 for each z âˆˆW and so
v = o. This is a contradiction to (u, v) Ì¸= o.
âŠ“âŠ”
To make Proposition 10.2.1 applicable, we need conditions suï¬ƒcient for (10.3).
A simple condition is available if int Q is nonempty.
Lemma 10.2.2 Let (A) be satisï¬ed. If Tx0 âˆˆâˆ’int Q for some x0 âˆˆK, then
(10.3) holds.
Proof. Choose p0 âˆˆint P and set Â¯y := Sx0+p0. By assumption there exist zero
neighborhoods V in G and W in H such that p0+V âŠ†int P and âˆ’Tx0+W âŠ†
Q. For each y âˆˆV and each z âˆˆW we thus obtain
(Â¯y + y) âˆ’Sx0 = p0 + y âˆˆint P
and
z âˆ’Tx0 âˆˆQ.
We conclude that (Â¯y + V ) Ã— W âŠ†C and so (Â¯y, o) âˆˆint C.
âŠ“âŠ”
Now we drop the assumption that Q has interior points. With a subset A
of K we formulate the following conditions:
âˆƒx0 âˆˆA :
S is continuous at x0 and Tx0 âˆˆâˆ’Q âˆ©int

T(A) + Q

.
(10.3a)
âˆƒx0 âˆˆint A :
S is continuous at x0 and Tx0 âˆˆâˆ’Q âˆ©int

T(E) + Q

.
(10.3b)
Proposition 10.2.3 Let (A) be satisï¬ed. Further let E and H be Banach
spaces and A be a closed convex subset of E such that A âŠ†K.
(a) If T : K â†’H is continuous on A and Q-convex, then (10.3a) implies
(10.3).

10.2 Systems of Convex Inequalities
199
(b) If T is deï¬ned, continuous, and Q-convex on all of E, then (10.3b) implies
(10.3a) and so (10.3).
Proof.
(a) Choose p0 âˆˆint P and a neighborhood V of zero in G such that p0 + V +
V âŠ†int P. Further set Â¯y := Sx0 + p0. Since S is continuous at x0, there
exists a neighborhood U of zero in E such that Sx0 âˆ’Sx âˆˆV for each
x âˆˆK âˆ©(x0 + U). Deï¬ne Î¦ : E â‡’H by
Î¦(x) :=

Tx + Q
if x âˆˆA,
âˆ…
if x âˆˆE \ A.
(10.6)
It is easy to see that graph Î¦ is closed and convex. Hence Theorem 10.1.2
applies to Î¦. Therefore, since Tx0 âˆˆint Î¦(A) = int range Î¦, we obtain
Tx0 âˆˆint

T(ËšB(x, Ï)) + Q

for each x âˆˆE satisfying Tx âˆ’Tx0 âˆˆâˆ’Q and
any Ï > 0. Hence there exists a neighborhood W of zero in H satisfying
Tx0 + W âŠ†T
ËšB(x0, 1)

+ Q.
(10.7)
We show that
(Â¯y + V ) Ã— W âŠ†C.
(10.8)
Thus let y âˆˆV and z âˆˆW be given. By (10.7) there exists x âˆˆËšB(x0, 1)
such that Tx0 + z âˆˆTx + Q and so z âˆ’Tx âˆˆâˆ’Tx0 + Q âŠ†Q + Q = Q.
Moreover, we also have
(Â¯y + y) âˆ’Sx = p0 + (Sx0 âˆ’Sx) + y âˆˆp0 + V + V âŠ†int P.
This shows that (Â¯y + y, z) âˆˆC. Hence (10.8) is veriï¬ed and it follows that
(Â¯y, o) âˆˆint C.
(b) Let U be a neighborhood of zero in E with x0+U âŠ†A. The multifunction
Î¦ deï¬ned by (10.6) again satisï¬es the assumptions of Theorem 10.1.2.
Hence there exists a neighborhood W of zero in H such that Tx0 + W âŠ†
T(x0 + U) + Q. Since x0 + U âŠ†A, we obtain Tx0 âˆˆint

T(A) + Q

.
âŠ“âŠ”
For later use we want to reformulate the special case Q = {o} of Propo-
sition 10.2.1, incorporating Proposition 10.2.3(a) with A := K. We therefore
consider the following assumptions:
(Ë†A) E, G, and H are normed vector spaces, with E and H complete.
K âŠ†E is nonempty, convex, and closed, P âŠ†G is a convex cone with
int(P) Ì¸= âˆ….
S : K â†’G is P-convex and continuous, T : E â†’H is linear and
continuous.

200
10 Multifunctions
Proposition 10.2.4 Let (Ë†A) be satisï¬ed and assume that T(R+K) = H.
Then precisely one of the following statements is true:
(a) âˆƒx âˆˆK :
Sx âˆˆâˆ’int P, Tx = o.
(b) âˆƒu âˆˆP â—¦\ {o}
âˆƒv âˆˆHâˆ—
âˆ€x âˆˆK :
âŸ¨u, SxâŸ©+ âŸ¨v, TxâŸ©â‰¤0.
Notice that in the case considered in Proposition 10.2.4, the hypothesis
T(R+K) = H implies (and in fact is equivalent to) the second condition of
(10.3a).
10.3 Metric Regularity and Linear Openness
Convention. Throughout this section, let E and F denote Banach spaces.
In order to motivate the following, we consider a generalized equation of
the form
h(x) âˆˆQ,
x âˆˆE,
(10.9)
where the mapping h : E â†’F and the nonempty subset Q of F are given.
We seek x âˆˆE that satisï¬es (10.9). It turns out that much information on
the solvability and the solutions of (10.9) can be obtained by studying the
perturbed generalized equation
h(x) âˆˆQ + y,
x âˆˆE
(10.10)
that depends on the parameter y âˆˆF. This leads us to considering the mul-
tifunction Î¦h : E â‡’F deï¬ned by
Î¦h(x) := h(x) âˆ’Q,
x âˆˆE.
(10.11)
Notice that (10.10) is equivalent to y âˆˆÎ¦h(x). In other words, for a given
y âˆˆF the solution set of (10.10) is Î¦âˆ’1
h (y).
The idea of stability is the following. Given (x, y) âˆˆE Ã— F, the distance
d

x, Î¦âˆ’1
h (y)

should be small whenever the distance d

y, Î¦h(x)

is small. For
an arbitrary multifunction Î¦, not necessarily of the form (10.11), the following
deï¬nition quantiï¬es this idea.
Deï¬nition 10.3.1 The multifunction Î¦ : E â‡’F is said to be metrically
regular around (Â¯x, Â¯y) âˆˆgraph(Î¦) if there exist a neighborhood W of (Â¯x, Â¯y)
and a constant Îº > 0 such that
d(x, Î¦âˆ’1(y)) â‰¤Îº d(y, Î¦(x))
âˆ€(x, y) âˆˆW.
(10.12)
The constant Îº is called constant of metric regularity.
Parallel to metric regularity we consider the following concept.

10.3 Metric Regularity and Linear Openness
201
Deï¬nition 10.3.2 The multifunction Î¦ : E â‡’F is said to be open at a
linear rate around (Â¯x, Â¯y) âˆˆgraph(Î¦) if there exist a neighborhood W of (Â¯x, Â¯y)
and constants Ï > 0 and Ï„0 > 0 such that
y + ÏÏ„ BF âŠ†Î¦(x + Ï„ BE)
âˆ€(x, y) âˆˆgraph(Î¦) âˆ©W
âˆ€Ï„ âˆˆ[0, Ï„0].
(10.13)
The constant Ï is called linear rate of openness.
To elucidate this concept we consider a mapping T : E â†’F. Observe that
T is an open mapping if and only if for any x âˆˆE and any Ï„ > 0 there exists
Ïƒ(x, Ï„) > 0 such that
T(x) + Ïƒ(x, Ï„)BF âŠ†T(x + Ï„BE).
In contrast to this, T is open at a linear rate around (Â¯x, T(Â¯x)) if for any
(x, T(x)) âˆˆW and any Ï„ âˆˆ[0, Ï„0], we have
T(x) + ÏÏ„BF âŠ†T(x + Ï„BE).
The latter means that in a neighborhood of (Â¯x, T(Â¯x)) and for Ï„ > 0 suï¬ƒciently
small, Ïƒ(x, Ï„) can be chosen to be of the form ÏÏ„, i.e., independent of x and
linear in Ï„. Instead of â€œopenness at a linear rateâ€ we shall sometimes brieï¬‚y
speak of â€œlinear openness.â€
Our strategy is as follows. We show that metric regularity and linear open-
ness are equivalent (Theorem 10.3.3). If Î¦ is convex, linear openness can be
characterized, using the generalized open mapping theorem, by the condition
Â¯y âˆˆint range Î¦,
(10.14)
see Theorem 10.3.5. We then proceed to show that metric regularity is stable
under Lipschitz continuous perturbations (Theorem 10.3.6). The latter result
will be applied below to characterize tangential approximations of sets of the
form hâˆ’1(Q), which in turn will be crucial for deriving multiplier rules.
Theorem 10.3.3 If Î¦ : E â‡’F is a multifunction and (Â¯x, Â¯y) âˆˆgraph(Î¦),
then the following assertions are equivalent:
(a) Î¦ is metrically regular around (Â¯x, Â¯y) with constant Îº > 0.
(b) Î¦ is open around (Â¯x, Â¯y) at the linear rate Ï = Îºâˆ’1.
Proof. First observe that Î¦ is metrically regular around (Â¯x, Â¯y) with constant
Îº if and only if the multifunction Î¨ : E â‡’F deï¬ned by Î¨(x) := Î¦(x + Â¯x) âˆ’Â¯y
is metrically regular around (o, o) with the same constant Îº. An analogous
remark applies to linear openness. Therefore we may and do assume that
(Â¯x, Â¯y) = (o, o).

202
10 Multifunctions
(a) =â‡’(b): Let (x, y) âˆˆgraph Î¦ be suï¬ƒciently close to (o, o) and let Ï„ > 0 be
suï¬ƒciently small. Then for each yâ€² âˆˆF satisfying âˆ¥yâ€² âˆ’yâˆ¥< Îºâˆ’1Ï„ we obtain
by (a) that
d(x, Î¦âˆ’1(yâ€²)) â‰¤Îº d(yâ€², Î¦(x)) â‰¤Îºâˆ¥yâ€² âˆ’yâˆ¥< Ï„.
Hence there exists xâ€² âˆˆÎ¦âˆ’1(yâ€²) such that âˆ¥x âˆ’xâ€²âˆ¥< Ï„. This implies yâ€² âˆˆ
Î¦(xâ€²) âŠ†Î¦(x + Ï„ BE). Since yâ€² âˆˆy + Îºâˆ’1Ï„ BF was arbitrary, we see that (b)
holds.
(b) =â‡’(a): We may assume that W, Ï, and Ï„0 in Deï¬nition 10.3.2 are such
that
W = Î´E BE Ã— Î´F BF ,
Ï„0Ï â‰¤1
2Î´F ,
(10.15)
where Î´E and Î´F are positive constants. Further let ÏµE and ÏµF be positive
constants satisfying
ÏµE â‰¤Î´E,
ÏÏµE + ÏµF â‰¤Ï„0Ï.
(10.16)
We show now that (a) holds with Îº = Ïâˆ’1. Let x âˆˆÏµEBE and y âˆˆÏµF BF be
given. Applying (10.13) with (o, o) instead of (x, y) and with Ï„ := Ïâˆ’1âˆ¥yâˆ¥, we
conclude that there exists xâ€² âˆˆÎ¦âˆ’1(y) such that âˆ¥xâ€²âˆ¥â‰¤Ïâˆ’1âˆ¥yâˆ¥. It follows
that
d(x, Î¦âˆ’1(y)) â‰¤âˆ¥x âˆ’xâ€²âˆ¥â‰¤âˆ¥xâˆ¥+ Ïâˆ’1âˆ¥yâˆ¥â‰¤ÏµE + Ïâˆ’1ÏµF .
Hence, if d(y, Î¦(x)) â‰¥Ï(ÏµE +Ïâˆ’1ÏµF ) = ÏÏµE +ÏµF , then the assertion is veriï¬ed.
Assume now that d(y, Î¦(x)) < Ï(ÏµE +Ïâˆ’1ÏµF ). Then for each suï¬ƒciently small
Î± > 0 there exists yÎ± âˆˆÎ¦(x) satisfying
âˆ¥y âˆ’yÎ±âˆ¥â‰¤d(y, Î¦(x)) + Î± < ÏÏµE + ÏµF
â‰¤
(10.16)
Ï„0Ï.
(10.17)
It follows that
âˆ¥yÎ±âˆ¥â‰¤âˆ¥yÎ± âˆ’yâˆ¥+ âˆ¥yâˆ¥< Ï„0Ï + ÏµF
â‰¤
(10.16)
Ï„0Ï + Ï„0Ï
â‰¤
(10.15)
Î´F
(10.18)
and so (x, yÎ±) âˆˆgraph(Î¦) âˆ©W. In view of (b) there exists xâ€² âˆˆÎ¦âˆ’1(y) such
that âˆ¥x âˆ’xâ€²âˆ¥â‰¤Ïâˆ’1âˆ¥y âˆ’yÎ±âˆ¥. We thus obtain
d(x, Î¦âˆ’1(y)) â‰¤âˆ¥x âˆ’xâ€²âˆ¥â‰¤Ïâˆ’1âˆ¥y âˆ’yÎ±âˆ¥
â‰¤
(10.17)
Ïâˆ’1 d(y, Î¦(x)) + Ïâˆ’1Î±.
Letting Î± â†“0 we see that (a) holds with Îº = Ïâˆ’1.
âŠ“âŠ”
Under additional assumptions on the multifunction we obtain reï¬ned
results.
Convex Multifunctions
Proposition 10.3.4 If the multifunction Î¦ : E â‡’F is convex, then for each
(Â¯x, Â¯y) âˆˆgraph Î¦ the following assertions are equivalent:

10.3 Metric Regularity and Linear Openness
203
(a) Î¦ is open at a linear rate around (Â¯x, Â¯y).
(b) There exist constants Âµ > 0 and Î½ > 0 such that
Â¯y + Î½ BF âŠ†Î¦(Â¯x + Âµ BE).
(10.19)
More precisely, if (b) holds, then (10.13) holds with the following data:
W = Âµ BE Ã— 1
2Î½ BF ,
Ï = Î½
4Âµ,
Ï„0 = 2Âµ.
(10.20)
Proof.
(a) =â‡’(b): Set Âµ = Ï„0 and Î½ = ÏÏ„0.
(b) =â‡’(a): We may assume that Â¯x = o and Â¯y = o. Deï¬ne W as in (10.20).
Now let (x, y) âˆˆgraph(Î¦) âˆ©W. For each ËœÏ„ âˆˆ[0, 1] we obtain
y + 1
2Î½ËœÏ„ BF = (1 âˆ’ËœÏ„)y + ËœÏ„(y + 1
2Î½ BF )
âŠ†(1 âˆ’ËœÏ„)y + ËœÏ„Î½ BF
âŠ†(1 âˆ’ËœÏ„)Î¦(x) + ËœÏ„Î¦(Âµ BE)
(by (10.19))
âŠ†Î¦

(1 âˆ’ËœÏ„)x + ÂµËœÏ„ BE

(since Î¦ is convex)
âŠ†Î¦(x + 2ÂµËœÏ„ BE).
Hence setting Ï„ := 2ÂµËœÏ„ we see that with Ï and Ï„0 as in (10.20), condi-
tion (10.13) is satisï¬ed.
âŠ“âŠ”
Now we can establish an important result in the theory of generalized
equations.
Theorem 10.3.5 (Stability Theorem) If Î¦ : E â‡’F is a closed convex
multifunction, then for each (Â¯x, Â¯y) âˆˆgraph Î¦ the following assertions are
equivalent:
(a) Î¦ is metrically regular around (Â¯x, Â¯y).
(b) Î¦ is open at a linear rate around (Â¯x, Â¯y).
(c) There exist constants Âµ > 0 and Î½ > 0 such that Â¯y + Î½ BF âŠ†Î¦(Â¯x + Âµ BE).
(d) Â¯y âˆˆint range Î¦.
In particular, assume that (c) holds and that (x, y) âˆˆE Ã— F satisï¬es
âˆ¥x âˆ’Â¯xâˆ¥< Âµ
2 ,
âˆ¥y âˆ’Â¯yâˆ¥< Î½
8.
(10.21)
Then one has
d(x, Î¦âˆ’1(y)) â‰¤4ÂµÎ½âˆ’1 d(y, Î¦(x)).
(10.22)
Proof. Concerning (a) â‡â‡’(b) and (b) â‡â‡’(c), see Theorem 10.3.3 and
Proposition 10.3.4, respectively.
(c) =â‡’(d): This is obvious.
(d) =â‡’(c): This follows from Theorem 10.1.2.

204
10 Multifunctions
Now assume that (c) and (10.21) hold. By Proposition 10.3.4, the multifunc-
tion Î¦ is open at a linear rate, the data according to (10.13) being
W = Î´E BE Ã— Î´F BF ,
Î´E := Âµ,
Î´F := 1
2Î½,
Ï = Î½
4Âµ,
Ï„0 = 2Âµ.
Passing from Ï„0 = 2Âµ to Ï„0 = Âµ, we obtain Ï„0Ï = Î½/4 = Î´F /2 and so (10.15)
holds. Moreover, setting ÏµE := Âµ/2 and ÏµF := Î½/8, we see that (10.16) is
also satisï¬ed. The proof of Theorem 10.3.3 therefore shows that we have
d(x, Î¦âˆ’1(y)) â‰¤Îº d(y, Î¦(x)), where Îº = Ïâˆ’1 = 4ÂµÎ½âˆ’1.
âŠ“âŠ”
Multifunctions of the Form x â†’h(x) âˆ’Q
Recall that given a mapping h : E â†’F and a nonempty subset Q of F, we de-
note by Î¦h : E â‡’F the multifunction deï¬ned by Î¦h(x) := h(x)âˆ’Q,
x âˆˆE.
For multifunctions of this type, we now show that metric regularity is stable
under small locally Lipschitz continuous perturbations. More precisely, we
pass from Î¦h to Î¦*h, where the Lipschitz constant of hâˆ’*h is suï¬ƒciently small.
Theorem 10.3.6 (Perturbation Theorem) Assume that
h,*h : E â†’F are continuous, Q âŠ†F is closed and convex,
Î¦h is metrically regular around (Â¯x, Â¯y) âˆˆgraph Î¦h with constant Îº > 0,
h âˆ’*h is locally L-continuous around Â¯x with Lipschitz constant Î» < Îºâˆ’1.
Then the multifunction Î¦*h is metrically regular around (Â¯x, Â¯y âˆ’h(Â¯x) + *h(Â¯x))
with constant Îº(Î») := Îº(1 âˆ’ÎºÎ»)âˆ’1.
Proof.
(I) Deï¬ne g(x) := h(x) âˆ’*h(x) for any x âˆˆE. By assumption on Î¦h and g
there exist positive constants Î´E and Î´F such that
d(x, Î¦âˆ’1
h (y)) â‰¤Îº d(y, Î¦h(x))
whenever x âˆˆB(Â¯x, Î´E), y âˆˆB(Â¯y, Î´F ),
(10.23)
âˆ¥g(x) âˆ’g(xâ€²)âˆ¥â‰¤Î»âˆ¥x âˆ’xâ€²âˆ¥
whenever x, xâ€² âˆˆB(Â¯x, Î´E).
(10.24)
We shall show that there exist positive constants ÏµE and ÏµF such that
d(x, Î¦âˆ’1
*h (y)) â‰¤Îº(Î») d(y, Î¦*h(x))
(10.25)
whenever
âˆ¥x âˆ’Â¯xâˆ¥< ÏµE,
âˆ¥y âˆ’(Â¯y âˆ’g(Â¯x))âˆ¥< ÏµF .
(10.26)
(II) Without loss of generality we may assume that g(Â¯x) = o. Choose Î², Ïµ > 0
such that
ÎºÎ» < Î² < 1,
(1 + Ïµ)ÎºÎ» < Î²
(10.27)

10.3 Metric Regularity and Linear Openness
205
and ÏµE, ÏµF > 0 such that
ÏµE < Î´E,
ÏµF + Î»ÏµE < Î´F .
(10.28)
Now let (x, y) âˆˆE Ã— F satisfy (10.26). We construct recursively a seq-
uence (xk) in E with the following properties:
x1 := x,
xk+1 âˆˆÎ¦âˆ’1
h (y + g(xk)),
k = 1, 2, . . . ,
(10.29)
âˆ¥xk+1 âˆ’xkâˆ¥â‰¤(1 + Ïµ) d

xk, Î¦âˆ’1
h (y + g(xk))

,
k = 1, 2, . . .
(10.30)
We have
âˆ¥xâˆ’Â¯xâˆ¥< Î´E,
âˆ¥y+g(x)âˆ’Â¯yâˆ¥â‰¤âˆ¥yâˆ’Â¯yâˆ¥+âˆ¥g(x)âˆ¥
<
(10.24),(10.28) Î´F (10.31)
and so (10.23) gives
d

x, Î¦âˆ’1
h (y + g(x))

â‰¤Îº d

h(x) âˆ’y âˆ’g(x), P

= Îº d

y, Î¦*h(x)

.
Hence there exists x2 âˆˆÎ¦âˆ’1
h (y + g(x)) satisfying
âˆ¥x2 âˆ’x1âˆ¥â‰¤(1 + Ïµ)Îº d(y, Î¦*h(x))
<
(10.27) Î»âˆ’1Î² d(y, Î¦*h(x)).
(10.32)
For Ï > 0 let Î±(Ï) denote the modulus of continuity of h at Â¯x, i.e.,
Î±(Ï) := sup{âˆ¥h(x) âˆ’h(Â¯x)âˆ¥| x âˆˆB(Â¯x, Ï)}.
It follows that
d(y, Î¦*h(x)) = d(h(x) âˆ’y âˆ’g(x), Q) â‰¤âˆ¥

h(x) âˆ’y âˆ’g(x)

âˆ’

h(Â¯x) âˆ’Â¯y

âˆ¥
â‰¤âˆ¥h(x) âˆ’h(Â¯x)âˆ¥+ âˆ¥y âˆ’Â¯yâˆ¥+ âˆ¥g(x)âˆ¥â‰¤Î±(ÏµE) + ÏµF + Î»ÏµE.
(10.33)
Concerning the ï¬rst inequality, notice that (Â¯x, Â¯y) âˆˆgraph(Î¦h) and so
h(Â¯x) âˆ’Â¯y âˆˆQ. In view of (10.33), the estimate (10.32) gives
âˆ¥x2 âˆ’x1âˆ¥< Î»âˆ’1Î²

Î±(ÏµE) + Î»ÏµE + ÏµF

.
(10.34)
Hence, if ÏµE and ÏµF (beside satisfying (10.28)) are small enough, then
âˆ¥x2 âˆ’Â¯xâˆ¥â‰¤âˆ¥x2 âˆ’x1âˆ¥+ âˆ¥x âˆ’Â¯xâˆ¥< Î´E,
âˆ¥

y + g(x2)

âˆ’Â¯yâˆ¥â‰¤âˆ¥

y + g(x)

âˆ’Â¯yâˆ¥+ âˆ¥g(x2) âˆ’g(x)âˆ¥< Î´F ;
(10.35)
here the last inequality follows from (10.24) and (10.31).

206
10 Multifunctions
(III) We now show by induction that ÏµE and ÏµF can be made so small that
for each k âˆˆN we have
âˆ¥xk âˆ’Â¯xâˆ¥< Î´E,
âˆ¥

y + g(xk)

âˆ’Â¯yâˆ¥< Î´F .
(10.36)
By (10.26) and (10.35) we know that (10.36) holds for k < k0 if k0 = 3.
Suppose now that (10.36) holds for all k < k0, where k0 â‰¥3. We have
to show that it also holds for k0. For each k âˆˆ{2, . . . , k0 âˆ’1} we have
âˆ¥xk+1 âˆ’xkâˆ¥
<
(10.30) Îºâˆ’1Î»âˆ’1Î² d

xk, Î¦âˆ’1
h (y + g(xk)

.
(10.37)
We further obtain
d

xk, Î¦âˆ’1
h (y + g(xk))

â‰¤Îº d

y + g(xk), Î¦h(xk)

â‰¤Îº âˆ¥

y + g(xk)

âˆ’

y + g(xkâˆ’1)

âˆ¥â‰¤ÎºÎ»âˆ¥xk âˆ’xkâˆ’1âˆ¥;
(10.38)
here the second inequality holds since xk âˆˆÎ¦âˆ’1
h (y+g(xkâˆ’1)) (see (10.29))
and so y+g(xkâˆ’1) âˆˆÎ¦h(xk). Inserting (10.38) into (10.37) yields âˆ¥xk+1âˆ’
xkâˆ¥< Î²âˆ¥xk âˆ’xkâˆ’1âˆ¥and so
âˆ¥xk+1 âˆ’xkâˆ¥< Î²kâˆ’1âˆ¥x2 âˆ’x1âˆ¥.
(10.39)
From this we get
âˆ¥xk0 âˆ’x1âˆ¥â‰¤âˆ¥xk0 âˆ’xk0âˆ’1âˆ¥+ Â· Â· Â· + âˆ¥x2 âˆ’x1âˆ¥â‰¤
1
1 âˆ’Î² âˆ¥x2 âˆ’x1âˆ¥
â‰¤
(10.32)
Î²
Î»(1 âˆ’Î²) d(y, Î¦*h(x)),
(10.40)
which implies
âˆ¥xk0 âˆ’Â¯xâˆ¥â‰¤âˆ¥xk0 âˆ’x1âˆ¥+ âˆ¥x1 âˆ’Â¯xâˆ¥<
Î²
Î»(1 âˆ’Î²) d(y, Î¦*h(x)) + ÏµE .
(10.41)
Moreover, we have
âˆ¥y + g(xk0) âˆ’Â¯yâˆ¥â‰¤âˆ¥y âˆ’Â¯yâˆ¥+ âˆ¥g(xk0) âˆ’g(Â¯x)âˆ¥
â‰¤âˆ¥y âˆ’Â¯yâˆ¥+ Î»âˆ¥xk0 âˆ’Â¯xâˆ¥â‰¤ÏµF + Î»ÏµE + Î²(1 âˆ’Î²)âˆ’1 d(y, Î¦*h(x)). (10.42)
The inequalities (10.41) and (10.42) together with (10.33) show that
there exists Î´ > 0, independent of k, such that (cf. (10.36))
xk âˆˆËšB(Â¯x, Î´),
y + g(xk) âˆˆËšB(Â¯y, Î´)
for k = 1, 2, . . .
(10.43)

10.3 Metric Regularity and Linear Openness
207
(IV) From (10.39) and 0 < Î² < 1 we conclude that (xk) is a Cauchy sequence
and so, since E is complete, is convergent to some xâ€² âˆˆB(Â¯x, Î´). Since g
is continuous, we have g(xk) â†’g(xâ€²) as k â†’âˆ. This, (10.29), and the
closedness of graph Î¦h imply (xâ€², y + g(xâ€²)) âˆˆgraph Î¦h. Since Î¦âˆ’1
h (y +
g(xâ€²)) = Î¦âˆ’1
*h (y), it follows that xâ€² âˆˆÎ¦âˆ’1
*h (y). We thus obtain
d

x, Î¦âˆ’1
*h (y)

â‰¤âˆ¥x1 âˆ’xâ€²âˆ¥
â‰¤
(10.40)
Î»âˆ’1(1 âˆ’Î²)âˆ’1Î² d(y, Î¦*h(x)).
Letting Î² â†“ÎºÎ» (notice (10.27)), we ï¬nally see that (10.25) holds for all
x âˆˆËšB(Â¯x, Î´) and all y âˆˆËšB(Â¯y âˆ’g(Â¯x), Î´).
âŠ“âŠ”
Now assume that, in addition,
h : E â†’F is continuously diï¬€erentiable at Â¯x âˆˆhâˆ’1(Q).
Then h is F-diï¬€erentiable on a nonempty open subset U of E containing Â¯x. Let
Ï > 0 be such that B(Â¯x, Ï) âŠ†U. Moreover, let *h : E â†’F be the linearization
of h at Â¯x, i.e.,
*h(x) := h(Â¯x) + hâ€²(Â¯x)(x âˆ’Â¯x),
x âˆˆE.
Parallel to
Î¦h(x) := h(x) âˆ’Q,
x âˆˆE,
(10.44)
we consider the linearized multifunction
Î¦*h(x) := *h(x) âˆ’Q = h(Â¯x) + hâ€²(Â¯x)(x âˆ’Â¯x) âˆ’Q,
x âˆˆE.
(10.45)
Since the function *h is continuous and aï¬ƒne, the linearized multifunction Î¦*h
is closed and convex. Hence by Theorem 10.3.5, Î¦*h is metrically regular at
(Â¯x, o) if and only if o âˆˆint range Î¦*h which is equivalent to
o âˆˆint

h(Â¯x) + hâ€²(Â¯x)(E) âˆ’Q

.
(10.46)
By the mean value theorem (Proposition 3.3.4), we have
âˆ¥

h(x) âˆ’*h(x)

âˆ’

h(xâ€²) âˆ’*h(xâ€²)

âˆ¥= âˆ¥

h(x) âˆ’h(xâ€²)

âˆ’hâ€²(Â¯x)(x âˆ’xâ€²)âˆ¥
â‰¤Î»âˆ¥x âˆ’Â¯xâˆ¥
for all x, xâ€² âˆˆB(Â¯x, Ï),
where
Î» := max{âˆ¥hâ€²(x) âˆ’hâ€²(Â¯x)âˆ¥| x âˆˆB(Â¯x, Ï)}.
Hence the function h âˆ’*h is locally Lipschitz continuous at Â¯x, where the
Lipschitz constant can be made suï¬ƒciently small by making Ï small enough.
Therefore Theorem 10.3.6 shows that Î¦h is also metrically regular. Conversely,
if Î¦h is metrically regular at (Â¯x, o), then by Theorem 10.3.6 the perturbed mul-
tifunction Î¦*h is also metrically regular at (Â¯x, o), which in turn is equivalent
to (10.46) by Theorem 10.3.5. Thus we have proved the following.

208
10 Multifunctions
Proposition 10.3.7 Let Q âŠ†F be closed and convex, assume that h : E â†’F
is continuous on E and continuously diï¬€erentiable at Â¯x âˆˆhâˆ’1(Q). Then the
following assertions are equivalent:
(a) Î¦h (see (10.44)) is metrically regular at (Â¯x, o).
(b) Î¦*h (see (10.45)) is metrically regular at (Â¯x, o).
(c) The condition (10.46) holds.
We want to establish conditions that are at least suï¬ƒcient for (10.46) or,
in view of later applications, for a slightly more general condition. Recall that
cr M denotes the core of the set M âŠ†F.
Let A be a nonempty subset of E. We consider the Robinson condition
(see [176])
o âˆˆint

h(Â¯x) + hâ€²(Â¯x)(A âˆ’Â¯x) âˆ’Q

,
(10.47)
the core condition
o âˆˆcr

h(Â¯x) + hâ€²(Â¯x)(A âˆ’Â¯x) âˆ’Q

,
(10.48)
and the Zoweâ€“Kurcyusz condition (see [229])
hâ€²(Â¯x)

R+(A âˆ’Â¯x)

âˆ’R+

Q âˆ’h(Â¯x)

= F.
(10.49)
Proposition 10.3.8 Assume that h, Q, and Â¯x are as in Proposition 10.3.7.
Assume further that A is a nonempty closed convex subset of E. Then
the Robinson condition (10.47), the core condition (10.48), and the Zoweâ€“
Kurcyusz condition (10.49) are mutually equivalent.
Proof. The implication (10.47) =â‡’(10.48) is obvious and the implica-
tion (10.48) =â‡’(10.49) is immediately veriï¬ed.
(10.49) =â‡’(10.47): Deï¬ne Î¨ : E Ã— R Ã— R â‡’F by
Î¨(x, Ïƒ, Ï„) :=

hâ€²(Â¯x)

Ïƒ(x âˆ’Â¯x)

âˆ’Ï„(Q âˆ’h(Â¯x))
if Ïƒ â‰¥0, Ï„ â‰¥0, x âˆˆA,
âˆ…
otherwise.
Then the multifunction Î¨ is closed and convex and
range Î¨ = hâ€²(Â¯x)

R+(A âˆ’Â¯x)

âˆ’R+(Q âˆ’h(Â¯x)).
The condition (10.49), therefore, implies o âˆˆint range Î¨. By the generalized
open mapping theorem (Theorem 10.1.2) we see that o âˆˆint Î¨

(R+(A âˆ’Â¯x) âˆ©
BE) Ã— [0, 1] Ã— [0, 1]

and so (10.47) is satisï¬ed.
âŠ“âŠ”

10.4 Openness Bounds of Multifunctions
209
10.4 Openness Bounds of Multifunctions
The following concept will turn out to be a suitable tool for the further study
of multifunctions.
Deï¬nition 10.4.1 Let the multifunction Î¦ : E â‡’F be open at a linear rate
around (Â¯x, Â¯y) âˆˆgraph Î¦. Then
ope(Î¦)(Â¯x, Â¯y) := supremum of all linear rates of openness of Î¦ around (Â¯x, Â¯y)
is called openness bound of Î¦ around (Â¯x, Â¯y).
We shall consider two classes of multifunctions for which the openness
bound can easily be computed.
Processes
A multifunction Î¦ : E â‡’F is called (convex) process if graph(Î¦) is a (convex)
cone. Notice that if Î¦ is a process, so is Î¦âˆ’1. A process is said to be bounded
if it maps bounded sets into bounded sets. If Î¦ is a bounded convex process,
then the (ï¬nite) expression
âˆ¥Î¦âˆ¥:=
sup
xâˆˆBâˆ©Dom Î¦
inf
yâˆˆÎ¦(x)
âˆ¥yâˆ¥
(10.50)
is called norm of Î¦.
Proposition 10.4.2 Let Î¦ : E â‡’F be a bounded convex process. If Î¦ is
open at a linear rate around (o, o), then 0 < âˆ¥Î¦âˆ’1âˆ¥< +âˆand
ope(Î¦)(o, o) =
1
âˆ¥Î¦âˆ’1âˆ¥.
(10.51)
Proof.
(I) We verify âˆ¥Î¦âˆ’1âˆ¥< +âˆ. Let Ï > 0 and Ï„0 be openness parameters of
Î¦ around (o, o). Then it follows that ÏÏ„BF âŠ†Î¦(Ï„BE) for all Ï„ âˆˆ[0, Ï„0].
Since Î¦ is a process, we have Î¦(Ï„BE) = Ï„Î¦(BE). Therefore
ÏBF âŠ†Î¦(BE).
(10.52)
We conclude that âˆ¥Î¦âˆ’1âˆ¥â‰¤1/Ï.
(II) Next we show that âˆ¥Î¦âˆ’1âˆ¥> 0. Assume âˆ¥Î¦âˆ’1âˆ¥= 0. Choose some y0 âˆˆ
BF âˆ©Dom(Î¦âˆ’1) such that y0 Ì¸= o (which exists by (10.52)). For each
n âˆˆN there exists xn âˆˆÎ¦âˆ’1(y0) such that âˆ¥xnâˆ¥< 1/n. It follows
that nxn âˆˆBE and ny0 âˆˆÎ¦(nxn). Hence Î¦(BE) is not bounded, which
contradicts the hypothesis on Î¦.
(III) Now we verify (10.51). As shown in step (I), if Ï is a linear rate of
openness, then (10.52) holds. Conversely, if (10.52) holds with some
Ï > 0, then
y + ÏÏ„BF âŠ†Î¦(x) + Î¦(Ï„BE) âŠ†Î¦(x + Ï„BE)
âˆ€(x, y) âˆˆgraph Î¦ âˆ€Ï„ â‰¥0.

210
10 Multifunctions
Hence we obtain
ope(Î¦)(o, o) = sup{Ï > 0 | ÏBF âŠ†Î¦(BE)}.
(10.53)
It is evident that (10.52) is equivalent to infxâˆˆÎ¦âˆ’1(y) âˆ¥xâˆ¥â‰¤1
Ï for any y âˆˆBF .
From this and (10.53) we deduce (10.51).
âŠ“âŠ”
Single-Valued Multifunctions
Recall that a functional f : E â†’R is identiï¬ed with the single-valued mul-
tifunction Ëœf : E â‡’R deï¬ned by Ëœf(x) := {f(x)}, x âˆˆE. In the following we
shall say that f is open at a linear rate around (Â¯x, f(Â¯x)) if Ëœf has this property,
and we write ope(f)(Â¯x) instead of ope( Ëœf)(Â¯x, Ëœf(Â¯x)).
Proposition 10.4.3 Let f : E â†’R be locally L-continuous around Â¯x âˆˆE
and assume that o /âˆˆâˆ‚â—¦f(Â¯x). Then f is open at a linear rate around (Â¯x, f(Â¯x))
and
ope(f)(Â¯x) = âˆ’inf
âˆ¥yâˆ¥=1 f â—¦(Â¯x, y).
(10.54)
Proof.
(I) First notice that p := âˆ’infâˆ¥yâˆ¥=1 f â—¦(Â¯x, y) is a positive real number.
In fact, since o /âˆˆâˆ‚â—¦f(Â¯x), we have f â—¦(Â¯x, y0) < 0 for some y0 âˆˆE, where
we may assume that âˆ¥y0âˆ¥= 1. Hence p > 0. Since f â—¦(Â¯x, Â·) is globally
L-continuous (Theorem 7.3.2), we have in particular f â—¦(Â¯x, y) â‰¥âˆ’Î»âˆ¥yâˆ¥
for each y âˆˆE, where Î» > 0 is a local Lipschitz constant of f at Â¯x.
Therefore p â‰¤Î» < +âˆ.
(II) We show that ope(f)(Â¯x) â‰¥p. Let Ïµ âˆˆ(0, p/4] be given. Then there
exists yÏµ âˆˆE such that âˆ¥yÏµâˆ¥= 1 and f â—¦(Â¯x, yÏµ) â‰¤âˆ’p + Ïµ
2. Moreover,
by the deï¬nition of f â—¦(Â¯x, yÏµ), there exists Ï„1 âˆˆ(0, 1] such that for all
x âˆˆÂ¯x + Ï„1BE and all Ï„ âˆˆ(0, Ï„1],
f(x + Ï„yÏµ) âˆ’f(x)
Ï„
â‰¤âˆ’p + Ïµ,
and so f(x + Ï„yÏµ) â‰¤f(x) âˆ’Ï„(p âˆ’Ïµ) < f(x). Applying the intermediate
value theorem to the restriction of f to x + Ï„BE, we obtain
[f(x) âˆ’Ï„(p âˆ’Ïµ), f(x)] âŠ†f(x + Ï„BE).
(10.55)
Recall that (âˆ’f)â—¦(Â¯x, âˆ’yÏµ) = f â—¦(Â¯x, yÏµ) (Theorem 7.3.2). Therefore, a sim-
ilar argument with f and yÏµ replaced by âˆ’f and âˆ’yÏµ, respectively, shows
that there exists Ï„2 âˆˆ(0, 1] such that for all x âˆˆÂ¯x + Ï„2BE and all
Ï„ âˆˆ(0, Ï„2],
[f(x), f(x) + Ï„(p âˆ’Ïµ)] âŠ†f(x + Ï„BE).
(10.56)
Set Ï„0 := min{Ï„1, Ï„2}. Combining (10.55) and (10.56), we obtain

10.5 Weak Metric Regularity and Pseudo-Lipschitz Continuity
211
f(x) + (p âˆ’Ïµ) Â· Ï„BE âŠ†f(x + Ï„BE)
âˆ€x âˆˆÂ¯x + Ï„0BE
âˆ€Ï„ âˆˆ(0, Ï„0],
which shows that pâˆ’Ïµ is an openness rate of f around (Â¯x, f(Â¯x)). Letting
Ïµ â†“0, we conclude that ope(f)(Â¯x) â‰¥p. In particular, we see that f is
open with a linear rate around (Â¯x, f(Â¯x)).
(III) Now we show that ope(f)(Â¯x) â‰¤p. This together with step (II) veriï¬es
(10.54). Let Ï > 0 be a linear rate of openness of f around (Â¯x, f(Â¯x)).
Then there exist a neighborhood W of (Â¯x, f(Â¯x)) and Ï„0 > 0 such that
f(x) + ÏÏ„Î· âˆˆf(x + Ï„BE)
âˆ€(x, f(x)) âˆˆW
âˆ€Ï„ âˆˆ[0, Ï„0]
âˆ€Î· âˆˆ[âˆ’1, 1].
In particular, there exists y1 âˆˆBE such that
f(x) âˆ’ÏÏ„ = f(x + Ï„y1)
âˆ€(x, f(x)) âˆˆW
âˆ€Ï„ âˆˆ[0, Ï„0].
It is clear that y1 Ì¸= o. By adjusting Ï„0 if necessary, we may assume that
âˆ¥y1âˆ¥= 1. It follows that âˆ’Ï = f â—¦(Â¯x, y1) â‰¥âˆ’p and so ope(f)(Â¯x) â‰¤p.
âŠ“âŠ”
10.5 Weak Metric Regularity and Pseudo-Lipschitz
Continuity
We introduce and study two concepts that are closely related to metric regu-
larity and linear openness.
Deï¬nition 10.5.1
(a) The multifunction Î¦ : E â‡’F is said to be weakly metrically regular
around (Â¯x, Â¯y) âˆˆgraph Î¦, if there exist a neighborhood U of Â¯x, a neigh-
borhood V of Â¯y, and a constant Îº > 0 such that for all x âˆˆU with
Î¦(x) âˆ©V Ì¸= âˆ…and all y âˆˆV one has
d(x, Î¦âˆ’1(y)) â‰¤Îº d(y, Î¦(x)).
(10.57)
(b) The multifunction Î¨ : F â‡’E is said to be pseudo-Lipschitz (or to have
the Aubin property) around (Â¯y, Â¯x) âˆˆgraph Î¨, if there exist a neighborhood
U of Â¯x, a neighborhood V of Â¯y, and a (Lipschitz) constant Î» > 0 such that
Î¨(y) âˆ©U Ì¸= âˆ…
âˆ€y âˆˆV
and
(10.58)
Î¨(y) âˆ©U âŠ†Î¨(yâ€²) + Î»âˆ¥y âˆ’yâ€²âˆ¥BE
âˆ€y, yâ€² âˆˆV.
(10.59)
It is obvious that a metrically regular multifunction is weakly metrically
regular. A mapping T : F â†’E which is pseudo-Lipschitz around (Â¯y, T(Â¯y)),
where U can be chosen to be E, is locally Lipschitz continuous around Â¯y.
Theorem 10.5.2 If Î¦ : E â‡’F is a closed-valued multifunction and (Â¯x, Â¯y) âˆˆ
graph Î¦, then the following assertions are equivalent:

212
10 Multifunctions
(a) Î¦ is weakly metrically regular around (Â¯x, Â¯y).
(b) Î¦âˆ’1 is pseudo-Lipschitz around (Â¯y, Â¯x).
Proof. (a) =â‡’(b): Let the condition of Deï¬nition 10.5.1(a) be satisï¬ed, where
we may assume that U := Â¯x+Ïµ1BE and V := Â¯y+Ïµ2BF with Ïµ1 > 0 and Ïµ2 > 0.
Since Â¯x âˆˆU and Â¯y âˆˆÎ¦(Â¯x) âˆ©V , we have by (10.57) that
d(Â¯x, Î¦âˆ’1(y)) â‰¤Îº d(y, Î¦(Â¯x)) â‰¤Îºâˆ¥y âˆ’Â¯yâˆ¥
âˆ€y âˆˆV.
(10.60)
Choose a positive number ËœÏµ2 < Ïµ2 so small that ÎºËœÏµ2 â‰¤Ïµ1. Set ËœU := Â¯x + ÎºÏµ2BE
and ËœV := Â¯y + ËœÏµ2BF . If y âˆˆËœV , then y âˆˆV and (10.60) gives d(Â¯x, Î¦âˆ’1(y)) â‰¤
ÎºËœÏµ2 < ÎºÏµ2. Hence there exists x âˆˆÎ¦âˆ’1(y) such that âˆ¥xâˆ’Â¯xâˆ¥< ÎºÏµ2. This shows
that Î¦âˆ’1(y) âˆ©ËœU Ì¸= âˆ…for any y âˆˆËœV . Now let y, yâ€² âˆˆËœV be given. For any
x âˆˆÎ¦âˆ’1(y) âˆ©ËœU it follows from (10.57) that
d(x, Î¦âˆ’1(yâ€²)) â‰¤Îº d(yâ€², Î¦(x)).
If Î» > Îº, we thus ï¬nd some xâ€² âˆˆÎ¦âˆ’1(yâ€²) âˆ©ËœU satisfying
âˆ¥x âˆ’xâ€²âˆ¥â‰¤Î» d(yâ€², Î¦(x)) â‰¤Î»âˆ¥yâ€² âˆ’yâˆ¥.
In this connection notice that if d(yâ€², Î¦(x)) = 0, then yâ€² âˆˆÎ¦(x) (as Î¦(x) is
closed) and so we may take xâ€² := x. We have thus shown that (b) holds.
(b) =â‡’(a): Let Ïµ > 0 be such that U := Â¯x + ÏµBE and V := Â¯y + ÏµBF satisfy
the condition of Deï¬nition 10.5.1(b). Set ËœV := Â¯y + (Ïµ/3)BF . By (10.58) there
exists a neighborhood ËœU of Â¯x such that ËœU âŠ†U and Î¦âˆ’1(y) âˆ©ËœU Ì¸= âˆ…for all
y âˆˆËœV . We also have
d(y, Î¦(x)) = d(y, Î¦(x) âˆ©ËœV )
âˆ€x âˆˆËœU
âˆ€y âˆˆËœV .
(10.61)
To verify this equation, let yâ€² âˆˆÎ¦(x) \ ËœV be given. Then
d(y, yâ€²) â‰¥d(yâ€², Â¯y) âˆ’d(Â¯y, y) > Ïµ âˆ’Ïµ
3 = 2
3Ïµ.
On the other hand, for any z âˆˆÎ¦(x) âˆ©ËœV we obtain
d(y, z) â‰¤d(y, Â¯y + d(Â¯y, z) â‰¤Ïµ
3 + Ïµ
3 = 2
3Ïµ.
Now let x âˆˆËœU be such that Î¦(x) âˆ©ËœV Ì¸= âˆ…and let y âˆˆËœV . By (10.59) we have
d(x, Î¦âˆ’1(y)) â‰¤Î» d(y, Î¦âˆ’1(x) âˆ©U) â‰¤Î»âˆ¥y âˆ’zâˆ¥
âˆ€z âˆˆÎ¦(x) âˆ©ËœV
and so
d(x, Î¦âˆ’1(y)) â‰¤Î» d(y, Î¦(x) âˆ©ËœV )
=
(10.61) Î» d(y, Î¦(x)),
which completes the proof.
âŠ“âŠ”

10.6 Linear Semiopenness and Related Properties
213
10.6 Linear Semiopenness and Related Properties
We modify the concepts introduced in the preceding sections. Assume again
that E and F are Banach spaces, Î¦ : E â‡’F is a multifunction and (Â¯x, Â¯y) âˆˆ
graph Î¦.
Deï¬nition 10.6.1
(a) The multifunction Î¦ is said to be linearly semiopen around (Â¯x, Â¯y) if there
exist numbers Ï > 0 and Ï„0 > 0 such that for all (x, y) âˆˆgraph Î¦ satisfy-
ing x âˆˆÂ¯x + Ï„0BE and y âˆˆÂ¯y + Ï„0BF and all Ï„ âˆˆ[0, Ï„0] one has
y + ÏÏ„âˆ¥x âˆ’Â¯xâˆ¥BF âŠ†Î¦(x + Ï„âˆ¥x âˆ’Â¯xâˆ¥BE).
(10.62)
(b) The multifunction Î¦ is said to be metrically semiregular around (Â¯x, Â¯y) if
there exist numbers Îº > 0 and Ï„1 > 0 such that for all (x, y) âˆˆE Ã— F
satisfying x âˆˆÂ¯x + Ï„1BE, y âˆˆÂ¯y + Ï„1BF , and d(y, Î¦(x)) â‰¤Ï„1âˆ¥x âˆ’Â¯xâˆ¥one
has
d(x, Î¦âˆ’1(y)) â‰¤Îº d(y, Î¦(x)).
(10.63)
(c) The multifunction Î¦ is said to be semi-pseudo-Lipschitz around (Â¯x, Â¯y) if
there exist numbers Î» > 0 and Ï„2 > 0 such that for all (x, y) âˆˆgraph Î¦
satisfying x âˆˆÂ¯x + Ï„2BE and y âˆˆÂ¯y + Ï„2BF there is a neighborhood V (y)
of y such that
Î¦(x) âˆ©V (y) âŠ†Î¦(xâ€²) + Î»âˆ¥x âˆ’xâ€²âˆ¥BF
âˆ€xâ€² âˆˆx + Ï„2âˆ¥y âˆ’Â¯yâˆ¥BE.
(10.64)
The numbers Ï > 0 and Ï„0 > 0 in Deï¬nition 10.6.1(a) will be referred to
as semiopenness parameters. An analogous terminology will be applied for
the numbers associated with metric semiregularity and semi-pseudo-Lipschitz
continuity.
Remark 10.6.2 It is obvious that linear openness implies linear semiopen-
ness. In fact, if Î¦ is open around (Â¯x, Â¯y) with the linear rate Ïâ€² and the parameter
Ï„ â€²
0, then Î¦ is linearly semiopen around (Â¯x, Â¯y) with the semiopenness parameters
Ï = Ïâ€² and Ï„0 = min{Ï„ â€²
0,
!
Ï„ â€²
0}. The norm functional on E, interpreted as a
multifunction from E to R, is not open at a linear rate around (0, 0) (it is not
even an open mapping) but is linearly semiopen around (0, 0). Observe that,
in contrast to openness at a linear rate, linear semiopenness does not impose
a condition on the multifunction at the reference point (Â¯x, Â¯y) âˆˆgraph Î¦.
Theorem 10.6.3 If Î¦ : E â‡’F is a closed-valued multifunction and (Â¯x, Â¯y) âˆˆ
graph Î¦, then the following assertions are mutually equivalent:
(a) Î¦ is linearly semiopen around (Â¯x, Â¯y).
(b) Î¦ is metrically semiregular around (Â¯x, Â¯y).
(c) Î¦âˆ’1 is semi-pseudo-Lipschitz around (Â¯y, Â¯x).

214
10 Multifunctions
Proof. As in the proof of Theorem 10.3.3 we may assume that (Â¯x, Â¯y) = (o, o).
The parameters used in the following refer to the respective deï¬nition.
(a) =â‡’(b): Choose Ï„1 > 0 so small that
Ï„1 < min

Ï„0
1 + ÏÏ„0
, ÏÏ„0

.
Let (x, y) âˆˆÏ„1BE Ã—Ï„1BF be such that d(y, Î¦(x)) â‰¤Ï„1âˆ¥xâˆ¥. We distinguish two
cases:
Case 1. First assume that d(y, Î¦(x)) > 0. Then x Ì¸= o. Deï¬ne Ï„ by
d(y, Î¦(x)) = ÏÏ„âˆ¥xâˆ¥. Then for any Î´ > 0 there exists yâ€² âˆˆÎ¦(x) such that
âˆ¥y âˆ’yâ€²âˆ¥â‰¤Ï(Ï„ + Î´) âˆ¥xâˆ¥and so
âˆ¥yâ€²âˆ¥â‰¤âˆ¥yâˆ¥+ âˆ¥y âˆ’yâ€²âˆ¥â‰¤Ï„1 + Ï(Ï„ + Î´)Ï„1.
Since ÏÏ„ â‰¤Ï„1 the choice of Ï„1 shows that Ï„ < Ï„0. Hence we ï¬nd Î´ = Î´(Ï„) > 0
such that Ï„ + Î´(Ï„) < Ï„0. We thus obtain
x âˆˆÏ„0BE,
yâ€² âˆˆÏ„0BF ,
y âˆˆyâ€² + ÏÏ„0âˆ¥xâˆ¥BF .
Since (a) holds, we conclude from (10.62), with y replaced by yâ€², that there
exists xâ€² âˆˆx + (Ï„ + Î´(Ï„))âˆ¥xâˆ¥BE such that y âˆˆÎ¦(xâ€²). Consequently,
d(x, Î¦âˆ’1(y)) â‰¤âˆ¥x âˆ’xâ€²âˆ¥â‰¤(Ï„ + Î´(Ï„))âˆ¥xâˆ¥â‰¤Ï„ + Î´(Ï„)
ÏÏ„
d(y, Î¦(x)).
Since this holds for all suï¬ƒciently small Î´(Ï„), we conclude that any Îº > Ïâˆ’1
satisï¬es (10.63).
Case 2. Assume now that d(y, Î¦(x)) = 0. Then y âˆˆÎ¦(x) as Î¦(x) is closed.
Therefore we have d(x, Î¦âˆ’1(y) = 0 â‰¤Îº d(y, Î¦(x)) with the same Îº as above.
(b) =â‡’(c): Choose Ï„2 > 0 such that Ï„2 + Ï„ 2
2 < Ï„1/2 and take any Î» > Îº.
Fix any (y, x) âˆˆgraph(Î¦âˆ’1) with x âˆˆÏ„2BE and y âˆˆÏ„2BF . Further let yâ€² âˆˆ
y + Ï„2âˆ¥xâˆ¥BF be given. We are going to show that with some neighborhood
U(x) of x, we have
Î¦âˆ’1(y) âˆ©U(x) âŠ†Î¦âˆ’1(yâ€²) + Î»âˆ¥y âˆ’yâ€²âˆ¥BE.
(10.65)
If x Ì¸= o, deï¬ne U(x) := x + 1
2âˆ¥xâˆ¥BE. Now let xâ€² âˆˆÎ¦âˆ’1(y) âˆ©U(x) be given.
Then we have the estimates
âˆ¥xâ€²âˆ¥â‰¤âˆ¥xâˆ¥+ âˆ¥x âˆ’xâ€²âˆ¥â‰¤Ï„2 + 1
2Ï„2 â‰¤3
4Ï„1 < Ï„1,
âˆ¥yâ€²âˆ¥â‰¤âˆ¥yâˆ¥+ Ï„2âˆ¥xâˆ¥â‰¤(1 + Ï„2)Ï„2 < Ï„1,
d(yâ€², Î¦(xâ€²)) â‰¤âˆ¥yâ€² âˆ’yâˆ¥â‰¤Ï„2âˆ¥xâˆ¥â‰¤2Ï„2âˆ¥xâ€²âˆ¥â‰¤Ï„1âˆ¥xâ€²âˆ¥.

10.6 Linear Semiopenness and Related Properties
215
Since (b) holds, we can apply (10.57) with x replaced by xâ€² to deduce
d(xâ€², Î¦âˆ’1(yâ€²)) â‰¤Îº d(yâ€², Î¦(xâ€²)).
Since Î» > Îº, there exists xâ€²â€² âˆˆÎ¦âˆ’1(yâ€²) satisfying
âˆ¥xâ€² âˆ’xâ€²â€²âˆ¥â‰¤Î» d(yâ€², Î¦(xâ€²)) â‰¤Î» âˆ¥y âˆ’yâ€²âˆ¥.
It follows that xâ€² âˆˆÎ¦âˆ’1(yâ€²)+Î» âˆ¥y âˆ’yâ€²âˆ¥BE. If x = o, then y +Ï„2âˆ¥xâˆ¥BF = {y},
and (10.65) holds with U(x) := E.
(c) =â‡’(a): Set Ï := 1/Î» and Ï„0 := Ï„2Î». Fix any (x, y) âˆˆgraph Î¦ with
x âˆˆÏ„0BE and y âˆˆÏ„0BF . If x = o, there is nothing to prove. Assume now that
x Ì¸= o. It suï¬ƒces to show that for any Ï„ âˆˆ(0, Ï„0] the implication
âˆ¥yâ€² âˆ’yâˆ¥= ÏÏ„âˆ¥xâˆ¥=â‡’yâ€² âˆˆÎ¦(x + Ï„âˆ¥xâˆ¥BE)
holds true. From âˆ¥yâ€² âˆ’yâˆ¥= ÏÏ„âˆ¥xâˆ¥we conclude yâ€² âˆˆy + Ï„2âˆ¥xâˆ¥BF . Now (c)
gives
x âˆˆÎ¦âˆ’1(y) âˆ©U(x) âŠ†Î¦âˆ’1(yâ€²) + Î» âˆ¥y âˆ’yâ€²âˆ¥BE.
Hence there exists xâ€² âˆˆÎ¦âˆ’1(yâ€²) such that x âˆˆxâ€² + Î» âˆ¥y âˆ’yâ€²âˆ¥BE and so
xâ€² âˆˆx + Î» âˆ¥y âˆ’yâ€²âˆ¥BE. It follows that
yâ€² âˆˆÎ¦(x+Î» âˆ¥y âˆ’yâ€²âˆ¥BE) = Î¦(x+Ï„âˆ¥xâˆ¥BE).
âŠ“âŠ”
Next we show that linear semiopenness is stable under local Lipschitz
perturbations (cf. Theorem 10.3.6).
Theorem 10.6.4 Assume that Î¦ : E â‡’F is closed and linearly semiopen
around (Â¯x, Â¯y) âˆˆgraph Î¦ with semiopenness rate Ï > 0 and that Î¨ : E â†’F
is locally L-continuous around Â¯x with constant Î» < Ï. Then Î¦ + Î¨ is linearly
semiopen around (Â¯x, Â¯y + Î¨(Â¯x)) with semiopenness rate Ï âˆ’Î».
Proof. Without loss of generality we can again assume that (Â¯x, Â¯y) = (o, o) and
that Î¨(o) = o. Beside Ï let Ï„0 be a semiopenness parameter of Î¦. Then for all
(x, y) âˆˆgraph Î¦ with x âˆˆÏ„0BE, y âˆˆÏ„0BF and all Ï„ âˆˆ(0, Ï„0] we have
y + ÏÏ„âˆ¥xâˆ¥BF âŠ†Î¦(x + Ï„âˆ¥xâˆ¥BE).
(10.66)
Choose Ï„1 > 0 such that
Ï„1 â‰¤min

2Ï„0
3(1 + Î»), 1
2, Ï„0
2 ,
1
2(Ï âˆ’Î»)

and that Î¨ is Lipschitz continuous on Ï„1BE with Lipschitz constant Î». Now
let (x0, y0) âˆˆgraph(Î¦ + Î¨) with x0 âˆˆÏ„1BE and y0 âˆˆÏ„1BF be given. We shall
show that for any Ï„ âˆˆ(0, Ï„1] we have
y0 + (Ï âˆ’Î»)Ï„âˆ¥x0âˆ¥BF âŠ†(Î¦ + Î¨)(x0 + Ï„âˆ¥x0âˆ¥BE).
(10.67)

216
10 Multifunctions
This is clear if x = o. Now let x Ì¸= o. Take any Ï„ âˆˆ(0, Ï„1] and any yâ€² âˆˆF
satisfying
âˆ¥yâ€² âˆ’y0âˆ¥= (Ï âˆ’Î»)Ï„âˆ¥x0âˆ¥.
We are going to show the existence of xâ€² âˆˆE such that
xâ€² âˆˆx0 + Ï„âˆ¥x0âˆ¥BE
and
yâ€² âˆˆ(Î¦ + Î¨)(xâ€²).
(10.68)
By assumption on (x0, y0) we have

x0, y0 âˆ’Î¨(x0)

âˆˆgraph Î¦,
âˆ¥x0âˆ¥â‰¤Ï„1 â‰¤Ï„0,
âˆ¥y0 âˆ’Î¨(x0)âˆ¥â‰¤âˆ¥y0âˆ¥+ âˆ¥Î¨(x0)âˆ¥â‰¤Ï„1 + Î»âˆ¥x0âˆ¥â‰¤(1 + Î»)Ï„1 â‰¤Ï„0,
âˆ¥

yâ€² âˆ’Î¨(x0)

âˆ’

y0 âˆ’Î¨(x0)

âˆ¥â‰¤(Ï âˆ’Î»)tâˆ¥x0âˆ¥â‰¤ÏÏ„0|x0âˆ¥.
The last line shows that
yâ€² âˆ’Î¨(x0) âˆˆ

y0 âˆ’Î¨(x0)

+ (Ï âˆ’Î»)Ï„âˆ¥x0âˆ¥BF .
Hence by (10.66) with y := y0 âˆ’Î¨(x0), there exists x1 âˆˆE satisfying
yâ€² âˆ’Î¨(x0) âˆˆÎ¦(x1),
âˆ¥x1 âˆ’x0âˆ¥â‰¤Ï âˆ’Î»
Ï
Ï„âˆ¥x0âˆ¥.
Now we proceed by induction. Suppose that for i = 1, . . . , n we have obtained
xi âˆˆE such that
yâ€² âˆ’Î¨(xiâˆ’1) âˆˆÎ¦(xi),
âˆ¥xi âˆ’xiâˆ’1âˆ¥â‰¤Ï âˆ’Î»
Ï
Î»
Ï
iâˆ’1
Ï„âˆ¥x0âˆ¥.
(10.69)
It follows that
âˆ¥xn âˆ’x0âˆ¥â‰¤
n
	
i=1
âˆ¥xi âˆ’xiâˆ’1âˆ¥â‰¤Ï âˆ’Î»
Ï
Ï„âˆ¥x0âˆ¥
n
	
i=1
Î»
Ï
iâˆ’1
â‰¤Ï âˆ’Î»
Ï
Ï„âˆ¥x0âˆ¥
âˆ
	
i=0
Î»
Ï
i
= Ï„âˆ¥x0âˆ¥â‰¤1
2âˆ¥x0âˆ¥.
(10.70)
On the one hand, this implies âˆ¥xnâˆ¥â‰¤3
4âˆ¥x0âˆ¥â‰¤Ï„0. On the other hand, using
âˆ¥xnâˆ¥â‰¥âˆ¥x0âˆ¥âˆ’âˆ¥xn âˆ’x0âˆ¥we also obtain âˆ¥xnâˆ¥â‰¥
1
2âˆ¥x0âˆ¥and so xn Ì¸= o.
Furthermore we have
âˆ¥yâ€² âˆ’Î¨(xnâˆ’1)âˆ¥â‰¤âˆ¥yâ€² âˆ’y0âˆ¥+ âˆ¥Î¨(xnâˆ’1)âˆ¥+ âˆ¥y0âˆ¥
â‰¤(Ï âˆ’Î»)Ï„1âˆ¥x0âˆ¥+ 3
2Î»âˆ¥x0âˆ¥+ âˆ¥y0âˆ¥â‰¤Ï„1
1
2Î» + 3
2Î» + 1

â‰¤Ï„0

10.7 Linearly Semiopen Processes
217
and also
âˆ¥

yâ€² âˆ’Î¨(xn)

âˆ’

yâ€² âˆ’Î¨(xnâˆ’1)

âˆ¥â‰¤Î»âˆ¥xn âˆ’xnâˆ’1âˆ¥
â‰¤(Ï âˆ’Î»)
Î»
Ï
i
Ï„âˆ¥x0âˆ¥â‰¤(Ï âˆ’Î»)
Î»
Ï
i
2Ï„1âˆ¥xnâˆ¥â‰¤ÏÏ„0âˆ¥xnâˆ¥.
Hence we can apply (10.66) with x := xn and y := yâ€² âˆ’Î¨(xnâˆ’1) to ï¬nd
xn+1 âˆˆE such that yâ€² âˆ’Î¨(xn) âˆˆÎ¦(xn+1) and
âˆ¥xn+1 âˆ’xnâˆ¥â‰¤1
Ïâˆ¥

yâ€² âˆ’Î¨(xn)

âˆ’

yâ€² âˆ’Î¨(xnâˆ’1)

âˆ¥
â‰¤Î»
Ï âˆ¥xn âˆ’xnâˆ’1âˆ¥â‰¤Ï âˆ’Î»
Ï
Î»
Ï
i
Ï„âˆ¥x0âˆ¥.
(10.71)
Since these estimates correspond to (10.69), we conclude that a sequence (xn)
exists in E satisfying (10.71) for all n âˆˆN. Since (xn) is a Cauchy sequence
in the Banach space E, it is convergent to some xâ€² âˆˆE. The continuity of Î¨
gives limnâ†’âˆÎ¨(xn) = Î¨(xâ€²). Since (xn+1, yâ€² âˆ’Î¨(xn)) âˆˆgraph Î¦ for all n and
graph Î¦ is closed, we see that (xâ€², yâ€²âˆ’Î¨(xâ€²)) âˆˆgraph Î¦ and so yâ€² âˆˆ(Î¦+Î¨)(xâ€²).
Finally, âˆ¥xn âˆ’x0âˆ¥â‰¤Ï„âˆ¥x0âˆ¥for any n implies âˆ¥xâ€² âˆ’x0âˆ¥â‰¤Ï„âˆ¥x0âˆ¥, which
completes the proof.
âŠ“âŠ”
10.7 Linearly Semiopen Processes
For processes there is a close relationship between linear openness and linear
semiopenness. This will be elaborated in this section. We assume that
E and F are Banach spaces and Î¦ : E â‡’F is a process.
The following notions will be helpful.
Deï¬nition 10.7.1
(a) A set S âŠ†E Ã— F is said to be generating for the process Î¦ if graph Î¦ =
R+S, i.e., graph Î¦ is the cone generated by S.
(b) A set S âŠ†E Ã— F is said to be bounded in E by r (where r > 0) if âˆ¥xâˆ¥â‰¤r
whenever (x, y) âˆˆS.
Example 10.7.2 Let Î¦ be such that Î¦(o) = {o}. Then the set
S := {(x, y) âˆˆgraph Î¦ | âˆ¥xâˆ¥= 1}
is generating for Î¦ and is bounded in E by r = 1.
Lemma 10.7.3 Let S be generating for Î¦ and bounded in E by r > 0. Assume
that Î¦ is open at a linear rate around each (x, y) âˆˆS with the openness
parameters Ï and Ï„0 being independent of (x, y). Then Î¦ is linearly semiopen
around (o, o) with the openness parameters Ï and ËœÏ„0 := min{Ï„0, Ï„0/r}.

218
10 Multifunctions
Proof. Let (x, y) âˆˆgraph Î¦, (x, y) Ì¸= (o, o), where x âˆˆËœÏ„0BE and y âˆˆËœÏ„0BF .
Then (Î»x, Î»y) âˆˆS for some Î» > 0. By assumption we have Î»y + ÏÏ„BF âŠ†
Î¦(Î»x + Ï„BE) for any Ï„ âˆˆ(0, Ï„0]. Since âˆ¥Î»xâˆ¥â‰¤r, it follows that
Î»y + ÏÏ„Î»âˆ¥xâˆ¥BF âŠ†Î¦(Î»x + Ï„Î»âˆ¥xâˆ¥BE)
âˆ€Ï„ âˆˆ(0, ËœÏ„0]
and so since Î¦ is a process,
Î»

y + ÏÏ„âˆ¥xâˆ¥BF

âŠ†Î» Î¦(x + Ï„âˆ¥xâˆ¥BE)
âˆ€Ï„ âˆˆ(0, ËœÏ„0].
Dividing by Î» results in the assertion.
âŠ“âŠ”
Lemma 10.7.4 Let Î¦ be open at a linear rate around (Â¯x, Â¯y) âˆˆgraph Î¦. Then
there are neighborhoods U of Â¯x and V of Â¯y as well as positive numbers Ï and
Ï„0 such that Î¦ is open at a linear rate around each (x, y) âˆˆgraph(Î¦)âˆ©(U Ã—V )
with the openness parameters Ï and Ï„0.
Proof. Let Â¯Ï and Â¯Ï„0 be openness parameters of Î¦ around (Â¯x, Â¯y). Then
yâ€² + Â¯ÏÏ„BF âŠ†Î¦(xâ€² + Ï„BE)
(10.72)
whenever (xâ€², yâ€²) âˆˆgraph Î¦, xâ€² âˆˆÂ¯x + Â¯Ï„0BE, yâ€² âˆˆÂ¯y + Â¯Ï„0BF , and Ï„ âˆˆ(0, Â¯Ï„0].
Deï¬ne
Ï := Â¯Ï,
Ï„0 := Â¯Ï„0/2,
U := Â¯x + Ï„0BE,
V := Â¯y + Ï„0BF .
Now let any (x, y) âˆˆgraph(Î¦) âˆ©(U Ã— V ) be given. Choose (xâ€², yâ€²) âˆˆgraph Î¦
such that xâ€² âˆˆx + Ï„0BE and yâ€² âˆˆy + Ï„0BF . Then xâ€² âˆˆÂ¯x + Â¯Ï„0BE and
yâ€² âˆˆÂ¯y + Â¯Ï„0BF . In view of (10.72) we obtain yâ€² + ÏÏ„BF âŠ†Î¦(xâ€² + Ï„BE) for any
Ï„ âˆˆ(0, Ï„0], and the proof is complete.
âŠ“âŠ”
Proposition 10.7.5 Let S âŠ†E Ã— F be a generating set for Î¦ and assume
that one of the following conditions is satisï¬ed:
(a) S is compact.
(b) E is ï¬nite dimensional, Î¦ : E â†’F is single-valued and locally L-
continuous around o, and S = {(x, Î¦(x)) | âˆ¥xâˆ¥= 1}.
If Î¦ is open at a linear rate around each point of S, then Î¦ is linearly semiopen
around (o, o).
Proof.
(I) First notice that in either case, S is bounded in E.
(II) By Lemma 10.7.4 we can assign to each (x, y) âˆˆS an open neighbor-
hood U(x) Ã— V (y) as well as positive numbers Ï(x, y) and Ï„0(x, y) such
that Î¦ is open at a linear rate around each (xâ€², yâ€²) âˆˆU(x) Ã— V (y) with
the openness parameters Ï(x, y) and Ï„0(x, y).

10.8 Maximal Monotone Multifunctions
219
(IIIa) If condition (a) is satisï¬ed, then the open covering

U(x)Ã—V (y)

(x,y)âˆˆS
of S contains a ï¬nite subcovering

U(xi) Ã— V (yi)

i=1,...,n. Deï¬ne
Ï := min{Ï(xi, yi) | i = 1, . . . , n},
Ï„0 := min{Ï„0(xi, yi) | i = 1, . . . , n}
and apply Lemma 10.7.3 to see that the assertion is true.
(IIIb) Now let condition (b) be satisï¬ed. Since Î¦ is positively homoge-
neous and locally L-continuous around o in particular, Î¦ is (glob-
ally) L-continuous. Hence for each x âˆˆE satisfying âˆ¥xâˆ¥= 1 we can
ï¬nd an open neighborhood U â€²(x) âŠ†U(x) such that xâ€² âˆˆU â€²(x) im-
plies Î¦(xâ€²) âˆˆV (Î¦(x)). Thus Î¦ is open at a linear rate around each
(xâ€², Î¦(xâ€²)), where xâ€² âˆˆU â€²(x), with openness parameters Ï(x) and Ï„0(x).
The open covering

U â€²(x)

âˆ¥xâˆ¥=1 of the compact set {x âˆˆE | âˆ¥xâˆ¥= 1}
contains a ï¬nite subcovering

U â€²(xi)

i=1,...,n. Setting
Ï := min{Ï(xi) | i = 1, . . . , n},
Ï„0 := min{Ï„0(xi) | i = 1, . . . , n}
and applying Lemma 10.7.3 concludes the proof.
âŠ“âŠ”
10.8 Maximal Monotone Multifunctions
The aim of this section is to establish conditions ensuring that a multifunction
Î¦ : E â‡’Eâˆ—satisï¬es range Î¦ = Eâˆ—, which means that for any xâˆ—âˆˆEâˆ—the
generalized equation xâˆ—âˆˆÎ¦(x) has a solution x âˆˆE. In this connection, the
following concept is crucial.
Deï¬nition 10.8.1 The multifunction Î¦ : E â‡’Eâˆ—is said to be maximal
monotone if Î¦ is monotone and graph Î¦ is not properly contained in the
graph of any other monotone multifunction.
Maximal monotone multifunctions play a prominent role in treating para-
bolic diï¬€erential equations as evolution equations in Sobolev spaces of Banach
space-valued functions. For instance, the generalized time derivative in the
time-periodic quasilinear parabolic problem turns out to be a (single-valued)
maximal monotone multifunction. A technical remark will be useful.
Remark 10.8.2 The monotone multifunction Î¦ : E â‡’Eâˆ—is maximal
monotone if and only if the following holds:
&
(y, yâˆ—) âˆˆE Ã— Eâˆ—and âŸ¨yâˆ—âˆ’xâˆ—, y âˆ’xâŸ©â‰¥0
âˆ€(x, xâˆ—) âˆˆgraph Î¦

=â‡’
(y, yâˆ—) âˆˆgraph Î¦.
We show the maximal monotonicity of the subdiï¬€erential mapping âˆ‚F f.
Theorem 10.8.3 Let E be a FrÃ©chet smooth Banach space, let f : E â†’R be
proper and l.s.c. If the multifunction âˆ‚F f : E â‡’Eâˆ—is monotone, then it is
maximal monotone.

220
10 Multifunctions
Proof. Let (b, bâˆ—) âˆˆEÃ—Eâˆ—be such that bâˆ—/âˆˆâˆ‚F f(b). In view of Remark 10.8.2,
we have to show that there exist x âˆˆE and xâˆ—âˆˆâˆ‚F f(x) satisfying (bâˆ—âˆ’
xâˆ—, b âˆ’x) < 0. Since o /âˆˆâˆ‚F (f âˆ’bâˆ—)(b), the point b is not a minimizer of
f âˆ’bâˆ—. Hence there exists a âˆˆE such that (f âˆ’bâˆ—)(a) < (f âˆ’bâˆ—)(b) := Ï. By
Zagrodnyâ€™s approximate mean value theorem (Theorem 9.4.1), there exist a
point c âˆˆ[a, b) as well as sequences (xn) in E and (xâˆ—
n) in Eâˆ—such that
lim
nâ†’âˆxn = c,
yâˆ—
n := xâˆ—
n âˆ’bâˆ—âˆˆâˆ‚F (f âˆ’bâˆ—)(xn)
âˆ€n,
lim inf
nâ†’âˆâŸ¨yâˆ—
n, c âˆ’xnâŸ©â‰¥0,
lim inf
nâ†’âˆâŸ¨yâˆ—
n, b âˆ’aâŸ©> 0.
Noting that b âˆ’c = Î»(b âˆ’a) with some Î» âˆˆ(0, 1], we conclude that
lim inf
nâ†’âˆâŸ¨xâˆ—
n âˆ’bâˆ—, b âˆ’xnâŸ©â‰¥lim inf
nâ†’âˆâŸ¨yâˆ—
n, b âˆ’câŸ©+ lim inf
nâ†’âˆâŸ¨yâˆ—
n, c âˆ’xnâŸ©
â‰¥âˆ¥b âˆ’câˆ¥
âˆ¥b âˆ’aâˆ¥lim inf
nâ†’âˆâŸ¨yâˆ—
n, b âˆ’aâŸ©+ lim inf
nâ†’âˆâŸ¨yâˆ—
n, c âˆ’xnâŸ©> 0.
Since we obviously have xâˆ—
n âˆˆâˆ‚F f(xn) for any n, it suï¬ƒces to set x := xn and
xâˆ—:= xâˆ—
n for n suï¬ƒciently large.
âŠ“âŠ”
Corollary 10.8.4 Let E be a FrÃ©chet smooth Banach space. If f : E â†’R
is proper, convex, and l.s.c., then the subdiï¬€erential mapping âˆ‚f (of convex
analysis) is maximal monotone.
Proof. The subdiï¬€erential mapping âˆ‚f is monotone (Proposition 4.3.7) and
coincides with âˆ‚F f (Proposition 9.1.9). Hence the assertion follows from
Theorem 10.8.3.
âŠ“âŠ”
To describe a class of single-valued maximal monotone multifunctions, we
need the following notion. The mapping T : E â†’Eâˆ—is said to be hemicon-
tinuous if for all x, y, z âˆˆE the real function Ï„ â†’âŸ¨T(x + Ï„y), zâŸ©is continuous
on [0, 1]. Notice that each hemicontinuous mapping is radially continuous.
Proposition 10.8.5 If T : E â†’Eâˆ—is monotone and hemicontinuous, then
T is maximal monotone.
Proof. See Exercise 10.10.3.
âŠ“âŠ”
Before we can establish the announced surjectivity statement, we derive
an auxiliary result that is a distinguished relative of the sandwich theorem.
Lemma 10.8.6 Let E and F be Banach spaces, let f : E â†’R and g : F â†’R
be convex functionals and let A : E â†’F be a continuous linear mapping.
Assume further that:
(C1) f and g are l.s.c. and o âˆˆcr (dom g âˆ’A(dom f) or
(C2) g is continuous at some point of A(dom f).

10.8 Maximal Monotone Multifunctions
221
Then there exists yâˆ—âˆˆF âˆ—such that for any x âˆˆE and y âˆˆF, one has
inf
xâˆˆE

f(x) + g(Ax)

â‰¤

f(x) âˆ’âŸ¨yâˆ—, AxâŸ©

+

g(y) + âŸ¨yâˆ—, yâŸ©

.
(10.73)
Proof.
(I) We deï¬ne the value functional h : F â†’R by
h(u) := inf
xâˆˆE

f(x) + g(Ax + u)

,
u âˆˆF.
The functional h is convex and satisï¬es dom h = dom g âˆ’A(dom f). We
now show that o âˆˆint dom h.
(II) First we assume that condition (C1) is satisï¬ed. Passing to suitable
translations of f and g if necessary, we may assume that f(o) = g(o) = 0.
Let
M :=

xâˆˆBE
{u âˆˆF | f(x) + g(Ax + u) â‰¤1}.
Obviously M is convex.
(IIa) We show that M is absorbing. Let y âˆˆF be given. By (C1) there
exists Ï„0 > 0 such that Ï„y âˆˆdom g âˆ’A(dom f) whenever |Ï„| â‰¤Ï„0.
For each such Ï„ let x âˆˆdom f be such that Ax + Ï„y âˆˆdom g. Then
f(x) + g(Ax + Ï„y) =: r < +âˆ. Let s â‰¥max{âˆ¥xâˆ¥, |r|, 1}. Since f and g
are convex and f(o) = g(o) = 0, we deduce that
f
1
sx

+ g

A
1
sx

+ Ï„
s y

â‰¤1
and so (Ï„/s)y âˆˆM. Hence M is absorbing, i.e., o âˆˆcr M.
(IIb) Next we show that M is cs-closed. Assume that Î»i â‰¥0, âˆ
i=1 Î»i = 1,
yi âˆˆM and y := âˆ
i=1 Î»iyi âˆˆF. Then for each i there is an xi âˆˆBE
satisfying
f(xi) + g(Axi + yi) â‰¤1.
(10.74)
Let Ïµ > 0 be given. Then there exists i0 such that n
i=m Î»i < Ïµ whenever
n > m â‰¥i0. It follows that

n
	
i=m
Î»ixi
 â‰¤
n
	
i=m
Î»iâˆ¥xiâˆ¥< Ïµ
whenever n > m â‰¥i0.
Hence âˆ
i=1 Î»ixi is convergent to some x in the Banach space E. The se-
quence (xi) is contained in the ball BE which is cs-closed (Lemma 1.2.2),
therefore x âˆˆBE. Since f and g are convex and l.s.c. and A is linear
and continuous, we deduce from (10.74) that
f(x) + g(Ax + y) = f
 âˆ
	
i=1
Î»ixi

+ g
 âˆ
	
i=1
Î»i(Axi + yi)

â‰¤
âˆ
	
i=1
Î»if(xi) +
âˆ
	
i=1
Î»ig(Axi + yi) â‰¤1
and so y âˆˆM. Thus M is cs-closed.

222
10 Multifunctions
(IIc) Now Proposition 1.2.3 shows that cr M = int M. This together with
step (IIa) yields o âˆˆint M.
(IId) Since h is convex and bounded above on M and o âˆˆint M, the functional
h is continuous at o.
(III) Now we assume that condition (C2) is satisï¬ed. Let Â¯y âˆˆA(dom f) be
such that g is continuous at Â¯y. Then there exists r > 0 such that g(Â¯y +
u) â‰¤g(Â¯y + 1 for any u âˆˆBF (o, r). Let Â¯x âˆˆdom f be such that Â¯y = AÂ¯x.
Then we obtain
h(u) â‰¤f(Â¯x) + g(AÂ¯x + u) â‰¤f(Â¯x) + g(Â¯y) + 1
âˆ€u âˆˆBF (o, r).
As in step (IId) it follows that h is continuous at o.
(IV) Since h is convex and continuous at o, Proposition 4.1.6 implies that
there exists âˆ’yâˆ—âˆˆâˆ‚h(o). We thus have
inf
xâˆˆE

f(x) + g(Ax)

= h(o) â‰¤h(u) + âŸ¨yâˆ—, uâŸ©
â‰¤f(x) + g(Ax + u) + âŸ¨yâˆ—, uâŸ©
âˆ€x âˆˆE âˆ€u âˆˆF.
(10.75)
Now, if x âˆˆE and y âˆˆF are given, then inserting u := y âˆ’Ax in
(10.75), we obtain (10.73).
âŠ“âŠ”
Recall that the duality mapping J : E â‡’Eâˆ—is deï¬ned by J = âˆ‚j, where
j(z) := 1
2âˆ¥zâˆ¥2. By Remark 4.6.3, J can be written as
J(z) = {zâˆ—âˆˆEâˆ—| âˆ¥zâˆ—âˆ¥= âˆ¥zâˆ¥, âŸ¨zâˆ—, zâŸ©= âˆ¥zâˆ¥2},
z âˆˆE.
(10.76)
If E is reï¬‚exive, then on identifying Eâˆ—âˆ—with E, the duality mapping
J : Eâˆ—â‡’E is deï¬ned analogously.
Theorem 10.8.7 Let E be a reï¬‚exive Banach space. If Î¦ : E â‡’Eâˆ—is max-
imal monotone, then range (Î¦ + Î»J) = Eâˆ—for any Î» > 0.
Proof.
(I) Suppose for the moment we had already veriï¬ed the existence of z âˆˆE
satisfying o âˆˆ(Î¦ + J)(z). Now let Î» > 0 and zâˆ—âˆˆEâˆ—be given. Since
Î»âˆ’1(Î¦âˆ’zâˆ—) inherits the maximal monotonicity from Î¦, we can conclude
that there exists z âˆˆE satisfying o âˆˆ(Î»âˆ’1(Î¦ âˆ’zâˆ—) + J)(z). It follows
that zâˆ—âˆˆ(Î¦ + Î»J)(z). Hence it remains to show that the generalized
equation o âˆˆ(Î¦ + J)(z) has a solution.
(II) Deï¬ne fÎ¦ : E Ã— Eâˆ—â†’R by
fÎ¦(x, xâˆ—) :=
sup
yâˆ—âˆˆÎ¦(y)

âŸ¨yâˆ—, xâŸ©+ âŸ¨xâˆ—, yâŸ©âˆ’âŸ¨yâˆ—, yâŸ©

= âŸ¨xâˆ—, xâŸ©+
sup
yâˆ—âˆˆÎ¦(y)
âŸ¨xâˆ—âˆ’yâˆ—, y âˆ’xâŸ©.

10.8 Maximal Monotone Multifunctions
223
The function fÎ¦ is proper, convex, and l.s.c. Since Î¦ is maximal
monotone, it follows that
fÎ¦(x, xâˆ—) â‰¥âŸ¨xâˆ—, xâŸ©,
(10.77)
and by Remark 10.8.2 equality holds if and only if xâˆ—âˆˆÎ¦(x).
(III) For any x âˆˆE and xâˆ—âˆˆEâˆ—we have
0 â‰¤1
2

âˆ¥xâˆ¥2 + âˆ¥xâˆ—âˆ¥2
âˆ’âˆ¥xâˆ¥Â· âˆ¥xâˆ—âˆ¥â‰¤1
2

âˆ¥xâˆ¥2 + âˆ¥xâˆ—âˆ¥2
+ âŸ¨xâˆ—, xâŸ©(10.78)
and so (10.77) passes into
0 â‰¤fÎ¦(x, xâˆ—) + 1
2

âˆ¥xâˆ¥2 + âˆ¥xâˆ—âˆ¥2
.
(10.79)
Lemma 10.8.6 (with E and F replaced by E Ã— Eâˆ—) now ensures the existence
of (z, zâˆ—) âˆˆE Ã— Eâˆ—such that for all (y, yâˆ—) âˆˆE Ã— Eâˆ—,
0 â‰¤fÎ¦(x, xâˆ—) âˆ’âŸ¨zâˆ—, xâŸ©âˆ’âŸ¨xâˆ—, zâŸ©+ 1
2

âˆ¥yâˆ¥2 + âˆ¥yâˆ—âˆ¥2
+ âŸ¨zâˆ—, yâŸ©+ âŸ¨yâˆ—, zâŸ©.
Choose yâˆ—âˆˆâˆ’J(z) and apply (10.76), analogously choose y âˆˆâˆ’J(zâˆ—). Then
(10.79) gives
fÎ¦(x, xâˆ—) âˆ’âŸ¨zâˆ—, xâŸ©âˆ’âŸ¨xâˆ—, zâŸ©â‰¥1
2

âˆ¥zâˆ¥2 + âˆ¥zâˆ—âˆ¥2
.
(10.80)
Let xâˆ—âˆˆÎ¦(x). Then fÎ¦(x, xâˆ—) = âŸ¨xâˆ—, xâŸ©(cf. step (II)). Hence (10.80) can be
written as
âŸ¨xâˆ—âˆ’zâˆ—, x âˆ’zâŸ©â‰¥1
2

âˆ¥zâˆ¥2 + âˆ¥zâˆ—âˆ¥2
+ âŸ¨zâˆ—, zâŸ©â‰¥0,
(10.81)
where the last inequality follows from (10.78). Since (10.81) holds for any
x, xâˆ—satisfying xâˆ—âˆˆÎ¦(x) and Î¦ is maximal monotone, we can conclude that
zâˆ—âˆˆÎ¦(z). Setting x := z and xâˆ—:= zâˆ—in (10.81), we obtain 1
2

âˆ¥zâˆ¥2+âˆ¥zâˆ—âˆ¥2
+
âŸ¨zâˆ—, zâŸ©= 0, which by (10.76) implies âˆ’zâˆ—âˆˆJ(z) and so o âˆˆ(Î¦ + J)(z).
âŠ“âŠ”
With the aid of Theorem 10.8.7 we shall establish a result on the surjec-
tivity of Î¦. For this, we need the following notion.
The multifunction Î¦ : E â‡’Eâˆ—is said to be coercive if Dom Î¦ is bounded,
or Dom Î¦ is unbounded and
inf{âŸ¨xâˆ—, xâŸ©| xâˆ—âˆˆÎ¦(x)}
âˆ¥xâˆ¥
â†’+âˆ
as x âˆˆDom Î¦, âˆ¥xâˆ¥â†’+âˆ.
Theorem 10.8.8 (Surjectivity Theorem) Let E be a reï¬‚exive Banach
space. If Î¦ : E â‡’Eâˆ—is maximal monotone and coercive, then range Î¦ = Eâˆ—.

224
10 Multifunctions
Proof.
(I) By Proposition 4.7.14, E admits an equivalent norm that is F-
diï¬€erentiable on E \ {o} and so the duality mapping J with respect to
this norm is single-valued. Notice that Î¦ is also coercive with respect to
the equivalent norm.
(II) Let zâˆ—âˆˆEâˆ—be given. Choose a sequence (Î»k) of positive numbers
tending to zero. By Theorem 10.8.7, for each k there exists xk âˆˆDom Î¦
such that zâˆ—âˆˆ(Î¦ + Î»kJ)(xk) and so there exists xâˆ—
k âˆˆÎ¦(xk) satisfying
zâˆ—= xâˆ—
k + Î»kJ(xk).
(10.82)
(III) If Dom Î¦ is bounded, then the sequence (xk) is also bounded. Assume
now that Dom Î¦ is unbounded. Since Î¦ is coercive, there exists Ï > 0
such that
âŸ¨xâˆ—, xâŸ©
âˆ¥xâˆ¥
> âˆ¥zâˆ—âˆ¥
whenever x âˆˆDom Î¦, âˆ¥xâˆ¥> Ï, xâˆ—âˆˆÎ¦(x).
For these x we obtain
âŸ¨xâˆ—âˆ’zâˆ—, xâŸ©= âŸ¨xâˆ—, xâŸ©âˆ’âŸ¨zâˆ—, xâŸ©> âˆ¥xâˆ¥Â· âˆ¥zâˆ—âˆ¥âˆ’âŸ¨zâˆ—, xâŸ©â‰¥0.
On the other hand, in view of (10.76) and (10.82) we have
âŸ¨xâˆ—
k âˆ’zâˆ—, xkâŸ©= âˆ’Î»kâŸ¨J(xk), xkâŸ©= âˆ’Î»kâˆ¥xkâˆ¥2 â‰¤0.
Therefore we must conclude that âˆ¥xkâˆ¥â‰¤Ï for any k. This further implies
âˆ¥xâˆ—
k âˆ’zâˆ—âˆ¥= Î»kâˆ¥J(xk)âˆ¥= Î»kâˆ¥xkâˆ¥â‰¤Î»kÏ â†’0
as k â†’âˆ.
(IV) Since E is reï¬‚exive, the bounded sequence (xk) contains a subsequence
(zk) that is weakly convergent to some z âˆˆE. We show that z sat-
isï¬es zâˆ—âˆˆÎ¦(z). Since Î¦ is monotone, we obtain for any y âˆˆDom Î¦
and yâˆ—âˆˆÎ¦(y) that âŸ¨zâˆ—
k âˆ’yâˆ—, zk âˆ’yâŸ©â‰¥0 for any k. In this context, (zâˆ—
k)
denotes the corresponding subsequence of (xâˆ—
k). Since by step (III) the se-
quence (zâˆ—
k) is norm convergent to zâˆ—, the last inequality implies âŸ¨zâˆ—âˆ’yâˆ—,
zâˆ’yâŸ©â‰¥0 (Exercise 10.10.1). Since Î¦ is maximal monotone, we conclude
that z âˆˆDom Î¦ and zâˆ—âˆˆÎ¦(z).
âŠ“âŠ”
As an immediate consequence of Theorem 10.8.8 and Proposition 10.8.5
we obtain:
Corollary 10.8.9 If E is a reï¬‚exive Banach space and T : E â†’Eâˆ—is
monotone, hemicontinuous, and coercive, then range T = Eâˆ—.

10.9 Convergence of Sets
225
10.9 Convergence of Sets
Convention. Throughout this section, unless otherwise speciï¬ed, E is a
normed vector space and F is a locally convex (not necessarily normed)
vector space.
Here we consider this more general setting because we will later apply the
following concepts to multifunctions of the form Î¦ : E â‡’Eâˆ—, where Eâˆ—is
equipped with the weakâˆ—topology Ïƒ(Eâˆ—, E).
Deï¬nition 10.9.1 Let (SÎ±)Î±âˆˆA, where A is a directed set, be a generalized
sequence of subsets of F.
(a) The PainlevÃ©â€“Kuratowski upper limit Lim supÎ±âˆˆA SÎ± is the set of cluster
points of generalized sequences (vÎ±)Î±âˆˆA, where vÎ± âˆˆSÎ± for any Î± âˆˆA.
(b) The PainlevÃ©â€“Kuratowski lower limit Lim infÎ±âˆˆA SÎ± is the set of limits of
generalized sequences (vÎ±)Î±âˆˆA, where vÎ± âˆˆSÎ± for any Î± âˆˆA.
The deï¬nition applies in particular to a sequence (Sk)kâˆˆN in F, in which
case we write Lim supkâ†’âˆ, Sk and Lim infkâ†’âˆ, Sk, respectively.
Now let Î¦ : E â‡’F be a multifunction and Â¯x âˆˆDom Î¦. We consider Î¦ as
a generalized sequence (Î¦(x))xâˆˆE in F, where E is directed by the preorder
y âª°x if and only if âˆ¥y âˆ’Â¯xâˆ¥â‰¤âˆ¥x âˆ’Â¯xâˆ¥. The resulting PainlevÃ©â€“Kuratowski
upper (lower) limit is then written
Lim sup
xâ†’Â¯x
Î¦(x)
and
Lim inf
xâ†’Â¯x
Î¦(x),
respectively. Lemma 10.9.2 gives the explicit characterization of these limits.
Lemma 10.9.2 If Î¦ : E â‡’F is a multifunction and Â¯x âˆˆDom Î¦, then:
(a) Lim supxâ†’Â¯x Î¦(x) is the set of cluster points of generalized sequences
(vÎ±)Î±âˆˆA, where vÎ± âˆˆÎ¦(xÎ±) for any Î± in the directed set A and (xÎ±)Î±âˆˆA
is convergent in E to Â¯x.
(b) Lim infxâ†’Â¯x Î¦(x) is the set of limits of generalized sequences (vÎ±)Î±âˆˆA,
where vÎ± âˆˆÎ¦(xÎ±) for any Î± âˆˆA and (xÎ±)Î±âˆˆA is convergent in E to Â¯x.
Proof. See Exercise 10.10.4.
âŠ“âŠ”
The following result is also easily veriï¬ed.
Lemma 10.9.3 One always has
Lim inf
xâ†’Â¯x
Î¦(x) âŠ†cl Î¦(Â¯x) âŠ†Lim sup
xâ†’Â¯x
Î¦(x).
Proof. See Exercise 10.10.5.
âŠ“âŠ”

226
10 Multifunctions
If, in addition, F is a normed vector space, we have a simple characteriza-
tion of these concepts. We write x â†’Î¦ Â¯x if x âˆˆDom Î¦ and x â†’Â¯x.
Lemma 10.9.4 If E and F are normed vector spaces and Î¦ : E â‡’F is a
multifunction, then
Lim sup
xâ†’Â¯x
Î¦(x) =

v âˆˆF
 lim inf
xâ†’Î¦Â¯x d(Î¦(x), v) = 0

,
Lim inf
xâ†’Â¯x
Î¦(x) =

v âˆˆF
 lim
xâ†’Î¦Â¯x d(Î¦(x), v) = 0

,
and these limits are closed sets.
Proof. See Exercise 10.10.6.
âŠ“âŠ”
We shall also make use of a sequential variant of the above concepts.
Deï¬nition 10.9.5 Let E be a normed vector space, Î¦ : E â‡’Eâˆ—be a mul-
tifunction, and Â¯x âˆˆDom Î¦. The sequential PainlevÃ©â€“Kuratowski upper limit
sLim supxâ†’Â¯xÎ¦(x) of Î¦ is deï¬ned to be the set of all xâˆ—âˆˆEâˆ—for which there
exist a sequence (xk) in Dom Î¦ that is norm convergent to Â¯x and a sequence
(xâˆ—
k) in Eâˆ—that is Ïƒ(Eâˆ—, E) convergent to xâˆ—such that xâˆ—
k âˆˆÎ¦(xk) for all
k âˆˆN.
Lemma 10.9.6 is an immediate consequence of the deï¬nitions.
Lemma 10.9.6 Let E be a normed vector space and equip Eâˆ—with the topol-
ogy Ïƒ(Eâˆ—, E). Further let Î¦ : E â‡’Eâˆ—. Then
sLim sup
xâ†’Â¯x
Î¦(x) âŠ†Lim sup
xâ†’Â¯x
Î¦(x).
Now we introduce a convergence concept for a generalized sequence of
functions.
Deï¬nition 10.9.7 Let (Ï•Î±)Î±âˆˆA be a generalized sequence of functions Ï•Î± :
F â†’R:
(a) The upper epi-limit of (Ï•Î±)Î±âˆˆA is the function eLim supÎ±âˆˆAÏ•Î± whose
epigraph is the PainlevÃ©â€“Kuratowski lower limit of epi Ï•Î±:
epi

eLim sup
Î±âˆˆA
Ï•Î±

:= Lim inf
Î±âˆˆA (epi Ï•Î±).
(10.83)
(b) The lower epi-limit of (Ï•Î±)Î±âˆˆA is the function eLim infÎ±âˆˆAÏ•Î± whose epi-
graph is the PainlevÃ©â€“Kuratowski upper limit of epi Ï•Î±:
epi

eLim inf
Î±âˆˆA
Ï•Î±

:= Lim sup
Î±âˆˆA
(epi Ï•Î±).
(10.84)
(c) If the upper and the lower epi-limit of (Ï•Î±)Î±âˆˆA coincide, then this function
is called epi-limit of (Ï•Î±)Î±âˆˆA and is denoted eLimÎ±âˆˆAÏ•Î±.

10.10 Bibliographical Notes and Exercises
227
It is left as Exercise 10.10.7 to show that the right-hand sides of (10.83)
and (10.84) in fact are the epigraphs of functions. If, in particular, (Ï•k) is a
sequence of functions, then the corresponding epi-limit functions are deï¬ned,
respectively, by
epi

eLim sup
kâ†’âˆ
Ï•k

:= Lim inf
kâ†’âˆ(epi Ï•k),
epi

eLim inf
kâ†’âˆ
Ï•k

:= Lim sup
kâ†’âˆ
(epi Ï•k),
epi

eLim
kâ†’âˆÏ•k

:= epi

eLim sup
kâ†’âˆ
Ï•k

= epi

eLim inf
kâ†’âˆ
Ï•k

.
In a normed vector space we have a simple characterization of the epi-limit.
Lemma 10.9.8 Let F be a normed vector space and Ï•k : F â†’R for all
k âˆˆN. Then Ï• = eLim
kâ†’âˆÏ•k if and only if for each x âˆˆF one has
Ï•(x) â‰¤lim inf
kâ†’âˆÏ•k(xk)
for any sequence xk â†’x
and
Ï•(x) â‰¥lim sup
kâ†’âˆ
Ï•k(xk)
for some sequence xk â†’x.
Proof. See Exercise 10.10.8.
âŠ“âŠ”
10.10 Bibliographical Notes and Exercises
The presentation of Sects. 10.1â€“10.5 was strongly inï¬‚uenced by Bonnans
and Shapiro [16]. Lemma 10.1.1 is due to Robinson [176]. The general-
ized open mapping theorem (Theorem 10.1.2) is due, independently, to
Robinson [176] and Ursescu [211]. Proposition 10.2.1 is a result of Tuy [210],
Proposition 10.2.3 appears in this context in [196].
The concept of openness at a linear rate is inherent in Lyusternikâ€™s orig-
inal proof (of 1934) of the tangent space theorem (see Theorem 11.4.2). The
concept was developed for single-valued mappings, under diï¬€erent names, by
Dmitruk et al. [54], Dolecki [55], Warga [214], and others.
Ioï¬€e [94] obtained Theorem 10.3.3, the proof given here follows Bonnans
and Shapiro [16]. The stability theorem (Theorem 10.3.5) is due, indepen-
dently, to Robinson [175] and Ursescu [211]. The perturbation theorem
(Theorem 10.3.6) can be traced back to Lyusternik [128] and Graves [79]. For
the estimate in the theorem see Ioï¬€e [93].
Proposition 10.4.3 is a result of PÂ¨uhl [172]. Jourani and Thibault [107]
have established a corresponding suï¬ƒcient condition for linear openness of
certain classes of multifunctions but without a representation of the openness
bound. PÂ¨uhl [171] gives a nice geometric proof for the fact that a continu-
ous convex functional f is open at a linear rate around Â¯x if and only if Â¯x

228
10 Multifunctions
is not a minimizer of f. This paper also contains suï¬ƒcient conditions for
cone-convex mappings to be open at a linear rate. Theorem 10.5.2 and its
proof are taken from Borwein and Zhuang [25]. Penot [164] showed that the
assumption that Î¦ be closed-valued can be dropped; see also Mordukhovich
and Shao [139].
Concerning the results of Sects. 10.6 and 10.7 we refer to PÂ¨uhl and Schi-
rotzek [173], see also the doctoral thesis of Heidrun PÂ¨uhl [172].
The elegant proof of Theorem 10.8.3 is taken from Borwein and Zhu [24].
In this connection, we had to assume that E be a FrÃ©chet smooth Banach space
so that we could apply Theorem 10.8.3 which in turn was deduced with the aid
of Theorem 9.4.1. By a quite diï¬€erent proof, Rockafellar [181] showed that the
conclusion of Corollary 10.8.4 holds in any Banach space E. A substantially
simpler proof of Rockafellarâ€™s result is due to Simons [198] (cf. Phelps [165]).
Groh [80] considers monotone operators via certain scalarizations called forms.
Also see Exercise 10.10.2.
Theorem 10.8.7 is due to Rockafellar [182]. Lemma 10.8.6 and the astound-
ingly easy proof of Theorem 10.8.7 are taken from Borwein and Zhu [24].
In this context, the function fÎ¦ is called Fitzpatrick function by Borwein and
Zhu. Theorem 10.8.8 together with results on the maximal monotonicity of the
sum of two multifunctions admits various important applications. For read-
ers interested in this subject, we recommend the comprehensive two-volume
monograph by Zeidler [223,224].
As standard references to multifunction theory we recommend Aubin and
Frankowska [8] (inï¬nite-dimensional spaces) and Rockafellar and Wets [189]
(ï¬nite-dimensional spaces).
Exercise 10.10.1 Assume that E is a Banach space, (xk) is a sequence in E
and (xâˆ—
k) is a sequence in Eâˆ—. Show that limkâ†’âˆâŸ¨xâˆ—
k, xkâŸ©= âŸ¨xâˆ—, xâŸ©if
(a) (xk) is norm convergent to x and (xâˆ—
k) is weakâˆ—convergent to xâˆ—or
(b) (xk) is weakly convergent to x and (xâˆ—
k) is norm convergent to xâˆ—.
Exercise 10.10.2 Prove the following assertion:
If E is a Banach space and f : E â†’R is convex and continuous, then âˆ‚f :
E â‡’Eâˆ—is maximal monotone.
Hint: Follow the proof of Theorem 10.8.3 but apply the mean value theorem
of Proposition 3.3.1 instead of Theorem 9.4.1 (cf. Phelps [165]).
Exercise 10.10.3 Verify Proposition 10.8.5.
Exercise 10.10.4 Prove Lemma 10.9.2.
Exercise 10.10.5 Verify Lemma 10.9.3.
Exercise 10.10.6 Prove Lemma 10.9.4.

10.10 Bibliographical Notes and Exercises
229
Exercise 10.10.7 Prove that the right-hand sides of (10.83) and (10.84) in
fact are the epigraphs of functions.
Hint: Show that a set S âŠ†F Ã— R is the epigraph of a function Ï• : F â†’R if
and only if it has the following two properties:
(a) (x, t) âˆˆS and tâ€² > t imply (x, tâ€²) âˆˆS and
(b) x âˆˆF and tâˆ—:= inf{t âˆˆR | (x, t) âˆˆS} imply (x, tâˆ—) âˆˆS.
Exercise 10.10.8 Prove Lemma 10.9.8.

11
Tangent and Normal Cones
11.1 Tangent Cones: First Properties
In this section, unless otherwise speciï¬ed, we assume that E is a normed vector
space, A is a nonempty subset of E, and Â¯x âˆˆA. Resuming the discussion
started in Sect. 7.1, we deï¬ne various tangent cones as local approximations
of A near Â¯x. By x â†’A Â¯x we mean that x âˆˆA and x â†’Â¯x.
Deï¬nition 11.1.1 One deï¬nes
Tr(A, Â¯x) := {y âˆˆE | âˆƒÏ„k â†“0 âˆ€k : Â¯x + Ï„ky âˆˆA},
cone of radial directions to A at Â¯x,
T(A, Â¯x) := {y âˆˆE | âˆƒÏ„k â†“0 âˆƒyk â†’y âˆ€k : Â¯x + Ï„kyk âˆˆA},
contingent cone to A at Â¯x,
TC(A, Â¯x) := {y âˆˆE | âˆ€xk â†’A Â¯x âˆ€Ï„k â†“0 âˆƒyk â†’y âˆ€k : xk + Ï„kyk âˆˆA},
Clarke tangent cone to A at Â¯x,
Ir(A, Â¯x) := {y âˆˆE | âˆƒÏµ > 0 âˆ€Ï„ âˆˆ(0, Ïµ) : Â¯x + Ï„y âˆˆA},
cone of radial inner directions, or
cone of feasible directions, to A at Â¯x,
I(A, Â¯x) := {y âˆˆE | âˆƒÏµ > 0 âˆ€Ï„ âˆˆ(0, Ïµ) âˆ€z âˆˆB(y, Ïµ) : Â¯x + Ï„z âˆˆA},
cone of inner directions to A at Â¯x,
H(A, Â¯x) := {y âˆˆE | âˆ€xk â†’A Â¯x âˆ€Ï„k â†“0 âˆ€yk â†’y âˆ€k : xk + Ï„kyk âˆˆA},
cone of hypertangents to A at Â¯x.
Proposition 11.1.2
(a) One has
I(A, Â¯x) âŠ†Ir(A, Â¯x) âŠ†Tr(A, Â¯x) âŠ†T(A, Â¯x),
H(A, Â¯x) âŠ†TC(A, Â¯x) âŠ†T(A, Â¯x).

232
11 Tangent and Normal Cones
Each of the sets is a cone, I(A, Â¯x) and H(A, Â¯x) may be empty, the other
cones contain the zero element.
(b) T(A, Â¯x) and TC(A, Â¯x) are closed, TC(A, Â¯x) is also convex.
(c) If U is a neighborhood of Â¯x, then T(A, Â¯x) = T(A âˆ©U, Â¯x), analogously for
the other cones considered in (a).
(d) If A is convex, then
Ir(A, Â¯x) = Tr(A, Â¯x) = R+(A âˆ’Â¯x),
T(A, Â¯x) = cl

R+(A âˆ’Â¯x)

,
I(A, Â¯x) = {Ï(x âˆ’Â¯x) | Ï > 0, x âˆˆint A}.
Proof.
(I) We show that T(A, Â¯x) is closed. Let (zn) be a sequence in T(A, Â¯x) con-
verging to some y âˆˆE. For each n âˆˆN there exist sequences (Ï„ (n)
k
) in
(0, +âˆ) and (y(n)
k ) in E satisfying
Ï„ (n)
k
â†“0,
y(n)
k
â†’zn as k â†’âˆ
and
Â¯x + Ï„ (n)
k
y(n)
k
âˆˆA âˆ€k âˆˆN.
Hence for each n âˆˆN there exists k(n) such that
Ï„ (n)
k
< 1
n
and
âˆ¥y(n)
k
âˆ’znâˆ¥< 1
n
âˆ€k â‰¥k(n).
Setting Ï„n := Ï„ (n)
k(n) and yn := y(n)
k(n), we obtain Ï„n â†“0 and yn â†’y as
n â†’âˆas well as Â¯x + Ï„nyn âˆˆA for each n. Therefore y âˆˆT(A, Â¯x).
(II) We now verify that TC(A, Â¯x) is convex. Let y1, y2 âˆˆTC(A, Â¯x). Since
TC(A, Â¯x) is a cone, we only have to show that y1+y2 âˆˆTC(A, Â¯x). Assume
that Ï„k â†“0 and xk â†’A Â¯x as k â†’âˆ. Then there exists (y(1)
k ) in E such
that y(1)
k
â†’y1 as k â†’âˆand x(1)
k
:= xk + Ï„ky(1)
k
âˆˆA for each k. Since
x(1)
k
â†’Â¯x, there also exists (y(2)
k ) in E satisfying
y(2)
k
â†’y2
and
xk + Ï„k

y(1)
k
+ y(2)
k

= x(1)
k
+ Ï„ky(2)
k
âˆˆA
âˆ€k âˆˆN.
Since we also have y(1)
k
+ y(2)
k
â†’y1 + y2, we conclude that y1 + y2 âˆˆ
TC(A, Â¯x).
The veriï¬cation of the remaining assertions is left as Exercise 11.7.1.
âŠ“âŠ”
Statement (c) of the proposition means that the approximating cones depend
on the local properties of A near Â¯x only.
Figure 11.1 supplements the ï¬gures in Sect. 7.1.
Proposition 11.1.3 If A, B âŠ†E and Â¯x âˆˆA âˆ©B, then
Tr(A, Â¯x) âˆ©Ir(B, Â¯x) âŠ†Tr(A âˆ©B, Â¯x),
(11.1)
T(A, Â¯x) âˆ©I(B, Â¯x) âŠ†T(A âˆ©B, Â¯x).
(11.2)

11.1 Tangent Cones: First Properties
233
T(A, Â¯x) + Â¯x
TC(A, Â¯x) + Â¯x
A
Â¯x
Fig. 11.1
Proof. We verify (11.2), leaving (11.1) as Exercise 11.7.2. Let y âˆˆT(A, Â¯x) âˆ©
I(B, Â¯x). Then there exist sequences Ï„k â†“0 and yk â†’y such that Â¯x + Ï„kyk âˆˆA
for any k âˆˆN. Further there exists Ïµ > 0 such that Â¯x + Ï„B(y, Ïµ) âˆˆB for any
Ï„ âˆˆ(0, Ïµ). For all suï¬ƒciently large k we therefore obtain Â¯x + Ï„kyk âˆˆA âˆ©B.
Hence y âˆˆT(A âˆ©B, Â¯x).
âŠ“âŠ”
The following example shows that in the above formulas, I(B, Â¯x) cannot
be replaced by T(B, Â¯x).
Example 11.1.4 In E := R2 consider the sets A := {(x, y) âˆˆR2 | y â‰¥x2}
and B := {(x, y) âˆˆR2 | y â‰¤âˆ’x2}. Then with Â¯x := (0, 0) we have
T(A, Â¯x) âˆ©T(B, Â¯x) = R Ã— {0}
but
T(A âˆ©B, Â¯x) = {(0, 0)}.
Proposition 11.1.5 There always holds
T(A, Â¯x) = {y âˆˆE | lim inf
Ï„â†“0
Ï„ âˆ’1dA(Â¯x + Ï„y) = 0},
TC(A, Â¯x) = {y âˆˆE | lim inf
Ï„â†“0
xâ†’A Â¯x
Ï„ âˆ’1dA(x + Ï„y) = 0}.
Proof. See Exercise 11.7.3.
âŠ“âŠ”
Now we establish a representation of the Clarke tangent cone in terms of
the Clarke directional derivative. It is easy to see that
dA(x) âˆ’dA(y)
 â‰¤âˆ¥x âˆ’yâˆ¥
âˆ€x, y âˆˆE,
(11.3)
i.e., the distance functional dA(Â·) is (globally) L-continuous and so dâ—¦
A(x, y)
exists for all x, y âˆˆE.
Proposition 11.1.6 One has
TC(A, Â¯x) = {y âˆˆE | dâ—¦
A(Â¯x, y) = 0}.

234
11 Tangent and Normal Cones
Proof.
(I) Let y âˆˆE satisfy dâ—¦
A(Â¯x, y) = 0. Further let sequences Ï„k â†“0 and xk â†’A Â¯x
be given. Then
0 = lim sup
Ï„â†“0
xâ†’Â¯x
1
Ï„

dA(x + Ï„y) âˆ’dA(x)

â‰¥lim sup
kâ†’âˆ
1
Ï„k

dA(xk + Ï„ky) âˆ’dA(xk)
  
=0

.
On the other hand, we have lim infkâ†’âˆ1
Ï„k dA(xk + Ï„ky) â‰¥0 and so
lim
kâ†’âˆ
1
Ï„k dA(xk + Ï„ky) = 0.
By the deï¬nition of dA, for each k âˆˆN there exists zk âˆˆA satisfying
âˆ¥zk âˆ’(xk + Ï„ky)âˆ¥â‰¤dA(xk + Ï„ky) + Ï„k
k .
Setting yk :=
1
Ï„k (zk âˆ’xk), we obtain
âˆ¥yk âˆ’yâˆ¥=
1
Ï„k âˆ¥zk âˆ’(xk + Ï„ky)âˆ¥â‰¤
1
Ï„k dA(xk + Ï„ky) + 1
k â†’0
as k â†’âˆ.
Further we have xk + Ï„kyk = zk âˆˆA for each k. Hence y âˆˆTC(A, Â¯x).
(II) Now let y âˆˆTC(A, Â¯x). By the deï¬nition of dâ—¦
A, there exist Ï„k â†“0 and
xâ€²
k â†’Â¯x satisfying
dâ—¦
A(Â¯x, y) = lim
kâ†’âˆ
1
Ï„k

dA(xâ€²
k + Ï„ky) âˆ’dA(xâ€²
k)

.
(11.4)
Notice that the sequence (xâ€²
k) need not belong to A. But since there does
exist a sequence (xk) in A converging to Â¯x (set, for example, xk := Â¯x for
each k), we have
dâ—¦
A(Â¯x, y) â‰¥lim sup
kâ†’âˆ
1
Ï„k

dA(xk + Ï„ky) âˆ’dA(xk)

â‰¥0.
Therefore it suï¬ƒces to show that the right-hand side of (11.4) is not
greater than zero. Let zk âˆˆA be such that
âˆ¥zk âˆ’xâ€²
kâˆ¥â‰¤dA(xâ€²
k) + Ï„k
k .
(11.5)
Since xâ€²
k â†’Â¯x as k â†’âˆ, it follows that
âˆ¥zk âˆ’Â¯xâˆ¥â‰¤âˆ¥zk âˆ’xâ€²
kâˆ¥+ âˆ¥xâ€²
k âˆ’Â¯xâˆ¥â‰¤dA(xâ€²
k) + Ï„k
k + âˆ¥xâ€²
k âˆ’Â¯xâˆ¥â†’0
and so zk â†’Â¯x. Since y âˆˆTC(A, Â¯x), there exists yk â†’y satisfying zk +
Ï„kyk âˆˆA for each k âˆˆN. Moreover, since dA is L-continuous with L-
constant 1 (see (11.3)), we obtain
dA(xâ€²
k + Ï„ky) â‰¤dA(zk + Ï„kyk) + âˆ¥zk âˆ’xâ€²
kâˆ¥+ Ï„kâˆ¥yk âˆ’yâˆ¥
â‰¤
(11.5)
dA(xâ€²
k) + Ï„k
 1
k + âˆ¥yk âˆ’yâˆ¥

.
Hence the right-hand side of (11.4) is in fact at most equal to zero.
âŠ“âŠ”

11.1 Tangent Cones: First Properties
235
Corollary 11.1.7 If A is convex, then TC(A, Â¯x) = T(A, Â¯x) = cl R+(A âˆ’Â¯x).
Proof. By Proposition 11.1.2(d) we know that the second equation holds true.
We now show that TC(A, Â¯x) = cl R+(Aâˆ’Â¯x). Since A is convex, the functional
dA is convex, and it is also L-continuous. Hence dA is regular (Remark 7.4.2)
and so dâ—¦
A(Â¯x, Â·) = dA,G(Â¯x, Â·). By Proposition 11.1.6, u âˆˆTC(A, Â¯x) is equivalent
to dA,G(Â¯x, u) = 0 and so to limÏ„â†“0 Ï„ âˆ’1dA(Â¯x+Ï„u) = 0. The latter relation holds
if and only if for each k âˆˆN there exist Ï„k âˆˆ(0, 1
k) and xk âˆˆA such that
uk := 1
Ï„k

Â¯x + Ï„ku âˆ’xk

â†’0
as k â†’âˆ.
Noting that u =
1
Ï„k

xk âˆ’Â¯x

+ uk completes the proof.
âŠ“âŠ”
The following â€œball characterizationsâ€ of the Clarke tangent cone and the
hypertangent cone will be useful in the sequel.
Lemma 11.1.8
(a) One has y âˆˆTC(A, Â¯x) if and only if for any Ïµ > 0 there exists Î´ > 0 such
that
A âˆ©B(Â¯x, Î´) + Ï„y âŠ†A + Ï„B(o, Ïµ)
âˆ€Ï„ âˆˆ(0, Î´).
(b) One has y âˆˆH(A, Â¯x) if and only if there exists Ïµ > 0 such that
u + Ï„v âˆˆA
whenever u âˆˆA âˆ©B(Â¯x, Ïµ), v âˆˆB(y, Ïµ), Ï„ âˆˆ(0, Ïµ).
Proof. See Exercise 11.7.4.
âŠ“âŠ”
The next result will be applied in Sect. 12.3 to derive a multiplier rule.
Proposition 11.1.9 H(A, Â¯x) is always open. If H(A, Â¯x) is nonempty, then
int TC(A, Â¯x) = H(A, Â¯x).
Proof.
(I) It follows easily from Lemma 11.1.8 that the cone H(A, Â¯x) is open. Since
it is a subset of TC(A, Â¯x), we always have H(A, Â¯x) âŠ†int TC(A, Â¯x).
(IIa) Assuming now that H(A, Â¯x) is nonempty, we have to show that
int TC(A, Â¯x) âŠ†H(A, Â¯x).
(11.6)
This will be done when we have veriï¬ed the relation
H(A, Â¯x) + TC(A, Â¯x) âŠ†H(A, Â¯x).
(11.7)
In fact, let y âˆˆint TC(A, Â¯x) be given. Choose z âˆˆH(A, Â¯x). Then y âˆ’
Î·z âˆˆTC(A, Â¯x) for some suï¬ƒciently small Î· > 0. Since we also have
Î·z âˆˆH(A, Â¯x), we see that
y = Î·z + (y âˆ’Î·z)
âˆˆ
(11.7) H(A, Â¯x).

236
11 Tangent and Normal Cones
(IIb) Thus it remains to verify (11.7). Let y1 âˆˆH(A, Â¯x) and y2 âˆˆTC(A, Â¯x) be
given. We have to show that for some Ïµ > 0,
A âˆ©B(Â¯x, Ïµ) + Ï„ B(y1 + y2, Ïµ) âŠ†A
âˆ€Ï„ âˆˆ(0, Ïµ).
(11.8)
Since y1 âˆˆH(A, Â¯x), there exists Ïµ1 > 0 such that
A âˆ©B(Â¯x, Ïµ1) + Ï„ B(y1, Ïµ1) âŠ†A
âˆ€Ï„ âˆˆ(0, Ïµ1).
(11.9)
Furthermore, y2 âˆˆTC(A, Â¯x) implies that for some Ïµ2 > 0 we have
A âˆ©B(Â¯x, Ïµ2) + Ï„ y2 âŠ†A + B

o, Ï„ Ïµ1
2

âˆ€Ï„ âˆˆ(0, Ïµ2).
(11.10)
Now let Ïµ be such that
0 < Ïµ < min

Ïµ2, Ïµ1
2 ,
Ïµ1
1 + Ïµ1 + âˆ¥y2âˆ¥

.
Let y be an element of the left-hand side of (11.7). It follows that y =
z + Ï„(y1 + y2 + Ïµzâ€²), where z âˆˆA âˆ©B(Â¯x, Ïµ) and zâ€² âˆˆB(o, 1). Since Ïµ â‰¤Ïµ2,
by (11.10) we see that for some zâ€²â€² âˆˆB(o, 1) we have z+Ï„y2âˆ’Ï„ Ïµ1
2 zâ€²â€² âˆˆA.
Moreover, we obtain
Â¯x âˆ’

z + Ï„y2 âˆ’Ï„ Ïµ1
2 zâ€²â€² â‰¤âˆ¥Â¯x âˆ’zâˆ¥+ Ï„
y2 âˆ’Ïµ1
2 zâ€²â€²
< Ïµ + Ïµ

âˆ¥y2âˆ¥+ Ïµ1
2

< Ïµ1
and so z + Ï„y2 âˆ’Ï„ Ïµ1
2 zâ€²â€² âˆˆA âˆ©B(Â¯x, Ïµ1). In view of (11.9), it follows that
z + Ï„y2 âˆ’Ï„ Ïµ1
2 zâ€²â€² + Ï„ B(y1, Ïµ1) âŠ†A.
(11.11)
Notice that
y = z + Ï„

y2 âˆ’Ïµ1
2 zâ€²â€²
+ Ï„

y1 + (Ïµzâ€² + Ïµ1
2 zâ€²â€²)

,
where
Ïµzâ€² + Ïµ1
2 zâ€²â€² â‰¤Ïµ + Ïµ1
2 < Ïµ1. Hence (11.11) implies y âˆˆA. We have
thus veriï¬ed (11.7) and so (11.6).
âŠ“âŠ”
In view of Proposition 11.1.9 we give the following:
Deï¬nition 11.1.10 The set A is said to be epi-Lipschitzian at Â¯x if H(A, Â¯x)
is nonempty. If H(A, x) is nonempty for all x âˆˆA, then A is said to be epi-
Lipschitzian.
Remark 11.1.11 Rockafellar [184] showed that if E is ï¬nite dimensional,
then A is epi-Lipschitzian at Â¯x if and only if int TC(A, Â¯x) is nonempty. He also
gave an example of a convex subset A of an inï¬nite-dimensional normed vector
space such that int TC(A, Â¯x) is nonempty but A is not epi-Lipschitzian.

11.2 Normal Cones: First Properties
237
The following result provides an important class of epi-Lipschitzian sets.
Proposition 11.1.12 If A is convex and int A is nonempty, then A is epi-
Lipschitzian.
Proof.
(I) Let xâ€² âˆˆint A and choose Ïµ > 0 such that B(xâ€², 2Ïµ) âŠ†A. Now let Â¯x be
any element of A. We show that y := xâ€² âˆ’Â¯x âˆˆH(A, Â¯x). First notice that
Â¯x + B(y, 2Ïµ) âŠ†A.
(11.12)
In fact, if v âˆˆB(y, 2Ïµ) and vâ€² := Â¯x + v, then âˆ¥vâ€² âˆ’xâ€²âˆ¥= âˆ¥v âˆ’yâˆ¥â‰¤2Ïµ and
so vâ€² âˆˆB(xâ€², 2Ïµ) âŠ†A.
(II) Now let u âˆˆA âˆ©B(Â¯x, Ïµ) and v âˆˆB(y, Ïµ) be given. We then have
âˆ¥(v + u âˆ’Â¯x) âˆ’yâˆ¥â‰¤âˆ¥v âˆ’yâˆ¥+ âˆ¥u âˆ’Â¯xâˆ¥â‰¤2Ïµ
and so (by (11.12)) u + v = Â¯x + (v + u âˆ’Â¯x) âˆˆA. Since A is convex, we
obtain u+Ï„v = Ï„(u+v)+(1âˆ’Ï„)u âˆˆA for any Ï„ âˆˆ[0, 1]. By Lemma 11.1.8
we conclude that y âˆˆH(A, Â¯x).
âŠ“âŠ”
In analogy to Proposition 11.1.3 we have the following intersection result.
Proposition 11.1.13 If A, B âŠ†E and Â¯x âˆˆA âˆ©B, then
TC(A, Â¯x) âˆ©H(B, Â¯x) âŠ†TC(A âˆ©B, Â¯x).
Proof. See Exercise 11.7.5.
âŠ“âŠ”
We formulate without proof a stronger intersection result due to
Rockafellar [183].
Proposition 11.1.14 Let A, B âŠ†E, let Â¯x âˆˆA âˆ©B, and assume that
TC(A, Â¯x) âˆ©H(B, Â¯x) is nonempty. Then
TC(A, Â¯x) âˆ©TC(B, Â¯x) âŠ†TC(A âˆ©B, Â¯x).
11.2 Normal Cones: First Properties
Let again A be a nonempty subset of the normed vector space E and let
Â¯x âˆˆA. We now deï¬ne several normal cones to A at Â¯x.
Deï¬nition 11.2.1 If A is convex, then
N(A, Â¯x) := (A âˆ’Â¯x)â—¦= {v âˆˆEâˆ—| âŸ¨v, x âˆ’Â¯xâŸ©â‰¤0
âˆ€x âˆˆA}
is called normal cone to A at Â¯x in the sense of convex analysis.

238
11 Tangent and Normal Cones
Lemma 11.2.2 If A is convex, then
N(A, Â¯x) = T(A, Â¯x)â—¦
and
N(A, Â¯x) = âˆ‚Î´A(Â¯x).
Proof. The ï¬rst equation follows by Proposition 11.1.2(d) and the second is
an immediate consequence of the deï¬nition of N(A, Â¯x).
âŠ“âŠ”
In the nonconvex case, the deï¬nition of normal cone is modeled on one or
the other of the preceding equations.
Deï¬nition 11.2.3 The cone NC(A, Â¯x) := TC(A, Â¯x)â—¦is called Clarke normal
cone to A at Â¯x.
Recall that clâˆ—M denotes the Ïƒ(Eâˆ—, E)-closure of M âŠ†Eâˆ—.
Proposition 11.2.4 One has NC(A, Â¯x) = clâˆ—
R+âˆ‚â—¦dA(Â¯x)

.
Proof. By Proposition 7.3.7, we have dâ—¦
A(Â¯x, y) = max{âŸ¨v, yâŸ©| v âˆˆâˆ‚â—¦dA(Â¯x)}.
Using this and Proposition 11.1.6, we obtain
y âˆˆTC(A, Â¯x) â‡â‡’dâ—¦
A(Â¯x, y) = 0 â‡â‡’âŸ¨v, yâŸ©â‰¤0 âˆ€v âˆˆâˆ‚â—¦dA(Â¯x)
â‡â‡’y âˆˆ

âˆ‚â—¦dA(Â¯x)
â—¦,
which
implies
NC(A, Â¯x)
=

âˆ‚â—¦dA(Â¯x)
â—¦â—¦.
The
bipolar
theorem
(Proposition 2.3.3) ï¬nally yields the assertion. In this connection, recall
that the Clarke subdiï¬€erential is convex.
âŠ“âŠ”
Deï¬nition 11.2.5 Let A be a nonempty subset of E and Â¯x âˆˆA. Then we
call
NF (A, Â¯x) := âˆ‚F Î´A(Â¯x)
FrÃ©chet normal cone to A at Â¯x,
NV (A, Â¯x) := âˆ‚V Î´A(Â¯x)
viscosity normal cone to A at Â¯x,
NP (A, Â¯x) := âˆ‚P Î´A(Â¯x)
proximal normal cone to A at Â¯x.
Each u âˆˆNF (A, Â¯x) is said to be a FrÃ©chet normal to A at Â¯x, analogously we
use viscosity normal and proximal normal.
We ï¬rst give a simple but useful characterization of FrÃ©chet normal cones.
Proposition 11.2.6 Let A be a nonempty subset of E and Â¯x âˆˆA. Then for
any xâˆ—âˆˆEâˆ—, the following assertions are mutually equivalent:
(a) xâˆ—âˆˆNF (A, Â¯x).
(b) For every Ïµ > 0 there exists Î´ > 0 such that
âŸ¨xâˆ—, x âˆ’Â¯xâŸ©â‰¤Ïµâˆ¥x âˆ’Â¯xâˆ¥
âˆ€x âˆˆA âˆ©B(Â¯x, Î´).
(c) There exists a function Ï• : E â†’R that is F-diï¬€erentiable at Â¯x with
Ï•â€²(Â¯x) = xâˆ—and attains a maximum over A at Â¯x.

11.2 Normal Cones: First Properties
239
Proof.
(a) =â‡’(b): This follows immediately from the deï¬nition of NF (A, Â¯x).
(b) =â‡’(c): It is easy to check that the function Ï• : E â†’R deï¬ned by
Ï•(x) :=

min{0, âŸ¨xâˆ—, x âˆ’Â¯xâŸ©}
if x âˆˆA,
âŸ¨xâˆ—, x âˆ’Â¯xâŸ©
otherwise
has the required properties.
(c) =â‡’(a): According to (c) we have
Ï•(x) = Ï•(Â¯x) + âŸ¨xâˆ—, x âˆ’Â¯xâŸ©+ r(x)
where
r(x)/âˆ¥x âˆ’Â¯xâˆ¥â†’0
as x â†’Â¯x.
Since Ï•(x) â‰¤Ï•(Â¯x) for any x âˆˆA, statement (a) follows.
âŠ“âŠ”
In a Hilbert space, proximal normals can be characterized in various ways.
Proposition 11.2.7 Let A be a nonempty subset of the Hilbert space E and
let Â¯x âˆˆA. Then for any u âˆˆE, the following assertions are mutually equiva-
lent:
(a) u âˆˆNP (A, Â¯x).
(b) Either u = o or there exist Î» > 0 and z âˆˆE \ A such that u = Î»(z âˆ’Â¯x)
and Â¯x âˆˆprojA(z).
(c) There exists Ï â‰¥0 such that (u | x âˆ’Â¯x) â‰¤Ïâˆ¥x âˆ’Â¯xâˆ¥2 for any x âˆˆA.
(d) There exist Ïƒ â‰¥0 and Ïµ > 0 such that (u | x âˆ’Â¯x) â‰¤Ïƒâˆ¥x âˆ’Â¯xâˆ¥2 for any
x âˆˆA âˆ©B(Â¯x, Ïµ).
(e) There exists Ï„ > 0 such that dA(Â¯x + Ï„u) = Ï„âˆ¥uâˆ¥.
Proof. We prepare the proof with two observations. First, we have
Â¯x âˆˆprojA(z)
â‡â‡’
âˆ¥z âˆ’Â¯xâˆ¥â‰¤âˆ¥z âˆ’xâˆ¥âˆ€x âˆˆA
â‡â‡’
(z âˆ’Â¯x | x âˆ’Â¯x) â‰¤(z âˆ’x | z âˆ’x) âˆ€x âˆˆA.
Simplifying the inner products in the last inequality leads to
Â¯x âˆˆprojA(z)
â‡â‡’
(z âˆ’Â¯x | x âˆ’Â¯x) â‰¤1
2âˆ¥x âˆ’Â¯xâˆ¥2
âˆ€x âˆˆA.
(11.13)
Second, for any Ï„ > 0 we have
âˆ¥x âˆ’(Â¯x + Ï„u)âˆ¥2 = âˆ¥x âˆ’Â¯xâˆ¥2 âˆ’2Ï„(u | x âˆ’Â¯x) + Ï„ 2âˆ¥uâˆ¥2.
(11.14)
(a) =â‡’(b): This is obvious for u = o. If u âˆˆâˆ‚P Î´A(Â¯x) and u Ì¸= o, then there
exists Ïƒ > 0 satisfying
(u | x âˆ’Â¯x) âˆ’Ïƒâˆ¥x âˆ’Â¯xâˆ¥2 â‰¤0
âˆ€x âˆˆA.
By (11.13) we obtain Â¯x âˆˆprojA(z), where z := Â¯x +
1
2Ïƒu. Observe that z /âˆˆA
and u = 2Ïƒ(z âˆ’Â¯x).

240
11 Tangent and Normal Cones
(b) =â‡’(c): Let u be as in (b). In view of (11.13) it follows that (u | x âˆ’Â¯x) â‰¤
Î»
2 âˆ¥x âˆ’Â¯xâˆ¥2 for each x âˆˆA.
(c) =â‡’(d) is obvious.
(d) =â‡’(e): Assume that (d) holds and choose any Ï„ > 0. Using (11.14), we
obtain
âˆ¥x âˆ’(Â¯x + Ï„u)âˆ¥2 â‰¥(1 âˆ’2Ï„Ïƒ)âˆ¥x âˆ’Â¯xâˆ¥2 + Ï„ 2âˆ¥uâˆ¥2
âˆ€x âˆˆA âˆ©B(Â¯x, Ïµ).
Since for x := Â¯x we have âˆ¥x âˆ’(Â¯x + Ï„u)âˆ¥2 = Ï„ 2âˆ¥uâˆ¥2, we conclude that dA(Â¯x +
Ï„u) = Ï„âˆ¥uâˆ¥.
(e) =â‡’(a): The condition (e) implies
âˆ¥x âˆ’(Â¯x + Ï„u)âˆ¥2 â‰¥Ï„ 2âˆ¥uâˆ¥2
âˆ€x âˆˆA,
(11.15)
which by (11.14) entails
Î´A(x) âˆ’Î´A(Â¯x) â‰¥(u | x âˆ’Â¯x) âˆ’1
2Ï„ âˆ¥x âˆ’Â¯xâˆ¥2
âˆ€x âˆˆE
(11.16)
and so u âˆˆNP (A, Â¯x).
âŠ“âŠ”
Geometric Interpretation
The equivalence of (a) and (b) means that NP (A, Â¯x) collects all points u on
rays emanating from Â¯x and meeting some point z âˆˆE \ A for which Â¯x is the
best approximation with respect to A (Fig. 11.2).
It is clear that generally we have NP (A, Â¯x) âŠ†NF (A, Â¯x).
Proposition 11.2.8 Assume that E is a FrÃ©chet smooth Banach space, A is
convex and closed, and Â¯x âˆˆA. Then
NP (A, Â¯x) = NF (A, Â¯x) = NC(A, Â¯x) = N(A, Â¯x).
Proof. See Exercise 11.7.6.
âŠ“âŠ”
A
NP (A, Â¯x)
Â¯x
z
u
Fig. 11.2

11.3 Tangent and Normal Cones to Epigraphs
241
Observe that the closedness of A is assumed only to ensure that Î´A is l.s.c.
which enters the deï¬nition of the proximal subdiï¬€erential. If A is convex (and
closed), then u âˆˆNP (A, Â¯x) if and only if (b) of Proposition 11.2.7 holds, which
is geometrically interpreted in Remark 5.3.2 and Fig. 5.1.
11.3 Tangent and Normal Cones to Epigraphs
Let f : E â†’R be proper and let Â¯x âˆˆdom f. Our aim now is to give repre-
sentations of approximating cones to epi f at Â¯x. Recall the lower directional
H-derivative
f H(Â¯x, y) = lim inf
Ï„â†“0
zâ†’y
1
Ï„

f(Â¯x + Ï„z) âˆ’f(Â¯x)

,
y âˆˆE.
Proposition 11.3.1 Let f : E â†’R be proper and Â¯x âˆˆdom f.
(a) There always holds
T

epi f, (Â¯x, f(Â¯x))

= epi f H(Â¯x, Â·).
(b) If f is locally L-continuous around Â¯x, then
TC

epi f, (Â¯x, f(Â¯x))

= epi f â—¦(Â¯x, Â·).
Proof.
(a) (I) Let (y, Ï) âˆˆT

epi f, (Â¯x, f(Â¯x))

be given. Then there exist sequences
(Ï„k) in (0, +âˆ) and (zk, Ïk) in E Ã— R satisfying Ï„k â†“0, zk â†’y, and
Ïk â†’Ï as k â†’âˆsuch that (Â¯x, f(Â¯x)) + Ï„k(zk, Ïk) âˆˆepi f for any
k âˆˆN. It follows that
1
Ï„k

f(Â¯x + Ï„kzk) âˆ’f(Â¯x)

â‰¤Ïk
âˆ€k âˆˆN
and so f +
H(Â¯x, y) â‰¤Ï which means (y, Ï) âˆˆepi f +
H(Â¯x, Â·).
(II) Now let (y, Ï) âˆˆepi f +
H(Â¯x, Â·) be given. We then have
inf
0<Ï„<Ïµ
âˆ¥zâˆ’yâˆ¥<Ïµ
1
Ï„

f(Â¯x + Ï„z) âˆ’f(Â¯x)

â‰¤Ï
âˆ€Ïµ > 0.
Hence for any k âˆˆN there exists Ï„k âˆˆ(0, 1
k) and zk âˆˆB(y, 1
k) such that
1
Ï„k

f(Â¯x + Ï„kzk) âˆ’f(Â¯x)

< Ï + 1
k
âˆ€k âˆˆN.
We thus see that Ï„k â†“0, (zk, Ï+ 1
k) â†’(y, Ï), and (Â¯x, f(Â¯x))+Ï„k(zk, Ï+ 1
k) âˆˆ
epi f. Hence (y, Ï) âˆˆT

epi f, (Â¯x, f(Â¯x))

.
(b) This is veriï¬ed analogously.
âŠ“âŠ”

242
11 Tangent and Normal Cones
Corollary 11.3.2 If f : E â†’R is locally L-continuous around Â¯x âˆˆdom f,
then for any xâˆ—âˆˆEâˆ—one has
xâˆ—âˆˆâˆ‚â—¦f(Â¯x)
â‡â‡’
(xâˆ—, âˆ’1) âˆˆNC

epi f, (Â¯x, f(Â¯x))

.
Proof. By Proposition 7.3.7 we have xâˆ—âˆˆâˆ‚â—¦f(Â¯x) if and only if f â—¦(Â¯x, y) â‰¥
âŸ¨xâˆ—, yâŸ©for any y âˆˆE. Hence using Proposition 11.3.1 and the deï¬nition of the
Clarke normal cone, we obtain
xâˆ—âˆˆâˆ‚â—¦f(Â¯x)
â‡â‡’
(y, Ï) âˆˆepi f â—¦(Â¯x, Â·)
âˆ€y âˆˆE
âˆ€Ï â‰¥f â—¦(Â¯x, y)
â‡â‡’
âŸ¨(xâˆ—, âˆ’1), (y, Ï)âŸ©= âŸ¨xâˆ—, yâŸ©âˆ’Ï â‰¤0
âˆ€(y, Ï) âˆˆepif â—¦(Â¯x, Â·)
â‡â‡’
(xâˆ—, âˆ’1) âˆˆTC

epi f, (Â¯x, , f(Â¯x))
â—¦= NC

epi f, (Â¯x, f(Â¯x))

.
âŠ“âŠ”
If f is strictly H-diï¬€erentiable at Â¯x, then by Proposition 7.3.9 the assertion
of the corollary reduces to (f â€²(Â¯x), âˆ’1) âˆˆNC

epi f, (Â¯x, f(Â¯x))

. In the language
of diï¬€erential geometry in the plane this means that (f â€²(Â¯x), âˆ’1) is a normal
vector to graph f at the point (Â¯x, f(Â¯x)).
Remark 11.3.3 By Proposition 11.3.1 we have
f H(Â¯x, y) = inf{Ï âˆˆR | (y, Ï) âˆˆT

epi f, (Â¯x, f(Â¯x))

}
âˆ€y âˆˆE,
f â—¦(Â¯x, y) = inf{Ï âˆˆR | (y, Ï) âˆˆTC

epi f, (Â¯x, f(Â¯x))

}
âˆ€y âˆˆE.
This shows that directional derivatives can also be deï¬ned with the aid of
approximating cones. Furthermore, Corollary 11.3.2 and Proposition 11.3.4
(which is the proximal subdiï¬€erential analogue to Corollary 11.3.2) indicate
that subdiï¬€erentials can be deï¬ned via normal cones.
Proposition 11.3.4 Let E be a Hilbert space, let f : E â†’R be proper and
l.s.c., and let Â¯x âˆˆdom f. Then for each xâˆ—âˆˆE one has
xâˆ—âˆˆâˆ‚P f(Â¯x)
â‡â‡’
(xâˆ—, âˆ’1) âˆˆNP

epif, (Â¯x, f(Â¯x))

.
Proof. =â‡’: Let xâˆ—âˆˆâˆ‚P f(Â¯x) be given. By the deï¬nition of the proximal
subdiï¬€erential there exist Ïƒ > 0 and Î´ > 0 such that for all x âˆˆB(Â¯x, Î´) and
all Î± â‰¥f(x) we have
Î± âˆ’f(Â¯x) + Ïƒ
&
âˆ¥x âˆ’Â¯xâˆ¥2 +

Î± âˆ’f(Â¯x)
2
â‰¥(xâˆ—| x âˆ’Â¯x).
(11.17)
In other words, if x âˆˆB(Â¯x, Î´) and (x, Î±) âˆˆepif, then

(xâˆ—, âˆ’1)
 (x, Î±) âˆ’(Â¯x, f(Â¯x))

=

(xâˆ—, âˆ’1)
 (x âˆ’Â¯x, Î± âˆ’f(Â¯x))

= (xâˆ—| x âˆ’Â¯x) âˆ’Î± + f(Â¯x)
â‰¤
(11.17)
Ïƒâˆ¥(x, Î±) âˆ’(Â¯x, f(Â¯x))âˆ¥2.

11.3 Tangent and Normal Cones to Epigraphs
243
By Proposition 11.2.7 we conclude that (xâˆ—, âˆ’1) âˆˆNP

epi f, (x, f(x))

.
â‡=: Assume now that (xâˆ—, âˆ’1) âˆˆNP

epi f, (Â¯x, f(Â¯x))

. By Proposition 11.2.7
there exists Î· > 0 such that for all (x, Î±) âˆˆepi f we have

Î·(xâˆ—, âˆ’1) | (x âˆ’Â¯x, Î± âˆ’f(Â¯x))

â‰¤1
2âˆ¥(x âˆ’Â¯x, Î± âˆ’f(Â¯x))âˆ¥2,
which in view of (11.13) implies that
(Â¯x, f(Â¯x)) âˆˆprojepif(p),
where p := (Â¯x, f(Â¯x)) + Î·(xâˆ—, âˆ’1).
(11.18)
The deï¬nition of the projection now shows (cf. Fig. 11.3, where Î´â€² :=
âˆ¥Î·(xâˆ—, âˆ’1)âˆ¥) that
âˆ¥Î·(xâˆ—, âˆ’1)âˆ¥2 â‰¤âˆ¥p âˆ’(x, Î±)âˆ¥2
âˆ€(x, Î±) âˆˆepi f.
In particular, choosing Î± = f(x) we obtain
Î´2âˆ¥xâˆ—âˆ¥2 + Î´2 â‰¤âˆ¥Â¯x âˆ’y + Î´xâˆ—âˆ¥2
f(Â¯x) âˆ’f(x) âˆ’Î´
2.
Evaluating âˆ¥Â· âˆ¥2 via the inner product, the latter inequality passes into
Î´2 + 2Î´ (xâˆ—| x âˆ’Â¯x) âˆ’âˆ¥x âˆ’Â¯xâˆ¥2 â‰¤

f(x) âˆ’f(Â¯x) + Î´
2.
(11.19)
Now choose Ïµ > 0 so small that for each x âˆˆB(Â¯x, Ïµ) the left-hand side of
(11.19) is positive and at the same time f(x) > f(Â¯x) âˆ’Î´ (the latter being
possible since f is l.s.c. at Â¯x). For each such x we obtain from (11.19) that
f(x) â‰¥g(x), where
g(x) := f(Â¯x) âˆ’Î´ +

Î´2 + 2Î´ (xâˆ—| x âˆ’Â¯x) âˆ’âˆ¥x âˆ’Â¯xâˆ¥21/2.
p
(Â¯x, f(Â¯x))
epi f
B(p, Î´â€²)
Fig. 11.3

244
11 Tangent and Normal Cones
By Example 3.6.2 the function g is twice continuously diï¬€erentiable on B(Â¯x, Ïµ)
(upon diminishing Ïµ if necessary) and gâ€²(Â¯x) = xâˆ—. Now Proposition 3.5.1
implies that with some Ïƒ > 0 we have
g(x) â‰¥g(Â¯x) + (xâˆ—| x âˆ’Â¯x) âˆ’Ïƒâˆ¥x âˆ’Â¯xâˆ¥2
âˆ€x âˆˆB(Â¯x, Ïµ).
This together with f(x) â‰¥g(x) and f(Â¯x) = g(Â¯x) gives
f(x) â‰¥f(Â¯x) + (xâˆ—| x âˆ’Â¯x) âˆ’Ïƒ|x âˆ’Â¯xâˆ¥2
âˆ€x âˆˆB(Â¯x, Ïµ)
and so xâˆ—âˆˆâˆ‚P f(Â¯x).
âŠ“âŠ”
Now we derive a result analogous to Proposition 11.3.4 for the viscosity
(FrÃ©chet) subdiï¬€erential and the viscosity (FrÃ©chet) normal cone.
Proposition 11.3.5 Let f : E â†’R be proper and l.s.c., and let Â¯x âˆˆdom f.
Then for each xâˆ—âˆˆE one has
xâˆ—âˆˆâˆ‚V f(Â¯x)
â‡â‡’
(xâˆ—, âˆ’1) âˆˆNV

epif, (Â¯x, f(Â¯x))

.
(11.20)
If, in addition, E is a FrÃ©chet smooth Banach space, then
xâˆ—âˆˆâˆ‚F f(Â¯x)
â‡â‡’
(xâˆ—, âˆ’1) âˆˆNF

epif, (Â¯x, f(Â¯x))

.
(11.21)
Proof.
(I) Let xâˆ—âˆˆâˆ‚V f(Â¯x) be given. By deï¬nition there exists a C1 function g
such that gâ€²(Â¯x) = xâˆ—and f âˆ’g attains a local minimum at Â¯x. Deï¬ne
h(y, r) := g(y) âˆ’r for y near Â¯x and r âˆˆR. Then h is a C1 function
satisfying hâ€²(Â¯x, f(Â¯x)) = (xâˆ—, âˆ’1) and
Î´epi f(y, r) âˆ’h(y, r) â‰¥Î´epi f(Â¯x, f(Â¯x)) âˆ’h(Â¯x, f(Â¯x)).
It follows that (xâˆ—, âˆ’1) âˆˆâˆ‚V Î´epi f(Â¯x, f(Â¯x)) = NV

epi f, (Â¯x, f(Â¯x))

.
(II) Now let (xâˆ—, âˆ’1) âˆˆNV

epi f, (Â¯x, f(Â¯x))

. Then there exists a C1 func-
tion h : E Ã— R â†’R such that hâ€²(Â¯x, f(Â¯x)) = (xâˆ—, âˆ’1) and h(x, t) â‰¤
h(Â¯x, f(Â¯x)) = 0 for any (x, t) âˆˆepi f that is suï¬ƒciently close to (Â¯x, f(Â¯x)).
Concerning the equation h(Â¯x, f(Â¯x)) = 0, notice that h can be chosen
in this way. Now the implicit function theorem (Theorem 3.7.2) ensures
the existence of a C1 function g : E â†’R satisfying h(x, g(x)) = 0 for
any x near Â¯x as well as g(Â¯x) = f(Â¯x) and
gâ€²(Â¯x) = âˆ’h 2(Â¯x, g(Â¯x))âˆ’1 â—¦h 1(Â¯x, g(Â¯x)) = xâˆ—.
Since h is continuously diï¬€erentiable and h 2(Â¯x, g(Â¯x)) = âˆ’1, there exists
Ïµ > 0 such that
h(x, t) < h(x, s)
whenever
x âˆˆB(Â¯x, Ïµ) and f(Â¯x) âˆ’Ïµ < s < t < f(Â¯x) + Ïµ.
(11.22)

11.4 Representation of Tangent Cones
245
Since g is continuous at Â¯x and f is l.s.c. at Â¯x, there exists Î´ âˆˆ(0, Ïµ) such
that
f(Â¯x) âˆ’Ïµ â‰¤g(x) â‰¤f(Â¯x) + Ïµ
and
f(x) > f(Â¯x) âˆ’Ïµ
âˆ€x âˆˆB(Â¯x, Î´).
Now let x âˆˆB(Â¯x, Î´). If f(x) â‰¥f(Â¯x) + Ïµ, then we immediately have
f(x) âˆ’g(x) â‰¥0 = f(Â¯x) âˆ’g(Â¯x). But the latter inequality also holds if
f(x) < f(Â¯x) + Ïµ because in this case h(x, f(x)) â‰¤0 = h(x, g(x)) by
(11.22). Thus, we have shown that xâˆ—âˆˆâˆ‚V f(Â¯x).
(III) The
additional
assertion
follows
from
the
above
by
virtue
of
Theorem 9.1.7 and the deï¬nition of the FrÃ©chet normal cone. In this
connection notice that if E is FrÃ©chet smooth, so is E Ã— R.
âŠ“âŠ”
Remark 11.3.6 Here we obtained the characterization (11.21) as a by-
product of (11.20). In a more general setting we shall later see that (11.21)
holds without the hypothesis that E be FrÃ©chet smooth.
11.4 Representation of Tangent Cones
Our aim in this section is to characterize (subsets of) approximating cones of
sets given by inequalities and/or equations.
Approximating hâˆ’1(Q)
We make the following assumptions:
(A) E and F are Banach spaces, Q is a nonempty closed convex subset of
F, h : E â†’F is continuous on E and continuously diï¬€erentiable at
Â¯x âˆˆhâˆ’1(Q).
Theorem 11.4.1 Let the assumptions (A) and the Robinson condition
o âˆˆint

h(Â¯x) + hâ€²(Â¯x)(E) âˆ’Q

be satisï¬ed. Then
T(hâˆ’1(Q), Â¯x) = hâ€²(Â¯x)âˆ’1
T(Q, h(Â¯x))

.
(11.23)
Proof.
(I) We show
hâ€²(Â¯x)âˆ’1
T(Q, h(Â¯x))

âŠ†T(hâˆ’1(Q), Â¯x).
(11.24)
Let y âˆˆhâ€²(Â¯x)âˆ’1
T(Q, h(Â¯x))

. By Proposition 11.1.5 there exists Ï„k â†“0
such that
lim
kâ†’âˆÏ„ âˆ’1
k d(Q, h(Â¯x) + Ï„khâ€²(Â¯x)y) = 0.
(11.25)

246
11 Tangent and Normal Cones
Since h is continuously diï¬€erentiable at Â¯x, we further have
h(Â¯x + Ï„y) = h(Â¯x) + Ï„hâ€²(Â¯x)y + o(Ï„),
Ï„ â†“0.
(11.26)
Hence Ï„ âˆ’1
k d(Q, h(Â¯x + Ï„ky)) â†’0 as k â†’âˆ. By Proposition 10.3.7 there
exists Îº > 0 such that d(hâˆ’1(Q), Â¯x + Ï„y) â‰¤Îº d(Q, h(Â¯x + Ï„y)). It follows
that
lim
kâ†’âˆÏ„ âˆ’1
k d(hâˆ’1(Q), Â¯x + Ï„ky) = 0
(11.27)
and so y âˆˆT(hâˆ’1(Q), Â¯x).
(II) Now we show the reverse inclusion to (11.24). So let y âˆˆT(hâˆ’1(Q), Â¯x) be
given. Then there exists Ï„k â†“0 such that (11.27) holds. Since the mapping
h is continuously diï¬€erentiable at Â¯x, it is locally Lipschitz continuous
there. Hence there exists Î» > 0 such that d(Q, h(x)) â‰¤Î» d(hâˆ’1(Q), x)
for any x near Â¯x. This and (11.27) imply that Ï„ âˆ’1
k d(h(Â¯x + Ï„ky), Q) â†’0
as k â†’âˆ. Using (11.26) again, we see that (11.25) holds and so hâ€²(Â¯x)y âˆˆ
T(Q, h(Â¯x)).
âŠ“âŠ”
Notice that we veriï¬ed the reverse inclusion to (11.24) without making
use of the Robinson condition. However, the crucial inclusion for deriving
multiplier rules in Chap. 12 will be (11.24), and this inclusion has been veriï¬ed
with the aid of Proposition 10.3.7 which is bound to the Robinson condition
or one of the equivalent conditions (see Proposition 10.3.8).
As a special case, Theorem 11.4.1 contains the following classical result
(cf. Fig. 7.3).
Theorem 11.4.2 (Tangent Space Theorem) Let the assumptions
(A)
with Q = {o} be satisï¬ed. If hâ€²(Â¯x) is surjective, then
T(ker h, Â¯x) = ker hâ€²(Â¯x).
(11.28)
Example 11.4.3 Let E = F := R2, Â¯x := (1, 0), and h = (h1, h2), where
h1(x1, x2) := âˆ’x2,
h2(x1, x2) := x2 + (x1 âˆ’1)3.
Then T(ker h, Â¯x) = {(0, 0)} but ker hâ€²(Â¯x) = R Ã— {0}, i.e., (11.28) is not valid.
Notice that in this case, hâ€²(Â¯x)

R2
= {Î±(âˆ’1, 1) | Î± âˆˆR} and so hâ€²(Â¯x) is not
surjective.
Approximating A âˆ©hâˆ’1(Q)
Now we consider sets of the form
A âˆ©hâˆ’1(Q) = {x âˆˆE | x âˆˆA, h(x) âˆˆQ}.

11.4 Representation of Tangent Cones
247
Theorem 11.4.4 In addition to the assumptions (A), let now A be a non-
empty closed convex subset of E and assume that the Robinson condition
o âˆˆint

h(Â¯x) + hâ€²(Â¯x)(A âˆ’Â¯x) âˆ’Q

(11.29)
is satisï¬ed. Then one has
T(A âˆ©hâˆ’1(Q), Â¯x) = T(A, Â¯x) âˆ©hâ€²(Â¯x)âˆ’1
T(Q, h(Â¯x))

.
(11.30)
Proof. Setting
%F := E Ã— F,
%Q := A Ã— Q,
%h(x) := (x, h(x)),
x âˆˆE,
we have
%hâˆ’1( %Q) = A âˆ©hâˆ’1(Q),
%hâ€²(Â¯x)y = (y, hâ€²(Â¯x)y)
for ally âˆˆE,
T( %Q,%h(Â¯x)) = T(A, Â¯x) Ã— T(Q, h(Â¯x)).
Hence the assertion follows from Theorem 11.4.1 as soon as we have shown
that the Robinson condition
(o, o) âˆˆint
Ëœh(Â¯x) + Ëœhâ€²(Â¯x)(E) âˆ’ËœQ

(11.31)
is satisï¬ed. According to (11.29) there exists Ïµ > 0 such that
Ïµ BF âŠ†h(Â¯x) + hâ€²(Â¯x)(A âˆ’Â¯x) âˆ’Q.
(11.32)
Choose Î´ > 0 such that âˆ¥zâˆ’hâ€²(Â¯x)x1âˆ¥< Ïµ whenever |x1âˆ¥< Î´ and âˆ¥zâˆ¥< Î´. Now
let (y, z) âˆˆÎ´ BEÃ—F be given. Set x1 := y. By (11.32) there exists x2 âˆˆA âˆ’Â¯x
such that
z âˆ’hâ€²(Â¯x)x1 âˆˆh(Â¯x) + hâ€²(Â¯x)x2 âˆ’Q.
Deï¬ning x := x1+x2, we have (y, z) âˆˆËœh(Â¯x)+Ëœhâ€²(Â¯x)xâˆ’ËœQ. This veriï¬es (11.31),
and the proof is complete.
âŠ“âŠ”
Approximating Sublevel Sets
Now we want to approximate the set
M := {x âˆˆE | x âˆˆA, gi(x) â‰¤0 (i = 1, . . . , m), h(x) = o},
(11.33)
where
g1, . . . , gm : E â†’R,
h : E â†’F.
Of course, M can be written as A âˆ©*h âˆ’1(Q) by setting
*h := (g1, . . . , gm, h) : E â†’Rm Ã— F,
Q := âˆ’Rm
+ Ã— {o}.

248
11 Tangent and Normal Cones
However, if we want to apply Theorem 11.4.4, we have to assume that beside
the mapping h, the functions g1, . . . , gm are also continuously diï¬€erentiable
at Â¯x. By a somewhat diï¬€erent approach we shall now show that we can do
with weaker diï¬€erentiability hypotheses on the functions gi. Therefore we ï¬rst
consider the set
M1 := {x âˆˆE | x âˆˆA, gi(x) â‰¤0 (i = 1, . . . , m)}.
(11.34)
We deï¬ne
I := {1, . . . , m},
I(Â¯x) := {i âˆˆI | gi(Â¯x) = 0}.
The set I(Â¯x) is the index set of the constraint functions that are active or
binding at the point Â¯x. In Fig. 11.4 we have 1 âˆˆI(Â¯x) and 2 Ì¸âˆˆI(Â¯x). It will turn
out that for i /âˆˆI(Â¯x), the constraint gi(x) â‰¤0 is not critical provided the
function gi is upper semicontinuous at Â¯x.
Figure 11.5 indicates what we can expect in Rn if i âˆˆI(Â¯x) and gi is
diï¬€erentiable at Â¯x. An â€œadmissibleâ€ direction y satisï¬es Ï€
2 < Î± < Ï€ and so
âŸ¨âˆ‡gi(Â¯x), yâŸ©â‰¤0. If gi is not diï¬€erentiable at Â¯x, then we use a (radial) upper
convex approximation Î³i. We set
Î³ := (Î³i)iâˆˆI(Â¯x),
L<(Î³, Â¯x) := {y âˆˆE | Î³i(y) < 0 âˆ€i âˆˆI(Â¯x)},
Lâ‰¤(Î³, Â¯x) := {y âˆˆE | Î³i(y) â‰¤0 âˆ€i âˆˆI(Â¯x)}.
The sets L<(Î³, Â¯x) and Lâ‰¤(Î³, Â¯x), which are obviously cones, are called lineariz-
ing cones of Î³ at Â¯x.
g2(x) = 0
M1
Â¯x
g1(x) = 0
Fig. 11.4
Î±
âˆ‡gi(Â¯x)
gi(x) = 0
Â¯x
M1
y
Fig. 11.5

11.4 Representation of Tangent Cones
249
Proposition 11.4.5 Let E be a normed vector space, A be a nonempty subset
of E, and gi : E â†’R for i âˆˆI. Assume that for i âˆˆI \ I(Â¯x) the function gi
is upper semicontinuous at Â¯x. Let M1 be deï¬ned by (11.34).
(a) If Î³i âˆˆUCr(gi, Â¯x) for i âˆˆI(Â¯x), then
L<(Î³, Â¯x) âŠ†Ir(M1, Â¯x),
(11.35)
Tr(A, Â¯x) âˆ©L<(Î³, Â¯x) âŠ†Tr(A âˆ©M1, Â¯x).
(11.36)
If, in addition, Kr âŠ†Tr(A, Â¯x) is a convex cone satisfying
Kr âˆ©L<(Î³, Â¯x) Ì¸= âˆ…,
(11.37)
then
Kr âˆ©Lâ‰¤(Î³, Â¯x) âŠ†cl Tr(A âˆ©M1, Â¯x).
(11.38)
(b) If Î³i âˆˆUC(gi, Â¯x) for i âˆˆI(Â¯x), then
L<(Î³, Â¯x) âŠ†I(M1, Â¯x),
(11.39)
T(A, Â¯x) âˆ©L<(Î³, Â¯x) âŠ†T(A âˆ©M1, Â¯x).
(11.40)
If, in addition, K âŠ†T(A, Â¯x) is a convex cone satisfying
K âˆ©L<(Î³, Â¯x) Ì¸= âˆ…,
(11.41)
then
K âˆ©Lâ‰¤(Î³, Â¯x) âŠ†T(A âˆ©M1, Â¯x).
(11.42)
Proof. Ad (11.39). Let y âˆˆL<(Î³, Â¯x). Then we have ( Â¯gi)+
H(Â¯x, y) â‰¤Î³i(y) < 0
for any i âˆˆI(Â¯x). Hence for any such i there exists Ïµi âˆˆ(0, 1) such that
1
Ï„
&
gi(Â¯x + Ï„z) âˆ’gi(Â¯x)
  
=0

< 0
âˆ€Ï„ âˆˆ(0, Ïµi) âˆ€z âˆˆB(y, Ïµi).
(11.43)
Now let i âˆˆI \ I(Â¯x). Then gi(Â¯x) < 0 and gi is upper semicontinuous at Â¯x.
Hence there exists Î´i > 0 such that
gi(x) < 0
âˆ€x âˆˆB(Â¯x, Î´i).
(11.44)
Set
ËœÏµ := min{Ïµi | i âˆˆI(Â¯x)}, Î´ := min{Î´i | i âˆˆI \ I(Â¯x)}, Ïµ := min
0
ËœÏµ,
Î´
ËœÏµ + âˆ¥yâˆ¥
1
.
If now Ï„ âˆˆ(0, Ïµ) and z âˆˆB(y, ËœÏµ), then it follows from (11.43) that gi(Â¯x+Ï„z) < 0
for each i âˆˆI(Â¯x). Furthermore we obtain
âˆ¥(Â¯x + Ï„z) âˆ’Â¯xâˆ¥= Ï„âˆ¥zâˆ¥â‰¤Ï„(âˆ¥z âˆ’yâˆ¥+ âˆ¥yâˆ¥) â‰¤Ïµ(ËœÏµ + âˆ¥yâˆ¥) â‰¤Î´

250
11 Tangent and Normal Cones
which, by (11.44), implies gi(Â¯x + Ï„z) < 0 for each i âˆˆI \ I(Â¯x). Thus we
conclude that y âˆˆI(M1, Â¯x).
Ad (11.40). This follows from (11.39) and Lemma 11.1.3.
Ad (11.42). Let y0 âˆˆK âˆ©L<(Î³, Â¯x) and y âˆˆK âˆ©Lâ‰¤(Î³, Â¯x). For Î» âˆˆ(0, 1), set
yÎ» := Î»y0 + (1 âˆ’Î»)y. Then we have yÎ» âˆˆK âŠ†T(A, Â¯x) and
Î³i(yÎ») â‰¤Î»Î³i(y0) + (1 âˆ’Î»)Î³i(y) < 0
âˆ€i âˆˆI(Â¯x)
and so yÎ» âˆˆL<(Î³Â¯x). In view of (11.39) and Proposition 11.1.3, we conclude
that
yÎ» âˆˆT(A, Â¯x) âˆ©I(M1, Â¯x) âŠ†T(A âˆ©M1, Â¯x)
and so y = limÎ»â†“0 yÎ» âˆˆT(A âˆ©M1, Â¯x) because the latter set is closed
(Proposition 11.1.2). It is left as Exercise 11.7.9 to verify the assertions (11.35),
(11.36), and (11.38).
âŠ“âŠ”
Remark 11.4.6
(a) The assumption that gi, for each i âˆˆI(Â¯x), admits a (radial) upper convex
approximation Î³i at Â¯x may be interpreted as a â€œdiï¬€erentiabilityâ€ require-
ment. If gi is locally L-continuous around Â¯x, then by Theorem 7.3.2, the
Clarke directional derivative gâ—¦
i (Â¯x, Â·) as well as the Michelâ€“Penot direc-
tional derivative gâ™¦
i (Â¯x, Â·) are possible choices for Î³i âˆˆUC(gi, Â¯x).
(b) The above proof shows that for (11.35) and (11.39) the convexity of Î³i, i âˆˆ
I(Â¯x), is dispensable. Hence these statements also hold with Î³i replaced by
the upper directional G-derivative (or H-derivative) of gi at Â¯x.
(c) The conditions (11.37) and (11.41) are called regularity conditions or
constraint qualiï¬cations. Notice that the set L<(Î³, Â¯x) may be empty. In
Proposition 11.4.5, the set A is not assumed to be convex. However, if
A happens to be convex, then Tr(A, Â¯x) and T(A, Â¯x) are convex cones
(Proposition 11.1.2) and so we can choose Kr := Tr(A, Â¯x), K := Tr(A, Â¯x)
or K := T(A, Â¯x).
In the preceding results we used the contingent cone for the local approx-
imation of sublevel sets. Now we choose the Clarke tangent cone. We start
with a deï¬nition.
Deï¬nition 11.4.7 The subset M of E is said to be tangentially regular at
Â¯x âˆˆM if TC(M, Â¯x) = T(M, Â¯x).
Now we consider the sublevel set
M := {x âˆˆE | g(x) â‰¤g(Â¯x)}.
(11.45)
Theorem 11.4.8 Let g : E â†’R be locally L-continuous around Â¯x âˆˆE and
assume that o /âˆˆâˆ‚â—¦g(Â¯x). Then, with M according to (11.45), one has
{y âˆˆE | gâ—¦(Â¯x, y) â‰¤0} âŠ†TC(M, Â¯x).
(11.46)
If g is regular at Â¯x, then (11.46) holds with equality and M is tangentially
regular at Â¯x.

11.4 Representation of Tangent Cones
251
Proof.
(I) By the deï¬nition of âˆ‚â—¦g(Â¯x) and since o /âˆˆâˆ‚â—¦g(Â¯x), there exists y0 âˆˆE
such that gâ—¦(Â¯x, y0) < 0. Now let Ëœy be any element of the left-hand side
of (11.46). Since gâ—¦(Â¯x, Â·) is sublinear, it follows that gâ—¦(Â¯x, Ëœy + Ïµy0) < 0
for each Ïµ > 0. In step (II) we shall show that every y âˆˆE satisfying
gâ—¦(Â¯x, y) < 0 belongs to TC(M, Â¯x). It then follows that Ëœy+Ïµy0 âˆˆTC(M, Â¯x)
for each Ïµ > 0, and since TC(M, Â¯x) is closed (Proposition 11.1.2), we
conclude letting Ïµ â†“0 that Ëœy âˆˆTC(M, Â¯x). This veriï¬es (11.46).
(II) Let y âˆˆE be such that gâ—¦(Â¯x, y) < 0. By the deï¬nition of gâ—¦(Â¯x, y) there
exist Ïµ > 0 and Î´ > 0 such that
g(x + Ï„y) âˆ’g(x) â‰¤âˆ’Î´Ï„
âˆ€x âˆˆB(Â¯x, Ïµ)
âˆ€Ï„ âˆˆ(0, Ïµ).
(11.47)
Now let (xk) be a sequence in M converging to Â¯x and Ï„k â†“0. In view of
(11.47) we obtain for all suï¬ƒciently large k,
g(xk + Ï„ky) â‰¤g(xk) âˆ’Î´Ï„k â‰¤g(Â¯x) âˆ’Î´Ï„k
and so xk + Ï„ky âˆˆM. This shows that y âˆˆTC(M, Â¯x).
(III) We verify the regularity statement. Assume that g is regular at Â¯x. Since
(11.46) is already veriï¬ed and TC(M, Â¯x) âŠ†T(M, Â¯x) always holds, it
suï¬ƒces to show that T(M, Â¯x) is a subset of the left-hand side of (11.46).
Thus let y âˆˆT(M, Â¯x) be given. Then Proposition 11.1.5 shows that
lim infÏ„â†“0 Ï„ âˆ’1dM(Â¯x + Ï„y) = 0. Hence for each Ïµ > 0 we ï¬nd a sequence
Ï„k â†“0 such that for all suï¬ƒciently large k we have dM(Â¯x + Ï„ky) â‰¤ÏµÏ„k.
Thus there exists xk âˆˆM satisfying âˆ¥(Â¯x + Ï„ky) âˆ’xkâˆ¥â‰¤2ÏµÏ„k. Let Î»
denote a local Lipschitz constant of g around Â¯x. Then we obtain, again
for k suï¬ƒciently large,
g(Â¯x + Ï„ky) âˆ’g(xk) â‰¤Î»âˆ¥(Â¯x + Ï„ky) âˆ’xkâˆ¥â‰¤2ÏµÏ„kÎ»
and so
1
Ï„k

g(Â¯x + Ï„ky) âˆ’g(Â¯x)

â‰¤1
Ï„k

g(xk) âˆ’g(Â¯x)

+ 2ÏµÎ» â‰¤2ÏµÎ».
Letting k â†’âˆand then Ïµ â†“0, we conclude that gâ—¦(Â¯x, y) = gG(Â¯x, y) â‰¤0.
âŠ“âŠ”
Approximating Levelâ€“Sublevel Sets
We return to the contingent cone, now considering the set
A âˆ©M,
where
M := {x âˆˆE | gi(x) â‰¤0 (i = 1, . . . , m), h(x) = o},
Â¯x âˆˆA âˆ©M.

252
11 Tangent and Normal Cones
We again set I := {1, . . . , m} and I(Â¯x) := {i âˆˆI | gi(Â¯x) = 0}. We make the
following hypotheses:
(H) E and F are Banach spaces, A âŠ†E is nonempty closed and convex,
gi : E â†’R for i âˆˆI, Î³i âˆˆUC(gi, Â¯x) for i âˆˆI(Â¯x),
gi is upper semicontinuous at Â¯x for i âˆˆI \ I(Â¯x),
h : E â†’F is continuous on E and continuously diï¬€erentiable at Â¯x.
Theorem 11.4.9 Assume that the hypotheses (H) hold and that
hâ€²(Â¯x)

R+(A âˆ’Â¯x)

= F.
(11.48)
Then:
(a) There always holds
R+(A âˆ’Â¯x) âˆ©L<(Î³, Â¯x) âˆ©ker hâ€²(Â¯x) âŠ†T(A âˆ©M, Â¯x).
(b) If
R+(A âˆ’Â¯x) âˆ©L<(Î³, Â¯x) âˆ©ker hâ€²(Â¯x) Ì¸= âˆ…,
(11.49)
then
R+(A âˆ’Â¯x) âˆ©Lâ‰¤(Î³, Â¯x) âˆ©ker hâ€²(Â¯x) âŠ†T(A âˆ©M, Â¯x).
Proof.
(a) Let y âˆˆR+(A âˆ’Â¯x) âˆ©L<(Î³, Â¯x) âˆ©ker hâ€²(Â¯x). By Theorem 11.4.4 (with Q =
{o}) we obtain y âˆˆT(A âˆ©ker h, Â¯x), and Proposition 11.4.5(b) implies
y âˆˆI(M1, Â¯x). Thus the assertion follows with the aid of Proposition 11.1.3.
(b) This is veriï¬ed in analogy to formula (11.42) in Proposition 11.4.5.
âŠ“âŠ”
11.5 Contingent Derivatives and a Lyusternik Type
Theorem
We introduce a derivative-like concept for multifunctions. In Sect. 13.2 we
shall study an alternative construction.
Deï¬nition 11.5.1 Let Î¦ : E â‡’F be a multifunction and (Â¯x, Â¯y) âˆˆgraph Î¦.
The multifunction DÎ¦(Â¯x, Â¯y) : E â‡’F deï¬ned by
DÎ¦(Â¯x, Â¯y)(u) := Lim sup
uâ€²â†’u, Ï„â†“0
1
Ï„

Î¦(Â¯x + Ï„uâ€²) âˆ’Â¯y

,
u âˆˆE,
is called contingent derivative of Î¦ at (Â¯x, Â¯y).

11.5 Contingent Derivatives and a Lyusternik Type Theorem
253
The deï¬nition implies
graph

DÎ¦(Â¯x, Â¯y)

= T

graph Î¦, (Â¯x, Â¯y)

,
(11.50)
where the right-hand side is the contingent cone to graph Î¦ at (Â¯x, Â¯y). This
is why DÎ¦(Â¯x, Â¯y) is called contingent derivative. If Î¦ : E â†’F is Hadamard
diï¬€erentiable at Â¯x, then
DÎ¦(Â¯x, Î¦(Â¯x))(u) = {Î¦â€²(Â¯x)u}
âˆ€u âˆˆE,
i.e., DÎ¦(Â¯x, Î¦(Â¯x)) can be identiï¬ed with the Hadamard derivative Î¦â€²(Â¯x).
The contingent derivative turns out to be an appropriate tool to estab-
lish a tangential approximation of ker Î¦, where Î¦ is a multifunction (cf. the
tangential approximations derived in Sect. 11.4).
Theorem 11.5.2 Let E and F be Banach spaces. If the multifunction Î¦ :
E â‡’F is linearly semiopen around (Â¯x, o) âˆˆgraph Î¦, then
T(ker Î¦, Â¯x) = ker

DÎ¦(Â¯x, o)

.
(11.51)
Proof.
(I) First let u âˆˆT(ker Î¦, Â¯x) be given. Then there exist sequences uk â†’u and
Ï„k â†“0 such that o âˆˆÎ¦(Â¯x + Ï„kuk) for any k âˆˆN. It follows that
o âˆˆlim sup
kâ†’âˆ
1
Ï„k
Î¦(Â¯x + Ï„kuk) âŠ†DÎ¦(Â¯x, o)(u).
Hence u âˆˆker

DÎ¦(Â¯x, o)

.
(II) Now let u âˆˆker

DÎ¦(Â¯x, o)

be given. If u = o, then u âˆˆT(ker Î¦, Â¯x). Thus
assume that u Ì¸= o. Denote the semiopenness parameters of Î¦ around
(Â¯x, o) by Ï and Ï„0. By deï¬nition of DÎ¦(Â¯x, o) there exist sequences uk â†’u,
Ï„k â†“0, and vk âˆˆÎ¦(Â¯x+Ï„kuk) such that limkâ†’âˆvk/Ï„k = o. For suï¬ƒciently
large k, we have Â¯x+Ï„kuk âˆˆÂ¯x+Ï„0BE and vk âˆˆÏ„0BF . Again for suï¬ƒciently
large k, we further have âˆ¥ukâˆ¥â‰¥1
2âˆ¥uâˆ¥and so
Ï„ â€²
k :=
âˆ¥vkâˆ¥
ÏÏ„kâˆ¥ukâˆ¥â‰¤
2
Ïâˆ¥uâˆ¥Â· âˆ¥vkâˆ¥
Ï„k
â†’0
as k â†’âˆ.
Deï¬ne zk := Â¯x + Ï„kuk. Then we obtain
o âˆˆvk + âˆ¥vkâˆ¥BF = vk + ÏÏ„ â€²
kâˆ¥zk âˆ’Â¯xâˆ¥BF âŠ†Î¦(zk + Ï„ â€²
kâˆ¥zk âˆ’Â¯xâˆ¥BE);
here the latter inclusion is a consequence of the linear semiopenness of Î¦.
Hence there exists zâ€²
k âˆˆker(Î¦) satisfying âˆ¥zâ€²
k âˆ’zkâˆ¥â‰¤Ï„ â€²
kÏ„âˆ¥ukâˆ¥. Deï¬ne

254
11 Tangent and Normal Cones
yk :=
1
Ï„k (zâ€²
k âˆ’Â¯x). Then Â¯x + Ï„kyk âˆˆker Î¦. It remains to show that yk â†’u
as k â†’âˆ. This follows from
âˆ¥yk âˆ’ukâˆ¥= 1
Ï„k
âˆ¥zâ€²
k âˆ’zkâˆ¥â‰¤Ï„ â€²
kâˆ¥ukâˆ¥â†’0
as k â†’âˆ
and so
âˆ¥yk âˆ’uâˆ¥â‰¤âˆ¥yk âˆ’ukâˆ¥+ âˆ¥uk âˆ’uâˆ¥â†’0
as k â†’âˆ.
âŠ“âŠ”
Remark 11.5.3 We
show
that
the
classical
tangent
space
theorem
(Theorem 11.4.2) can be regained from Theorem 11.5.2. We use the assump-
tions and the notation of Theorem 11.4.2. Since the continuous linear mapping
hâ€²(Â¯x) is surjective, it is open by the Banach open mapping theorem. Hence
x â†’hâ€²(Â¯x)(x âˆ’Â¯x) is open at a linear rate, say Ï, around Â¯x. Furthermore,
since h is continuously diï¬€erentiable at Â¯x âˆˆker(h), there exists a mapping
r : E â†’F such that
h(x) = hâ€²(Â¯x)(x âˆ’Â¯x) + r(x),
where lim
xâ†’Â¯x r(x)/âˆ¥xâˆ¥= o,
(11.52)
and we have
1
âˆ¥x1 âˆ’x2âˆ¥

r(x1) âˆ’r(x2)

=
1
âˆ¥x1 âˆ’x2âˆ¥
#
h(x1) âˆ’h(x2)

âˆ’hâ€²(Â¯x)(x1 âˆ’x2)
$
â†’o
as x1, x2 â†’Â¯x.
Here the limit relation holds by Proposition 3.2.4(v) because h is strictly
diï¬€erentiable (Proposition 3.4.2). Hence for any Ïµ > 0 there exists Î´ > 0 such
that
âˆ¥r(x1) âˆ’r(x2)âˆ¥â‰¤Ïµâˆ¥x1 âˆ’x2âˆ¥
âˆ€x1, x2 âˆˆBE(Â¯x, Î´).
(11.53)
In particular, we can take Ïµ âˆˆ(0, Ï). Then Theorem 10.3.6 shows that the
mapping h is linearly semiopen around Â¯x. Therefore Theorem 11.5.2 implies
T(ker h, Â¯x) = ker

Dh(Â¯x)

= ker hâ€²(Â¯x).
(11.54)
The above argument suggests how to slightly weaken the hypotheses of
the Lyusternik theorem. In this connection, we consider the multifunction
hâ€²(Â¯x)âˆ’1 : F â‡’E which is deï¬ned as usual by
hâ€²(Â¯x)âˆ’1(y) := {x âˆˆE | hâ€²(Â¯x)(x) = y},
y âˆˆF.
Notice that hâ€²(Â¯x)âˆ’1 is a process and âˆ¥hâ€²(Â¯x)âˆ’1âˆ¥denotes its norm according to
(10.50).
Proposition 11.5.4 Assume that h : E â†’F is F-diï¬€erentiable at Â¯x âˆˆ
ker(h), that hâ€²(Â¯x) is surjective, and that the mapping r in (11.52) is locally
Lipschitz continuous at Â¯x with a Lipschitz constant Î» < 1/âˆ¥hâ€²(Â¯x)âˆ’1âˆ¥. Then
(11.54) holds.

11.6 Representation of Normal Cones
255
Proof. The mapping Î¦ : x â†’hâ€²(Â¯x)(x), interpreted as a multifunction, is open
at a linear rate around (o, o) (cf. Remark 11.5.3) and is a bounded process.
By Proposition 10.4.2, the openness bound of Î¦ around (o, o) is ope(Î¦)(o, o) =
1/âˆ¥hâ€²(Â¯x)âˆ’1âˆ¥. Since hâ€²(Â¯x) is linear, the mapping x â†’hâ€²(x âˆ’Â¯x) is open at a
linear rate around (Â¯x, o) with the same openness bound 1/âˆ¥hâ€²(Â¯x)âˆ’1âˆ¥. Now the
assertion follows by Theorems 10.3.6 and 11.5.2.
âŠ“âŠ”
Example 11.5.5 Deï¬ne h : R2 â†’R deï¬ned by
h(x1, x2) :=

ax1 + bx2 + x1x2
if x1 â‰¥0,
ax1 + bx2 âˆ’x1x2
if x1 < 0,
where |a| + |b| > 2. The function h satisï¬es the above assumptions at (0, 0)
while h is not diï¬€erentiable at (0, x2) if x2 Ì¸= 0 and so the classical Lyusternik
theorem does not apply.
11.6 Representation of Normal Cones
In this section we characterize normal cones of a set M âŠ†E which is deï¬ned
by an inequality or an equation.
The Clarke Normal Cone to Sublevel Sets
We start with the set
M := {x âˆˆE | f(x) â‰¤f(Â¯x)}.
(11.55)
Theorem 11.6.1 Let f
: E
â†’R be proper and locally L-continuous
around Â¯x. Assume that o /âˆˆâˆ‚â—¦f(Â¯x). Then, with M as in (11.55), one has
NC(M, Â¯x) âŠ†R+âˆ‚â—¦f(Â¯x).
(11.56)
If, in addition, f is regular at Â¯x, then (11.56) holds as an equation.
Proof. Taking polars in (11.46) (see Theorem 11.4.8), we obtain
NC(M, Â¯x) âŠ†{y âˆˆE | f â—¦(Â¯x, y) â‰¤0}â—¦=

âˆ‚â—¦f(Â¯x)
â—¦â—¦.
(11.57)
Here the equation follows by Proposition 7.3.7(b). Applying the bipolar the-
orem to the right-hand side and recalling that âˆ‚â—¦f(Â¯x) is weakâˆ—compact not
containing o, the assertion follows. If f is regular at Â¯x, then by Theorem 11.4.8
the inclusion in (11.57) is an equation and so is the inclusion in (11.56).
âŠ“âŠ”
Now let M be deï¬ned by
M := {x âˆˆE | fi(x) â‰¤0,
i = 1, . . . , n}.
(11.58)

256
11 Tangent and Normal Cones
Corollary 11.6.2 For i = 1, . . . , n, let fi : E â†’R be strictly H-diï¬€erentiable
at Â¯x, where f1(Â¯x) = Â· Â· Â· = fn(Â¯x) = 0. If the functionals f â€²
1(Â¯x), . . . , f â€²
n(Â¯x) are
positively linearly independent, then the set M in (11.58) is regular at Â¯x and
one has
NC(M, Â¯x) =
0
n
	
i=1
Î»if â€²
i(Â¯x)
 Î»i â‰¥0, i = 1, . . . , n
1
.
(11.59)
Proof. Deï¬ne f := max{f1, . . . , fn}. By Proposition 7.3.9(c), each fi is locally
L-continuous around Â¯x and so is f. Moreover, by Proposition 7.4.7, f is also
regular at Â¯x. Since M = {x âˆˆE | f(x) â‰¤0}, Theorem 11.6.1 implies that
(11.56) holds with equality. Finally, the maximum rule of Proposition 7.4.7
yields (11.59).
âŠ“âŠ”
The Proximal Normal Cone to Sublevel Sets
Next we give the complete, geometrically appealing proof for the represen-
tation of NP (M, Â¯x) in a Hilbert space and then indicate the more technical
proof for NF (M, Â¯x) in a FrÃ©chet smooth Banach space. We consider the set
M := {x âˆˆE | f(x) â‰¤0}.
(11.60)
Theorem 11.6.3 Let E be a Hilbert space and let M be given by (11.60),
where f : E â†’R is proper and l.s.c. Let Â¯x âˆˆM and u âˆˆNP (M, Â¯x). Then
either
(C1) for any Ïµ > 0 and Î· > 0 there exists x âˆˆE such that
âˆ¥x âˆ’Â¯xâˆ¥< Î·,
|f(x) âˆ’f(Â¯x)| < Î·,
âˆ‚P f(x) âˆ©BEâˆ—(o, Ïµ) Ì¸= âˆ…
or
(C2) for any Ïµ > 0 there exist x âˆˆE, v âˆˆâˆ‚P f(x), and Î» > 0 such that
âˆ¥x âˆ’Â¯xâˆ¥< Ïµ,
|f(x) âˆ’f(Â¯x)| < Ïµ,
âˆ¥Î»v âˆ’uâˆ¥< Ïµ.
Proof. Assuming that (C1) does not hold, we shall show that (C2) is valid.
Obviously we may suppose that u Ì¸= o.
(I) Since u âˆˆNP (M, Â¯x), Proposition 11.2.7 implies that there exist Ï > 0
and Ïƒ > 0 such that
0 â‰¥(u | x âˆ’Â¯x) âˆ’Ïƒâˆ¥x âˆ’Â¯xâˆ¥2
âˆ€x âˆˆM âˆ©B(Â¯x, Ïâˆ¥uâˆ¥).
(11.61)
Since f is l.s.c., there exists m > 0 such that, on diminishing Ï if
necessary, f(x) â‰¥âˆ’m for all x âˆˆB(Â¯x, Ïâˆ¥uâˆ¥). The functional x â†’
(u | xâˆ’Â¯x)âˆ’Ïƒâˆ¥xâˆ’Â¯xâˆ¥2 attains a positive value at x = Â¯x+2Î·u if Î· âˆˆ(0, 1
2Ïƒ).
By continuity, for Î· > 0 suï¬ƒciently small we have
(u | x âˆ’Â¯x) âˆ’Ïƒâˆ¥x âˆ’Â¯xâˆ¥2 > 0
âˆ€x âˆˆK := B(Â¯x + 2Î·u, 2Î·âˆ¥uâˆ¥) \ {Â¯x}.
Hence if x âˆˆK, then x /âˆˆM and so f(x) > 0.

11.6 Representation of Normal Cones
257
(II) For any positive Î± < min{Î·, 1/m} let
hÎ±(x) := Î±âˆ’1
max{0, âˆ¥x âˆ’Â¯x âˆ’Î·uâˆ¥âˆ’Î·âˆ¥uâˆ¥}
2,
pÎ±(z) := f(z) + hÎ±(z) + Î´B(Â¯x,Ïâˆ¥uâˆ¥)(z).
Since (C1) does not hold, o is not a proximal subderivative of f at Â¯x and
so infE pÎ± < 0. By Theorem 8.3.3 applied to pÎ± with
Î» :=
!
2ÏµÎ±/Î±,
Ïµ := ÏµÎ± := min{Î±/2, âˆ’inf
E pÎ±/2}
there exist yÎ±, wÎ± âˆˆE such that
âˆ¥yÎ± âˆ’wÎ±âˆ¥< Î»,
pÎ±(yÎ±) < inf
E pÎ± + ÏµÎ± < 0,
and the functional
z â†’pÎ±(z) + Î±
2 âˆ¥z âˆ’wÎ±âˆ¥2
(11.62)
attains a global minimum at z = yÎ±. Moreover, since pÎ±(yÎ±) < 0, we
have yÎ± âˆˆB(Â¯x, Ïâˆ¥uâˆ¥). We further obtain the following estimate:
hÎ±(yÎ±) â‰¤hÎ±(yÎ±) + Î±
2 âˆ¥yÎ± âˆ’wÎ±âˆ¥2
< hÎ±(yÎ±) + ÏµÎ±
(because âˆ¥yÎ± âˆ’wÎ±âˆ¥< Î»)
= pÎ±(yÎ±) + ÏµÎ± âˆ’f(yÎ±) < inf
E pÎ± + 2ÏµÎ± âˆ’f(yÎ±)
â‰¤âˆ’f(yÎ±) â‰¤m
(because 2ÏµÎ± â‰¤âˆ’inf
E pÎ±).
The deï¬nition of hÎ± shows that
âˆ¥yÎ± âˆ’Â¯x âˆ’Î·uâˆ¥â‰¤âˆšmÎ± + Î·âˆ¥uâˆ¥,
(11.63)
i.e.,
yÎ± âˆˆKÎ± := B(Â¯x + Î·u, âˆšmÎ± + Î·âˆ¥uâˆ¥).
On the other hand, pÎ±(yÎ±) < 0 implies f(yÎ±) < 0 and so yÎ± /âˆˆK (cf.
Fig. 11.6), i.e.,
âˆ¥yÎ± âˆ’Â¯x âˆ’2Î·uâˆ¥> 2Î·âˆ¥uâˆ¥.
(11.64)
K
KÎ±
Â¯x
yÎ±
Fig. 11.6

258
11 Tangent and Normal Cones
Applying the parallelogram identity to yÎ± âˆ’Â¯x âˆ’Î·u and Î·u, we obtain
âˆ¥yÎ± âˆ’Â¯xâˆ¥2 + âˆ¥yÎ± âˆ’Â¯x âˆ’2Î·uâˆ¥2 = 2âˆ¥yÎ± âˆ’Â¯x âˆ’Î·uâˆ¥2 + 2Î·2âˆ¥uâˆ¥2.
The estimates (11.63) and (11.64) now give
âˆ¥yÎ± âˆ’Â¯xâˆ¥2 â‰¤2(Î·âˆ¥uâˆ¥+ âˆšmÎ±)2 + 2Î·2âˆ¥uâˆ¥2 âˆ’4Î·2âˆ¥uâˆ¥2 = 4Î·âˆ¥uâˆ¥âˆšmÎ± + mÎ±,
showing that limÎ±â†’0 yÎ± = Â¯x.
(III) We further have
f(yÎ±) â‰¤pÎ±(yÎ±) < inf
E pÎ± + ÏµÎ± â‰¤pÎ±(Â¯x) + ÏµÎ± = f(Â¯x) + ÏµÎ±
and so limÎ±â†’0 f(yÎ±) = f(Â¯x) (recall that f is l.s.c. and ÏµÎ± â†’0 as Î± â†’0).
(IV) Since yÎ± is a global minimizer of the functional in (11.62) and yÎ± is in
ËšB(Â¯x, Ïâˆ¥uâˆ¥) for Î± suï¬ƒciently small, the functional
f âˆ’gÎ±,
where gÎ±(z) := âˆ’hÎ±(z) âˆ’Î±
2 âˆ¥z âˆ’wÎ±âˆ¥2
attains a local minimum at yÎ±. We have
gâ€²
Î±(yÎ±) = âˆ’hâ€²(yÎ±) âˆ’Î±(yÎ± âˆ’wÎ±) = k(Î±)(Â¯x + Î·u âˆ’yÎ±) + Î±(wÎ± âˆ’yÎ±),
where
k(Î±) :=
â§
â¨
â©
2(âˆ¥yÎ± âˆ’Â¯x âˆ’Î·uâˆ¥âˆ’Î·âˆ¥uâˆ¥)
Î±âˆ¥yÎ± âˆ’Â¯x âˆ’Î·uâˆ¥
if hÎ±(yÎ±) > 0,
0
if hÎ±(yÎ±) = 0.
Observe that the F-derivative of hÎ± is locally L-continuous and that in
particular hâ€²
Î±(x) = o whenever hÎ±(x) = 0. Hence for each Î± suï¬ƒciently
small, gâ€²
Î±(yÎ±) is a proximal subgradient of f at Â¯x.
(V) Assume that lim infÎ±â†’0 k(Î±) = 0. Then for some sequence Î±i â†’0 we
had gâ€²(yÎ±i) â†’o as i â†’âˆand so (C1) would hold: a contradiction.
Therefore the lim inf is positive. We have gâ€²
Î±(yÎ±) = Î·k(Î±)(u + o(1)) as
Î± â†’0. It follows that for Î± small enough,
âˆ¥yÎ± âˆ’Â¯xâˆ¥< Ïµ,
|f(yÎ±) âˆ’f(Â¯x)| < Ïµ,

1
Î·k(Î±)gâ€²
Î±(yÎ±) âˆ’u
 < Ïµ.
Hence assertion (C2) holds with x := yÎ±, Î» := 1/Î·k(Î±), and v := gâ€²(yÎ±).
âŠ“âŠ”
The Proximal Normal Cone to Level Sets
Now we consider the set
M := {x âˆˆE | f(x) = 0}.
(11.65)

11.6 Representation of Normal Cones
259
Theorem 11.6.4 Let E be a Hilbert space and let M be given by (11.65),
where f : E â†’R is continuous. Let Â¯x âˆˆM and u âˆˆNP (M, Â¯x). Then either
(D1) for any Ïµ > 0 and Î· > 0 there exists x âˆˆE such that
âˆ¥x âˆ’Â¯xâˆ¥< Î·,
|f(x) âˆ’f(Â¯x)| < Î·,

âˆ‚P f(x) âˆªâˆ‚P (âˆ’f)(x)

âˆ©BEâˆ—(o, Ïµ) Ì¸= âˆ…
or
(D2) for any Ïµ > 0 there exist x âˆˆE, v âˆˆâˆ‚P f(x) âˆªâˆ‚P (âˆ’f)(x), and Î» > 0
such that
âˆ¥x âˆ’Â¯xâˆ¥< Ïµ,
|f(x) âˆ’f(Â¯x)| < Ïµ,
âˆ¥Î»v âˆ’uâˆ¥< Ïµ.
Sketch of the Proof. As in the proof of Theorem 11.6.3 we may suppose that
u Ì¸= o. Deï¬ne Ï, K, and hÎ± as above, and m as upper bound of |f|. Then
f(x) Ì¸= 0 for all x âˆˆK and so (since K is convex and f is continuous), f does
not change sign on K. Deï¬ne
pÎ± :=

f + hÎ± + Î´B(Â¯x,Ïâˆ¥uâˆ¥)
if f is positive on K,
âˆ’f + hÎ± + Î´B(Â¯x,Ïâˆ¥uâˆ¥)
if f is negative on K.
The argument is now analogous to that in the preceding proof.
âŠ“âŠ”
The FrÃ©chet Normal Cone to Sublevel Sets
Now we pass to the FrÃ©chet normal cone. In this connection, we shall make
use of the following condition:
lim inf
xâ†’f Â¯x d

o, âˆ‚F f(x)

> 0;
(11.66)
here, x â†’f Â¯x means that x â†’Â¯x and f(x) â†’f(Â¯x). Condition 11.66 will serve
to exclude a case analogous to (C1) in Theorem 11.6.3.
Theorem 11.6.5 Let E be a FrÃ©chet smooth Banach space and let M :=
{x âˆˆE | f(x) â‰¤0}, where f : E â†’R is proper and l.s.c. Assume that (11.66)
holds. Let Â¯x âˆˆM and u âˆˆNF (M, Â¯x). Then for any Ïµ > 0 there exist x âˆˆE,
v âˆˆâˆ‚F f(x), and Î» > 0 such that
âˆ¥x âˆ’Â¯xâˆ¥< Ïµ,
|f(x) âˆ’f(Â¯x)| < Ïµ,
âˆ¥Î»v âˆ’uâˆ¥< Ïµ.
Sketch of the Proof. Let c be such that 0 < c < lim infxâ†’f Â¯x d

o, âˆ‚F f(x)

.
It is shown that Î·, Î´ âˆˆ(0, Ïµ) can be chosen such that

Â¯x + K(u, Î·)

âˆ©M âˆ©B(Â¯x, Î´) = {Â¯x},

260
11 Tangent and Normal Cones
where K(u, Î·) denotes the Bishopâ€“Phelps cone. Deï¬ne A := Â¯x+K(u, 2Î·) and
gi(x) := f(x) + i dA(x) for any x âˆˆE. We distinguish two cases:
(I) If
inf
B(Â¯x,Î´) gi < 0, then Ekelandâ€™s variational principle of Corollary 8.2.6
ensures the existence of some yi âˆˆB(Â¯x, Î´) that minimizes the functional
hi(x) := gi(x) + 1
i âˆ¥x âˆ’yiâˆ¥
over B(Â¯x, Î´) and is such that gi(yi) < 0. It can be shown that
Î·
2Î· + 1âˆ¥yi âˆ’Â¯xâˆ¥â‰¤dA(yi) â†’0
as i â†’âˆ
and so yi â†’Â¯x as i â†’âˆ. Therefore, yi âˆˆËšB(Â¯x, Î´) for i suï¬ƒciently large.
(II) If
inf
B(Â¯x,Î´) gi = 0, then set yi := Â¯x for any i.
Hence in both cases, yi is a local minimizer of hi for any suï¬ƒciently large i.
By the approximate sum rule of Theorem 9.2.6, for these i there exist xi, zi âˆˆ
ËšB(Â¯x, Î´), xâˆ—
i âˆˆâˆ‚F f(xi), and zâˆ—
i âˆˆâˆ‚F dA(zi) such that |f(xi) âˆ’f(Â¯x)| < Î´ and
âˆ¥xâˆ—
i + izâˆ—
i âˆ¥< Î· + 1/i.
(11.67)
By using the separation theorem it can be shown that
âˆ‚F dA(zi) âŠ†{Î±(âˆ’u + 2Î·âˆ¥uâˆ¥BEâˆ—| Î± > 0} âˆ©BEâˆ—.
Therefore, zâˆ—
i = Î±i(âˆ’u + 2Î·âˆ¥uâˆ¥bâˆ—for some Î±i > 0 and some bâˆ—âˆˆBEâˆ—. Now
it follows from (11.67) that âˆ¥xâˆ—
i âˆ’iÎ±iuâˆ¥< 2iÎ±iâˆ¥uâˆ¥Î· + Î· + 1/i. We must
conclude that iÎ±i > c/(2âˆ¥uâˆ¥(1 + 2Î·)) because otherwise we had âˆ¥xâˆ—
i âˆ¥< c
which contradicts the choice of c. Letting Î»i := 1/(iÎ±i), we obtain
âˆ¥Î»ixâˆ—
i âˆ’uâˆ¥< 2Î·âˆ¥uâˆ¥+ 2Î·âˆ¥uâˆ¥(1 + 2Î·)
c
+ 2âˆ¥uâˆ¥(1 + 2Î·)
ic
.
Thus, if i > 4âˆ¥uâˆ¥(1 + 2Î·)/cÏµ, then setting Î» := Î»i, x := xi, and v := xâˆ—
i , we
have âˆ¥Î»v âˆ’uâˆ¥< Ïµ.
âŠ“âŠ”
The FrÃ©chet Normal Cone to Level Sets
Now we consider the condition
lim inf
xâ†’Â¯x d

o, âˆ‚F f(x) âˆªâˆ‚F (âˆ’f)(x)

> 0.
(11.68)
Theorem 11.6.6 Let E be a FrÃ©chet smooth Banach space and let M :=
{x âˆˆE | f(x) = 0}, where f : E â†’R is continuous. Assume that (11.68)
holds. Let Â¯x âˆˆM and u âˆˆNF (M, Â¯x). Then for any Ïµ > 0 there exist x âˆˆE,
v âˆˆâˆ‚F f(x) âˆªâˆ‚F (âˆ’f)(x), and Î» > 0 such that
âˆ¥x âˆ’Â¯xâˆ¥< Ïµ,
|f(x) âˆ’f(Â¯x)| < Ïµ,
âˆ¥Î»v âˆ’uâˆ¥< Ïµ.

11.7 Bibliographical Notes and Exercises
261
Sketch of the Proof. Let c be such that
0 < c < lim inf
xâ†’Â¯x d

o, âˆ‚F f(x) âˆªâˆ‚F (âˆ’f)(x)

.
Again it is shown that Î·, Î´ âˆˆ(0, Ïµ) can be chosen such that

Â¯x + K(u, Î·)

âˆ©M âˆ©B(Â¯x, Î´) = {Â¯x}.
Since f is continuous, it follows that:
(a) f(x) â‰¥0 for all x âˆˆ

Â¯x + K(u, Î·)

âˆ©B(Â¯x, Î´) or
(b) f(x) â‰¤0 for all x âˆˆ

Â¯x + K(u, Î·)

âˆ©B(Â¯x, Î´).
Deï¬ne A := Â¯x + K(u, 2Î·) and for each i,
gi :=

f + i dA
in case (a),
âˆ’f + i dA
in case (b).
The remainder of the proof is analogous to that of Theorem 11.6.5.
âŠ“âŠ”
11.7 Bibliographical Notes and Exercises
Normal cones to convex sets can be traced back to Minkowski [131] and
were studied systematically by Fenchel [66]. The contingent cone goes back to
Bouligand [26]. Clarke [34] introduced (in ï¬nite-dimensional spaces) the cone
TC(A, Â¯x) according to the formula in Proposition 11.1.6. The sequential char-
acterization of TC(A, Â¯x), taken here as deï¬nition, is due to Hiriart-Urruty [85].
Proposition 11.1.9 was established by Rockafellar [184].
Proximal normals already appear, under the name perpendicular vectors,
with Clarke [33]. The results on proximal normals presented above are essen-
tially taken from Clarke et al. [39]. Theorem 11.4.8 is due to Rockafellar [183]
(cf. Clarke [36]).
Theorem 11.4.1 was established by Robinson [175] and Zowe and Kur-
cyusz [228], while Theorem 11.4.2 is a classical result of Lyusternik [128]
(see also Graves [79]). The concept of contingent cone was introduced by
Aubin [5]. Theorem 11.5.2 is due to PÂ¨uhl and Schirotzek [173] (see also
PÂ¨uhl [172]). Proposition 11.5.4 and its proof are taken from PÂ¨uhl [172]. In
a diï¬€erent way, Ledzevicz and Walczak [122] deduced the result under the ad-
ditional hypothesis that ker hâ€²(Â¯x) has a topological complement in E. These
authors also constructed Example 11.5.5. Lyusternik type results related to
Theorem 11.5.2 were established, among others, by Cominetti [40], Klatte and
Kummer [110], and Penot [161].
Theorems 11.6.3â€“11.6.6 are taken from Borwein et al. [21] (see also Borwein
and Zhu [24]).
For more results on tangents and normals, we refer to Aubin and
Frankowska [8] and Clarke et al. [39]. By now, a lot of further tangent

262
11 Tangent and Normal Cones
and normal sets, not all of them cones and most of them not convex, have
been introduced in the literature (see the detailed discussion in Rockafellar
and Wets [189]).
Exercise 11.7.1 Fill the gaps in the proof of Proposition 11.1.2.
Exercise 11.7.2 Prove the inclusion (11.1) in Proposition 11.1.3.
Exercise 11.7.3 Verify Proposition 11.1.5.
Exercise 11.7.4 Prove Lemma 11.1.8.
Exercise 11.7.5 Prove Proposition 11.1.13.
Exercise 11.7.6 Prove Proposition 11.2.8.
Exercise 11.7.7 Let A âŠ†E be closed and Â¯x âˆˆA. Show that NF (A, Â¯x) is
closed and convex.
Exercise 11.7.8 Let A be a closed subset of a FrÃ©chet smooth Banach space
and Â¯x âˆˆA. Formulate and verify a representation of NC(A, Â¯x) in terms of
F-normals to A at Â¯x. Hint: Recall Proposition 9.5.1.
Exercise 11.7.9 Verify the assertions (11.35), (11.36), and (11.38) of
Proposition 11.4.5.
Exercise 11.7.10 Deï¬ne for any (x1, x2) âˆˆR2,
g1(x1, x2) := x2 âˆ’x3
1, g2(x1, x2) := âˆ’x2, Ëœg1 = g1, Ëœg2 := g2, Ëœg3(x1, x2) := âˆ’x1.
Show that
M := {(x1, x2) âˆˆR2 | gi(x1, x2) â‰¤0 (i = 1, 2)}
= {(x1, x2) âˆˆR2 | Ëœgk(x1, x2) â‰¤0 (k = 1, 2, 3)}
but for Â¯x := (0, 0) one has Lâ‰¤((Î³1, Î³2), Â¯x) Ì¸= Lâ‰¤((ËœÎ³1, ËœÎ³2, ËœÎ³3), Â¯x). Also calculate
T(M, Â¯x) (cf. Elster et al. [59]).
Exercise 11.7.11 The aim of this exercise is to generalize Theorem 11.4.9
(cf. Schirotzek [196]). Assume that E and H are Banach spaces, G is a normed
vector space, A âŠ†E is nonempty closed and convex, P âŠ†G is a convex cone
with nonempty interior, and Q âŠ†H is a closed convex cone. Further let
g : E â†’G and h : E â†’H be given, deï¬ne
M := {x âˆˆE | g(x) âˆˆâˆ’P, h(x) âˆˆâˆ’Q}
and let Â¯x âˆˆA âˆ©M. Assume that the directional H-derivative dHg(Â¯x, Â·) exists
and is P-convex on E, and that h is continuous on E and continuously
diï¬€erentiable at Â¯x. Finally deï¬ne
Li(g, Â¯x) := {y âˆˆE | dH(Â¯x, y) âˆˆâˆ’int P + R g(Â¯x)},
L(g, Â¯x) := {y âˆˆE | dH(Â¯x, y) âˆˆâˆ’P + R g(Â¯x)},
L(h, Â¯x) := {y âˆˆE | hâ€²(Â¯x)y âˆˆâˆ’Q + R h(Â¯x)}.

11.7 Bibliographical Notes and Exercises
263
(a) Modeling the proof of Theorem 11.4.9(b), prove the following:
Theorem 11.7.12 Assume that
R+(A âˆ’Â¯x) âˆ©Li(g, Â¯x) âˆ©L(h, Â¯x) Ì¸= âˆ…
and
hâ€²(Â¯x)

R+(A âˆ’Â¯x)

+ R+(Q + h(Â¯x)) = H.
Then one has
R+(A âˆ’Â¯x) âˆ©L(g, Â¯x) âˆ©L(h, Â¯x) âŠ†T(A âˆ©M, Â¯x).
(b) Formulate and verify a corresponding result that is analogous to
Theorem 11.4.9(a).

12
Optimality Conditions for Nonconvex Problems
12.1 Basic Optimality Conditions
Let f : E â†’R be proper, let A âŠ†E, and let Â¯x âˆˆA âˆ©dom f. As shown in
Sect. 7.1, the method of tangent directions leads to the following result.
Proposition 12.1.1 Let Â¯x be a local minimizer of f on A.
(a) One has f G(Â¯x, y) â‰¥0 for any y âˆˆTr(A, Â¯x) and f H(Â¯x, y) â‰¥0 for any
y âˆˆT(A, Â¯x).
(b) If f is G-diï¬€erentiable at Â¯x, then âŸ¨f â€²(Â¯x), yâŸ©â‰¥0 for any y âˆˆTr(A, Â¯x).
(c) If f is H-diï¬€erentiable at Â¯x, then âŸ¨f â€²(Â¯x), yâŸ©â‰¥0 for any y âˆˆT(A, Â¯x).
We apply the method of penalization (cf. Sect. 7.1). In the case of a locally
L-continuous functional, a penalty term of the form Î»dA is adequate.
Proposition 12.1.2 Let f be locally L-continuous with L-constant Ë†Î» on an
open set U containing A. If Â¯x is a minimizer of f on A, then for all Î» â‰¥Ë†Î», Â¯x
is a minimizer of f + Î»dA on U (hence a local minimizer of f + Î»dA on E).
Proof. By assumption we have
f(z) âˆ’Ë†Î»âˆ¥y âˆ’zâˆ¥â‰¤f(y) â‰¤f(z) + Ë†Î»âˆ¥y âˆ’zâˆ¥
âˆ€y, z âˆˆU,
f(Â¯x) â‰¤f(y)
âˆ€y âˆˆA.
Let z âˆˆU and Ïµ > 0. Then there exists y âˆˆA such that âˆ¥y âˆ’zâˆ¥â‰¤dA(z) + Ïµ.
It follows that
f(Â¯x) + Î»dA(Â¯x) = f(Â¯x) â‰¤f(y) â‰¤f(z) + Ë†Î»âˆ¥y âˆ’zâˆ¥â‰¤f(z) + Î»dA(z) + Î»Ïµ.
Letting Ïµ â†“0 proves the assertion.
âŠ“âŠ”
Now we can supplement the optimality criteria in Proposition 12.1.1.

266
12 Optimality Conditions for Nonconvex Problems
Proposition 12.1.3 Let f be locally L-continuous on an open set contain-
ing A. If Â¯x is a local minimizer of f on A, then
f â—¦(Â¯x, y) â‰¥0
âˆ€y âˆˆTC(A, Â¯x)
and
o âˆˆâˆ‚â—¦f(Â¯x) + NC(A, Â¯x).
Proof.
(I) Let Î· > 0 be such that Â¯x minimizes f on AÎ· := A âˆ©B(Â¯x, Î·). Then
0 â‰¤(f + Î»dAÎ·)â—¦(Â¯x, y) â‰¤f â—¦(Â¯x, y) + Î»dâ—¦
AÎ·(Â¯x, y)
âˆ€y âˆˆE;
(12.1)
the inequalities are a consequence of Proposition 12.1.2 and the deï¬ni-
tion of Clarkeâ€™s directional derivative. By Proposition 11.1.6 we obtain
f â—¦(Â¯x, y) â‰¥0 for all y âˆˆTC(AÎ·, Â¯x). By Proposition 11.1.2(c), TC(AÎ·, Â¯x) is
equal to TC(A, Â¯x).
(II) From (12.1) we deduce o âˆˆâˆ‚â—¦(f + Î»dAÎ·)(Â¯x). The sum rule (Proposi-
tion 7.4.3) and Proposition 11.2.4 show that o âˆˆâˆ‚â—¦f(Â¯x) + NC(AÎ·, Â¯x).
As in step (I) we have NC(AÎ·, Â¯x) = NC(A, Â¯x).
âŠ“âŠ”
Next we assume that f is l.s.c. only. Again we apply the method of penal-
ization, now with the penalty term Î´A. Recall that if Â¯x is a local minimizer of
f on A, then Â¯x is a local minimizer of f + Î´A on E. The generalized Fermat
rule of Proposition 9.1.5 thus yields
o âˆˆâˆ‚F (f + Î´A)(Â¯x).
(12.2)
It remains to apply a sum rule. However, in general we only have approximate
sum rules for F-subdiï¬€erentials unless f is F-diï¬€erentiable at Â¯x. Accordingly
we obtain approximate optimality conditions only. In particular, applying the
weak approximate sum rule of Theorem 9.2.7 to (12.2), we obtain:
Proposition 12.1.4 Assume that E is a FrÃ©chet smooth Banach space, f :
E â†’R is proper and l.s.c., and A is a closed subset of E. Let Â¯x âˆˆA be a local
minimizer of f on A. Then for any Ïµ > 0 and any weakâˆ—neighborhood V of
zero in Eâˆ—, there exist x0, x1 âˆˆB(Â¯x, Ïµ) such that x1 âˆˆA, |f(x0) âˆ’f(x1)| < Ïµ,
and
o âˆˆâˆ‚F f(x0) + NF (A, x1) + V.
Proof. See Exercise 12.6.1.
âŠ“âŠ”
In Sect. 13.7 we shall derive, in FrÃ©chet smooth Banach spaces, exact nec-
essary optimality conditions in terms of another subdiï¬€erential.
To conclude, recall that âˆ‚Ff(Â¯x)
:=
âˆ’âˆ‚F (âˆ’f)(Â¯x) denotes the F-
superdiï¬€erential of f at Â¯x. For certain classes of nondiï¬€erentiable functionals
this is an adequate derivative-like object, e.g., for concave continuous func-
tionals. In this case, we have a quite strong optimality condition.

12.2 Application to the Calculus of Variations
267
Proposition 12.1.5 Assume that E is a FrÃ©chet smooth Banach space and
f : E â†’R is proper and l.s.c. If Â¯x is a local minimizer of f on A, then
âˆ’âˆ‚Ff(Â¯x) âŠ†NF (A, Â¯x).
Proof. There is nothing to prove if âˆ‚Ff(Â¯x) is empty. Now let xâˆ—âˆˆâˆ’âˆ‚Ff(Â¯x)
be given. Then there exists a function g : E â†’R that is F-diï¬€erentiable at Â¯x
with gâ€²(Â¯x) = xâˆ—and
0 = (âˆ’f âˆ’g)(Â¯x) â‰¤(âˆ’f âˆ’g)(x)
for any x near Â¯x.
By assumption on Â¯x we further have f(Â¯x) â‰¤f(x) for any x âˆˆA near Â¯x.
It follows that Â¯x is a local minimizer of âˆ’g on A. From Proposition 9.2.2 we
obtain that
xâˆ—= âˆ’(âˆ’g)â€²(Â¯x) âˆˆâˆ‚F Î´A(Â¯x) = NF (A, Â¯x),
which completes the proof.
âŠ“âŠ”
12.2 Application to the Calculus of Variations
We consider the classical ï¬xed end point problem in the calculus of variations:
Minimize f(x) :=
 b
a
Ï•

t, x(t), Ë™x(t)

dt,
x âˆˆA,
where
A := {x âˆˆE | x(a) = Î±, x(b) = Î²},
E := ACâˆ[a, b].
(12.3)
Recall that E is a Banach space with respect to the norm âˆ¥xâˆ¥1,âˆ(see
Example 3.6.3). The following results hold analogously for absolutely con-
tinuous functions on [a, b] with values in Rn.
The Smooth Case
First we repeat a classical result, making the following assumptions:
(A) The real-valued function (t, x, v) â†’Ï•(t, x, v) is continuous on [a, b]Ã—RÃ—R
and has continuous ï¬rst-order partial derivatives with respect to x and
v there; a, b, Î±, Î² are given real numbers with a < b.
If Â¯x âˆˆE, we write
Ï•(t) := Ï•

t, Â¯x(t), Ë™Â¯x(t)

,
t âˆˆ[a, b].
As shown in Example 3.6.3, the functional f is G-diï¬€erentiable (even contin-
uously diï¬€erentiable) at each Â¯x âˆˆE and
âŸ¨f â€²(Â¯x), yâŸ©=
 b
a

Ï•x(t) Â· y(t) + Ï•v(t) Â· Ë™y(t)

dt,
y âˆˆE.

268
12 Optimality Conditions for Nonconvex Problems
It is immediate that
T(A, Â¯x) = Tr(A, Â¯x) = {x âˆˆE | x(a) = x(b) = 0} =: E0.
(12.4)
Assume now that Â¯x âˆˆA is a local minimizer of f on A. Then Proposition 12.1.1
gives
 b
a

Ï•x(t) Â· y(t) + Ï•v(t) Â· Ë™y(t)

dt = 0
âˆ€y âˆˆE0;
(12.5)
notice that we have equality here since E0 is a linear subspace of E. Let
q(t) :=
 t
a
Ï•x(s) ds,
t âˆˆ[a, b].
Then q is absolutely continuous and
Ë™q(t) = Ï•x(t)
for almost all t âˆˆ[a, b].
(12.6)
Using this and applying partial integration to the ï¬rst term on the left-hand
side of (12.5), we obtain
 b
a

Ï•v(t) âˆ’q(t)

Â· Ë™y(t) dt = 0
âˆ€y âˆˆE0.
(12.7)
Now we need the following fundamental lemma of the calculus of variations.
Lemma 12.2.1 (Du Boisâ€“Reymond) Assume that g, h âˆˆL1[a, b] and
 b
a

h(t) Â· y(t) + g(t) Â· Ë™y(t)

dt = 0
âˆ€y âˆˆE0.
Then the function g is absolutely continuous and satisï¬es Ë™g(t) = h(t) for
almost all t âˆˆ[a, b].
The proof of this lemma or one of its various modiï¬cations can be found in
any standard book on the calculus of variations (see, for instance, Cesari [30]
or Giaquinta and Hildebrandt [71], see also Loewen [123]).
Applying Lemma 12.2.1 with h = o to (12.7), we obtain the following
result.
Proposition 12.2.2 Let the assumptions (A) be satisï¬ed. If Â¯x is a local
solution of (12.3), then there exists an absolutely continuous function p :
[a, b] â†’R such that

Ë™p(t)
p(t)

=

Ï•x(t)
Ï•v(t)

for almost all t âˆˆ[a, b].
(12.8)
Eliminating the function p, we see that under the assumptions of Propo-
sition 12.2.2 the function t â†’Ï•v(t) is absolutely continuous on [a, b] and
satisï¬es
d
dtÏ•v(t) = Ï•x(t)
for almost all t âˆˆ[a, b].
(12.9)
This is the Eulerâ€“Lagrange equation for Problem (12.3).

12.2 Application to the Calculus of Variations
269
The Nonsmooth Case
Our purpose now is to weaken the diï¬€erentiability hypotheses of (A).
Denote by L1 the Ïƒ-algebra of all Lebesgue measurable subsets of [a, b], by
Bn the Ïƒ-algebra of all Borel subsets of Rn, and by L1Ã—Bn the corresponding
product Ïƒ-algebra. Let Â¯x âˆˆM be given. We make the following assumptions:
(Ë†A) The function Ï• : [a, b]Ã—RÃ—R â†’Râˆª{+âˆ} is L1Ã—B2-measurable. There
exist Ïµ > 0 and a positive function g âˆˆL1[a, b] such that for almost all
t âˆˆ[a, b] the function (x, v) â†’Ï•(t, x, v) is real-valued and Lipschitz
continuous on

Â¯x(t), Ë™Â¯x(t)

+ ÏµB with Lipschitz constant g(t).
We establish a generalization of Proposition 12.2.2.
Theorem 12.2.3 Let the assumptions (Ë†A) be satisï¬ed. If Â¯x is a local solution
of (12.3), then there exists an absolutely continuous function p : [a, b] â†’R
such that
 Ë™p(t)
p(t)

âˆˆâˆ‚â—¦Ï•(t, Â¯x(t), Ë™Â¯x(t))
for almost all t âˆˆ[a, b].
(12.10)
Here, âˆ‚â—¦Ï•(t, Â¯x(t), Ë™Â¯x(t)) denotes the Clarke subdiï¬€erential of the function
(x, v) â†’Ï•(t, x, v) at the point ((x(t), Ë™x(t)).
Notice that under the assumptions (A), Proposition 7.3.9 implies
âˆ‚â—¦Ï•(t, Â¯x(t), Ë™Â¯x(t)) =
Ï•x(t)
Ï•v(t)

so that (12.10) passes into (12.8).
To prepare the proof of Theorem 12.2.3, we quote two propositions. The
ï¬rst is a measurable selection statement which we take from Loewen [123].
Proposition 12.2.4 Let g : [a, b] Ã— R â†’R âˆª{+âˆ} be L1 Ã— B1-measurable
and let p âˆˆ[1, +âˆ). Assume that:
â€“ For each t âˆˆ[a, b] the function v â†’g(t, v) is lower semicontinuous and
real-valued at some point of R.
â€“ There exists Ëœu âˆˆLp[a, b] such that the function t â†’g(t, Ëœu(t)) is integrable
over [a, b].
Then the integral of the function t â†’infvâˆˆR g(t, v) over [a, b] is deï¬ned (per-
haps equal to âˆ’âˆ), and one has
 b
a
inf
vâˆˆR g(t, v) dt =
inf
uâˆˆLp[a,b]
 b
a
g(t, u(t)) dt.
The next result is Aubinâ€™s nonsymmetric minimax theorem (see Aubin [6] or
Aubin and Ekeland [7]).

270
12 Optimality Conditions for Nonconvex Problems
Proposition 12.2.5 Let K be a compact convex subset of a topological vector
space, let U be a convex subset of a vector space, and let h : K Ã— U â†’R be a
function such that:
â€“ For each u âˆˆU, the function x â†’h(x, u) is convex and l.s.c.
â€“ For each x âˆˆK, the function u â†’âˆ’h(x, u) is convex.
Then there exists Ë†x âˆˆK such that
sup
uâˆˆU
h(Ë†x, u) = sup
uâˆˆU
inf
xâˆˆK
h(x, u).
In particular,
inf
xâˆˆK
sup
uâˆˆU
h(x, u) = sup
uâˆˆU
inf
xâˆˆK
h(x, u).
Proof of Theorem 12.2.3. By Proposition 12.1.1 and (12.4) we have for each
y âˆˆE0,
0 â‰¤f G(Â¯x, y)
= lim sup
Ï„â†“0
 b
a
Ï„ âˆ’1
Ï•

t, Â¯x(t) + Ï„y(t), Ë™Â¯x(t) + Ï„ Ë™y(t)

âˆ’Ï•

t, Â¯x(t), Ë™Â¯x(t)

dt.
By assumption (Ë†A), the integrand on the right-hand side is a measurable
function of t and, for almost all t âˆˆ[a, b], is majorized by the integrable
function g(t)âˆ¥

y(t), Ë™y(t)

âˆ¥. Hence by a variant of the Fatou lemma, we have
lim sup
" b
a Â· Â· Â· â‰¤
" b
a lim sup Â· Â· Â· , and it follows that
0 â‰¤
 b
a
Ï•â—¦
t, Â¯x(t), Ë™Â¯x(t); y(t), Ë™y(t)

dt;
(12.11)
here Ï•â—¦(Â· Â· Â· ) denotes the Clarke directional derivative of the function (x, v) â†’
Ï•(t, x, v) at the point (Â¯x(t), Ë™Â¯x(t)) in the direction (y(t), Ë™y(t)). The relation
(12.11) holds for any y âˆˆE0, in particular for y = o. Therefore we have
0 = inf
yâˆˆE0
 b
a
Ï•â—¦
t, Â¯x(t), Ë™Â¯x(t); y(t), Ë™y(t)

dt.
Applying Proposition 7.3.7 we further obtain
0 = inf
yâˆˆE0
 b
a
sup

(u(t), p(t)), (y(t), Ë™y(t))
  (u(t), p(t)) âˆˆâˆ‚â—¦Ï•(t, Â¯x(t), Ë™Â¯x(t))

dt,
which by Proposition 12.2.4 passes into
0 = inf
yâˆˆE0
sup
(u,p)âˆˆK
 b
a

u(t) y(t) + p(t) Ë™y(t)

dt,
(12.12)
where
K := {(u, p) âˆˆL1 Ã— L1  (u(t), p(t)) âˆˆâˆ‚â—¦Ï•(t, Â¯x(t), Ë™Â¯x(t)), t âˆˆ[a, b] (a.e.)};

12.2 Application to the Calculus of Variations
271
here, L1 stands for L1[a, b]. The set K is convex and weakly compact and the
integral in (12.12) depends bilinearly on u, p. Hence by Proposition 12.2.5, the
inï¬mum and the supremum in (12.12) can be interchanged and the supremum
is attained at some (u, p) âˆˆK, i.e., we have
0 = inf
yâˆˆE0
 b
a

u(t) y(t) + p(t) Ë™y(t)

dt.
Since the integral depends linearly on y, we can conclude that
0 =
 b
a

u(t) y(t) + p(t) Ë™y(t)

dt
âˆ€y âˆˆE0.
Applying Lemma 12.2.1, we see that p is absolutely continuous and Ë™p(t) = u(t)
for almost all t âˆˆ[a, b]. In view of the deï¬nition of K, the proof is complete.
âŠ“âŠ”
Finally we indicate how to extend the class of problems that can be treated
using the tools of nonsmooth analysis. Recall that E := ACâˆ[a, b]. Consider
the so-called Bolza problem
f(x) := Î³

x(a), x(b)

+
 b
a
Ï•

t, x(t), Ë™x(t)

dt âˆ’â†’min, x âˆˆE.
(12.13)
This is a classical problem if the function Ï• satisï¬es the assumptions (A) and
the function (Î¾, Î·) â†’Î³(Î¾, Î·) mapping R2 into R is diï¬€erentiable at (Â¯x(a), Â¯x(b)).
Here Â¯x âˆˆE denotes a local minimum point of f on E. In this case, necessary
conditions are (12.8) together with the natural boundary conditions
p(a) = Î³Î¾(Â¯x(a), Â¯x(b)),
p(b) = âˆ’Î³Î·(Â¯x(a), Â¯x(b)).
However, within the framework of nonsmooth analysis the functions Ï• and Î³
are allowed to attain the value +âˆ. For instance, let
Î³(Î¾, Î·) :=

0
if Î¾ = Î± and Î· = Î²,
+âˆ
otherwise.
Then (12.13) passes into the ï¬xed end point problem (12.3). Now we consider
a more interesting class of problems. Let the function Î³ : R2 â†’R âˆª{+âˆ}
and the multifunction F : R2 â‡’R be given. Consider the problem
Î³(x(a), x(b)) âˆ’â†’min, x âˆˆE, Ë™x(t) âˆˆF(t, x(t)), t âˆˆ[a, b] (a.e.).
(12.14)
Setting
Ï•(t, x, v) :=

0
if v âˆˆF(t, x),
+âˆ
otherwise,

272
12 Optimality Conditions for Nonconvex Problems
we have
 b
a
Ï•(t, x(t), Ë™x(t)) dt =

0
if Ë™x(t) âˆˆF(t, x(t)), t âˆˆ[a, b] (a.e.),
+âˆ
otherwise.
Hence problem (12.14) is of the form (12.13). Of course, the assumptions (Ë†A)
are not satisï¬ed for the function Ï• in this case. Nevertheless, it is possible to
reduce problem (12.14) in such a way that Theorem 12.2.3 applies. However,
this requires facts on diï¬€erentiable inclusions that lie beyond the scope of this
book (we refer to Clarke [36], Clarke et al. [39], and Loewen [123]).
12.3 Multiplier Rules Involving Upper Convex
Approximations
Our aim in this section is to establish necessary optimality conditions for the
problem
f(x) â†’min,
x âˆˆM âˆ©A,
under the assumption that M is described by scalar inequalities and/or an
operator equation. First we consider the problem:
(P1) Minimize f(x)
subject to gi(x) â‰¤0 (i = 1, . . . , m),
x âˆˆA.
We set
I := {1, . . . , m}, I(Â¯x) := {i âˆˆI | gi(Â¯x) = 0}
(12.15)
and make the following assumptions:
(A1) E is a normed vector space,
A âŠ‚E is nonempty and convex, D âŠ‚E is nonempty and open,
f, gi : D â†’R for i = 1, . . . , m,
there exist Ï• âˆˆUCr(f, Â¯x) and Ïˆi âˆˆUCr(gi, Â¯x) for i âˆˆI(Â¯x),
gi is upper semicontinuous at Â¯x for i âˆˆI \ I(Â¯x).
Theorem 12.3.1 Let (A1) be satisï¬ed and assume that Â¯x is a local solution
of (P1).
(a) One has:
âˆƒÎ» âˆˆR+ âˆƒÂµi âˆˆR+ (i âˆˆI(Â¯x)) : not all equal to zero,
Î» Ï•(y) +
	
iâˆˆI(Â¯x)
Âµi Ïˆi(y) â‰¥0
âˆ€y âˆˆA âˆ’Â¯x.
(12.16)
(b) Let the following condition be satisï¬ed:
âˆƒy0 âˆˆA âˆ’Â¯x
âˆ€i âˆˆI(Â¯x) : Ïˆi(y0) < 0.
(12.17)

12.3 Multiplier Rules Involving Upper Convex Approximations
273
Then (a) holds with Î» = 1.
Proof.
(a) Let y âˆˆA âˆ’Â¯x and Ïˆi(y) < 0 for each i âˆˆI(Â¯x). Then it follows from
Proposition 11.4.5(a) that y âˆˆTr(M1 âˆ©A, Â¯x), where
M1 := {x âˆˆD | gi(x) â‰¤0 (i = 1, . . . , m)}.
In this connection, notice that A âˆ’Â¯x âŠ†Tr(A, Â¯x) because A is convex.
Since Â¯x is a local solution of f on M1 âˆ©A, Proposition 12.1.1(a) implies
that Ï•(y) â‰¥0. Consequently, the system
y âˆˆA âˆ’Â¯x, Ï•(y) < 0, Ïˆi(y) < 0 âˆ€i âˆˆI(Â¯x)
has no solution. The assertion now follows by Proposition 10.2.1 with
H := {o}. (Notice that to verify (10.3), we need only set Â¯yi := Ïˆi(x0) + 1
for each i âˆˆI(Â¯x), with some x0 âˆˆA âˆ’Â¯x.)
(b) This is an immediate consequence of (a).
âŠ“âŠ”
Remark 12.3.2
(a) In terms of radial upper convex approximations, the conditions in (a)
and (b) above are generalized John conditions and generalized Karushâ€“
Kuhnâ€“Tucker conditions, respectively (cf. Sect. 5.2). Likewise, (12.17) is
a generalized Slater condition.
(b) Concerning the existence of (radial) upper convex approximations Ï• and
Ïˆi, we refer to Theorem 7.3.2 (cf. Remark 11.4.6(a)).
Now we consider the problem:
(P2) Minimize f(x)
subject to gi(x) â‰¤0 (i = 1, . . . , m),
h(x) = o,
x âˆˆA.
Recall the notation (12.15). We agree on the following assumptions:
(A2) E and F are Banach spaces,
A âŠ†E is nonempty, convex, and closed, D âŠ†E is nonempty and open,
f, gi : D â†’R for i = 1, . . . , m,
there exist Ï• âˆˆUC(f, Â¯x) and Ïˆi âˆˆUC(gi, Â¯x) for i âˆˆI(Â¯x),
gi is upper semicontinuous at Â¯x for i âˆˆI \ I(Â¯x),
h : D â†’F is F-diï¬€erentiable on a neighborhood of Â¯x, hâ€² is continuous
at Â¯x.
Theorem 12.3.3 Let (A2) be satisï¬ed and assume that Â¯x is a local solution
of (P2):
(a) If hâ€²(Â¯x)
&
R+(A âˆ’Â¯x)

is closed or F is ï¬nite dimensional, then
âˆƒÎ» âˆˆR+
Âµi âˆˆR+ (i âˆˆI(Â¯x))
âˆƒv âˆˆF âˆ—:
Î», Âµi, v not all zero,
Î» Ï•(y) +
	
iâˆˆI(Â¯x)
Âµi Ïˆi(y) +

v â—¦hâ€²(Â¯x), y
 
â‰¥0
âˆ€y âˆˆA âˆ’Â¯x.
(12.18)

274
12 Optimality Conditions for Nonconvex Problems
(b) Let Ï• and Ïˆi, i âˆˆI(Â¯x), be continuous on E and let the following condition
be satisï¬ed:
hâ€²(Â¯x)

R+(A âˆ’Â¯x)

= F.
(12.19)
Then (12.18) holds with Î», Âµi, i âˆˆI(Â¯x), not all zero.
(c) Let (12.19) and the following condition be satisï¬ed:
âˆƒy0 âˆˆA âˆ’Â¯x : Ïˆi(y0) < 0 âˆ€i âˆˆI(Â¯x), hâ€²(Â¯x)y0 = o.
(12.20)
Then (12.18) holds with Î» = 1.
Proof.
(a) In view of (b), we may assume that hâ€²(Â¯x)

R+(Aâˆ’Â¯x)

Ì¸= F. Then by a sep-
aration theorem (Theorem 1.5.9 in the general case, or Proposition 1.5.7
if F is ï¬nite dimensional), there exists v âˆˆF âˆ—satisfying v Ì¸= o and
âŸ¨v, zâŸ©â‰¥0 for each z âˆˆhâ€²(Â¯x)

R+(A âˆ’Â¯x)]. Hence the assertion holds with
Î» = 0 and Âµi = 0 for each i âˆˆI(Â¯x).
(b) Let y âˆˆA âˆ’Â¯x, Ïˆi(y) < 0 for each i âˆˆI(Â¯x), and hâ€²(Â¯x)y = o. Then it
follows from Theorem 11.4.9 that y âˆˆT(M2 âˆ©A, Â¯x), where M2 is deï¬ned
by the functional constraints. Since Â¯x is a local solution of f on M2 âˆ©A,
Proposition 12.1.1(b) says that Ï•(y) â‰¥0. Consequently, the system
y âˆˆA âˆ’Â¯x, Ï•(y) < 0, Ïˆi(y) < 0 âˆ€i âˆˆI(Â¯x), hâ€²(Â¯x)y = o
has no solution. The assertion now follows by Proposition 10.2.4.
(c) This is an immediate consequence of (b).
âŠ“âŠ”
Remark 12.3.4
(a) The optimality condition (12.18) is again a generalized John condition or,
if Î» = 1, a generalized Karushâ€“Kuhnâ€“Tucker condition, with the Lagrange
multipliers Âµi and v.
(b) If, in particular, f is H-diï¬€erentiable at Â¯x, we set Ï• := f â€²(Â¯x), analogously
for gi, i âˆˆI(Â¯x). If, in addition, A = E, then (12.18) reduces to
Î» f â€²(Â¯x) +

iâˆˆI(Â¯x)
Âµi gâ€²
i(Â¯x) + v â—¦hâ€²(Â¯x) = o.
Moreover, if F := Rr and so h = (h1, . . . , hr), where hk : D â†’R for
k = 1, . . . , r, then (12.18), (12.19), and (12.20) pass, respectively, into
âˆƒÎ» âˆˆR+,
âˆƒÂµi âˆˆR+ (i âˆˆI(Â¯x)),
âˆƒÎ½j âˆˆR (j = 1, . . . , r) :
not all zero,
Î» f â€²(Â¯x) +

iâˆˆI(Â¯x)
Âµi gâ€²
i(Â¯x) +
r

j=1
Î½j hâ€²
j(Â¯x) = o ,
(12.21)
hâ€²
1(Â¯x), . . . , hâ€²
r(Â¯x) are linearly independent elements of Eâˆ—,
(12.22)
âˆƒy0 âˆˆE : âŸ¨gâ€²
i(Â¯x), y0âŸ©< 0 âˆ€i âˆˆI(Â¯x), âŸ¨hâ€²
j(Â¯x), y0âŸ©= 0 âˆ€j = 1, . . . , r.
(12.23)

12.3 Multiplier Rules Involving Upper Convex Approximations
275
The conditions (12.22) and (12.23) together are the Mangasarianâ€“
Fromowitz regularity condition.
(c) If, in (P2), the inequalities gi(x) â‰¤0, i âˆˆI, are absent, then the corre-
sponding data in Theorem 12.3.3 have to be omitted. This is veriï¬ed by
applying Theorem 11.4.1 instead of Theorem 11.4.9.
For ï¬nite-dimensional F, we now relax the diï¬€erentiability hypothesis on
the mapping h. We assume that h is F-diï¬€erentiable at the point Â¯x only. Also
we now choose concrete upper convex approximations for the functionals gi.
More precisely, we consider the following nonsmooth optimization problem:
(P3) Minimize f(x)
subject to gi(x) â‰¤0,
i = 1, . . . , p,
Ëœgj(x) â‰¤0,
j = 1, . . . , q,
hk(x) = 0,
k = 1, . . . , r,
x âˆˆA.
We want to establish a necessary condition for a point Â¯x âˆˆE to be a local
solution of (P3). We set
I := {1, . . . , p},
I(Â¯x) := {i âˆˆI | gi(Â¯x) = 0},
J := {1, . . . , q},
J(Â¯x) := {j âˆˆJ | Ëœgj(Â¯x) = 0}.
The assumptions are:
(A3) E is a Banach space, A âŠ†E is closed and epi-Lipschitz at Â¯x,
f : E â†’R is H-diï¬€erentiable at Â¯x or locally L-continuous around Â¯x,
gi : E â†’R is H-diï¬€erentiable at Â¯x for i âˆˆI(Â¯x),
gi : E â†’R is continuous at Â¯x for i âˆˆI \ I(Â¯x),
Ëœgj : E â†’R is locally L-continuous around Â¯x for j âˆˆJ(Â¯x),
Ëœgj : E â†’R is continuous at Â¯x for j âˆˆJ \ J(Â¯x),
hk : E â†’R is F-diï¬€erentiable at Â¯x and continuous in a neighborhood
of Â¯x for k = 1, . . . , r.
Further we need certain constraint qualiï¬cations:
hâ€²
1(Â¯x), . . . , hâ€²
r(Â¯x) are linearly independent elements of Eâˆ—.
(12.24)
âˆƒy0 âˆˆTC(A, Â¯x) : âŸ¨gâ€²
i(Â¯x), y0âŸ©< 0 âˆ€i âˆˆI(Â¯x), Ëœgâ™¦
j (Â¯x, y0) < 0 âˆ€j âˆˆJ(Â¯x),
âŸ¨hâ€²
k(Â¯x), y0âŸ©= 0 âˆ€k = 1, . . . , r.
(12.25)
Theorem 12.3.5 Let the assumptions (A3) be satisï¬ed and let Â¯x be a local
solution of (P3):
(a) There exist scalars Î» â‰¥0, Âµi â‰¥0 for i âˆˆI(Â¯x), ËœÂµj â‰¥0 for j âˆˆJ(Â¯x), and
Î½k for k = 1, . . . , r that are not all zero, such that for any y âˆˆTC(A, Â¯x),
Î» f â™¦(Â¯x, y) +
	
iâˆˆI(Â¯x)
ÂµiâŸ¨gâ€²
i(Â¯x), yâŸ©+
	
jâˆˆJ(Â¯x)
ËœÂµj Ëœgâ™¦
j (Â¯x, y) +
r
	
k=1
Î½kâŸ¨hâ€²
k(Â¯x), yâŸ©â‰¥0.
(12.26)

276
12 Optimality Conditions for Nonconvex Problems
(b) If (12.24) is satisï¬ed, then (a) holds, where Î», Âµi (i âˆˆI(Â¯x)), and ËœÂµj (j âˆˆ
J(Â¯x)) are not all zero.
(c) If (12.24) and (12.25) are satisï¬ed, then (a) holds with Î» = 1.
Proof.
(I) Deï¬ne h : E â†’Rr by h := (h1, . . . , hr). If (12.24) is not satisï¬ed,
then hâ€²(Â¯x)(E) is a proper linear subspace of Rr. Hence there exists
(Î½1, . . . , Î½r) âˆˆRr \ {o} such that r
k=1 Î½kâŸ¨hâ€²
k(Â¯x), yâŸ©= 0 for any y âˆˆE.
Setting Î» = Âµi = ËœÂµj = 0, we see that (12.26) holds.
(II) Assume now that (12.24) is satisï¬ed. We show that (b) holds, which
also veriï¬es (a) in this case. Since the F-derivative hâ€²(Â¯x) is surjective,
Halkinâ€™s correction theorem (Theorem 3.7.5) ensures that there exist a
neighborhood U of Â¯x and a mapping Ï : U â†’E that is F-diï¬€erentiable
at Â¯x and satisï¬es
Ï(Â¯x) = o,
Ïâ€²(Â¯x) = o,
(12.27)
hk

x + Ï(x)

= âŸ¨hâ€²
k(Â¯x), x âˆ’Â¯xâŸ©
âˆ€x âˆˆU
âˆ€k = 1, . . . , r.
(12.28)
(III) We claim that the following system has no solution:
y âˆˆint TC(A, Â¯x),
(12.29)
f â™¦(Â¯x, y) < 0,
(12.30)
âŸ¨gâ€²
i(Â¯x), yâŸ©< 0,
i âˆˆI(Â¯x),
(12.31)
Ëœgâ™¦
j (Â¯x, y) < 0,
j âˆˆJ(Â¯x),
(12.32)
âŸ¨hâ€²
k(Â¯x), yâŸ©= 0,
k = 1, . . . , r.
(12.33)
Assume, to the contrary, that the system does have a solution y. Set
Î¸(Ï„) := Â¯x + Ï„y + Ï(Â¯x + Ï„y),
Ï„ âˆˆ[0, 1].
The relations (12.28) and (12.33) show that hk

Î¸(Ï„)

= 0 for k = 1, . . . , r
whenever Ï„ âˆˆ[0, 1] is so small that Â¯x+Ï„y âˆˆU. The properties of Ï entail
Î¸(0) = Â¯x and Î¸â€²(0) = y. Hence the chain rule (Proposition 3.4.4) gives
lim
Ï„â†“0 Ï„ âˆ’1&
gi

Î¸(Ï„)

âˆ’gi

Î¸(0)

= âŸ¨gâ€²
i(Â¯x), yâŸ©
<
(12.31) 0
âˆ€i âˆˆI(Â¯x).
Since, for i âˆˆI(Â¯x), gi

Î¸(0)

= gi(Â¯x) = o, we deduce that
gi

Î¸(Ï„)

< 0
for Ï„ âˆˆ(0, 1] suï¬ƒciently small and all i âˆˆI(Â¯x).
(12.34)
Since Ëœgj is locally L-continuous around Â¯x, the Michelâ€“Penot directional
derivative can be written as
Ëœgâ™¦
j (Â¯x, y) = sup
zâˆˆE
lim sup
Ï„â†“0
yâ€²â†’y
Ï„ âˆ’1&
Ëœgj

Â¯x + Ï„(yâ€² + z)

âˆ’Ëœgj(Â¯x + Ï„z)

âˆ€j âˆˆJ(Â¯x).
(12.35)

12.3 Multiplier Rules Involving Upper Convex Approximations
277
By (12.27) we have
yâ€² := y + Ï„ âˆ’1Ï(Â¯x + Ï„y) â†’y
as Ï„ â†“0.
(12.36)
From this, (12.32), and (12.35) we conclude that
Ï„ âˆ’1&
Ëœgj

Â¯x + Ï„y + Ï(Â¯x + Ï„y)

âˆ’Ëœgj(Â¯x)

< 0
âˆ€j âˆˆJ(Â¯x)
and so
Ëœgj

Î¸(Ï„)

< 0
for Ï„ âˆˆ(0, 1] suï¬ƒciently small and all j âˆˆJ(Â¯x).
(12.37)
Analogously, by (12.30) we obtain
f

Î¸(Ï„)

< f(Â¯x)
for Ï„ âˆˆ(0, 1] suï¬ƒciently small.
(12.38)
By assumption (A3), the hypertangent cone H(A, Â¯x) is nonempty and so
coincides with int TC(A, x) (Proposition 11.1.9). Therefore y âˆˆH(A, Â¯x).
In view of (12.36) and Lemma 11.1.8, we obtain
Î¸(Ï„) = Â¯x + Ï„

y + Ï„ âˆ’1Ï(Â¯x + Ï„y)

âˆˆA.
(12.39)
Since gi, i /âˆˆI(Â¯x), and Ëœgj, j /âˆˆJ(Â¯x), are continuous at Â¯x, we further have
gi

Î¸(Ï„)

< 0
for Ï„ âˆˆ(0, 1] suï¬ƒciently small and all i âˆˆI \ I(Â¯x),
(12.40)
Ëœgj

Î¸(Ï„)

< 0
for Ï„ âˆˆ(0, 1] suï¬ƒciently small and all j âˆˆJ \ J(Â¯x).
(12.41)
The relations (12.34)â€“(12.41) contradict the fact that Â¯x is a local solution
of (P3). Thus we have shown that the system (12.29)â€“(12.33) has no
solution.
(IV) We want to apply Proposition 10.2.4. Deï¬ne
s := card I(Â¯x),
t := card J(Â¯x),
G := E Ã— R Ã— Rs Ã— Rt,
P := âˆ’TC(A, Â¯x) Ã— R+ Ã— Rs
+ Ã— Rt
+,
S(y) :=

y, f â™¦(Â¯x, y), (âŸ¨gâ€²
i(Â¯x), yâŸ©)iâˆˆI(Â¯x), (Ëœgâ™¦
j (Â¯x, y))jâˆˆJ(Â¯x)

,
y âˆˆE,
T(y) :=

âŸ¨hâ€²
1(Â¯x), yâŸ©, . . . , âŸ¨hâ€²
r(Â¯x), yâŸ©

,
y âˆˆE.
Notice that P is a convex cone with nonempty interior in G and that
the mapping S : E â†’G is P-convex. By step (III), the system
y âˆˆE, S(y) âˆˆâˆ’int P, T(y) = o

278
12 Optimality Conditions for Nonconvex Problems
has no solution. Hence by Proposition 10.2.4 there exist u âˆˆTC(A, Â¯x)â—¦,
Î» â‰¥0, Âµi â‰¥0, i âˆˆI(Â¯x), and ËœÂµj â‰¥0, j âˆˆJ(Â¯x), not all zero, as well as
Î½1, . . . , Î½r âˆˆR satisfying
âˆ’âŸ¨u, yâŸ©âˆ’Î» f â™¦(Â¯x, y) âˆ’
	
iâˆˆI(Â¯x)
ÂµiâŸ¨gâ€²
i(Â¯x), yâŸ©
âˆ’
	
jâˆˆJ(Â¯x)
ËœÂµj Ëœgâ™¦
j (Â¯x, y) âˆ’
r
	
k=1
Î½kâŸ¨hâ€²
k(Â¯x), yâŸ©â‰¤0
âˆ€y âˆˆE.
(12.42)
The multipliers Î», Âµi, i âˆˆI(Â¯x), and ËœÂµj, j âˆˆJ(Â¯x), cannot be simultane-
ously equal to zero since otherwise the inequality (12.42) would imply
that u is also zero which is contradictory. The assertion of the theorem
now follows from (12.42) since âŸ¨u, yâŸ©â‰¤0 for any y âˆˆTC(A, Â¯x).
(V) The assertion (c) is obvious.
âŠ“âŠ”
12.4 Clarkeâ€™s Multiplier Rule
A drawback of the multiplier rules established so far is the diï¬€erentiability
assumption on the operator h : E â†’F deï¬ning the equality constraint. In this
section, we present a multiplier rule under a crucially weakened assumption
on h, provided F is ï¬nite dimensional. We consider the following problem:
(P4) Minimize f(x)
subject to gi(x) â‰¤0 (i = 1, . . . , m), hj(x) = 0 (j = 1, . . . , n),
x âˆˆA.
The assumptions are:
(A4) E is a Banach space, A âŠ†E is nonempty and closed,
f, gi, hj
:
E
â†’
R (i
=
1, . . . , m, j
=
i, . . . , n)
are all locally
L-continuous around any x âˆˆA.
Theorem 12.4.1 (Clarkeâ€™s Multiplier Rule) Let (A4) be satisï¬ed and
assume that Â¯x is a local solution of (P4). Then:
âˆƒÎ» âˆˆR+ âˆƒÂµi âˆˆR+ (i = 1, . . . , m) âˆƒÎ½j âˆˆR (j = 1, . . . , n) : not all zero,
Âµigi(Â¯x) = 0 (i = 1, . . . , m),
(12.43)
o âˆˆÎ» âˆ‚â—¦f(Â¯x) +
m
	
i=1
Âµi âˆ‚â—¦gi(Â¯x) +
n
	
j=1
Î½j âˆ‚hj(Â¯x) + NC(A, Â¯x).
(12.44)
Proof.
(I) We may and do assume that Â¯x is a global solution of (P4) because the
following argument can be applied with A replaced by Aâˆ©B(Â¯x, Î·), where
Î· > 0 is suï¬ƒciently small.

12.4 Clarkeâ€™s Multiplier Rule
279
(II) Let Ïµ > 0 be given. Deï¬ne Ïˆ : E â†’R by
Ïˆ(x) := max

f(x) âˆ’f(Â¯x) + Ïµ
2, g1(x), . . . , gm(x), |h1(x)|, . . . , |hn(x)|

.
Then Ïˆ is locally L-continuous and so l.s.c. Since Â¯x is a solution of (P4),
we have
Ïˆ(x) > 0
âˆ€x âˆˆA,
(12.45)
which, together with Ïˆ(Â¯x) = Ïµ/2, implies
Ïˆ(Â¯x) < inf
xâˆˆA Ïˆ(x) + Ïµ.
(12.46)
(III) By step (II), Ekelandâ€™s variational principle in the form of Corollary 8.2.6
applies to Ïˆ. Choosing Î» := âˆšÏµ we conclude that there exists xÏµ âˆˆA
such that
âˆ¥xÏµ âˆ’Â¯xâˆ¥â‰¤âˆšÏµ,
(12.47)
Ïˆ(xÏµ) â‰¤Ïˆ(x) + âˆšÏµ âˆ¥xÏµ âˆ’xâˆ¥
âˆ€x âˆˆA.
(12.48)
(IV) Let Îº0 be a common local Lipschitz constant of the functionals f,
g1, . . . , gm, and h1, . . . , hn around Â¯x. Then, as is easy to see, each Îº > Îº0
is a local Lipschitz constant of the functional x â†’Ïˆ(x) + âˆšÏµ âˆ¥xÏµ âˆ’xâˆ¥
around xÏµ for Ïµ suï¬ƒciently small. Since by (12.48), this functional has
a minimum on A at xÏµ, Proposition 12.1.2 shows that xÏµ is a local
minimizer of
%Ïˆ(x) := Ïˆ(x) + âˆšÏµ Ï‰xÏµ(x) + ÎºdA(x),
where Ï‰xÏµ(x) := âˆ¥xÏµ âˆ’xâˆ¥.
Hence the sum rule (Proposition 7.4.3) gives
o âˆˆâˆ‚â—¦%Ïˆ(xÏµ) âŠ†âˆ‚â—¦Ïˆ(xÏµ) + âˆšÏµ âˆ‚â—¦Ï‰xÏµ(xÏµ) + Îºâˆ‚â—¦dA(xÏµ).
(V) Now we apply the maximum rule (Proposition 7.4.7) to Ïˆ, Proposi-
tions 4.6.2 and 7.3.9 to Ï‰xÏµ, and Proposition 11.2.4 to dA. Hence there
exist nonnegative numbers Ë†Î», Ë†Âµ1, . . . , Ë†Âµm and Î½â€²
1, . . . , Î½â€²
n such that
Ë†Î» +
m
	
i=1
Ë†Âµi +
n
	
j=1
Î½â€²
j = 1,
(12.49)
o âˆˆË†Î»âˆ‚â—¦f(xÏµ) +
m
	
i=1
Ë†Âµiâˆ‚â—¦fi(xÏµ) +
n
	
j=1
Î½â€²
jâˆ‚â—¦|hj|(xÏµ) + âˆšÏµ BEâˆ—+ NC(A, xÏµ).
(12.50)
Since in the maximum rule, the active indices only count and Ïˆ(xÏµ) > 0
(see (12.45)), we also have
gi(xÏµ) â‰¤0
=â‡’
Ë†Âµi = 0 (i = 1, . . . , m),
hj(xÏµ) = 0
=â‡’
Î½â€²
j = 0
(j = 1, . . . , n).
(12.51)

280
12 Optimality Conditions for Nonconvex Problems
For j = 1, . . . , n deï¬ne
Ë†Î½j :=

sign(hj(xÏµ)

Î½â€²
j
if hj(xÏµ) Ì¸= 0,
0
if hj(xÏµ) = 0.
By the chain rule (Corollary 7.4.6 with g := | Â· |), we then obtain
Î½â€²
j âˆ‚â—¦|hj|(xÏµ) âŠ†Ë†Î½j âˆ‚â—¦hj(xÏµ)
(j = 1, . . . , n).
This and (12.50) imply the existence of some xâˆ—
Ïµ âˆˆEâˆ—satisfying
xâˆ—
Ïµ âˆˆË†Î» âˆ‚â—¦f(xÏµ) +
n
	
i=1
Ë†Âµi âˆ‚â—¦gi(xÏµ) +
n
	
j=1
Ë†Î½j âˆ‚â—¦hj(xÏµ),
(12.52)
xâˆ—
Ïµ âˆˆâˆšÏµBEâˆ—âˆ’NC(A, xÏµ).
(12.53)
(VI) Now we replace Ïµ by a sequence Ïµk â†“0. From (12.47) we obtain xÏµk â†’Â¯x
as k â†’âˆ. Moreover, in view of (12.52) the sequence (xâˆ—
Ïµk) is contained
in a Ïƒ(Eâˆ—, E)-compact set (cf. Proposition 7.3.7) and so has a Ïƒ(Eâˆ—, E)-
cluster point xâˆ—. Observe that the numbers Ë†Âµi also depend on Ïµk, and by
(12.49) have cluster points Âµi. An analogous observation yields scalars
Î» and Î½j, j = 1, . . . , n. By Proposition 7.3.7(c) we have
xâˆ—âˆˆÎ»âˆ‚â—¦f(Â¯x) +
n
	
i=1
Âµiâˆ‚â—¦gi(Â¯x) +
n
	
j=1
Î½jâˆ‚â—¦hj(Â¯x)
and
xâˆ—âˆˆâˆ’NC(A, Â¯x),
which is equivalent to (12.44).
(VII) The numbers Ë†Î» and Ë†Âµi, i = 1, . . . , m, are nonnegative and so are Î»
and Âµi. By (12.49) the numbers Î», Âµi, and Î½j are not all zero. It remains
to verify (12.43). Let i âˆˆ{1, . . . , m} be such that gi(Â¯x) < 0. Then the
continuity of gi implies that, for all k suï¬ƒciently large, gi(xÏµk) < 0 and
so (by (12.51)) Ë†Âµi = 0. Hence Âµi = 0.
âŠ“âŠ”
12.5 Approximate Multiplier Rules
We again consider problem (P4). However, for technical reasons we now adopt
a somewhat diï¬€erent notation for the functionals involved. More precisely, we
consider the problem:
(P5) Minimize f(x)
subject to fi(x) â‰¤0 (i = 1, . . . , m),
fi(x) = 0 (i = m + 1, . . . , n),
x âˆˆA.

12.5 Approximate Multiplier Rules
281
Our aim now is to derive multiplier rules under the following weak
assumptions:
(A5) E is a FrÃ©chet smooth Banach space, A âŠ†E is nonempty and closed,
fi : E â†’R is l.s.c. for i = 0, 1, . . . , m,
fi : E â†’R is continuous for i = m + 1, . . . , n.
The principal ingredients of the proof of the following multiplier rule are
the weak local approximate sum rule (Theorem 9.2.7) and the representation
results of Theorems 11.6.5 and 11.6.6.
Theorem 12.5.1 (Approximate Multiplier Rule) Let (A5) be satisï¬ed
and assume that Â¯x is a local solution of (P5).
(a) For any Ïµ > 0 and any Ïƒ(Eâˆ—, E)-neighborhood V of zero, the following
holds:
âˆƒ(xi, fi(xi)) âˆˆ(Â¯x, fi(Â¯x)) + ÏµBEÃ—R
(i = 0, 1, . . . , n)
âˆƒxn+1 âˆˆÂ¯x + ÏµBE
âˆƒÂµi â‰¥0 (i = 0, . . . , n) :
Âµi not all zero,
o âˆˆ
m
	
i=0
Âµiâˆ‚F fi(xi)+
n
	
i=m+1
Âµi

âˆ‚F fi(xi) âˆªâˆ‚F (âˆ’fi)(xi)

+NF (A, xn+1)+V.
(b) Assume that, in addition, the following conditions are satisï¬ed:
lim inf
xâ†’f Â¯x d(âˆ‚F fi(x), o) > 0
for i = 1, . . . , m,
lim inf
xâ†’Â¯x d(âˆ‚F fi(x) âˆªâˆ‚F (âˆ’fi)(x), o) > 0
for i = m + 1, . . . , n.
(12.54)
Then conclusion (a) holds with Âµ0 = 1 and Âµi > 0 for i = 1, . . . , n.
Proof. Let Ïµ > 0 and a Ïƒ(Eâˆ—, E)-neighborhood V of zero be given:
(I) First we verify (b). By assumption, Â¯x is a local minimizer of Ïˆ := f0 +
Î´(âˆ©n
i=1Si)âˆ©A, where
Si :=

{x âˆˆE | fi(x) â‰¤0}
if i = 1, . . . , m,
{x âˆˆE | fi(x) = 0}
if i = m + 1, . . . , n.
Hence we have
o âˆˆâˆ‚F Ïˆ(Â¯x) = âˆ‚F

f0 +
n
	
i=1
Î´Si + Î´A

(Â¯x).
(12.55)
Let Î· âˆˆ(0, Ïµ/2) and let U be a convex Ïƒ(Eâˆ—, E)-neighborhood of zero
satisfying U + Î·BEâˆ—âŠ†V . By Theorem 9.2.7 there exist (x0, f0(x0)) âˆˆ

282
12 Optimality Conditions for Nonconvex Problems
(Â¯x, f0(Â¯x)) + Î·BEÃ—R, (yi, fi(yi)) âˆˆ(Â¯x, fi(Â¯x)) + Î·BEÃ—R (i = 1, . . . , n), and
xn+1 âˆˆÎ·BE such that
o âˆˆâˆ‚F f(x0) +
n
	
i=1
NF (Si, yi) + NF (A, xn+1) + U;
in this connection notice that by deï¬nition âˆ‚F Î´Si(yi) = NF (Si, yi). Now
let xâˆ—
0 âˆˆâˆ‚F f(x0), yâˆ—
i âˆˆNF (Si, yi) (i = 1, . . . , n), and yâˆ—
n+1 âˆˆNF (A, xn+1)
be such that o âˆˆxâˆ—
0 +n
i=1 yâˆ—
i +yâˆ—
n+1 +U. By Theorems 11.6.5 and 11.6.6
there exist (xi, fi(xi)) âˆˆ(yi, fi(yi)) + Î·BEÃ—R, Î»i > 0, and
xâˆ—
i âˆˆâˆ‚F fi(xi)
for i = 1, . . . , m,
xâˆ—
i âˆˆâˆ‚F fi(xi) âˆªâˆ‚F (âˆ’fi)(xi)
for i = m + 1, . . . , n
such that âˆ¥Î»ixâˆ—
i âˆ’yâˆ—
i âˆ¥< Î·
n for i = 1, . . . , n. It follows that
o âˆˆxâˆ—
0 +
n
	
i=1
Î»ixâˆ—
i + yâˆ—
n+1 + Î·BEâˆ—+ U.
Setting
Âµ0 :=
1
1 + n
i=1 Î»i
,
Âµi :=
Î»i
1 + n
i=1 Î»i
for i = 1, . . . , n
and recalling that U is a convex set containing o, we obtain
o âˆˆ
n
	
i=0
Âµixâˆ—
i +

1 +
n
	
i=1
Î»i
âˆ’1yâˆ—
n+1 + Î·BEâˆ—+ U.
Since NF (A, xn+1) is a cone and Î·BEâˆ—+ U âŠ†V , conclusion (b) follows.
(II) Now we verify (a). In view of step (I) we may assume that con-
dition (12.54) fails. Suppose that for some i
âˆˆ
{1, . . . , m} we
have lim infxâ†’f Â¯x d(âˆ‚F fi(x), o)
=
0; the argument is analogous if
i âˆˆ{m + 1, . . . , n}. We may assume that Ïµ âˆˆ(0, 1) is so small that
BEâˆ—(o, Ïµ) âŠ†V . Then there exist xi âˆˆBE(Â¯x, Ïµ) and xâˆ—
i âˆˆâˆ‚F fi(xi) such
that |fi(xi) âˆ’fi(Â¯x)| < Ïµ and âˆ¥xâˆ—
i âˆ¥< Ïµ. Then âˆ’xâˆ—
i âˆˆV . Setting Âµi := 1
and Âµj := 0 for any j Ì¸= i, conclusion (a) follows.
âŠ“âŠ”
Remark 12.5.2
(a) If âˆ‚F (âˆ’fi)(xi) = âˆ’âˆ‚F fi(xi) (as is the case if, for instance, fi is a C2
function), then Âµi

âˆ‚F fi(xi) âˆªâˆ‚F (âˆ’fi)(xi)

, where Âµi âˆˆR+, corresponds
to Âµiâˆ‚F fi(xi), where Âµi âˆˆR, and so to the fact that Lagrange multi-
pliers associated with equality constraints have arbitrary sign (cf. Re-
mark 12.3.4(b)).
(b) Conclusion (a) of Theorem 12.5.1 is of John type while conclusion (b) is of
Karushâ€“Kuhnâ€“Tucker type. The conditions (12.54) constitute a constraint
qualiï¬cation.

12.6 Bibliographical Notes and Exercises
283
12.6 Bibliographical Notes and Exercises
Theorem 12.2.3 is due to Clarke (see [36]), our presentation follows
Loewen [123]. Concerning detailed presentations of the classical calculus of
variations we recommend Cesari [30] and Giaquinta and Hildebrandt [71,72].
Theorem 12.4.1 was established by Clarke [35]. In a similar way but with
the aid of a more sophisticated maximum rule, Clarke [36] obtained a sharp-
ened multiplier rule. Theorem 12.4.1 provides an optimality condition of the
John type (cf. Sects. 5.2 and 12.3). As a regularity condition, Clarke intro-
duced the concept of calmness, see [35,36]. A modiï¬cation of this concept is
due to Rockafellar [187].
Theorem 12.3.5 generalizes a multiplier rule of Halkin [82], where all func-
tionals involved are assumed to be F-diï¬€erentiable at Â¯x. For results related
to Theorem 12.3.5 but in terms of subdiï¬€erentials, we refer to Ye [217]. The
multiplier rule of Theorem 12.5.1 was established by Borwein et al. [21] (see
also Borwein and Zhu [23]).
In addition to the above references, we give a (necessarily subjective) sel-
ection of further papers on optimality conditions for nonconvex problems:
Bazaraa et al. [10], Degiovanni and Schuricht [46], Hiriart-Urruty [84,85,87],
Ngai and ThÃ©ra [152, 153], Ioï¬€e [99], Jourani [107], Loewen [123], Mor-
dukhovich and Wang [146], Neustadt [150], Penot [159,162], Pshenichnyi [169],
Scheï¬„er [190], Scheï¬„er and Schirotzek [192], and Schirotzek [194, 195]. For
a detailed discussion and a lot of references on the subject we recommend
Mordukhovich [137].
Substantial applications of generalized derivatives are elaborated by Clarke
et al. [39], Panagiotopoulos [157], and Papageorgiou and Gasinski [158].
Exercise 12.6.1 Prove Proposition 12.1.4.
Exercise 12.6.2 Apply Theorem 12.3.1 to the following problem (cf. Exer-
cise 11.7.10):
minimize f(x1, x2) := x1 + x2
subject to
0 â‰¤x2 â‰¤x3
1, (x1, x2) âˆˆR2.
Exercise 12.6.3 Deï¬ne f, h : R2 â†’R by f(x, y) := x and
h(x, y) :=
â§
âª
â¨
âª
â©
y
if x â‰¥0,
y âˆ’x2
if x < 0, y â‰¤0,
y + x2
if x < 0, y > 0.
The problem f(x, y) âˆ’â†’min subject to h(x, y) = 0 obviously has the solution
(Â¯x, Â¯y) = (0, 0). Show that no nonzero Lagrange multipliers exist at (Â¯x, Â¯y).
Which assumption of Theorem 12.3.5 is violated (cf. Fernandez [67])?
Exercise 12.6.4 The aim of this exercise is to generalize Theorem 12.3.3 (cf.
Schirotzek [196]):

284
12 Optimality Conditions for Nonconvex Problems
(a) Applying Theorem 11.7.12 (see Exercise 11.7.11(a)), prove the following:
Theorem 12.6.5 In addition to the assumptions of Theorem 11.7.12, sup-
pose that f : E â†’R is regularly locally convex at Â¯x and that Â¯x is a local
minimizer of f on A âˆ©M. Then there exist Î» âˆˆR+, yâˆ—âˆˆP â—¦, and zâˆ—âˆˆQâ—¦
such that (Î», yâˆ—) Ì¸= o and
Î»fH(Â¯x, y) + âŸ¨yâˆ—, gH(Â¯x, y)âŸ©+ âŸ¨zâˆ—, hâ€²(Â¯x)yâŸ©â‰¥0
âˆ€y âˆˆA âˆ’Â¯x,
âŸ¨yâˆ—, g(Â¯x)âŸ©= 0,
âŸ¨zâˆ—, h(Â¯x)âŸ©= 0.
(b) Formulate and verify corresponding variants of the other assertions of
Theorem 12.3.3.
Exercise 12.6.6 Let p, q : [a, b] â†’R and k : [a, b] Ã— [a, b] â†’R be continuous
functions. Denote
A := {x âˆˆL2[a, b] | |x(t)| â‰¤1 for almost all t âˆˆ[a, b]}.
Consider the problem (see TrÂ¨oltzsch [209], cf. Schirotzek [196])
minimize f(x) :=
 b
a
p(t)x(t) dt,
subject to
 b
a
k(s, t)x2(s) ds â‰¤q(t)
âˆ€t âˆˆ[a, b],
x âˆˆA.
Show that if Â¯x is a local solution of the problem, then there exist a number
Î» âˆˆR+ and a nondecreasing function v : [a, b] â†’R such that (Î», v) Ì¸= o, and
 b
a
y(t)
4
Î» p(t) + 2Â¯x(t)
 b
a
k(t, s) dv(s)
5
dt â‰¥0
âˆ€y âˆˆA âˆ’Â¯x,
 b
a
4 b
a
k(s, t)Â¯x2(s) ds âˆ’q(t)
5
dv(t) = 0.
Find a condition ensuring that Î» > 0.
Hint: Choose, among others, G := C[a, b] with the maximum norm and apply
Theorem 12.6.5.

13
Extremal Principles and More
Normals and Subdiï¬€erentials
FrÃ©chet subdiï¬€erentials are a ï¬‚exible tool for nonsmooth analysis, in particular
in FrÃ©chet smooth Banach spaces where they coincide with viscosity subdif-
ferentials. But in general they admit approximate calculus rules only. Applying
set convergence operations, Mordukhovich developed concepts of subdiï¬€eren-
tials and normals that admit a rich exact calculus. To a great extent the prop-
erties of these objects are based on extremal principles, which work especially
well in FrÃ©chet smooth Banach spaces (more generally, in Asplund spaces),
where the new subdiï¬€erentials and normal cones are sequential PainlevÃ©â€“
Kuratowski upper limits of FrÃ©chet subdiï¬€erentials and FrÃ©chet normal cones,
respectively.
13.1 Mordukhovich Normals and Subdiï¬€erentials
We start with a deï¬nition.
Deï¬nition 13.1.1 Let A be a nonempty subset of E.
(a) If x âˆˆA and Ïµ â‰¥0, then the set
*
NÏµ(A, x) :=
0
xâˆ—âˆˆEâˆ— lim sup
yâ†’Ax
âŸ¨xâˆ—, y âˆ’xâŸ©
âˆ¥y âˆ’xâˆ¥
â‰¤Ïµ
1
is called set of Ïµ-normals to A at x.
(b) If Â¯x âˆˆA, then the set
NM(A, Â¯x) := sLim sup
xâ†’Â¯x
Ïµâ†“0
*
NÏµ(A, x)
will be called Mordukhovich normal cone (M-normal cone) to A at Â¯x.

286
13 Extremal Principles and More Normals and Subdiï¬€erentials
Remark 13.1.2
(a) In general, the set *
NÏµ(A, x) is not a cone unless Ïµ = 0. The deï¬nitions
immediately yield
NF (A, x) = âˆ‚F Î´A(x) = *
N0(A, x)
and
NF (A, x) + ÏµBEâˆ—âŠ†*
NÏµ(A, x)
âˆ€Ïµ > 0.
(b) We have xâˆ—âˆˆ*
NÏµ(A, x) if and only if for any Î³ > 0 the function
Ï•(x) := âŸ¨xâˆ—, x âˆ’Â¯xâŸ©âˆ’(Ïµ + Î³)âˆ¥x âˆ’Â¯xâˆ¥,
x âˆˆA,
attains a local maximum at Â¯x.
(c) The set NM(A, Â¯x) is easily seen to be a cone. Recalling the deï¬nition of the
sequential PainlevÃ©â€“Kuratowski upper limit, we see that xâˆ—âˆˆNM(A, Â¯x)
if and only if there exist sequences Ïµk â†“0, xk â†’A Â¯x, and xâˆ—
k
wâˆ—
âˆ’âˆ’â†’xâˆ—such
that xâˆ—
k âˆˆ*
NÏµk(A, xk) for any k âˆˆN.
(d) We always have NF (A, x) âŠ†NM(A, x). Example 13.1.3 shows that this in-
clusion may be strict; it also shows that NM(A, Â¯x), in contrast to *
NÏµ(A, x),
is in general nonconvex and so cannot be the polar of any tangent cone
to A at Â¯x.
Example 13.1.3 Let A := {(x, y) âˆˆR2 | y â‰¥âˆ’|x|}. Then NF (A, (0, 0)) =
{(0, 0)} but
NM(A, (0, 0)) = {(xâˆ—, xâˆ—) âˆˆR2 | xâˆ—â‰¤0} âˆª{(xâˆ—, âˆ’xâˆ—) âˆˆR2 | xâˆ—â‰¥0}.
In ï¬nite-dimensional spaces there is a close relationship between the
Mordukhovich and the FrÃ©chet normal cone.
Theorem 13.1.4 If A is a closed subset of the Euclidean space E, then
NM(A, Â¯x) = sLim sup
xâ†’Â¯x
NF (A, x).
(13.1)
Proof. We identify Eâˆ—with E. It is obvious that the right-hand side of (13.1)
is contained in the left-hand side. We show the opposite inclusion. Thus let
xâˆ—âˆˆNM(A, Â¯x) be given. Then (cf. Remark 13.1.2(c)) there exist sequences
Ïµk â†“0, xk â†’A Â¯x, and xâˆ—
k
wâˆ—
âˆ’âˆ’â†’xâˆ—such that xâˆ—
k âˆˆ*
NÏµk(A, xk) for any k âˆˆN. Let
Î· > 0 be arbitrary. For any k âˆˆN choose yk âˆˆprojA(xk + Î·xâˆ—
k) which exists
by Corollary 5.4.5. Since yk depends on Î·, we also write yk = yk(Î·). We have
âˆ¥xk + Î·xâˆ—
k âˆ’ykâˆ¥2 â‰¤Î·2âˆ¥xâˆ—
kâˆ¥2.
(13.2)
Calculating the left-hand side via the inner product gives
âˆ¥xk + Î·xâˆ—
k âˆ’ykâˆ¥2 = âˆ¥xk âˆ’ykâˆ¥2 + 2Î·(xâˆ—
k | xk âˆ’yk) + Î·2âˆ¥xâˆ—
kâˆ¥2.

13.1 Mordukhovich Normals and Subdiï¬€erentials
287
Hence (13.2) passes into
âˆ¥xk âˆ’ykâˆ¥2 â‰¤2Î·(xâˆ—
k | yk âˆ’xk).
(13.3)
By (13.2) it follows that yk(Î·) â†’xk as Î· â†“0. From this and the choice of xâˆ—
k,
we deduce that for any k there exists Î·k > 0 such that, with zk := yk(Î·k),
we have (xâˆ—
k | zk âˆ’xk) â‰¤2Ïµkâˆ¥zk âˆ’xkâˆ¥for any k âˆˆN. This inequality together
with (13.3) shows that âˆ¥xk âˆ’zkâˆ¥â‰¤4Î·kÏµk and so zk â†’Â¯x as k â†’âˆ. Deï¬ning
zâˆ—
k := xâˆ—
k + (1/Î·k)(xk âˆ’zk), we obtain âˆ¥zâˆ—
k âˆ’xâˆ—
kâˆ¥â‰¤4Ïµk and so zâˆ—
k â†’xâˆ—as
k â†’âˆ. Therefore, to see that xâˆ—âˆˆsLim sup
xâ†’Â¯x
NF (A, x), it remains to show
that zâˆ—
k âˆˆNF (A, zk) for any k. Given x âˆˆA, we calculate
0 â‰¤âˆ¥xk + Î·kxâˆ—
k âˆ’xâˆ¥2 âˆ’âˆ¥xk + Î·kxâˆ—
k âˆ’zkâˆ¥2
= (Î·kxâˆ—
k + xk âˆ’x | Î·kxâˆ—
k + xk âˆ’zk) + (Î·kxâˆ—
k + xk âˆ’x | zk âˆ’x)
âˆ’(Î·kxâˆ—
k + xk âˆ’zk | x âˆ’zk) âˆ’(Î·kxâˆ—
k + xk âˆ’zk | Î·kxâˆ—
k + xk âˆ’x)
= âˆ’2Î·k(zâˆ—
k | x âˆ’zk) + âˆ¥x âˆ’zkâˆ¥2.
We thus obtain (zâˆ—
k | x âˆ’zk) â‰¤(1/2Î·k)âˆ¥x âˆ’zkâˆ¥2 for all x âˆˆA, which implies
that in fact zâˆ—
k âˆˆNF (A, zk).
âŠ“âŠ”
If the set A is convex, we have a simple representation of *NÏµ(A, Â¯x).
Proposition 13.1.5 If A âŠ†E is convex and Â¯x âˆˆA, then
*NÏµ(A, Â¯x) = {xâˆ—âˆˆEâˆ—| âŸ¨xâˆ—, x âˆ’Â¯xâŸ©â‰¤Ïµâˆ¥x âˆ’Â¯xâˆ¥
âˆ€x âˆˆA}
âˆ€Ïµ â‰¥0.
(13.4)
In particular, *N0(A, Â¯x) = NF (A, Â¯x) = N(A, Â¯x).
Proof. It is clear that the right-hand side of (13.4) is contained in *NÏµ(A, Â¯x)
(even if A is not convex). Now let xâˆ—âˆˆ*NÏµ(A, Â¯x) be given and ï¬x x âˆˆA. For
any Ï„ âˆˆ(0, 1] we then have xÏ„ := Â¯x + Ï„(x âˆ’Â¯x) âˆˆA (because A is convex)
and xÏ„ â†’Â¯x as Ï„ â†“0. The deï¬nition of the Ïµ-normals now implies that for any
Î³ > 0 we obtain
âŸ¨xâˆ—, xÏ„ âˆ’Â¯xâŸ©â‰¤(Ïµ + Î³)âˆ¥xÏ„ âˆ’Â¯xâˆ¥
for all suï¬ƒciently small Ï„ > 0.
It follows that xâˆ—is an element of the right-hand side of (13.4).
âŠ“âŠ”
The concept to be introduced now will be important for calculus rules. In
this connection, recall Remark 13.1.2(d).
Deï¬nition 13.1.6 The nonempty subset A of E is said to be normally reg-
ular at Â¯x âˆˆA if NM(A, Â¯x) = NF (A, Â¯x).
The next result yields examples of normally regular sets.

288
13 Extremal Principles and More Normals and Subdiï¬€erentials
Proposition 13.1.7 Let A âŠ†E and Â¯x âˆˆA. Assume that for some neigh-
borhood U of Â¯x the set A âˆ©U is convex. Then A is normally regular at Â¯x
and
NM(A, Â¯x) = {xâˆ—âˆˆEâˆ—| âŸ¨xâˆ—, x âˆ’Â¯xâŸ©â‰¤0
âˆ€x âˆˆA âˆ©U}.
(13.5)
Proof. By Proposition 13.1.5 and Remark 13.1.2(d) we know that the right-
hand side of (13.5) is contained in NM(A, Â¯x). Now take any xâˆ—âˆˆNM(A, Â¯x).
Then there exist sequences (Ïµk), (xk), and (xâˆ—
k) as in Remark 13.1.2(c). For all
k âˆˆN suï¬ƒciently large we thus have xk âˆˆAâˆ©U and so by Proposition 13.1.5,
âŸ¨xâˆ—
k, x âˆ’xkâŸ©â‰¤Ïµkâˆ¥x âˆ’xkâˆ¥
âˆ€x âˆˆA âˆ©U.
Letting k â†’âˆand recalling Exercise 10.10.1, we see that xâˆ—is an element of
the right-hand side of (13.5).
âŠ“âŠ”
We will use the M-normal cone to deï¬ne subdiï¬€erentials of (arbitrary)
proper functions f : E â†’R. In view of this we ï¬rst establish a result on the
structure of the M-normal cone to an epigraph.
Lemma 13.1.8 Assume that f : E â†’R is proper and (Â¯x, Â¯Î±) âˆˆepi f. Then
(xâˆ—, âˆ’Î») âˆˆNM(epi f, (Â¯x, Â¯Î±)) implies Î» â‰¥0.
Proof. Let (xâˆ—, âˆ’Î») âˆˆNM(epi f, (Â¯x, Â¯Î±)) be given. By the deï¬nition of the M-
normal cone there exist sequences Ïµk â†“0, (xk, Î±k) â†’epi f (Â¯x, Â¯Î±), xâˆ—
k
wâˆ—
âˆ’âˆ’â†’xâˆ—,
and Î»k â†’Î» such that
lim sup
(x,Î±)â†’epi f (xk,Î±k)
âŸ¨xâˆ—
k, x âˆ’xkâŸ©âˆ’Î»k(Î± âˆ’Î±k)
âˆ¥(x, Î±) âˆ’(xk, Î±k)âˆ¥
â‰¤Ïµk
âˆ€k âˆˆN.
Choosing x := xk we obtain
lim sup
Î±â†’Î±k
âˆ’Î»k sgn(Î± âˆ’Î±k)
âˆ¥(xk, 1)âˆ¥
â‰¤Ïµk
âˆ€k âˆˆN.
Letting k â†’âˆ, we see that Î» â‰¥0.
âŠ“âŠ”
Deï¬nition 13.1.9 Let f : E â†’R be proper and Â¯x âˆˆdom f. We call
âˆ‚Mf(Â¯x) :=

xâˆ—âˆˆEâˆ—| (xâˆ—, âˆ’1) âˆˆNM

epi f, (Â¯x, f(Â¯x))

Mordukhovich subdiï¬€erential (M-subdiï¬€erential) or basic subdiï¬€erential of f
at Â¯x and we call
âˆ‚âˆ
Mf(Â¯x) :=

xâˆ—âˆˆEâˆ—| (xâˆ—, 0) âˆˆNM

epi f, (Â¯x, f(Â¯x))

singular Mordukhovich subdiï¬€erential (singular M-subdiï¬€erential) of f at Â¯x.

13.1 Mordukhovich Normals and Subdiï¬€erentials
289
Remark 13.1.10 It follows immediately from the deï¬nitions that the M-
normal cone can be regained from the M-subdiï¬€erentials. In fact, for any
subset A of E and any point Â¯x âˆˆA one has
NM(A, Â¯x) = âˆ‚MÎ´A(Â¯x) = âˆ‚âˆ
MÎ´A(Â¯x).
As a consequence of Lemma 13.1.8 we have
Lemma 13.1.11 Let f : E â†’R be proper and Â¯x âˆˆdom f. If NM

epi f,
(Â¯x, f(Â¯x)

Ì¸= {(o, 0)} and âˆ‚âˆ
Mf(Â¯x) = {o}, then âˆ‚Mf(Â¯x) is nonempty.
Proof. See Exercise 13.13.1.
âŠ“âŠ”
Below we shall derive alternative descriptions of the Mordukhovich subdif-
ferential in terms of subdiï¬€erentials to be deï¬ned now that modify the FrÃ©chet
subdiï¬€erential.
Deï¬nition 13.1.12 Let f : E â†’R be proper, Â¯x âˆˆdom f, and Ïµ â‰¥0. The
set
*âˆ‚Ïµf(Â¯x) :=
0
xâˆ—âˆˆEâˆ— lim inf
xâ†’Â¯x
f(x) âˆ’f(Â¯x) âˆ’âŸ¨xâˆ—, x âˆ’Â¯xâŸ©
âˆ¥x âˆ’Â¯xâˆ¥
â‰¥âˆ’Ïµ
1
is called (FrÃ©chet) Ïµ-subdiï¬€erential of f at Â¯x.
Remark 13.1.13
(a) For Ïµ = 0 we regain the FrÃ©chet subdiï¬€erential: *âˆ‚0f(Â¯x) = âˆ‚F f(Â¯x).
(b) For every Ïµ â‰¥0 we have xâˆ—âˆˆ*âˆ‚Ïµf(Â¯x) if and only if for any Î³ > 0 the
function
Ïˆ(x) := f(x) âˆ’f(Â¯x) âˆ’âŸ¨xâˆ—, x âˆ’Â¯xâŸ©+ (Ïµ + Î³)âˆ¥x âˆ’Â¯xâˆ¥,
x âˆˆE,
attains a local minimum at Â¯x (cf. Remark 13.1.2(b)).
We deï¬ne still another sort of Ïµ-subdiï¬€erentials.
Deï¬nition 13.1.14 Let f : E â†’R be proper, Â¯x âˆˆdom f, and Ïµ â‰¥0. The
set
*âˆ‚gÏµf(Â¯x) := {xâˆ—| (xâˆ—, âˆ’1) âˆˆ*NÏµ(epi f, (Â¯x, f(Â¯x))}
is said to be the geometric Ïµ-subdiï¬€erential of f at Â¯x.
The next result describes the relationship between the two Ïµ-subdif-
ferentials.
Theorem 13.1.15 Let f : E â†’R be proper and Â¯x âˆˆdom f.
(a) For any Ïµ â‰¥0 one has *âˆ‚Ïµf(Â¯x) âŠ†*âˆ‚gÏµf(Â¯x).
(b) If Ïµ âˆˆ[0, 1) and xâˆ—âˆˆ*âˆ‚gÏµf(Â¯x), then xâˆ—âˆˆ*âˆ‚ËœÏµf(Â¯x), where ËœÏµ := Ïµ(1 +
âˆ¥xâˆ—âˆ¥)/(1 âˆ’Ïµ).

290
13 Extremal Principles and More Normals and Subdiï¬€erentials
Proof.
(a) Let Ïµ â‰¥0, xâˆ—âˆˆ*âˆ‚Ïµf(Â¯x), and Î³ > 0 be given. By Remark 13.1.2(b) there
exists a neighborhood U of Â¯x such that
f(x) âˆ’f(Â¯x) âˆ’âŸ¨xâˆ—, x âˆ’Â¯xâŸ©â‰¥âˆ’(Ïµ + Î³)âˆ¥x âˆ’Â¯xâˆ¥
âˆ€x âˆˆU.
It follows that
âŸ¨xâˆ—, x âˆ’Â¯xâŸ©+ f(Â¯x) âˆ’Î± â‰¤(Ïµ + Î³)âˆ¥(x, Î±) âˆ’(Â¯x, f(Â¯x))âˆ¥.
Hence the function
ËœÏ•(x, Î±) : = âŸ¨xâˆ—, x âˆ’Â¯xâŸ©âˆ’(Î± âˆ’f(Â¯x))
âˆ’(Ïµ + Î³)âˆ¥(x, Î±) âˆ’(Â¯x, f(Â¯x))âˆ¥,
(x, Î±) âˆˆepi f,
attains a local maximum at (Â¯x, f(Â¯x)). By Remark 13.1.2(b) we conclude
that (xâˆ—, âˆ’1) âˆˆ*
NÏµ(epi f, (Â¯x, f(Â¯x)) and so xâˆ—âˆˆ*âˆ‚gÏµf(Â¯x).
(b) Now let Ïµ âˆˆ[0, 1) and ËœÏµ as above be given. Assume that xâˆ—âˆˆE is not
in *âˆ‚ËœÏµf(Â¯x). Then there are Î³ > 0 and a sequence (xk) converging to Â¯x as
k â†’âˆsuch that
f(xk) âˆ’f(Â¯x) âˆ’âŸ¨xâˆ—, x âˆ’Â¯xâŸ©+ (ËœÏµ + Î³)âˆ¥xk âˆ’Â¯xâˆ¥< 0
âˆ€k âˆˆN.
Put Î±k := f(Â¯x) + âŸ¨xâˆ—, xk âˆ’Â¯xâŸ©âˆ’(ËœÏµ + Î³)âˆ¥xk âˆ’Â¯xâˆ¥. Then Î±k â†’f(Â¯x) as
k â†’âˆand (xk, Î±k) âˆˆepi f for any k âˆˆN. An elementary consideration
shows that for any k âˆˆN,
âŸ¨xâˆ—, xk âˆ’Â¯xâŸ©âˆ’(Î±k âˆ’f(Â¯x))
âˆ¥(xk, Î±k) âˆ’(Â¯x, f(Â¯x))âˆ¥
=
(ËœÏµ + Î³)âˆ¥xk âˆ’Â¯xâˆ¥

xk âˆ’Â¯x, âŸ¨xâˆ—, xk âˆ’Â¯xâŸ©âˆ’(ËœÏµ + Î³)âˆ¥xk âˆ’Â¯xâˆ¥

â‰¥
ËœÏµ + Î³
1 + âˆ¥xâˆ—âˆ¥+ (ËœÏµ + Î³) >
ËœÏµ
1 + âˆ¥xâˆ—âˆ¥+ ËœÏµ = Ïµ.
Hence (xâˆ—, âˆ’1) /âˆˆ*NÏµ

epi f, (Â¯x, f(Â¯x))

and so xâˆ—/âˆˆ*âˆ‚gÏµf(Â¯x).
âŠ“âŠ”
Remark 13.1.16 For Ïµ = 0, Theorem 13.1.15 and Remark 13.1.13(a) yield
*âˆ‚g0f(Â¯x) = *âˆ‚0f(Â¯x) = âˆ‚F f(Â¯x).
This together with the deï¬nition of the geometric Ïµ-subdiï¬€erential and Re-
mark 13.1.2(a) show that in any Banach space E we have (cf. Remark 11.3.6)
âˆ‚F f(Â¯x) =

xâˆ—| (xâˆ—, âˆ’1) âˆˆNF

epi f, (Â¯x, f(Â¯x))

.
Now
we
establish
the
announced
alternative
description
of
the
M-subdiï¬€erential.

13.1 Mordukhovich Normals and Subdiï¬€erentials
291
Theorem 13.1.17 Let f : E â†’R be proper and Â¯x âˆˆdom f.
(a) One always has
âˆ‚Mf(Â¯x) = sLimsup
xâ†’f Â¯x, Ïµâ†“0
*âˆ‚gÏµf(x) = sLim sup
xâ†’f Â¯x, Ïµâ†“0
*âˆ‚Ïµf(x).
(13.6)
(b) If, in addition, f is l.s.c. and E is ï¬nite dimensional, then
âˆ‚Mf(Â¯x) = sLim sup
xâ†’f Â¯x
âˆ‚F f(x).
(13.7)
Proof.
(a) The ï¬rst equation in (13.6) follows immediately from the deï¬nitions
of the geometric Ïµ-subdiï¬€erential and the Ïµ-normal set. This and The-
orem 13.1.15(a) further show that sLim supxâ†’f Â¯x, Ïµâ†“0*âˆ‚Ïµf(x) âŠ†âˆ‚Mf(Â¯x).
Now we verify the opposite inclusion. Thus let xâˆ—âˆˆâˆ‚Mf(Â¯x) be given.
Then there exist sequences Ïµk â†“0, xk â†’f
Â¯x, and xâˆ—
k
wâˆ—
âˆ’âˆ’â†’xâˆ—such
that xâˆ—
k âˆˆ*âˆ‚gÏµkf(xk) for any k âˆˆN. For all suï¬ƒciently large k we
have Ïµk âˆˆ(0, 1). By Theorem 13.1.15(b) it follows for these k that
xâˆ—
k âˆˆ*âˆ‚ËœÏµkf(xk), where ËœÏµk := Ïµk(1 + âˆ¥xâˆ—
kâˆ¥)/(1 âˆ’Ïµk). Since the sequence
(xâˆ—
k) is bounded, we have ËœÏµk â†“0 as k â†’âˆ. This shows that xâˆ—is an
element of the right-hand side of (13.6).
(b) This is a consequence of Theorem 13.1.4 and Remark 13.1.16.
âŠ“âŠ”
Since âˆ‚F f(Â¯x) = *âˆ‚0f(Â¯x) âŠ†*âˆ‚Ïµf(Â¯x) for any Ïµ > 0, it follows from Theo-
rem 13.1.17 that we always have âˆ‚F f(Â¯x) âŠ†âˆ‚Mf(Â¯x). The example
f(x) :=
â§
â¨
â©
x2 sin(1/x)
if x Ì¸= 0,
0
if x = 0
shows that the inclusion may be strict. In fact, here we have âˆ‚F f(0) =
{f â€²(0)} = {0} but âˆ‚Mf(0) = [âˆ’1, 1]. Below it will turn out that equality in
the above inclusion will ensure equality in calculus rules for M-subdiï¬€erentials.
This motivates the following notion.
Deï¬nition 13.1.18 The proper functional f : E â†’R is said to be lower
regular at Â¯x âˆˆdom f if âˆ‚Mf(Â¯x) = âˆ‚F f(Â¯x).
Proposition 13.1.19 Let A âŠ†E and Â¯x âˆˆA. The indicator functional Î´A is
lower regular at Â¯x if and only if the set A is normally regular at Â¯x.
Proof. See Exercise 13.13.2.
âŠ“âŠ”
In FrÃ©chet smooth Banach spaces (and more generally, in Asplund spaces)
the M-subdiï¬€erential at Â¯x can be represented with the aid of F-subdiï¬€erentials

292
13 Extremal Principles and More Normals and Subdiï¬€erentials
at nearby points. We prepare this result by an approximate sum rule for
Ïµ-subdiï¬€erentials.
Lemma 13.1.20 Assume that E is a FrÃ©chet smooth Banach space and that
f1, f2 : E â†’R are proper and l.s.c. with f1 locally L-continuous around
Â¯x âˆˆdom f1 âˆ©dom f2. Then for any Ïµ â‰¥0 and any Î³ > 0 one has
*âˆ‚Ïµ(f1 + f2)(Â¯x) âŠ†
0
âˆ‚F f1(x1) + âˆ‚F f2(x2)

xi âˆˆBE(Â¯x, Î³), |fi(xi) âˆ’fi(Â¯x)| â‰¤Î³, i = 1, 2
1
+ (Ïµ + Î³)BEâˆ—.
Proof.
(I) Fix Ïµ and Î³ as above and choose Î· such that 0 < Î· < min{Î³/4, ËœÎ·}, where ËœÎ·
is the positive solution of ËœÎ·2 +(2+Ïµ)ËœÎ·âˆ’Î³ = 0. Now let xâˆ—âˆˆ*âˆ‚Ïµ(f1 +f2)(Â¯x)
be given and deï¬ne
f0(x) := f1(x) âˆ’âŸ¨xâˆ—, x âˆ’Â¯xâŸ©+ (Ïµ + Î·)âˆ¥x âˆ’Â¯xâˆ¥
âˆ€x âˆˆE.
By Remark 13.1.13 the function f0 + f2 attains a local minimum at Â¯x.
Then Lemma 9.2.5 shows that condition (9.19) is satisï¬ed for f0 + f2.
Applying the approximate sum rule of Theorem 9.2.6 (with Î· instead of
Ïµ) to the sum f0 + f2, we ï¬nd xi âˆˆB(Â¯x, Î·), i = 1, 2, xâˆ—
0 âˆˆâˆ‚F f0(x1) and
xâˆ—
2 âˆˆâˆ‚F f2(x2), such that
|f1(x1) + (Ïµ + Î·)âˆ¥x1 âˆ’Â¯xâˆ¥âˆ’f1(Â¯x)| â‰¤Î·,
|f2(x2) âˆ’f2(Â¯x)| â‰¤Î·,
o âˆˆxâˆ—
0 + xâˆ—
2 + Î·BEâˆ—.
By Proposition 9.2.2 we obtain xâˆ—
0 = xâˆ—
1 âˆ’xâˆ—with
xâˆ—
1 âˆˆâˆ‚F

f1 + (Ïµ + Î·)Ï‰Â¯x

(x1),
where Ï‰Â¯x(x) := âˆ¥x âˆ’Â¯xâˆ¥.
It follows that
|f1(x1) âˆ’f1(Â¯x)| â‰¤Î·(Ïµ + Î· + 1)
and
xâˆ—âˆˆxâˆ—
1 + xâˆ—
2 + Î·BEâˆ—.
(II) Now we evaluate xâˆ—
1. Applying Remark 13.1.13 to xâˆ—
1, we conclude that,
with
g(x) := (Ïµ + Î·)âˆ¥x âˆ’Â¯xâˆ¥âˆ’âŸ¨xâˆ—
1, x âˆ’x1âŸ©+ Î·âˆ¥x âˆ’x1âˆ¥,
x âˆˆE,
the function f1 + g attains a local minimum at x1. By Proposition 4.6.2
the convex function g satisï¬es âˆ‚g(x) âŠ†âˆ’xâˆ—
1 + (Ïµ + 2Î·)BEâˆ—for any x âˆˆE.
Now we apply Theorem 9.2.6 to the sum f1+g and obtain Ëœx1 âˆˆBE(x1, Î·)
such that
âˆ¥f1(Ëœx1 âˆ’f1(x1)| â‰¤Î·
and
xâˆ—
1 âˆˆâˆ‚F f1(Ëœx1) + (Ïµ + 3Î·)BEâˆ—.

13.1 Mordukhovich Normals and Subdiï¬€erentials
293
Summarizing we have
xâˆ—âˆˆâˆ‚F f1(Ëœx1) + âˆ‚F f2(x2) + (Ïµ + 4Î·)BEâˆ—,
âˆ¥Ëœx1 âˆ’Â¯xâˆ¥â‰¤2Î·,
|f1(Ëœx1) âˆ’f1(Â¯x)| â‰¤Î·(Ïµ + Î· + 2).
The deï¬nition of Î· shows that the proof is complete.
âŠ“âŠ”
With the aid of Lemma 13.1.20 we obtain, in a FrÃ©chet smooth Banach
space, a limiting representation of the M-subdiï¬€erential that is simpler than
the one in an arbitrary Banach space and that generalizes the corresponding
result for ï¬nite-dimensional Banach spaces (see Theorem 13.1.17).
Theorem 13.1.21
Assume that E is a FrÃ©chet smooth Banach space, f :
E â†’R is proper and l.s.c., and Â¯x âˆˆdom f.
(a) For any Ïµ â‰¥0 and any Î³ > 0 one has
*âˆ‚Ïµf(Â¯x) âŠ†
0
âˆ‚F f(x)
 x âˆˆBE(Â¯x, Î³), |f(x) âˆ’f(Â¯x)| â‰¤Î³
1
+ (Ïµ + Î³)BEâˆ—.
(13.8)
(b) One has
âˆ‚Mf(Â¯x) = sLim sup
xâ†’f Â¯x
âˆ‚F f(x).
Proof. Applying Lemma 13.1.20 with f1 := o and f2 := f, we immediately
obtain (a). Now choose Î³ := Ïµ in (13.8) and pass to the limit Ïµ â†“0. This
yields (b).
âŠ“âŠ”
Due to Theorem 13.1.21(b) we can reformulate Proposition 9.5.1 on the
Clarke subdiï¬€erential in the following way.
Proposition 13.1.22 Let E be a FrÃ©chet smooth Banach space and let f :
E â†’R be locally L-continuous on E. Then for any Â¯x âˆˆE one has
âˆ‚â—¦f(Â¯x) = coâˆ—âˆ‚Mf(Â¯x).
In this context, recall the discussion in Remark 9.5.2. The normal cone
counterpart of Theorem 13.1.21 is
Theorem 13.1.23 Assume that E is a FrÃ©chet smooth Banach space, A is a
closed subset of E, and Â¯x âˆˆA.
(a) For any Ïµ â‰¥0 and any Î³ > 0 one has
*NÏµ(A, Â¯x) âŠ†
0
NF (A, x)
 x âˆˆA âˆ©B(Â¯x, Î³)
1
+ (Ïµ + Î³)BEâˆ—.
(13.9)
(b) One has
NM(A, Â¯x) = sLim sup
xâ†’Â¯x
NF (A, Â¯x).
Proof. See Exercise 13.13.3.
âŠ“âŠ”

294
13 Extremal Principles and More Normals and Subdiï¬€erentials
13.2 Coderivatives
Convention. In this section, unless otherwise speciï¬ed, E and F are FrÃ©chet
smooth Banach spaces.
In Sect. 11.5 we considered contingent derivatives as derivative-like objects
for multifunctions. Now we study an alternative concept. Since we want to
apply the approximate calculus for F-subdiï¬€erentials established above, we
restrict ourselves to FrÃ©chet smooth Banach spaces.
Deï¬nition 13.2.1 Let Î¦ : E â‡’F be a closed multifunction and (Â¯x, Â¯y) âˆˆ
graph Î¦.
(a) For any Ïµ â‰¥0, the multifunction *Dâˆ—
ÏµÎ¦(Â¯x, Â¯y) : F âˆ—â‡’Eâˆ—deï¬ned by
*Dâˆ—
ÏµÎ¦(Â¯x, Â¯y)(yâˆ—) :=

xâˆ—âˆˆEâˆ—| (xâˆ—, âˆ’yâˆ—) âˆˆ*NÏµ

graph Î¦, (Â¯x, Â¯y)

âˆ€yâˆ—âˆˆF âˆ—
is said to be the Ïµ-coderivative of Î¦ at (Â¯x, Â¯y). In particular, Dâˆ—
F Î¦(Â¯x, Â¯y) :=
*Dâˆ—
0Î¦(Â¯x, Â¯y) is called FrÃ©chet coderivative (F-coderivative) of Î¦ at (Â¯x, Â¯y).
(b) The multifunction Dâˆ—
MÎ¦(Â¯x, Â¯y) : F âˆ—â‡’Eâˆ—deï¬ned by
Dâˆ—
MÎ¦(Â¯x, Â¯y)(yâˆ—) :=

xâˆ—âˆˆEâˆ—| (xâˆ—, âˆ’yâˆ—) âˆˆNM

graph Î¦, (Â¯x, Â¯y)

âˆ€yâˆ—âˆˆF âˆ—
is said to be the Mordukhovich coderivative (M-coderivative) of Î¦ at (Â¯x, Â¯y).
Remark 13.2.2
(a) By deï¬nition of the respective normal cone we have the following charac-
terizations of these coderivatives:
Dâˆ—
MÎ¦(Â¯x, Â¯y)(Â¯yâˆ—) =
sLim sup
(x, y) â†’(Â¯x, Â¯y)
yâˆ—
wâˆ—
âˆ’âˆ’âˆ’â†’Â¯yâˆ—
Ïµ â†“0
*Dâˆ—
ÏµÎ¦(x, y)(yâˆ—),
i.e., Dâˆ—
MÎ¦(Â¯x, Â¯y)(Â¯yâˆ—) consists of all Â¯xâˆ—âˆˆEâˆ—for which there exist sequences
Ïµk â†“0, (xk, yk) â†’(Â¯x, Â¯y), and (xâˆ—
k, yâˆ—
k)
wâˆ—
âˆ’âˆ’â†’(Â¯xâˆ—, Â¯yâˆ—) satisfying (xk, yk) âˆˆ
graph Î¦ and xâˆ—
k âˆˆ*Dâˆ—
ÏµÎ¦(xk, yk)(yâˆ—
k).
(b) In particular, we have
xâˆ—âˆˆDâˆ—
F Î¦(Â¯x, Â¯y)(yâˆ—)
â‡â‡’
(xâˆ—, âˆ’yâˆ—) âˆˆâˆ‚F Î´graph Î¦(Â¯x, Â¯y).
The viscosity characterization of the F-subdiï¬€erential now shows that
xâˆ—âˆˆDâˆ—
F Î¦(Â¯x, Â¯y)(yâˆ—) if and only if there exists a C1 function g : E Ã—F â†’R
such that gâ€²(Â¯x, Â¯y) = (xâˆ—, âˆ’yâˆ—) and Î´graph Î¦(x, y) âˆ’g(x, y) â‰¥0 for any
(x, y) âˆˆE Ã— F near (Â¯x, Â¯y).

13.2 Coderivatives
295
If Î¦ is single-valued, we write Dâˆ—
F Î¦(Â¯x)(yâˆ—) instead of Dâˆ—
F Î¦(Â¯x, Î¦(Â¯x))(yâˆ—),
analogously for Dâˆ—
M. If f : E â†’R is a proper functional, we deï¬ne the
epigraphical multifunction Ef : E â‡’R by
Ef(x) := {Ï„ âˆˆR | Ï„ â‰¥f(x)}
âˆ€x âˆˆE.
Proposition 13.2.3 relates coderivatives to familiar concepts.
Proposition 13.2.3
(a) If Î¦ : E â†’F is an F-diï¬€erentiable function, then
Dâˆ—
F Î¦(Â¯x)(yâˆ—) = {Î¦â€²(Â¯x)âˆ—yâˆ—}
âˆ€yâˆ—âˆˆF âˆ—,
i.e., Dâˆ—
F Î¦(Â¯x) can be identiï¬ed with the adjoint of the continuous linear
operator Î¦â€²(Â¯x).
(b) If Î¦ : E â†’F is a strictly F-diï¬€erentiable function, then Dâˆ—
MÎ¦(Â¯x) can be
identiï¬ed with the adjoint of the continuous linear operator Î¦â€²(Â¯x).
(c) If f : E â†’R is a proper functional and Â¯x âˆˆdom f, then
âˆ‚Mf(Â¯x) = Dâˆ—
MEf(Â¯x, f(Â¯x))(1)
and
âˆ‚âˆ
Mf(Â¯x) = Dâˆ—
MEf(Â¯x, f(Â¯x))(0).
Proof. Leaving (a) and (c) as Exercise 13.13.5, we now verify (b). The proof
of (a) is independent of that of (b), thus we may assume that we already have
{Î¦â€²(Â¯x)âˆ—yâˆ—} = Dâˆ—
F Î¦(Â¯x)(yâˆ—) âŠ†Dâˆ—
MÎ¦(Â¯x)(yâˆ—)
âˆ€yâˆ—âˆˆF âˆ—.
It remains to prove the reverse inclusion. Take any yâˆ—âˆˆF âˆ—and xâˆ—âˆˆ
Dâˆ—
MÎ¦(Â¯x)(yâˆ—). By Remark 13.2.2 there exist sequences Ïµk â†“0, xk â†’Â¯x, and
(xâˆ—
k, yâˆ—
k)
wâˆ—
âˆ’âˆ’â†’(xâˆ—, yâˆ—) such that for any x close to Â¯x and any k âˆˆN we have
âŸ¨xâˆ—
k, x âˆ’xkâŸ©âˆ’âŸ¨yâˆ—
k, Î¦(x) âˆ’Î¦(xk)âŸ©â‰¤Ïµk

âˆ¥x âˆ’xkâˆ¥+ âˆ¥Î¦(x) âˆ’Î¦(xkâˆ¥

.
Since Î¦ is strictly F-diï¬€erentiable, Proposition 3.2.4(iv) shows that for any
sequence Î·i â†“0 as i â†’âˆthere exist Ïi > 0 such that
âˆ¥Î¦(x) âˆ’Î¦(z) âˆ’Î¦â€²(Â¯x)(x âˆ’z)âˆ¥â‰¤Î·iâˆ¥x âˆ’zâˆ¥
âˆ€x, z âˆˆB(Â¯x, Ïi) âˆ€i âˆˆN.
Hence we ï¬nd a sequence (ki) in N such that
âŸ¨xâˆ—
ki âˆ’Î¦â€²(Â¯x)âˆ—yâˆ—
ki, x âˆ’xkiâŸ©â‰¤ËœÏµiâˆ¥x âˆ’xkiâˆ¥
âˆ€x âˆˆB(xki, Ïki) âˆ€i âˆˆN;
here, ËœÏµi := (Î» + 1)(Ïµki + Î·iâˆ¥yâˆ—
kiâˆ¥and Î» > 0 denotes a Lipschitz constant of Î¦
around Â¯x. It follows that
âˆ¥xâˆ—
ki âˆ’Î¦â€²(Â¯x)âˆ—yâˆ—
kiâˆ¥â‰¤ËœÏµi
for all suï¬ƒciently large i âˆˆN.
(13.10)
Since
ËœÏµi â†“0
and
xâˆ—
ki âˆ’Î¦â€²(Â¯x)âˆ—yâˆ—
ki
wâˆ—
âˆ’âˆ’â†’xâˆ—âˆ’Î¦â€²(Â¯x)âˆ—yâˆ—
as i â†’âˆ,

296
13 Extremal Principles and More Normals and Subdiï¬€erentials
and the norm functional on Eâˆ—is weakâˆ—l.s.c. (see Exercise 1.8.10), we ï¬nally
obtain from (13.10) that xâˆ—= Î¦â€²(Â¯x)âˆ—yâˆ—.
âŠ“âŠ”
Next we consider coderivatives of locally L-continuous mappings.
Proposition 13.2.4 Let E and F be Banach spaces and let f : E â†’F be
locally L-continuous around Â¯x âˆˆE with Lipschitz constant Î» > 0.
(a) For any Ïµ â‰¥0 there exists Î· > 0 such that
sup

âˆ¥xâˆ—âˆ¥
 xâˆ—âˆˆ*Dâˆ—
Ïµf(x)(yâˆ—)

â‰¤Î»âˆ¥yâˆ—âˆ¥+ Ïµ(1 + Î»)
whenever x âˆˆB(Â¯x, Î·), âˆ¥f(x) âˆ’f(Â¯x)âˆ¥â‰¤Î·, and yâˆ—âˆˆF âˆ—.
(b) If, in particular, F is ï¬nite dimensional, then
sup{âˆ¥xâˆ—âˆ¥| xâˆ—âˆˆDâˆ—
Mf(Â¯x)(yâˆ—} â‰¤Î»âˆ¥yâˆ—âˆ¥
âˆ€yâˆ—âˆˆF âˆ—.
Proof.
(a) Without loss of generality we may assume that Î» â‰¥1. Let Î· > 0 be such
that
âˆ¥f(x) âˆ’f(u)âˆ¥â‰¤Î»âˆ¥x âˆ’uâˆ¥
âˆ€x, u âˆˆB(Â¯x, 2Î·).
(13.11)
Take x âˆˆB(Â¯x, Î·) satisfying âˆ¥f(x) âˆ’f(Â¯x)âˆ¥â‰¤Î·, yâˆ—âˆˆF âˆ—, and xâˆ—âˆˆ
*Dâˆ—
Ïµf(x)(yâˆ—). Furthermore, take Î³ > 0. By the deï¬nition of Ïµ-coderivatives
and Ïµ-normals, there exists Î± âˆˆ(0, Î·) such that
âŸ¨xâˆ—, uâˆ’xâŸ©âˆ’âŸ¨yâˆ—, f(u)âˆ’f(x)âŸ©â‰¤(Ïµ+Î³)(âˆ¥uâˆ’xâˆ¥+âˆ¥f(u)âˆ’f(x)âˆ¥) (13.12)
whenever u âˆˆB(x, Î±) and âˆ¥f(u) âˆ’f(x)âˆ¥â‰¤Î±. Take any u âˆˆB(x, Î±/Î») âŠ†
B(x, Î±). Then u âˆˆB(Â¯x, 2Î·), and (13.11) yields âˆ¥f(x) âˆ’f(u)âˆ¥â‰¤Î»(Î±/Î») =
Î±. Invoking this estimate into (13.12), we obtain
âŸ¨xâˆ—, u âˆ’xâŸ©â‰¤âˆ¥yâˆ—âˆ¥Î± + (Ïµ + Î³)(Î±/Î» + Î±).
Since this is true for any u âˆˆB(x, Î±/Î»), it follows that âˆ¥xâˆ—âˆ¥â‰¤Î»|âˆ¥yâˆ—âˆ¥+
(Ïµ + Î³)(1 + Î»). Since Î³ > 0 was arbitrary, the conclusion follows.
(b) Take any xâˆ—âˆˆDâˆ—
Mf(Â¯x)(yâˆ—). Then there exist sequences Ïµk â†“0, xk â†’Â¯x,
xâˆ—
k
wâˆ—
âˆ’âˆ’â†’xâˆ—, and yâˆ—
k â†’yâˆ—(here we exploit that F is ï¬nite dimensional)
such that xâˆ—
k âˆˆDâˆ—
Ïµkf(xk)(yâˆ—
k) for any k âˆˆN. By (a) we have âˆ¥xâˆ—
kâˆ¥â‰¤
Î»âˆ¥yâˆ—
kâˆ¥+ Ïµk(1 + Î») for all k large enough. Since the norm functional on
Eâˆ—is weakâˆ—l.s.c. (see Exercise 1.8.10), we obtain the assertion by letting
k â†’âˆ.
âŠ“âŠ”
Corollary 13.2.5 If f : E â†’R is locally L-continuous around Â¯x âˆˆE, then
Dâˆ—
Mf(Â¯x)(0) = âˆ‚âˆ
Mf(Â¯x) = {o}.
(13.13)

13.2 Coderivatives
297
Proof. The Lipschitz property of f implies that the set epi f is closed and
that for some closed neighborhood U of (Â¯x, f(Â¯x)) we have U âˆ©graph f =
U âˆ©bd(epi f). By Exercise 13.13.4 we therefore obtain âˆ‚âˆ
Mf(Â¯x) âŠ†Dâˆ—
Mf(Â¯x)(0).
In view of Proposition 13.2.4(b) the assertion is veriï¬ed.
âŠ“âŠ”
We supplement Corollary 13.2.5 by a result that we state without proof (see
Mordukhovich [137]).
Proposition 13.2.6 If f : E â†’R is locally L-continuous around Â¯x âˆˆE,
then
Dâˆ—
Mf(Â¯x)(Î±) = âˆ‚M(Î±f)(Â¯x)
âˆ€Î± âˆˆR.
We brieï¬‚y turn to calculus rules for F-coderivatives. As in the case
of F-subdiï¬€erentials, approximate calculus rules for F-coderivatives can be
established in weak form and in strong form.
Theorem 13.2.7 (Weak Coderivative Sum Rule) Let Î¦1, . . . , Î¦n : E â‡’
F and Î¦ := n
i=1 Î¦i be closed multifunctions. Further let Â¯x âˆˆE, Â¯y âˆˆÎ¦(Â¯x),
Â¯yi âˆˆÎ¦i(Â¯x) for i = 1, . . . , n and assume that Â¯y = n
i=1 Â¯yi. Suppose that yâˆ—âˆˆF âˆ—
and xâˆ—âˆˆDâˆ—
F Î¦(Â¯x, Â¯y)(yâˆ—).
Then for any Ïµ > 0 and any weakâˆ—neighborhoods U of zero in Eâˆ—and V of
zero in F âˆ—, there exist (xi, yi) âˆˆ(graph Î¦i) âˆ©B((Â¯x, Â¯yi), Ïµ), yâˆ—
i âˆˆyâˆ—+ V , and
xâˆ—
i âˆˆDâˆ—
F Î¦i(xi, yi)(yâˆ—
i ), i = 1, . . . , n, such that
max
i=1,...,n{âˆ¥xâˆ—
i âˆ¥, âˆ¥yâˆ—
i âˆ¥} Â· diam{(x1, y1), . . . , (xn, yn)} < Ïµ,
(13.14)
xâˆ—âˆˆ
n
	
i=1
xâˆ—
i + U.
(13.15)
Proof. Since xâˆ—âˆˆDâˆ—
F Î¦(Â¯x, Â¯y)(yâˆ—), there exists a C1 function g as in Re-
mark 13.2.2. Observe that
n
	
i=1
Î´graph Î¦i(x, yi) â‰¥Î´graph Î¦

x,
n
	
i=1
yi

and
n
	
i=1
Î´graph Î¦i(Â¯x, Â¯yi) = Î´graph Î¦(Â¯x, Â¯y) = 0.
Thus, deï¬ning Ëœf, Ëœg : E Ã— F Ã— Â· Â· Â· Ã— F â†’R by
Ëœf(x, y1, . . . , yn) :=
n
	
i=1
Î´graph Î¦i(x, yi),
Ëœg(x, y1, . . . , yn) := g

x,
n
	
i=1
yi

,
we see that
Ëœf âˆ’Ëœg attains a local minimum at (Â¯x, Â¯y1, . . . , Â¯yn). Since
gâ€²(Â¯x, Â¯y) = (xâˆ—, âˆ’yâˆ—) (cf. Remark 13.2.2), it follows that Ëœgâ€²(Â¯x, Â¯y1, . . . , Â¯yn) =
(xâˆ—, âˆ’yâˆ—, . . . , âˆ’yâˆ—). Hence
(xâˆ—, âˆ’yâˆ—, . . . , âˆ’yâˆ—) âˆˆâˆ‚F Ëœf(Â¯x, Â¯y1, . . . , Â¯yn).

298
13 Extremal Principles and More Normals and Subdiï¬€erentials
By the approximate sum rule of Theorem 9.2.7 there exist xi âˆˆB(Â¯x, Ïµ), yi âˆˆ
B(Â¯yi, Ïµ), yâˆ—
i âˆˆF âˆ—, and xâˆ—
i âˆˆDâˆ—
F Î¦i(xi, yi)(yâˆ—
i ) satisfying (13.14) and
(xâˆ—, âˆ’yâˆ—, . . . , âˆ’yâˆ—) âˆˆ(xâˆ—
1, âˆ’yâˆ—
1, o, . . . , o) + (xâˆ—
2, o, âˆ’yâˆ—
2, o, . . . , o)
+ Â· Â· Â· + (xâˆ—
n, o, . . . , o, âˆ’yâˆ—
n) + (U Ã— V Ã— Â· Â· Â· Ã— V ).
It follows that yâˆ—
i âˆˆyâˆ—+ V for i = 1, . . . , n and that (13.15) holds.
âŠ“âŠ”
Similarly a weak chain rule can be derived for F-coderivatives. We employ
the following notation. Given multifunctions Î¨ : E â‡’F and Î¦ : F â‡’G, we
deï¬ne the composition Î¦ â—¦Î¨ : E â‡’G by
Î¦ â—¦Î¨(x) :=

{Î¦(y) | y âˆˆÎ¨(x)}.
Theorem 13.2.8 (Weak Coderivative Chain Rule) In addition to E
and F let G be a FrÃ©chet smooth Banach space, let Î¨ : E â‡’F and Î¦ : F â‡’G
be closed multifunctions, let Â¯x âˆˆE, Â¯y âˆˆÎ¨(Â¯x), and Â¯z âˆˆÎ¦(Â¯y). Suppose that
zâˆ—âˆˆGâˆ—and xâˆ—âˆˆDâˆ—
F (Î¦ â—¦Î¨)(Â¯x, Â¯z)(zâˆ—). Then for any Ïµ > 0 and any weakâˆ—
neighborhoods U of zero in Eâˆ—, V of zero in F âˆ—, and W of zero in Gâˆ—, there
exist x2 âˆˆBE(Â¯x, Ïµ), yi âˆˆBF (Â¯y, Ïµ), i = 1, 2, and z1 âˆˆBG(Â¯z, Ïµ) as well as
xâˆ—
2 âˆˆEâˆ—, yâˆ—
i âˆˆF âˆ—, i = 1, 2, and zâˆ—
1 âˆˆGâˆ—satisfying
yâˆ—
1 âˆ’yâˆ—
2 âˆˆV,
zâˆ—
1 âˆˆzâˆ—+ W,
yâˆ—
1 âˆˆDâˆ—
F Î¦(y1, z1)(zâˆ—
1),
xâˆ—
2 âˆˆDâˆ—
F Î¨(x2, y2)(yâˆ—
2),
max{âˆ¥xâˆ—
2âˆ¥, âˆ¥yâˆ—
1âˆ¥, âˆ¥yâˆ—
2âˆ¥, âˆ¥zâˆ—
1âˆ¥} Â· âˆ¥y1 âˆ’y2âˆ¥< Ïµ,
xâˆ—âˆˆxâˆ—
2 + U.
Proof. Since xâˆ—âˆˆDâˆ—
F (Î¦â—¦Î¨)(Â¯x, Â¯z)(zâˆ—), there exists a C1 function g : EÃ—G â†’R
such that gâ€²(Â¯x, Â¯z) = (xâˆ—, âˆ’zâˆ—) and Î´graph(Î¦â—¦Î¨)(x, z)âˆ’g(x, z) â‰¥0 for any (x, z)
near (Â¯x, Â¯z). We have
Î´graph Î¦(y, z) + Î´graph Î¨(x, y) â‰¥Î´graph(Î¦â—¦Î¨)(x, z)
and
Î´graph Î¦(Â¯y, Â¯z) + Î´graph Î¨(Â¯x, Â¯y) = Î´graph(Î¦â—¦Î¨)(Â¯x, Â¯z) = 0.
Deï¬ning Ëœf, Ëœg : E Ã— F Ã— G â†’R by
Ëœf(x, y, z) := Î´graph Î¦(y, z) + Î´graph Î¨(x, y),
Ëœg(x, y, z) := g(x, z),
we thus conclude that (Â¯x, Â¯y, Â¯z) is a local minimizer of the functional Ëœf âˆ’Ëœg.
Moreover, we have Ëœgâ€²(Â¯x, Â¯y, Â¯z) = (xâˆ—, o, âˆ’zâˆ—). Therefore
(xâˆ—, o, âˆ’zâˆ—) âˆˆâˆ‚F Ëœf(Â¯x, Â¯y, Â¯z).

13.2 Coderivatives
299
The conclusion of the theorem now follows by applying Theorem 9.2.7 to Ëœf.
The details are left as Exercise 13.13.6.
âŠ“âŠ”
Strong calculus rules for F-coderivatives can be obtained similarly by ap-
plying the strong local approximate sum rule of Theorem 9.2.6 instead of
Theorem 9.2.7. As a consequence of the above results, we can easily derive
exact sum and chain rules for M-coderivatives in ï¬nite-dimensional spaces.
First we introduce another concept.
Deï¬nition 13.2.9 The multifunction Î¦ : E â‡’F is said to be inner semi-
compact at Â¯x âˆˆDom Î¦ if for any sequence xk â†’Â¯x there exists a sequence
yk âˆˆÎ¦(xk) that contains a convergent subsequence.
Observe that if Dom Î¦ = E and Î¦ is locally compact at Â¯x (in particular, if F is
ï¬nite dimensional and Î¦ is locally bounded at Â¯x), then Î¦ is inner semicompact
at Â¯x.
Theorem 13.2.10 (Exact Coderivative Sum Rule) Let E
and F
be
ï¬nite-dimensional Banach spaces, let Î¦1 and Î¦2 be closed multifunctions and
let Â¯y âˆˆÎ¦1(Â¯x) + Î¦2(Â¯x). Assume that the multifunction S : E Ã— F â‡’F Ã— F
deï¬ned by
S(x, y) := {(y1, y2) | y1 âˆˆÎ¦1(x) y2 âˆˆÎ¦2(x), y1 + y2 = y}
(13.16)
is inner semicompact at (Â¯x, Â¯y). Assume also that
Dâˆ—
MÎ¦1(Â¯x, y1)(o) âˆ©

âˆ’Dâˆ—
MÎ¦2(Â¯x, y2)(o)

= {o}
âˆ€(y1, y2) âˆˆS(Â¯x, Â¯y).
(13.17)
Then for any yâˆ—âˆˆF âˆ—one has
Dâˆ—
M(Î¦1 + Î¦2)(Â¯x, Â¯y)(yâˆ—) âŠ†

(y1,y2)âˆˆS(Â¯x,Â¯y)

Dâˆ—
MÎ¦1(Â¯x, y1)(yâˆ—) + Dâˆ—
MÎ¦2(Â¯x, y2)(yâˆ—)

.
Proof. Take any xâˆ—âˆˆDâˆ—
M(Î¦1 + Î¦2)(Â¯x, Â¯y)(yâˆ—). Then
(xâˆ—, âˆ’yâˆ—) âˆˆNM(graph(Î¦1 + Î¦2), (Â¯x, Â¯y)).
By Theorem 13.1.4 there exist sequences (xk, yk) â†’(Â¯x, Â¯y) and (xâˆ—
k, yâˆ—
k) â†’
(xâˆ—, yâˆ—) as k â†’âˆsuch that (xk, yk) âˆˆgraph(Î¦1 + Î¦2) and xâˆ—
k âˆˆDâˆ—
F (Î¦1 +
Î¦2)(yâˆ—
k) for any k âˆˆN. Since S is inner semicompact, we may assume (omitting
relabeling) that there exists a sequence (y1k, y2k) âˆˆÎ¨(xk, yk) converging to
(y1, y2) âˆˆÎ¨(Â¯x, Â¯y). Applying Theorem 13.2.7 for any k, we ï¬nd yâˆ—
ik âˆˆB(yâˆ—
k, 1/k)
such that
xâˆ—
ik âˆˆDâˆ—
F Î¦i(xk, yik)(yâˆ—
ik)
and
âˆ¥xâˆ—
k âˆ’xâˆ—
1k âˆ’xâˆ—
2kâˆ¥< 1/k,
i = 1, 2. (13.18)
(I) If the sequence (âˆ¥xâˆ—
1kâˆ¥) is unbounded, we may assume (passing to a sub-
sequence if necessary) that âˆ¥xâˆ—
1kâˆ¥â†’âˆand that (xâˆ—
1k/âˆ¥xâˆ—
1k) converges

300
13 Extremal Principles and More Normals and Subdiï¬€erentials
to a unit vector zâˆ—. Dividing the second relation in (13.18) by âˆ¥xâˆ—
1kâˆ¥and
letting k â†’âˆ, we conclude that (xâˆ—
2k/âˆ¥xâˆ—
1kâˆ¥) converges to âˆ’zâˆ—. The ï¬rst
relation in (13.18) now shows that
zâˆ—âˆˆDâˆ—
MÎ¦1(Â¯x, y1)(o) âˆ©

âˆ’Dâˆ—
MÎ¦2(Â¯x, y2)(o)

,
which contradicts the assumption (13.17).
(II) Since by step (I) we know that the sequence (âˆ¥xâˆ—
1kâˆ¥) is bounded, the sec-
ond relation in (13.18) shows that the sequence (âˆ¥xâˆ—
2kâˆ¥) is also bounded.
Thus we may assume that both sequences are convergent, and passing to
the limit in (13.18) as k â†’âˆwe conclude that xâˆ—âˆˆDâˆ—
MÎ¦1(Â¯x, y1)(yâˆ—) +
Dâˆ—
MÎ¦2(Â¯x, y2)(yâˆ—), which proves the theorem.
âŠ“âŠ”
In a similar way, an exact coderivative chain rule can be established in
ï¬nite-dimensional spaces.
Theorem 13.2.11 (Exact Coderivative Chain Rule) Let E, F, G be
ï¬nite-dimensional Banach spaces, let Î¨ : E â‡’F and Î¦ : F â‡’G be closed
multifunctions, let Â¯x âˆˆE and Â¯z âˆˆ(Î¦ â—¦Î¨)(Â¯x). Assume that the multifunction
T : E Ã— G â‡’F deï¬ned by T(x, z) := Î¨(x) âˆ©Î¦âˆ’1(z) is inner semicompact at
(Â¯x, Â¯z). Assume further that for any Â¯y âˆˆT(Â¯x, Â¯z) the condition
Dâˆ—
MÎ¦(Â¯y, Â¯z)(o) âˆ©

âˆ’Dâˆ—
MÎ¨ âˆ’1(Â¯y, Â¯x)(o)

= {o}
is satisï¬ed. Then for any zâˆ—âˆˆGâˆ—one has
DM(Î¦ â—¦Î¨)(Â¯x, Â¯z)(zâˆ—) âŠ†

Â¯yâˆˆT (Â¯x,Â¯z)

Dâˆ—
MÎ¨(Â¯x, Â¯y) â—¦Dâˆ—
MÎ¦(Â¯y, Â¯z)(zâˆ—)

.
Proof. See Exercise 13.13.7.
âŠ“âŠ”
The following example shows that in an inï¬nite-dimensional space, exact
calculus rules as that of Theorem 13.2.10 may fail.
Example 13.2.12 Let E be a separable inï¬nite-dimensional Banach space,
let H1 and H2 be closed subspaces of E such that HâŠ¥
1 âˆ©HâŠ¥
2
= {o} and
HâŠ¥
1 + HâŠ¥
2 is weakâˆ—dense (which implies H1 âˆ©H2 = {o}) but not closed in
Eâˆ—; see Exercise 13.13.8 for a concrete example. Now deï¬ne Î¦1, Î¦2 : E â‡’
R by graph Î¦i := Hi Ã— R+ for i = 1, 2. Then we have graph(Î¦1 + Î¦2) =
{o} Ã— R+ , S(o, o) = {(0, 0)}, and S(x, y) = âˆ…whenever (x, y) Ì¸= (o, o); here
S is as in (13.16). The multifunction S is evidently inner semicompact at
(o, o). Moreover, it is easy to see that Dâˆ—
MÎ¦i(o, o)(0) = HâŠ¥
i
for i = 1, 2 and
Dâˆ—
M(Î¦1 +Î¦2)(o, o)(0) = Eâˆ—. Hence the regularity condition (13.17) is satisï¬ed
but the sum rule
Dâˆ—
M(Î¦1 + Î¦2)(o, o)(0) âŠ†Dâˆ—
MÎ¦1(o, o)(0) + Dâˆ—
MÎ¦2(o, o)(0)
fails.

13.3 Extremal Principles Involving Translations
301
13.3 Extremal Principles Involving Translations
We start with a deï¬nition.
Deï¬nition 13.3.1 Let A1, . . . , An be nonempty subsets of the normed vector
space E. A point Â¯x âˆˆâˆ©n
i=1Ai is said to be a local extremal point of the system
(A1, . . . , An) if there exist sequences (z1k), . . . , (znk) in E and a neighborhood
U of Â¯x such that zik â†’o as k â†’âˆfor i = 1, . . . , n and
n
6
i=1
(Ai âˆ’zik) âˆ©U = âˆ…
for all suï¬ƒciently large k âˆˆN.
In this case, (A1, . . . , An, Â¯x) is said to be an extremal system in E.
Remark 13.3.2 Geometrically this means that the sets A1, . . . , An can be
locally pushed apart by small translations. In particular, a point Â¯x âˆˆA1 âˆ©A2
is a local extremal point of (A1, A2) if and only if there exists a neighbor-
hood U of Â¯x such that for any Ïµ > 0 there is an element z âˆˆB(o, Ïµ) with
(A1 + z) âˆ©A2 âˆ©U = âˆ….
Example 13.3.3 shows the close relationship of this extremality concept to
constrained optimization.
Example 13.3.3 Let f : E â†’R and let M âŠ†E. If Â¯x is a local solution to
the problem
minimize f(x) subject to x âˆˆM,
then (Â¯x, f(Â¯x)) is a local extremal point of the system (A1, A2), where A1 :=
epi f and A2 := M Ã— {f(Â¯x)} (see Exercise 13.13.9).
The example A1 := {(Î¾, Î¾) | Î¾ âˆˆR}, A2 := {(Î¾, âˆ’Î¾) | Î¾ âˆˆR}, Â¯x := (0, 0)
shows that the condition A1 âˆ©A2 = {Â¯x} does not imply that Â¯x is a local
extremal point of (A1, A2). On the other hand, we have the following necessary
condition.
Lemma 13.3.4 If (A1, . . . , An, Â¯x) is an extremal system in E, then there
exists a neighborhood U of Â¯x such that
(int A1) âˆ©Â· Â· Â· âˆ©(int Anâˆ’1) âˆ©An âˆ©U = âˆ….
Proof. See Exercise 13.13.10.
âŠ“âŠ”
The next result reveals the relationship between extremality and the sep-
aration property.
Proposition 13.3.5 If A1 and A2 are subsets of E such that A1 âˆ©A2 Ì¸= âˆ…,
then the following holds:
(a) If A1 and A2 are separated, then (A1, A2, Â¯x) is an extremal system for any
Â¯x âˆˆA1 âˆ©A2.

302
13 Extremal Principles and More Normals and Subdiï¬€erentials
(b) Assume, in addition, that A1 and A2 are convex and int A1 Ì¸= âˆ…. If
(A1, A2, Â¯y) is an extremal system for some Â¯y âˆˆA1 âˆ©A2, then A1 and A2
are separated (and (A1, A2, Â¯x) is an extremal system for any Â¯x âˆˆA1 âˆ©A2).
Proof.
(a) If A1 and A2 are separated, then there exist xâˆ—âˆˆEâˆ—\ {o} and Î± âˆˆR
such that
âŸ¨xâˆ—, xâŸ©â‰¤Î± âˆ€x âˆˆA1
and
âŸ¨xâˆ—, yâŸ©â‰¥Î± âˆ€y âˆˆA2.
(13.19)
Choose x0 âˆˆE such that âŸ¨xâˆ—, x0âŸ©> 0 and set zk := (1/k)x0 for all k âˆˆN.
We show that (A1âˆ’zk)âˆ©A2 = âˆ…for any k âˆˆN, which evidently implies the
conclusion of (a). Assume, to the contrary, there exists y âˆˆ(A1 âˆ’zk)âˆ©A2
for any k. Then it follows that
Î± â‰¥âŸ¨xâˆ—, y + zkâŸ©= âŸ¨xâˆ—, yâŸ©+ 1
k âŸ¨xâˆ—, x0âŸ©
âˆ€k,
which contradicts the second inequality in (13.19).
(b) If (A1, A2, Â¯y) is an extremal system, then Lemma 13.3.4 implies that
(int A1) âˆ©(A2 âˆ©U) is empty for some neighborhood U of Â¯y which may be
assumed to be convex. By the weak separation theorem (Theorem 1.5.3)
there exist xâˆ—âˆˆEâˆ—and Î± âˆˆR such that
âŸ¨xâˆ—, xâŸ©â‰¤Î± âˆ€x âˆˆA1
and
âŸ¨xâˆ—, yâŸ©â‰¥Î± âˆ€y âˆˆA2 âˆ©U.
It remains to show that âŸ¨xâˆ—, yâŸ©â‰¥Î± for all y âˆˆA2. Suppose we had
âŸ¨xâˆ—, y0âŸ©< Î± for some y0 âˆˆA2. Set y := Î»y0 + (1 âˆ’Î»)Â¯y. If Î» âˆˆ(0, 1) is
suï¬ƒciently small, we have y âˆˆA2âˆ©U and so Î± â‰¤Î»âŸ¨xâˆ—, y0âŸ©+(1âˆ’Î»)âŸ¨xâˆ—, Â¯yâŸ©,
which is a contradiction because âŸ¨xâˆ—, y0âŸ©< Î± and âŸ¨xâˆ—, Â¯yâŸ©â‰¤Î±.
âŠ“âŠ”
By Proposition 13.3.5 and the weak separation theorem we now obtain:
Corollary 13.3.6 If A1 and A2 are convex subsets of E such that A1âˆ©A2 Ì¸= âˆ…
and int A1 Ì¸= âˆ…, then the following conditions are mutually equivalent:
(i) (A1, A2, Â¯x) is an extremal system for any Â¯x âˆˆA1 âˆ©A2.
(ii) A1 and A2 are separated.
(iii) (int A1) âˆ©A2 = âˆ….
Deï¬nition 13.3.7
(a) An extremal system (A1, . . . , An, Â¯x) in E is said to satisfy the exact ex-
tremal principle if there exist xâˆ—
i âˆˆNM(Ai, Â¯x), i = 1, . . . , n, such that
xâˆ—
1 + Â· Â· Â· + xâˆ—
n = o
and
âˆ¥xâˆ—
1âˆ¥+ Â· Â· Â· + âˆ¥xâˆ—
nâˆ¥= 1.
(13.20)

13.3 Extremal Principles Involving Translations
303
(b) An extremal system (A1, . . . , An, Â¯x) in E is said to satisfy the approximate
extremal principle if for every Ïµ > 0 there exist
xi âˆˆAi âˆ©BE(Â¯x, Ïµ)
and
xâˆ—
i âˆˆNF (Ai, xi) + ÏµBEâˆ—,
i = 1, . . . , n,
such that (13.20) holds.
Remark 13.3.8 We consider the case of two sets:
(a) An extremal system (A1, A2, Â¯x) satisï¬es the exact extremal principle if
and only if there exists xâˆ—âˆˆEâˆ—\ {o} such that
xâˆ—âˆˆNM(A1, Â¯x) âˆ©

âˆ’NM(A2, Â¯x)

.
(13.21)
If A1 and A2 are convex, then by Proposition 13.1.5 the relation (13.21)
is equivalent to
âŸ¨xâˆ—, y1âŸ©â‰¤âŸ¨xâˆ—, y2âŸ©
âˆ€y1 âˆˆA1 âˆ€y2 âˆˆA2,
which means that A1 and A2 are separated. Hence the exact extremal
principle can be considered as a statement on local separation of noncon-
vex sets.
(b) Similarly, an extremal system (A1, A2, Â¯x) satisï¬es the approximate
extremal principle if and only if for any Ïµ > 0 there exist xi âˆˆAi âˆ©B(Â¯x, Ïµ),
where i = 1, 2, and xâˆ—âˆˆEâˆ—such that âˆ¥xâˆ—âˆ¥= 1 and
xâˆ—âˆˆ

NF (A1, x1) + ÏµBEâˆ—
âˆ©

âˆ’NF (A2, x2) + ÏµBEâˆ—
.
(13.22)
This can be analogously interpreted as an approximate separation of A1
and A2 near Â¯x.
We consider a ï¬rst application of the approximate extremal principle.
Recall that in terms of the normal cone of convex analysis, N(A, Â¯x), the set
of support points of A is

x âˆˆbd A | N(A, x) Ì¸= {o}

.
If A is closed and convex, the Bishopâ€“Phelps theorem (Theorem 1.5.6) ensures
that this set is dense in bd A. Now we show that the approximate extremal
principle yields an approximate analogue of the Bishopâ€“Phelps theorem with-
out the convexity hypothesis if N(A, Â¯x) is replaced by the FrÃ©chet normal cone
NF (A, Â¯x).
Proposition 13.3.9 Let A be a proper closed subset of E and Â¯x âˆˆbd A. If
the approximate extremal principle holds for the system (A, {Â¯x}, Â¯x), then the
set

x âˆˆbd A | NF (A, x) Ì¸= {o}

is dense in bd A.

304
13 Extremal Principles and More Normals and Subdiï¬€erentials
Proof. By the approximate extremal principle for (A, {Â¯x}, Â¯x) with Ïµ âˆˆ(0, 1/2),
we ï¬nd x âˆˆA âˆ©BE(Â¯x, Ïµ) and xâˆ—âˆˆNF (A, x) + ÏµBEâˆ—such that âˆ¥xâˆ—âˆ¥= 1/2.
It follows that x âˆˆbd A because otherwise we had NF (A, x) = {o} and so
âˆ¥xâˆ—âˆ¥â‰¤Ïµ < 1/2: a contradiction. In particular we see that NF (A, x) Ì¸= {o}.
âŠ“âŠ”
The next result will be crucial for substantial applications of the approxi-
mate extremal principle.
Theorem 13.3.10 If E is a FrÃ©chet smooth Banach space, then the approx-
imate extremal principle holds for any extremal system (A1, . . . , An, Â¯x) in E,
where n âˆˆN and the sets A1, . . . , An are closed.
Proof.
(I) First we consider the case n = 2.
(Ia) Let Â¯x âˆˆA1 âˆ©A2 be a local extremal point of the system (A1, A2). Then
there exists a closed neighborhood U of Â¯x such that for any Ïµ > 0 there
is z âˆˆE satisfying âˆ¥zâˆ¥â‰¤Ïµ3/2 and
(A1 + z) âˆ©A2 âˆ©U = âˆ….
(13.23)
Obviously we may assume that U = E (otherwise replace A2 by A2 âˆ©U)
and Ïµ < 1/2. Equip E Ã— E with the Euclidean product norm, which is
also F-diï¬€erentiable away from the origin. Deï¬ne Ï• : E Ã— E â†’R by
Ï•(x) := Ï‰(x1 âˆ’x2 + z) = âˆ¥x1 âˆ’x2 + zâˆ¥,
where
x := (x1, x2) âˆˆE Ã— E.
By (13.23) we have Ï•(x) > 0 for any x âˆˆA1 Ã— A2. Hence Ï• is a C1
function in a neighborhood of each point of A1 Ã— A2. Set x := (Â¯x, Â¯x) and
deï¬ne the set
W(x) :=

x âˆˆA1 Ã— A2 | Ï•(x) + (Ïµ/2)âˆ¥x âˆ’xâˆ¥2 â‰¤Ï•(x)

,
which is nonempty and closed. For any x âˆˆW(x) we obtain (Ïµ/2)âˆ¥x âˆ’
xâˆ¥2 â‰¤Ï•(x) and so
âˆ¥x1 âˆ’Â¯xâˆ¥2 + âˆ¥x2 âˆ’Â¯xâˆ¥2 â‰¤(2/Ïµ)Ï•(x) = (2/Ïµ)âˆ¥zâˆ¥â‰¤Ïµ2.
We conclude that W(x) âŠ†BEÃ—E(Â¯x, Ïµ).
(Ib) For k = 0, 1, . . . we inductively deï¬ne points xk âˆˆA1 Ã— A2 and sets
W(xk) as follows. Given xk and W(xk), choose xk+1 âˆˆW(xk) such that
Ï•(xk+1) + Ïµ
k
	
i=0
âˆ¥xk+1 âˆ’xiâˆ¥2
2i+1
<
inf
xâˆˆW (xk)

Ï•(x) + Ïµ
k
	
i=0
âˆ¥x âˆ’xiâˆ¥2
2i+1

+
Ïµ3
23k+2

13.3 Extremal Principles Involving Translations
305
and deï¬ne
W(xk+1) :=

x âˆˆA1 Ã— A2
 Ï•(x) + Ïµ
k+1
	
i=0
âˆ¥x âˆ’xiâˆ¥2
2i+1
'
â‰¤Ï•(xk+1) + Ïµ
k
	
i=0
âˆ¥xk+1 âˆ’xiâˆ¥2
2i+1
'
.
For any k, the set W(xk) is a nonempty closed subset of A1 Ã— A2 and
one has W(xk+1) âŠ†W(xk). We show that diam W(xk) â†’0 as k â†’âˆ.
For all k âˆˆN and x âˆˆW(xk+1) we obtain
Ïµâˆ¥x âˆ’xk+1âˆ¥2
2k+2
â‰¤Ï•(xk+1)
+ Ïµ
k
	
i=0
âˆ¥xk+1 âˆ’xiâˆ¥2
2i+1
âˆ’

Ï•(x) + Ïµ
k
	
i=0
âˆ¥x âˆ’xiâˆ¥2
2i+1

â‰¤Ï•(xk+1) + Ïµ
k
	
i=0
âˆ¥xk+1 âˆ’xiâˆ¥2
2i+1
âˆ’
inf
xâˆˆW (xk)

Ï•(x) + Ïµ
k
	
i=0
âˆ¥x âˆ’xiâˆ¥2
2i+1
'
<
Ïµ3
23k+2 .
Thus diam W(xk) â‰¤Ïµ/2kâˆ’1 â†’0 as k â†’âˆ. By the Cantor intersection
theorem the set âˆ©âˆ
k=0W(xk) consists of exactly one point Ë†x = (Ë†x1, Ë†x2) âˆˆ
W(x0) âŠ†BEÃ—E(x, Ïµ) and one has xk â†’Ë†x as k â†’âˆ.
(Ic) We show that Ë†x is a minimizer of the function
%Ï•(x) := Ï•(x) + Ïµ
âˆ
	
i=0
âˆ¥x âˆ’xiâˆ¥2
2i+1
,
x âˆˆE Ã— E,
over A1 Ã— A2. Thus let x âˆˆA1 Ã— A2, x Ì¸= Ë†x. The construction of W(xk)
shows that for some k âˆˆN we have
Ï•(x) + Ïµ
k
	
i=0
âˆ¥x âˆ’xiâˆ¥2
2i+1
> Ï•(xk) + Ïµ
kâˆ’1
	
i=0
âˆ¥xk âˆ’xiâˆ¥2
2i+1
.
Since the sequence on the right-hand side is nonincreasing as k â†’âˆ, it
follows that in fact Ë†x is a minimizer of %Ï• on A1 Ã— A2 and so a minimizer
of Ïˆ := %Ï• + Î´A1Ã—A2 on E Ã— E. We conclude that o âˆˆâˆ‚F Ïˆ(Ë†x) (Propo-
sition 9.1.5). Since Ï• is a C1 function in a neighborhood of Ë†x, so is the
function %Ï•. By Proposition 9.2.2 and the deï¬nition of the FrÃ©chet normal
cone we obtain
âˆ’%Ï•â€²(Ë†x) âˆˆNF (A1 Ã— A2, Ë†x) = NF (A1, Ë†x) Ã— NF (A2, Ë†x).
(13.24)

306
13 Extremal Principles and More Normals and Subdiï¬€erentials
(Id) We calculate %Ï•â€²(Ë†x). It follows from the deï¬nition of %Ï• that %Ï•â€²(Ë†x) =
(uâˆ—
1, uâˆ—
2) âˆˆEâˆ—Ã— Eâˆ—, where
uâˆ—
1 := xâˆ—+ Ïµ
âˆ
	
i=0
vâˆ—
1i
âˆ¥Ë†x1 âˆ’x1iâˆ¥
2i
,
uâˆ—
2 := âˆ’xâˆ—+ Ïµ
âˆ
	
i=0
vâˆ—
2i
âˆ¥Ë†x2 âˆ’x2iâˆ¥
2i
,
xâˆ—:= Ï‰â€²(Ë†x1 âˆ’Ë†x2 + z),
(x1i, x2i) := xi,
vâˆ—
ji :=

Ï‰â€²(Ë†xj âˆ’xji)
if Ë†xj âˆ’xji Ì¸= o,
o
otherwise;
here i = 0, 1, . . . and j = 1, 2. We have âˆ¥xâˆ—âˆ¥= 1 and for j = 1, 2,
âˆ
	
i=0
âˆ¥vâˆ—
jiâˆ¥âˆ¥Ë†xj âˆ’xjiâˆ¥
2i
â‰¤1.
Thus, putting xj := Ë†xj and xâˆ—
j := (âˆ’1)jxâˆ—/2 for j = 1, 2, we obtain the
conclusion of the theorem in the case n = 2.
(II) Now we treat the general case by induction. If Â¯x is a local extremal point
of the system (A1, . . . , An), where n > 2, then y := (Â¯x, . . . , Â¯x) âˆˆEnâˆ’1 is
a local extremal point of the system (B1, B2), where
B1 := A1 Ã— Â· Â· Â· Ã— Anâˆ’1
and
B2 := {(x, . . . , x) âˆˆEnâˆ’1 | x âˆˆAn}.
By step (I) the approximate extremal principle holds for the system
(B1, B2, y), from which the assertion follows. The details are left as
Exercise 13.13.12.
âŠ“âŠ”
Now we are going to discuss the relationship between the approximate
extremal principle and other properties of a Banach space. In this connection
we adopt the following terminology.
Deï¬nition 13.3.11 We say that the subdiï¬€erential variational principle
holds in the Banach space E if for every proper l.s.c. functional f : E â†’R
bounded below, every Ïµ > 0, every Î» > 0, and every Â¯x âˆˆE such that
f(Â¯x) < infE f + Ïµ, there exist z âˆˆE and zâˆ—âˆˆâˆ‚F f(z) satisfying
âˆ¥z âˆ’Â¯xâˆ¥< Î»,
f(z) < inf
E f + Ïµ
and
âˆ¥zâˆ—âˆ¥< Ïµ/Î».
Theorem 13.3.12 (Characterization of Asplund Spaces) For
any
Banach space E the following assertions are mutually equivalent:
(a) E is an Asplund space.
(b) The approximate extremal principle holds for any extremal system
(A1, . . . , An, Â¯x), where n âˆˆN and A1, . . . , An are closed sets.
(c) The subdiï¬€erential variational principle holds in E.

13.3 Extremal Principles Involving Translations
307
Proof. Remarks on (a) =â‡’(b): By Theorem 13.3.10 we know that the approx-
imate extremal principle holds if E is FrÃ©chet smooth. If now E is an arbitrary
Asplund space, then every separable subspace is FrÃ©chet smooth (see Deville
et al. [50]). By a method called separable reduction certain problems concern-
ing F-subdiï¬€erentials and F-normal cones can be reduced from an arbitrary
Banach space to separable subspaces. In this way, the approximate extremal
principle can be transmitted from a FrÃ©chet smooth Banach space to an ar-
bitrary Asplund space. However, the method of separable reduction is quite
involved and will not be treated here; we refer to Borwein and Zhu [24] and
Mordukhovich [136].
(b) =â‡’(c): Let f, Ïµ, Î», and Â¯x be as in the deï¬nition of the subdiï¬€erential vari-
ational principle. Choose ËœÏµ âˆˆ(0, Ïµ) such that f(Â¯x) < infE f + (Ïµ âˆ’ËœÏµ) and put
ËœÎ» := (2Ïµâˆ’ËœÏµ)Î»/(2Ïµ). Notice that ËœÎ» < Î». By Ekelandâ€™s variational principle (The-
orem 8.2.4) there exists z âˆˆE satisfying âˆ¥z âˆ’Â¯xâˆ¥< ËœÎ», f(z) < infE f + (Ïµ âˆ’ËœÏµ),
and
f(z) < f(x) + âˆ¥x âˆ’zâˆ¥(Ïµ âˆ’ËœÏµ)/ËœÎ»
âˆ€x âˆˆE \ {z}.
(13.25)
We equip E Ã— R with the norm (x, Ï„) := âˆ¥xâˆ¥+ |Ï„| and Eâˆ—Ã— R with the
corresponding dual norm (xâˆ—, Ï„ âˆ—)âˆ¥= max{âˆ¥xâˆ—âˆ¥, |Ï„ âˆ—|}. Put g(x) := âˆ¥xâˆ’zâˆ¥(Ïµâˆ’
ËœÏµ)/ËœÎ» and deï¬ne
A1 := epi f
and
A2 := {(x, Ï„) âˆˆE Ã— R | Ï„ â‰¤f(z) âˆ’g(x)}.
Then A1 and A2 are closed in E Ã—R, and it follows from (13.25) that (z, f(z))
is a local extremal point of the system (A1, A2). Hence (b) ensures that the
approximate extremal principle holds in E and so in E Ã—R. Consequently, for
any Î· > 0 we ï¬nd (xi, Ï„i) âˆˆAi and (xâˆ—
i , Ï„ âˆ—
i ) âˆˆNF (Ai, (xi, Ï„i)), where i = 1, 2,
such that
âˆ¥xi âˆ’zâˆ¥+ |Ï„i âˆ’f(z)| < Î·,
(13.26)
1/2 âˆ’Î· < max{âˆ¥xâˆ—
i âˆ¥, |Ï„ âˆ—
i |} < 1/2 + Î·,
(13.27)
max{âˆ¥xâˆ—
1 + xâˆ—
2âˆ¥, |Ï„ âˆ—
1 + Ï„ âˆ—
2 |} < Î·.
(13.28)
The deï¬nition of the FrÃ©chet normal cone entails that for i = 1, 2 we have
lim sup
(x,Ï„)â†’Ai(xi,Ï„i)
âŸ¨xâˆ—
i , x âˆ’xiâŸ©+ Ï„ âˆ—
i (Ï„ âˆ’Ï„i)
âˆ¥x âˆ’xiâˆ¥+ |Ï„ âˆ’Ï„i|
â‰¤0.
(13.29)
It follows from the deï¬nition of A2 and (13.26) that Ï„2 = f(z)âˆ’g(x) whenever
Î· is suï¬ƒciently small. Moreover, by (13.27) we see that (xâˆ—
2, Ï„ âˆ—
2 ) Ì¸= o. Thus,
(13.29) shows that Ï„ âˆ—
2 > 0. Hence we obtain
xâˆ—
2/Ï„ âˆ—
2 âˆˆâˆ‚F g(x2)
and
âˆ¥xâˆ—
2âˆ¥/Ï„ âˆ—
2 â‰¤(Ïµ âˆ’ËœÏµ)/ËœÎ».
The latter inequality together with (13.27) yields
Ï„ âˆ—
2 â‰¥min

(1 âˆ’2Î·)ËœÎ»
2(Ïµ âˆ’ËœÏµ) , 1
2 âˆ’Î·
'
.
(13.30)

308
13 Extremal Principles and More Normals and Subdiï¬€erentials
From this estimate and (13.28) we must conclude that Ï„ âˆ—
1 < 0 whenever Î·
is suï¬ƒciently small. Now it follows that Ï„1 = f(x1). In fact, by (13.29) with
i = 1 the inequality Ï„1 > f(x1) would imply that Ï„ âˆ—
1 = 0. Thus we have shown
that âˆ’xâˆ—
1/Ï„ âˆ—
1 âˆˆâˆ‚F f(x1). The estimate (13.30) also yields Î·/Ï„ âˆ—
2 â†’0 as Î· â†“0.
Therefore, for Î· suï¬ƒciently small we have
âˆ¥xâˆ—
1âˆ¥
|Ï„ âˆ—
1 | < âˆ¥xâˆ—
2âˆ¥+ Î·
Ï„ âˆ—
2 âˆ’Î·
=
âˆ¥xâˆ—
2âˆ¥
Ï„ âˆ—
2
+ Î·
Ï„ âˆ—
2
 7
1 âˆ’Î·
Ï„ âˆ—
2

< Ïµ
Î».
Furthermore, the deï¬nition of ËœÎ» and (13.26) give
âˆ¥x1 âˆ’Â¯xâˆ¥< ËœÎ» + Î·
and
f(x1) = Ï„1 < inf
E f + Ïµ âˆ’ËœÏµ + Î·.
Deï¬ning z := x1 and zâˆ—:= âˆ’xâˆ—
1/Ï„ âˆ—
1 , the conclusion of (c) follows.
(c) =â‡’(a): Let Ï• : E â†’R be convex and continuous. Then for any x âˆˆE
the set âˆ‚F Ï•(x) coincides with âˆ‚Ï•(x) and is nonempty (Proposition 4.1.6).
We show that there exists a dense subset D of E such that âˆ‚F (âˆ’Ï•)(x) is
nonempty for any x âˆˆD. It is evident that this implies F-diï¬€erentiability of
Ï• on D. Choose Â¯x âˆˆE and Ïµ > 0. Since Ïˆ := âˆ’Ï• is continuous, there exists
Î· âˆˆ(0, Ïµ) such that Ïˆ(x) > Ïˆ(Â¯x) âˆ’Ïµ for every x âˆˆB(Â¯x, Î·). The functional
f := Ïˆ +Î´B(Â¯x,Î·) is l.s.c. on E. By applying (c) to f we obtain z âˆˆE satisfying
âˆ¥z âˆ’Â¯xâˆ¥< Î· and âˆ‚F f(z) Ì¸= âˆ…. It follows that âˆ‚F (âˆ’Ï•)(z) Ì¸= âˆ…. Therefore, Ï• is
F-diï¬€erentiable on a dense subset of E.
âŠ“âŠ”
By Theorem 13.3.12 the approximate extremal principle holds in an
Asplund space for arbitrary closed sets. Next we shall show that the exact
extremal principle holds in an Asplund space for closed sets with an addi-
tional property to be deï¬ned now.
Deï¬nition 13.3.13 The set A âŠ†E is said to be sequentially normally com-
pact (SNC) at Â¯x âˆˆA if for any sequence ((Ïµk, xk, xâˆ—
k)) in (0, +âˆ) Ã— A Ã— Eâˆ—
one has
&
Ïµk â†“0,
xk â†’Â¯x,
xâˆ—
k âˆˆ*NÏµk(A, xk),
xâˆ—
k
wâˆ—
âˆ’âˆ’â†’o
as
k â†’âˆ

=â‡’
xâˆ—
k â†’o
as
k â†’âˆ.
If E is an Asplund space, then due to Theorem 13.1.23 we may choose
Ïµk = 0 for any k âˆˆN in Deï¬nition 13.3.13. Clearly in a ï¬nite-dimensional
Banach space any nonempty subset is SNC at each of its points. In Sect. 13.4
we shall describe classes of SNC sets in inï¬nite-dimensional Banach spaces.
Theorem 13.3.14 Let E be an Asplund space and (A1, . . . , An, Â¯x) be an
extremal system in E. Assume that the sets A1, . . . , An are closed and all
but one of them are SNC at Â¯x. Then the exact extremal principle holds for
(A1, . . . , An, Â¯x).

13.4 Sequentially Normally Compact Sets
309
Proof. Let (Ïµk) be a sequence of positive numbers such that Ïµk â†“0 as k â†’âˆ.
Since the approximate extremal principle holds for (A1, . . . , An, Â¯x), for any k âˆˆ
N and i = 1, . . . , n there exist xik âˆˆAiâˆ©B(Â¯x, Ïµk) and xâˆ—
ik âˆˆNF (Ai, xik)+ÏµkBEâˆ—
satisfying
xâˆ—
1k + Â· Â· Â· + xâˆ—
nk = o
and
âˆ¥xâˆ—
1kâˆ¥+ Â· Â· Â· + âˆ¥xâˆ—
nkâˆ¥= 1.
(13.31)
We have xik â†’Â¯x as k â†’âˆfor i = 1, . . . , n. Since for i = 1, . . . , n the sequence
(xâˆ—
ik)kâˆˆN is bounded in the dual of the Asplund space E, Theorem 4.3.21
implies that a subsequence, again denoted (xâˆ—
ik)kâˆˆN, is weakâˆ—convergent to
some xâˆ—
i âˆˆEâˆ—. Since xâˆ—
ik âˆˆ*NÏµk(Ai, xik) for any k (cf. Remark 13.1.2(a)), the
deï¬nition of the M-normal cone shows that xâˆ—
i âˆˆNM(Ai, Â¯x). It is evident that
xâˆ—
1 + Â· Â· Â· + xâˆ—
n = o. It remains to show that the xâˆ—
i are not simultaneously zero.
By hypothesis we may assume that A1, . . . , Anâˆ’1 are SNC. We now suppose
we had xâˆ—
i = o for i = 1, . . . , n âˆ’1. Since
âˆ¥xâˆ—
nkâˆ¥â‰¤âˆ¥xâˆ—
1kâˆ¥+ Â· Â· Â· + âˆ¥xâˆ—
nâˆ’1kâˆ¥
âˆ€k âˆˆN,
we must conclude, letting k â†’âˆ, that xâˆ—
n = o. But this contradicts the
second equation in (13.31).
âŠ“âŠ”
Applying Theorem 13.3.14 to the system (A, {Â¯x}, Â¯x), we obtain the follow-
ing result.
Corollary 13.3.15 Let E be an Asplund space and A be a proper closed
subset of E. Then NM(A, Â¯x) Ì¸= {o} at every boundary point Â¯x of A where A
is SNC.
13.4 Sequentially Normally Compact Sets
We will now describe classes of SNC sets. For this we introduce a concept that
generalizes that of an epi-Lipschitzian set (cf. Exercise 13.13.13).
Deï¬nition 13.4.1 The set A âŠ†E is said to be compactly epi-Lipschitzian
at Â¯x âˆˆA if there exist a compact set C âŠ†E and numbers Î· > 0 and Ë†Ï„ > 0
such that
A âˆ©B(Â¯x, Î·) + Ï„B(o, Î·) âŠ†A + Ï„C
âˆ€Ï„ âˆˆ(0, Ë†Ï„).
(13.32)
If E is ï¬nite dimensional, then choosing Î· = Ë†Ï„ := 1 and C := B(o, 1) we
see that any subset A of E is compactly epi-Lipschitzian at each point Â¯x âˆˆA
but A need not be epi-Lipschitzian (see Remark 11.1.11).
Proposition 13.4.2 If A âŠ†E is compactly epi-Lipschitzian at Â¯x âˆˆA, then
A is SNC at Â¯x.

310
13 Extremal Principles and More Normals and Subdiï¬€erentials
Proof. Let C, Î·, and Ë†Ï„ be as in Deï¬nition 13.4.1. We will show that there
exists Î± > 0 such that for any Ïµ > 0 we have
*NÏµ(A, x) âŠ†

xâˆ—âˆˆEâˆ— Î·âˆ¥xâˆ—âˆ¥â‰¤Ïµ(Î± + Î·) + max
zâˆˆC âŸ¨xâˆ—, zâŸ©

âˆ€x âˆˆA âˆ©B(Â¯x, Î·).
(13.33)
Let x âˆˆA âˆ©B(Â¯x, Î·) and a sequence (Ï„k) in (0, Ë†Ï„) with Ï„k â†“0 be given. In view
of (13.32), for any k âˆˆN and any y âˆˆB(o, 1) there exists zk âˆˆC such that
x + Ï„k(Î·y âˆ’zk) âˆˆA. Since C is compact, a subsequence of (zk) is convergent
to some point Ë†z âˆˆC as k â†’âˆ. By the deï¬nition of *NÏµ(A, x) it follows that
âŸ¨xâˆ—, Î·y âˆ’Ë†zâŸ©âˆ’Ïµâˆ¥Î·y âˆ’Ë†zâˆ¥â‰¤0
âˆ€xâˆ—âˆˆ*NÏµ(A, x).
Since this is true for any y âˆˆB(o, 1), it follows that (13.33) holds with Î± :=
maxzâˆˆC âˆ¥zâˆ¥.
Now let sequences Ïµk â†“0, xk â†’A Â¯x, and xâˆ—
k
wâˆ—
âˆ’âˆ’â†’o be given such that
xâˆ—
k âˆˆ*NÏµk(A, xk) for all k âˆˆN. Since C is compact, we have âŸ¨xâˆ—
k, zâŸ©â†’0 as
k â†’âˆuniformly in z âˆˆC. Therefore, (13.33) implies that âˆ¥xâˆ—
kâˆ¥â†’0 as
k â†’âˆ. Hence A is SNC.
âŠ“âŠ”
Our aim now is to give a suï¬ƒcient condition for the intersection of SNC sets
to be SNC. This result will later be applied to derive optimality conditions.
To prepare the result, we ï¬rst establish an approximate intersection rule for
F-normal cones that is also remarkable on its own.
Proposition 13.4.3 Assume that E is a FrÃ©chet smooth Banach space, A1
and A2 are closed subsets of E, and Â¯x âˆˆA1 âˆ©A2. Further let xâˆ—âˆˆNF (A1 âˆ©
A2, Â¯x). Then for any Ïµ > 0 there exist Î» â‰¥0, xi âˆˆAi âˆ©B(Â¯x, Ïµ), and xâˆ—
i âˆˆ
NF (Ai, xi) + ÏµBEâˆ—, i = 1, 2, such that
Î»xâˆ—= xâˆ—
1 + xâˆ—
2
and
max{Î», âˆ¥xâˆ—
1âˆ¥} = 1.
(13.34)
Proof. Fix Ïµ > 0. The deï¬nition of the F-normal cone implies that there is a
neighborhood U of Â¯x such that
âŸ¨xâˆ—, x âˆ’Â¯xâŸ©âˆ’Ïµâˆ¥x âˆ’Â¯xâˆ¥â‰¤0
âˆ€x âˆˆA1 âˆ©A2 âˆ©U.
(13.35)
Equip E Ã— R with the norm âˆ¥(x, Î±)âˆ¥:= âˆ¥xâˆ¥+ |Î±|. Deï¬ne closed subsets B1,
B2 of E Ã— R by
B1 := {(x, Î±) | x âˆˆA1, Î± â‰¥0},
B2 := {(x, Î±) | x âˆˆA2, Î± â‰¤âŸ¨xâˆ—, x âˆ’Â¯xâŸ©âˆ’Ïµâˆ¥x âˆ’Â¯xâˆ¥}.
From (13.35) we obtain
B1 âˆ©(B2 âˆ’(o, Ï)) âˆ©(U Ã— R) = âˆ…
âˆ€Ï > 0.

13.4 Sequentially Normally Compact Sets
311
Hence (Â¯x, 0) âˆˆB1 âˆ©B2 is a local extremal point of the system (B1, B2). By
the approximate extremal principle of Theorem 13.3.10 we ï¬nd (xi, Î±i) âˆˆBi
and (Ëœxâˆ—
i , Î»i) âˆˆNF (Bi, (xi, Î±i)), i = 1, 2, such that
max{âˆ¥Ëœxâˆ—
1 + Ëœxâˆ—
2âˆ¥, |Î»1 + Î»2|} < Ïµ,
(13.36)
1
2 âˆ’Ïµ < max{âˆ¥Ëœxâˆ—
i âˆ¥, |Î»i|} < 1
2 + Ïµ,
i = 1, 2,
(13.37)
âˆ¥xi âˆ’Â¯xâˆ¥+ |Î±i| < Ïµ
i = 1, 2.
(13.38)
The deï¬nition of the F-normal cone implies that Ëœxâˆ—
1 âˆˆNF (A1, x1), Î»1 â‰¤0,
and
lim sup
(x,Î±)â†’B2(x2,Î±2)
âŸ¨Ëœxâˆ—
2, x âˆ’x2âŸ©+ Î»2(Î± âˆ’Î±2)
âˆ¥x âˆ’x2âˆ¥+ |Î± âˆ’Î±2|
â‰¤0.
(13.39)
The deï¬nition of B2 shows that Î»2 â‰¥0 and
Î±2 â‰¤âŸ¨xâˆ—, x2 âˆ’Â¯xâŸ©âˆ’Ïµâˆ¥x2 âˆ’Â¯xâˆ¥.
(13.40)
Now we distinguish two cases:
Case 1. We assume that the inequality in (13.40) is strict. Then (13.39) implies
that Î»2 = 0 and Ëœxâˆ—
2 âˆˆNF (A2, x2). Deï¬ne
xâˆ—
1 := Ëœxâˆ—
1
and
xâˆ—
2 := âˆ’Ëœxâˆ—
1 = Ëœxâˆ—
2 âˆ’(Ëœxâˆ—
1 + Ëœxâˆ—
2).
It then follows from (13.36) to (13.38) that the assertion (13.34) holds with
Î» = 0.
Case 2. Now we assume that (13.40) holds as an equation. Take any (x, Î±) âˆˆ
B2 such that
Î± = âŸ¨xâˆ—, x âˆ’Â¯xâŸ©âˆ’Ïµâˆ¥x âˆ’Â¯xâˆ¥,
x âˆˆA2 \ {x2}.
(13.41)
Substituting this into (13.39), we conclude that for some neighborhood V of
x2 we have
âŸ¨Ëœxâˆ—
2, x âˆ’x2âŸ©+ Î»2(Î± âˆ’Î±2) â‰¤Ïµ(âˆ¥x âˆ’x2âˆ¥+ |Î± âˆ’Î±2|)
âˆ€x âˆˆA2 âˆ©V ; (13.42)
here, Î± satisï¬es (13.41) and so
Î± âˆ’Î±2 = âŸ¨xâˆ—, x âˆ’x2âŸ©+ Ïµ(âˆ¥x2 âˆ’Â¯xâˆ¥âˆ’âˆ¥x âˆ’Â¯xâˆ¥).
(13.43)
It follows that
|Î± âˆ’Î±2| â‰¤(âˆ¥xâˆ—âˆ¥+ Ïµ)âˆ¥x âˆ’x2âˆ¥.
(13.44)
Now we substitute the right-hand side of (13.43) for Î± âˆ’Î±2 into the left-hand
side of (13.42), and we apply the estimate (13.44) to the right-hand side of
(13.42). In this way, (13.42) passes into
âŸ¨Ëœxâˆ—
2 + Î»2xâˆ—, x âˆ’x2âŸ©â‰¤Ïµcâˆ¥x âˆ’x2âˆ¥
âˆ€x âˆˆA2 âˆ©V,

312
13 Extremal Principles and More Normals and Subdiï¬€erentials
where c := 1 + âˆ¥xâˆ—âˆ¥+ Î»2 + Ïµ. The deï¬nition of Ïµ-normals shows that
Ëœxâˆ—
2 + Î»2xâˆ—âˆˆ*NÏµc(A2, x2).
Recall that Î»2 is nonnegative, and by (13.37) we have Î»2 + Ïµ < 1 if Ïµ is suï¬ƒ-
ciently small. It follows that 1 + âˆ¥xâˆ—âˆ¥< c < 2 + âˆ¥xâˆ—âˆ¥and so the positive con-
stant c may be chosen depending only on xâˆ—. By virtue of Theorem 13.1.23(a)
there exists z2 âˆˆA2 âˆ©B(x2, Ïµ) such that
Ëœxâˆ—
2 + Î»2xâˆ—âˆˆNF (A2, z2) + 2Ïµc BEâˆ—.
Put Î· := max{Î»2, âˆ¥Ëœxâˆ—
2âˆ¥}. For Ïµ < 1
4 we obtain from (13.37) that 1
4 < Î· < 3
4.
Now deï¬ne
Î» := Î»2/Î·,
xâˆ—
1 := âˆ’Ëœxâˆ—
2/Î·,
xâˆ—
2 := (Ëœxâˆ—
2 + Î»2xâˆ—)/Î·.
Then Î» â‰¥0, max{Î», âˆ¥xâˆ—
1âˆ¥} = 1, and Î»xâˆ—= xâˆ—
1 + xâˆ—
2. By (13.36) we further
have âˆ¥Ëœxâˆ—
1 + Ëœxâˆ—
2âˆ¥/Î· â‰¤4Ïµ. Hence we ï¬nally obtain
xâˆ—
1 = Ëœxâˆ—
1/Î· âˆ’(Ëœxâˆ—
1 + Ëœxâˆ—
2)/Î· âˆˆNF (A1, x1) + 4Ïµ BEâˆ—,
xâˆ—
2 âˆˆNF (A2, z2) + 8Ïµc BEâˆ—.
Recalling that c > 0 depends on xâˆ—only completes the proof.
âŠ“âŠ”
In Sect. 13.6 we will describe the M-normal cone of the inverse image of
a multifunction. In this context we shall need SNC properties of sets in a
product space which we now deï¬ne.
Deï¬nition 13.4.4 Assume that E and F are FrÃ©chet smooth Banach spaces,
A is a nonempty closed subset of E Ã— F, and (Â¯x, Â¯y) âˆˆA.
(a) The set A is said to be partially sequentially normally compact (PSNC)
at (Â¯x, Â¯y) with respect to E if for any sequences (xk, yk) â†’A (Â¯x, Â¯y) and
(xâˆ—
k, yâˆ—
k) âˆˆNF (A, (xk, yk)), one has
&
xâˆ—
k
wâˆ—
âˆ’âˆ’â†’o and âˆ¥yâˆ—
kâˆ¥â†’0 as k â†’âˆ

=â‡’
âˆ¥xâˆ—
kâˆ¥â†’0 as k â†’âˆ.
(b) The set A is said to be strongly partially sequentially normally com-
pact (strongly PSNC) at (Â¯x, Â¯y) with respect to E if for any sequences
(xk, yk) â†’A (Â¯x, Â¯y) and (xâˆ—
k, yâˆ—
k) âˆˆNF (A, (xk, yk)), one has
&
xâˆ—
k
wâˆ—
âˆ’âˆ’â†’o and yâˆ—
k
wâˆ—
âˆ’âˆ’â†’o as k â†’âˆ

=â‡’
âˆ¥xâˆ—
kâˆ¥â†’0 as k â†’âˆ.
The (strong) PSNC property with respect to F is deï¬ned analogously.
It is clear that if the set A is SNC, then it is strongly PSNC and so PSNC.
The strong PSNC property will not be needed until Sect. 13.6; for comparison
with the PSNC property we already introduced it here. We also need the
following concept.

13.4 Sequentially Normally Compact Sets
313
Deï¬nition 13.4.5 Assume that E and F are FrÃ©chet smooth Banach spaces,
A1 and A2 are closed subsets of E Ã— F, and (Â¯x, Â¯y) âˆˆA1 âˆ©A2. The system
(A1, A2) is said to satisfy the mixed qualiï¬cation condition at (Â¯x, Â¯y) with
respect to F if for any sequences (xik, yik) â†’Ai (Â¯x, Â¯y) and (xâˆ—
ik, yâˆ—
ik)
wâˆ—
âˆ’âˆ’â†’
(xâˆ—
i , yâˆ—
i ) as k â†’âˆwith (xâˆ—
ik, yâˆ—
ik) âˆˆNF (Ai, (xik, yik)), i = 1, 2, one has
&
xâˆ—
1k +xâˆ—
2k
wâˆ—
âˆ’âˆ’â†’o, âˆ¥yâˆ—
1k +yâˆ—
2kâˆ¥â†’0 as k â†’âˆ

=â‡’
(xâˆ—
1, yâˆ—
1) = (xâˆ—
2, yâˆ—
2) = o.
Remark 13.4.6 It is left as Exercise 13.13.14 to show that the condition
NM(A1, (Â¯x, Â¯y)) âˆ©

âˆ’NM(A2, (Â¯x, Â¯y))

= {(o, o)}
is suï¬ƒcient for the system (A1, A2) to satisfy the mixed qualiï¬cation condition
at (Â¯x, Â¯y) with respect to F.
Theorem 13.4.7 Assume that E and F are FrÃ©chet smooth Banach spaces,
A1 and A2 are closed subsets of E Ã—F, and (Â¯x, Â¯y) âˆˆA1 âˆ©A2, one of A1, A2 is
SNC and the other is PSNC at (Â¯x, Â¯y) with respect to E. Assume further that
(A1, A2) satisï¬es the mixed qualiï¬cation condition at (Â¯x, Â¯y) with respect to F.
Then A1 âˆ©A2 is PSNC at (Â¯x, Â¯y) with respect to E.
Proof.
(I) Assume that A1 is SNC at (Â¯x, Â¯y) and A2 is PSNC at (Â¯x, Â¯y) with respect
to E. Take any sequences (xk, yk) âˆˆA1 âˆ©A2 and (xâˆ—
k, yâˆ—
k) âˆˆNF (A1 âˆ©
A2, (xk, yk)) satisfying (xk, yk) â†’(Â¯x, Â¯y), xâˆ—
k
wâˆ—
âˆ’âˆ’â†’o, and âˆ¥yâˆ—
kâˆ¥â†’0 as
k â†’âˆ. We have to show that âˆ¥xâˆ—
kâˆ¥â†’0 as k â†’âˆ. Observe that it
suï¬ƒces to show that some subsequence of (xâˆ—
k) is norm convergent to
zero. In fact, if this is done and the entire sequence (xâˆ—
k) were not norm
convergent to zero, we could ï¬nd a subsequence (xâˆ—
kÎ½) and some Ï > 0
such that âˆ¥xâˆ—
kÎ½âˆ¥â‰¥Ï for any Î½ âˆˆN. Applying the above to the sequences
(xkÎ½) and (xâˆ—
kÎ½), we would ï¬nd a subsequence of the latter that is norm
convergent to zero, which contradicts the construction of (xâˆ—
kÎ½).
(II) Take an arbitrary sequence Ïµk â†“0 as k â†’âˆ. Applying Proposi-
tion 13.4.3 to xâˆ—
k for every k, we obtain sequences (xik, yik) âˆˆAi,
(xâˆ—
ik, yâˆ—
ik) âˆˆNF (Ai, (xik, yik)), where i = 1, 2, and Î»k â‰¥0 such that
âˆ¥(xik, yik) âˆ’(xk, yk)âˆ¥â‰¤Ïµk
âˆ€k âˆˆN,
i = 1, 2,
(13.45)
âˆ¥(xâˆ—
1k, yâˆ—
1k) + (xâˆ—
2k, yâˆ—
2k) âˆ’Î»k(xâˆ—
k, yâˆ—
k)âˆ¥â‰¤2Ïµk
âˆ€k âˆˆN,
(13.46)
1 âˆ’Ïµk â‰¤max{Î»k, âˆ¥xâˆ—
1kâˆ¥, âˆ¥yâˆ—
1kâˆ¥} â‰¤1 + Ïµk
âˆ€k âˆˆN.
(13.47)
Since the sequence (xâˆ—
k, yâˆ—
k) is weakâˆ—convergent, it is bounded. Hence
by (13.46) and (13.47) the sequences (xâˆ—
ik), (yâˆ—
ik), i = 1, 2, and (Î»k) are
also bounded. Since E and F are Asplund spaces, we conclude by The-
orem 4.3.21 that a subsequence of (xâˆ—
ik, yâˆ—
ik) (which we do not relabel) is

314
13 Extremal Principles and More Normals and Subdiï¬€erentials
weakâˆ—convergent as k â†’âˆto some (Ëœxâˆ—
i , Ëœyâˆ—
i ), i = 1, 2, and that the corre-
sponding subsequence of Î»k is convergent to some Î» â‰¥0. From xâˆ—
k
wâˆ—
âˆ’âˆ’â†’o,
âˆ¥yâˆ—
kâˆ¥â†’0, and (13.46) we obtain
xâˆ—
1k + xâˆ—
2k
wâˆ—
âˆ’âˆ’â†’o
and
âˆ¥yâˆ—
1k + yâˆ—
2kâˆ¥â†’0
as k â†’âˆ.
(13.48)
The mixed qualiï¬cation condition implies that Ëœxâˆ—
i = Ëœyâˆ—
i = o for i = 1, 2.
Since A1 is SNC, we conclude that âˆ¥xâˆ—
1kâˆ¥â†’0 and âˆ¥yâˆ—
1kâˆ¥â†’0. The latter
together with (13.48) yields âˆ¥yâˆ—
2kâˆ¥â†’0. Moreover, since A2 is PSNC at
(Â¯x, Â¯y) with respect to E, we obtain âˆ¥xâˆ—
2kâˆ¥â†’0. From (13.47) we now see
that Î» > 0. Hence (13.46) implies that (xâˆ—
k) is norm convergent to zero
as k â†’âˆ.
âŠ“âŠ”
Corollary 13.4.8 Assume that A1, . . . , An are closed subsets of the FrÃ©chet
smooth Banach space E, that Â¯x âˆˆâˆ©n
i=1Ai, and that
&
xâˆ—
i âˆˆNM(Ai, Â¯x), i = 1, . . . , n, xâˆ—
1 + Â· Â· Â· + xâˆ—
n = o

=â‡’xâˆ—
1 = Â· Â· Â· = xâˆ—
n = o.
(13.49)
If each Ai is SNC at Â¯x, then so is A1 âˆ©Â· Â· Â· âˆ©An.
Proof. For n = 2 this follows immediately from Theorem 13.4.7 with F := {o}.
In this connection observe that by Remark 13.4.6 the condition (13.49) ensures
that the mixed qualiï¬cation condition is satisï¬ed. For n > 2 the assertion
follows by induction.
âŠ“âŠ”
Now we turn to the SNC property of sets of the form Î¦âˆ’1(S). First we
formulate some hypotheses:
(H1) E and F are FrÃ©chet smooth Banach spaces, S is a closed subset of F.
(H2) Î¦ : E â‡’F is a multifunction, Â¯x âˆˆÎ¦âˆ’1(S).
(H3) The multifunction x â†’Î¦(x) âˆ©S is inner semicompact at Â¯x.
(H4) graph Î¦ is closed and is SNC at (Â¯x, Â¯y) for every Â¯y âˆˆÎ¦(Â¯x) âˆ©S.
(H5) NM(S, Â¯y) âˆ©kerDâˆ—
MÎ¦(Â¯x, Â¯y) = {o} for every Â¯y âˆˆÎ¦(Â¯x) âˆ©S.
Theorem 13.4.9 If the hypotheses (H1)â€“(H5) are satisï¬ed, then Î¦âˆ’1(S) is
SNC at Â¯x.
Proof.
(I) Consider sequences xk â†’Â¯x and xâˆ—
k
wâˆ—
âˆ’âˆ’â†’o, where xâˆ—
k âˆˆNF (Î¦âˆ’1(S), xk)
for any k âˆˆN. We have to show that âˆ¥xâˆ—
kâˆ¥â†’0 as k â†’âˆ. By (H3) and
(H4) we ï¬nd a sequence yk âˆˆÎ¦(xk) âˆ©S that contains a subsequence,
again denoted (yk), converging to some Â¯y âˆˆÎ¦(xk) âˆ©S. Deï¬ning
B1 := graph Î¦
and
B2 := E Ã— S,
we obtain that (xâˆ—
k, o) âˆˆNF (B1 âˆ©B2, (xk, yk)).

13.5 Calculus for Mordukhovich Subdiï¬€erentials
315
(II) We want to apply Theorem 13.4.7. Therefore, we check the SNC prop-
erties of the sets B1 and B2. First notice that
NF (B2, (xk, yk)) = NF (E, xk) Ã— NF (S, yk) = {o} Ã— NF (S, yk).
(13.50)
Hence B2 is always PSNC at (Â¯x, Â¯y) with respect to E. Moreover, by (H4)
the set B1 is SNC at (Â¯x, Â¯y) or B1 is PSNC at (Â¯x, Â¯y) with respect to F.
Thus, the SNC properties required in Theorem 13.6.4 are satisï¬ed.
(III) It is left as Exercise 13.13.15 to show that the hypothesis (H5) implies
the mixed qualiï¬cation condition with respect to F.
(IV) By Theorem 13.4.7 the set B1 âˆ©B2 is PSNC at (Â¯x, Â¯y) with respect to E.
Hence it follows that (xâˆ—
k) is norm convergent to zero.
âŠ“âŠ”
13.5 Calculus for Mordukhovich Subdiï¬€erentials
We start with a special case of a sum rule for M-subdiï¬€erentials.
Proposition 13.5.1 Assume that f : E â†’R is proper and l.s.c., Â¯x âˆˆdom f,
and g : E â†’R.
(a) If g is strictly F-diï¬€erentiable at Â¯x, then
âˆ‚M(f + g)(Â¯x) = âˆ‚Mf(Â¯x) + {gâ€²(Â¯x)}.
(13.51)
(b) If g is locally L-continuous around Â¯x, then âˆ‚âˆ
Mg(Â¯x) = {o} and
âˆ‚âˆ
M(f + g)(Â¯x) = âˆ‚âˆ
Mf(Â¯x).
(13.52)
Proof.
(a) (I) First we show that
âˆ‚M(f + g)(Â¯x) âŠ†âˆ‚Mf(Â¯x) + {gâ€²(Â¯x)}.
(13.53)
Since g is strictly F-diï¬€erentiable, for any sequence Î·i â†“0 as i â†’âˆ
there exists a sequence Î´i â†“0 such that
|g(z) âˆ’g(x) âˆ’âŸ¨gâ€²(Â¯x), z âˆ’xâŸ©| â‰¤Î·iâˆ¥z âˆ’xâˆ¥
âˆ€x, z âˆˆB(Â¯x, Î´i)
âˆ€i âˆˆN.
(13.54)
Now let xâˆ—âˆˆâˆ‚M(f + g)(Â¯x) be given. By Theorem 13.1.17 there are
sequences xk â†’f+g Â¯x, xâˆ—
k
wâˆ—
âˆ’âˆ’â†’xâˆ—, and Ïµk â†“0 as k â†’âˆsatisfying
xâˆ—
k âˆˆ*âˆ‚Ïµk(f + g)(xk)
âˆ€k âˆˆN.
(13.55)
Let (ki) be a strictly increasing sequence of positive integers such that
âˆ¥xki âˆ’Â¯xâˆ¥â‰¤Î´i/2 for any i âˆˆN. In view of (13.55) we ï¬nd Ë†Î´i âˆˆ(0, Î´i/2)
such that for all x âˆˆB(xki, Ë†Î´i) and any i âˆˆN we have
f(x)âˆ’f(xki)+g(x)âˆ’g(xki)âˆ’âŸ¨xâˆ—
ki, xâˆ’xkiâŸ©â‰¥âˆ’2Ïµkiâˆ¥xâˆ’xkiâˆ¥. (13.56)

316
13 Extremal Principles and More Normals and Subdiï¬€erentials
Since x âˆˆB(xki, Ë†Î´i) implies x âˆˆB(Â¯x, Î´i), it follows from (13.54) and
(13.56) that for all x âˆˆB(xki, Ë†Î´i) and any i âˆˆN we obtain
g(x) âˆ’g(xki) âˆ’âŸ¨xâˆ—
ki âˆ’gâ€²(Â¯x), x âˆ’xkiâŸ©â‰¥âˆ’(2Ïµki + Î·i)âˆ¥x âˆ’xkiâˆ¥.
We conclude that
xâˆ—
ki âˆ’gâ€²(Â¯x) âˆˆ*âˆ‚ËœÏµif(xki),
where ËœÏµi := 2Ïµki + Î·i
âˆ€i âˆˆN.
(13.57)
Since f(xki) + g(xki) â†’f(Â¯x) + g(Â¯x) and g is continuous at Â¯x, we
see that f(xki) â†’f(Â¯x) as i â†’âˆ. Therefore, by Theorem 13.1.17 it
follows from (13.57) that xâˆ—âˆ’gâ€²(Â¯x) âˆˆâˆ‚Mf(Â¯x). This veriï¬es (13.53).
(II) The opposite inclusion to (13.53) is obtained from the latter inclusion
in the following way:
âˆ‚Mf(Â¯x) = âˆ‚M[(f + g) + (âˆ’g)](Â¯x) âŠ†âˆ‚M(f + g)(Â¯x) âˆ’gâ€²(Â¯x).
(b) Now we prove
âˆ‚âˆ
M(f + g)(Â¯x) âŠ†âˆ‚âˆ
Mf(Â¯x).
(13.58)
Once this is done, the opposite inclusion follows as in step (II) above.
Finally, the relation âˆ‚âˆ
Mg(Â¯x) = {o} is the special case f = o of (13.52)
(and is already contained in Corollary 13.2.5).
Let xâˆ—âˆˆâˆ‚âˆ
M(f + g)(Â¯x) be given. By deï¬nition of the singular M-
subdiï¬€erential there exist sequences xk â†’Â¯x, Î±k â†’(f + g)(Â¯x), Ïµk â†“0,
Î·k â†“0, and Î³k â†’0 such that Î±k â‰¥f(xk) + g(xk) and
âŸ¨xâˆ—
k, x âˆ’xkâŸ©+ Î³k(Î± âˆ’Î±k) â‰¤2Ïµk(âˆ¥x âˆ’xkâˆ¥+ |Î± âˆ’Î±k|)
(13.59)
for all (x, Î±) âˆˆepi (f + g) satisfying x âˆˆB(xk, Î·k) and |Î± âˆ’Î±k| â‰¤Î·k for
any k âˆˆN. Let Î» > 0 denote a Lipschitz constant of g around Â¯x and put
ËœÎ·k :=
Î·k
2(Î» + 1),
ËœÎ±k := Î±k âˆ’g(xk).
It follows that ËœÎ±k â‰¥f(xk) for any k and ËœÎ±k â†’f(Â¯x) as k â†’âˆ. Notice
that for any k and any (x, ËœÎ±) satisfying
(x, ËœÎ±) âˆˆepi f,
x âˆˆB(xk, ËœÎ·k)
and
|ËœÎ± âˆ’ËœÎ±k| â‰¤ËœÎ·k,
(13.60)
we have
(x, ËœÎ± + g(x)) âˆˆepi (f + g)
and
|(ËœÎ± + g(x)) âˆ’Î±k| â‰¤Î·k.
This and (13.59) give
âŸ¨xâˆ—
k, x âˆ’xkâŸ©+ Î±k(ËœÎ± âˆ’ËœÎ±k)
â‰¤ËœÏµk(âˆ¥x âˆ’xkâˆ¥+ |ËœÎ± âˆ’ËœÎ±k|), where ËœÏµk := 2Ïµk(Î» + 1) + |Î³k|Î»
for any (x, ËœÎ±) satisfying (13.60). It follows that
(xâˆ—
k, Î³k) âˆˆ*NËœÏµk(epi f, (xk, ËœÎ±k))
âˆ€k âˆˆN.
This implies xâˆ—âˆˆâˆ‚âˆ
Mf(Â¯x) and completes the proof.
âŠ“âŠ”

13.5 Calculus for Mordukhovich Subdiï¬€erentials
317
Next we derive a useful property of M-subdiï¬€erentials of locally L-
continuous functionals.
Proposition 13.5.2 Let E be an Asplund space and f : E â†’R be a proper
l.s.c. functional. Then âˆ‚Mf(Â¯x) Ì¸= âˆ…for every Â¯x âˆˆdom f where f is locally
L-continuous.
Proof. The assumptions on f imply that the set A := epi f is closed and epi-
Lipschitzian around (Â¯x, f(Â¯x)). By Proposition 13.4.2, epi f is also SNC. Hence
Corollary 13.3.15 implies that NM

epi f, (Â¯x, f(Â¯x)

) Ì¸= {(o, 0)}. By Proposi-
tion 13.5.1 we know that âˆ‚âˆ
Mf(Â¯x) = {o}. Hence Lemma 13.1.11 completes the
proof.
âŠ“âŠ”
Applying the approximate extremal principle, we now establish an ex-
act sum rule for M-subdiï¬€erentials in a FrÃ©chet smooth Banach space. In
this context, the following property will compensate for the absence of ï¬nite
dimensionality.
Deï¬nition 13.5.3 The proper functional f : E â†’R is said to be sequentially
normally epi-compact (SNEC) at Â¯x âˆˆdom f if epi f is SNC at (Â¯x, f(Â¯x)).
Remark 13.5.4 The functional f is SNEC at Â¯x if epi f is compactly epi-
Lipschitzian at (Â¯x, f(Â¯x)) (Proposition 13.4.2) and so, in particular, if epi f is
epi-Lipschitzian at (Â¯x, f(Â¯x)) (Exercise 13.13.13) or E is ï¬nite dimensional.
We will also make use of the following qualiï¬cation condition:
&
xâˆ—
i âˆˆâˆ‚âˆ
Mfi(Â¯x), i = 1, . . . , n and xâˆ—
1 + Â· Â· Â· + xâˆ—
n = o

=â‡’xâˆ—
1 = Â· Â· Â· = xâˆ—
n = o.
(13.61)
Theorem 13.5.5 (Sum Rule for M-Subdiï¬€erentials) Let E be a FrÃ©chet
smooth Banach space, let f1, . . . , fn : E â†’R be l.s.c., and let Â¯x âˆˆâˆ©n
i=1dom fi.
Assume that all but one of fi are SNEC at Â¯x âˆˆâˆ©n
i=1dom fi and that condi-
tion (13.61) is satisï¬ed. Then
âˆ‚M(f1 + Â· Â· Â· + fn)(Â¯x) âŠ†âˆ‚Mf1(Â¯x) + Â· Â· Â· + âˆ‚Mfn(Â¯x).
(13.62)
If, in addition, f1, . . . , fn are all lower regular at Â¯x, then so is f1 + Â· Â· Â· + fn
and (13.62) holds with equality.
Proof. We verify the assertions for the case that n = 2, leaving the induction
proof in the case n > 2 as Exercise 13.13.18. Thus let f1 and f2 be given and
assume that f1 is SNEC at Â¯x. Take any xâˆ—âˆˆâˆ‚M(f1 +f2)(Â¯x). By the deï¬nition
of the M-subdiï¬€erential there exist sequences xk â†’Â¯x and xâˆ—
k
wâˆ—
âˆ’âˆ’â†’xâˆ—such that
fi(xk) â†’fi(Â¯x) as k â†’âˆ, where i = 1, 2, and xâˆ—
k âˆˆâˆ‚F (f1 + f2)(xk) for all
k âˆˆN. Let (Ïµk) be a sequence of positive real numbers such that Ïµk â†“0 as

318
13 Extremal Principles and More Normals and Subdiï¬€erentials
k â†’âˆ. The deï¬nition of the F-subdiï¬€erential implies that for any k âˆˆN
there exists a neighborhood Uk of xk such that
(f1+f2)(x)âˆ’(f1+f2)(xk)âˆ’âŸ¨xâˆ—
k, xâˆ’xkâŸ©+Ïµkâˆ¥xâˆ’xkâˆ¥â‰¥0
âˆ€x âˆˆUk. (13.63)
Since f1 and f2 are l.s.c., the sets
A1k := {(x, Âµ) âˆˆE Ã— R | f1(x) âˆ’f1(xk) â‰¤Âµ}
and
A2k := {(x, Âµ) âˆˆE Ã— R | f2(x) âˆ’f2(xk) âˆ’âŸ¨xâˆ—
k, x âˆ’xkâŸ©+ Ïµkâˆ¥x âˆ’xkâˆ¥â‰¤âˆ’Âµ}
are closed. Applying (13.63) we obtain for any k,
(xk, 0) âˆˆA1k âˆ©A2k
and
A1k âˆ©(A2k âˆ’(0, Î±)) âˆ©(Uk Ã— R) = âˆ…
âˆ€Î± > 0.
Hence (A1k, A2k, (xk, 0)) is an extremal system and so by Theorem 13.3.10 the
extremal principle holds for this system. It follows that for i = 1, 2 and any
k âˆˆN there exist (xi,k, Âµi,k) âˆˆ(epi fi) âˆ©B(xk, fi(xk), Ïµk), (Ëœxâˆ—
k, Î±k) âˆˆEâˆ—Ã— R,
and (Ëœyâˆ—
k, Î²k) âˆˆEâˆ—Ã— R satisfying
1/2 âˆ’Ïµk â‰¤âˆ¥Ëœxâˆ—
kâˆ¥+ |Î±k| â‰¤1/2 + Ïµk,
(13.64)
1/2 âˆ’Ïµk â‰¤âˆ¥Ëœyâˆ—
kâˆ¥+ |Î²k| â‰¤1/2 + Ïµk,
(13.65)
âˆ¥(Ëœxâˆ—
k, Î±k) + (Ëœyâˆ—
k, Î²k)âˆ¥â‰¤Ïµk,
(13.66)
(Ëœxâˆ—
k, Î±k) âˆˆNF

A1k, (x1,k, Âµ1,k âˆ’f1(xk))

,
(13.67)
(Ëœyâˆ—
k, Î²k) âˆˆNF

A2k, (x2,k, Î³k)

,
(13.68)
where Î³k := âˆ’Âµ2,k + f2(xk) + âŸ¨xâˆ—
k, x2,k âˆ’xkâŸ©âˆ’Ïµkâˆ¥x2,k âˆ’xkâˆ¥. For i = 1, 2 the
sequence (xi,k, Âµi,k) converges in epi fi to (Â¯x, fi(Â¯x)) as k â†’âˆ. Since the se-
quences (Ëœxâˆ—
k, Î±k) and (Ëœyâˆ—
k, Î²k) are bounded and E is an Asplund space (Propo-
sition 4.7.15), the sequences contain subsequences, again denoted (Ëœxâˆ—
k, Î±k) and
(Ëœyâˆ—
k, Î²k), that are weakâˆ—convergent to some (Ëœxâˆ—, Î±) and (Ëœyâˆ—, Î²), respectively
(Theorem 4.3.21). In view of (13.67) and the deï¬nition of the Mordukhovich
normal cone we conclude that
(Ëœxâˆ—, Î±) âˆˆNM

epi f1, (Â¯x, f1(Â¯x))

.
(13.69)
Moreover, by (13.68) and the deï¬nition of the FrÃ©chet normal cone we obtain
lim sup
(x,Âµ) â†’
epif2
(x2,k, Âµ2,k)
âŸ¨Ëœyâˆ—
k, x âˆ’x2,kâŸ©âˆ’Î²k

Âµ âˆ’Âµ2,k âˆ’âŸ¨xâˆ—
k, x âˆ’x2,kâŸ©+ Ïµkâˆ¥x âˆ’x2,kâˆ¥
âˆ¥x âˆ’x2,kâˆ¥+ |Âµ âˆ’Âµ2,k| + |âŸ¨xâˆ—
k, x âˆ’x2,kâŸ©| + Ïµkâˆ¥x âˆ’x2,kâˆ¥
â‰¤0,

13.5 Calculus for Mordukhovich Subdiï¬€erentials
319
which implies
(Î²kxâˆ—
k + Ëœyâˆ—
k, âˆ’Î²k) âˆˆ*NÎ·k

epi f2, (x2,k, Âµ2,k)

,
where Î·k := Ïµk(1+âˆ¥xâˆ—
kâˆ¥+Ïµk +|Î²k|) for each k. Letting k â†’âˆ, we deduce that
(Î²xâˆ—+ Ëœyâˆ—, âˆ’Î²) âˆˆNM

epi f2, (Â¯x, f2(Â¯x))

, where by (13.66) we have Ëœyâˆ—= âˆ’Ëœxâˆ—
and Î² = âˆ’Î±. Thus,
(âˆ’Î±xâˆ—âˆ’Ëœxâˆ—, Î±) âˆˆNM

epi f2, (Â¯x, f2(Â¯x))

.
(13.70)
Now we show that Î± Ì¸= 0. Suppose we have Î± = 0, then (13.69) and (13.70)
give
(Ëœxâˆ—, 0) âˆˆNM

epi f1, (Â¯x, f1(Â¯x))

and (âˆ’Ëœxâˆ—, 0) âˆˆNM

epi f2, (Â¯x, f2(Â¯x))

.
Hence the deï¬nition of the singular subdiï¬€erential and the condition (13.61)
imply that xâˆ—= o, which entails that (Ëœxâˆ—
k, Î±k)
wâˆ—
âˆ’âˆ’â†’(o, 0) as k â†’âˆ. Notice
that by (13.67) we have (Ëœxâˆ—
k, Î±k) âˆˆNF (epi f1, (x1,k, Âµ1,k)) and that f1 is
SNEC at Â¯x. Therefore the sequence ((Ëœxâˆ—
k, Î±k)) is norm convergent to (o, 0) as
k â†’âˆ. But this contradicts the inequalities (13.64) and (13.65). Hence we
must conclude that Î± Ì¸= 0 and so Î± < 0 because Î±k â‰¤0 for any k. Now (13.69)
and (13.70) pass into
(Ëœxâˆ—/|Î±|, âˆ’1) âˆˆNM

epi f1, (Â¯x, f1(Â¯x))
and (xâˆ—âˆ’Ëœxâˆ—/|Î±|, âˆ’1) âˆˆNM

epi f2, (Â¯x, f2(Â¯x))
.
Deï¬ning xâˆ—
1 :=
Ëœxâˆ—/|Î±|, xâˆ—
2 := xâˆ—âˆ’xâˆ—
1, and recalling that âˆ‚Mfi(Â¯x) =
NM

epi fi, (Â¯x, fi(Â¯x))

, we obtain xâˆ—âˆˆâˆ‚Mf1(Â¯x) + âˆ‚Mf2(Â¯x), and the proof
of (13.62) is complete.
To verify the statement on equality, notice that we always have
âˆ‚F f1(Â¯x) + Â· Â· Â· + âˆ‚F fn(Â¯x) âŠ†âˆ‚F (f1 + Â· Â· Â· + fn)(Â¯x).
If each fi is lower regular at Â¯x, then it follows from the latter inclusion and
(13.62) that f1 + Â· Â· Â· + fn is also lower regular at Â¯x and (13.62) holds with
equality.
âŠ“âŠ”
If E is ï¬nite dimensional, any function f : E â†’R is SNEC at any
Â¯x âˆˆdom f. Therefore the next result is an immediate consequence of The-
orem 13.5.5.
Corollary 13.5.6 Let E be a ï¬nite-dimensional Banach space, let f1, . . . , fn :
E â†’R be l.s.c., and let Â¯x âˆˆâˆ©n
i=1dom fi. Assume that condition (13.61) is
satisï¬ed. Then (13.62) holds. If, in addition, f1, . . . , fn are all lower regular
at Â¯x, then so is f1 + Â· Â· Â· + fn and (13.62) holds with equality.
By examples similar to Example 13.2.12 one can show that in an inï¬nite-
dimensional Banach space the SNEC property is not dispensable.

320
13 Extremal Principles and More Normals and Subdiï¬€erentials
13.6 Calculus for Mordukhovich Normals
The sum rule for M-subdiï¬€erentials implies an intersection rule for M-normal
cones that will be crucial for deriving multiplier rules. We need the following
qualiï¬cation condition:
&
xâˆ—
i âˆˆNM(Ai, Â¯x),
i = 1, . . . , n
and
xâˆ—
1 + Â· Â· Â· + xâˆ—
n = o

=â‡’
xâˆ—
1 = Â· Â· Â· = xâˆ—
n = o.
(13.71)
Theorem 13.6.1 (Intersection Rule 1 for M-normal Cones) Let E be
a FrÃ©chet smooth Banach space, let A1, . . . , An be nonempty closed subsets of
E, and let Â¯x âˆˆâˆ©n
i=1Ai. Assume that all but one of Ai are SNC at Â¯x and that
condition (13.71) is satisï¬ed. Then
NM(A1 âˆ©Â· Â· Â· âˆ©An, Â¯x) âŠ†NM(A1, Â¯x) + Â· Â· Â· + NM(An, Â¯x).
(13.72)
If, in addition, A1, . . . , An are all normally regular at Â¯x, then so is A1âˆ©Â· Â· Â·âˆ©An
and (13.72) holds with equality.
Proof. Apply Theorem 13.5.5 to fi := Î´Ai and use the statement of Exer-
cise 13.13.17.
âŠ“âŠ”
Next we will establish an intersection rule for M-normal cones in a product
space Z := E Ã—F that we equip with the norm âˆ¥(x, y)âˆ¥:= âˆ¥xâˆ¥+âˆ¥yâˆ¥, (x, y) âˆˆ
E Ã— F. Recall that if E and F are FrÃ©chet smooth, so is E Ã— F. We will make
use of the following concept.
Deï¬nition 13.6.2 Let A1 and A2 be closed subsets of the FrÃ©chet smooth
Banach space Z and let Â¯z âˆˆA1 âˆ©A2. The system (A1, A2) is said to satisfy
the limiting qualiï¬cation condition at Â¯z if for any sequences zik â†’Ai Â¯z, zâˆ—
ik âˆˆ
NF (Ai, zik), and zâˆ—
ik
wâˆ—
âˆ’âˆ’â†’zâˆ—
i as k â†’âˆ, i = 1, 2, one has
&
âˆ¥zâˆ—
1k + zâˆ—
2kâˆ¥â†’0 as k â†’âˆ

=â‡’
zâˆ—
1 = zâˆ—
2 = o.
Remark 13.6.3 Observe that the limiting qualiï¬cation condition is a special
case of the mixed qualiï¬cation condition with respect to E when F := {o}.
Hence by Remark 13.4.6 the condition
NM(A1, Â¯z) âˆ©

âˆ’NM(A2, Â¯z)

= {o}
(13.73)
is suï¬ƒcient for the system (A1, A2) to satisfy the limiting qualiï¬cation condi-
tion.
Theorem 13.6.4 (Intersection Rule 2 for M-normal Cones) Let
E
and F be FrÃ©chet smooth Banach spaces, A1 and A2 be closed subsets of
E Ã— F, and (Â¯x, Â¯y) âˆˆA1 âˆ©A2. Assume that (A1, A2) satisï¬es the limiting
qualiï¬cation condition, A1 is PSNC at (Â¯x, Â¯y) with respect to E, and A2 is
strongly PSNC at (Â¯x, Â¯y) with respect to F. Then one has
NM(A1 âˆ©A2, (Â¯x, Â¯y)) âŠ†NM(A1, (Â¯x, Â¯y)) + NM(A2, (Â¯x, Â¯y)).
(13.74)

13.6 Calculus for Mordukhovich Normals
321
Proof.
(I) Take any (xâˆ—, yâˆ—) âˆˆNM(A1 âˆ©A2, (Â¯x, Â¯y)). By Theorem 13.1.23 there exist
sequences (xk, yk) âˆˆA1âˆ©A2 and (xâˆ—
k, yâˆ—
k) âˆˆNF (A1âˆ©A2, (xk, yk)) satisfying
(xk, yk) â†’(Â¯x, Â¯y)
and
(xâˆ—
k, yâˆ—
k)
wâˆ—
âˆ’âˆ’â†’(xâˆ—, yâˆ—).
Take any sequence Ïµk â†“0 as k â†’âˆ. By applying the approximate in-
tersection rule of Proposition 13.4.3 for every k, we ï¬nd (uik, vik) âˆˆAi,
(uâˆ—
ik, vâˆ—
ik) âˆˆNF (Ai, (uik, vik)), where i = 1, 2, and Î»k â‰¥0 such that
âˆ¥(uik, vik) âˆ’(xk, yk)âˆ¥â‰¤Ïµk,
i = 1, 2,
(13.75)
âˆ¥(uâˆ—
1k, vâˆ—
1k) + (uâˆ—
2k, vâˆ—
2k) âˆ’Î»k(xâˆ—
k, yâˆ—
k)âˆ¥â‰¤2Ïµk,
(13.76)
1 âˆ’Ïµk â‰¤max{Î»k, âˆ¥(uâˆ—
1k, vâˆ—
1k)âˆ¥} â‰¤1 + Ïµk.
(13.77)
The sequence (xk, yk) is weakâˆ—convergent and therefore bounded. By
(13.76) and (13.77), for i = 1, 2 the sequence (uâˆ—
ik, vâˆ—
ik) is also bounded
and so by Theorem 4.3.21 some subsequence (which we do not relabel)
is weakâˆ—convergent to (uâˆ—
i , vâˆ—
i ). We further have Î»k â†’Î» â‰¥0. From
(13.76) and (13.77) we obtain for k â†’âˆthat (uâˆ—
i , vâˆ—
i ) âˆˆNM(Ai, (Â¯x, Â¯y)),
i = 1, 2, and Î»(xâˆ—, yâˆ—) = (uâˆ—
1, vâˆ—
1) + (uâˆ—
2, vâˆ—
2). It remains to show that
Î» > 0.
(II) Suppose that Î» = 0. Then (13.76) shows that âˆ¥(uâˆ—
1k, vâˆ—
1k)+(uâˆ—
1k, vâˆ—
1k)âˆ¥â†’0
as k â†’âˆ. Since (A1, A2) satisï¬es the limiting qualiï¬cation condition, it
follows that (uâˆ—
i , vâˆ—
i ) = o for i = 1, 2. Hence
(uâˆ—
ik, vâˆ—
ik)
wâˆ—
âˆ’âˆ’â†’(o, o)
as k â†’âˆ,
i = 1, 2.
(13.78)
The strong PSNC property of A2 implies that âˆ¥vâˆ—
2kâˆ¥â†’0 as k â†’âˆand
(13.76) shows that âˆ¥vâˆ—
1kâˆ¥â†’0, too. This, (13.78), and the PSNC property
of A1 now yield âˆ¥uâˆ—
1kâˆ¥â†’0 and so âˆ¥(uâˆ—
1k, vâˆ—
1k)âˆ¥â†’0 as k â†’âˆ, which
contradicts the estimate (13.77).
âŠ“âŠ”
Applying Theorem 13.6.4 with F := {o} immediately gives the following
result.
Corollary 13.6.5 Let E be a FrÃ©chet smooth Banach space, A1 and A2 be
closed subsets of E, and Â¯x âˆˆA1 âˆ©A2. Assume that (A1, A2) satisï¬es the
limiting qualiï¬cation condition at Â¯x and that A1 or A2 is SNC at Â¯x. Then
(13.74) holds.
Our aim now is to describe the M-normal cone to a set of the form Î¦âˆ’1(S),
where Î¦ : E â‡’F is a multifunction and S âŠ†F. We make the following
assumptions:
(A1) The multifunction x â†’Î¦(x) âˆ©S is inner semicompact at Â¯x.

322
13 Extremal Principles and More Normals and Subdiï¬€erentials
(A2) For every Â¯y âˆˆÎ¦(Â¯x)âˆ©S, the set S is SNC at Â¯y or the set graph Î¦ is PSNC
at (Â¯x, Â¯y) with respect to F.
(A3) For every Â¯y âˆˆÎ¦(Â¯x) âˆ©S one has NM(S, Â¯y) âˆ©ker Dâˆ—
MÎ¦(Â¯x, Â¯y) = {o}.
Theorem 13.6.6 Let E and F be FrÃ©chet smooth Banach spaces, Î¦ : E â‡’F
be a multifunction with closed graph, and S be a closed subset of F. Let the
assumptions (A1)â€“(A3) be satisï¬ed. Then one has
NM(Î¦âˆ’1(S), Â¯x) âŠ†

Dâˆ—
M Î¦(Â¯x, Â¯y)(yâˆ—)
 yâˆ—âˆˆNM(S, Â¯y), Â¯y âˆˆÎ¦(Â¯x) âˆ©S

.
(13.79)
Proof.
(I) Take an arbitrary xâˆ—âˆˆNM(Î¦âˆ’1(S), Â¯x). Then there are sequences xk â†’Â¯x
and xâˆ—
k âˆˆNF (Î¦âˆ’1(S), xk) such that xk â†’Â¯x and xâˆ—
k
wâˆ—
âˆ’âˆ’â†’xâˆ—. By (A1) we
ï¬nd a subsequence of yk âˆˆÎ¦(xk) âˆ©S that converges to some Â¯y âˆˆF. The
closedness assumptions ensure that Â¯y âˆˆÎ¦(Â¯x) âˆ©S. Deï¬ne B1 := graph Î¦
and B2 := E Ã— S, which are closed subsets of the FrÃ©chet smooth Banach
space E Ã— F. It is clear that (xk, yk) âˆˆB1 âˆ©B2 for any k and it is easy
to see that (xâˆ—
k, o) âˆˆNF (B1 âˆ©B2, (xk, yk)) for any k. Hence (xâˆ—, o) âˆˆ
NM(B1 âˆ©B2, (Â¯x, Â¯y)).
(II) As in the proof of Theorem 13.4.9 it follows that B1 and B2 have the SNC
properties required in Theorem 13.6.4. We show that condition (13.73)
is satisï¬ed for the system (B1, B2), which by Remark 13.6.3 implies the
limiting qualiï¬cation condition for this system. Take any
(uâˆ—, vâˆ—) âˆˆNM(B1, (Â¯x, Â¯y)) âˆ©

âˆ’NM(B2, (Â¯x, Â¯y))

.
By deï¬nition of the coderivative we immediately obtain uâˆ—âˆˆDâˆ—
MÎ¦(Â¯x, Â¯y)
(âˆ’vâˆ—). In view of (13.50) we further have (âˆ’uâˆ—, âˆ’vâˆ—) âˆˆ{o} Ã— NM(S, Â¯y).
It follows that uâˆ—= o and so
âˆ’vâˆ—âˆˆNM(S, Â¯y) âˆ©kerDâˆ—
MÎ¦(Â¯x, Â¯y).
Assumption (A3) now implies that vâˆ—= o. Hence (13.73) is satisï¬ed.
Therefore we may apply Theorem 13.6.4, which yields the existence of
(xâˆ—
1, yâˆ—
1) âˆˆNM(graph Î¦, (Â¯x, Â¯y)) and yâˆ—
2 âˆˆNM(S, Â¯y) satisfying (xâˆ—, o) =
(xâˆ—
1, yâˆ—
1) + (o, yâˆ—
2) and so
(xâˆ—, âˆ’yâˆ—
2) = (xâˆ—
1, yâˆ—
1) âˆˆNM(graph Î¦, (Â¯x, Â¯y)).
Thus xâˆ—âˆˆDâˆ—
MÎ¦(Â¯x, Â¯y)(yâˆ—
2), and it follows that xâˆ—is an element of the
right-hand side of (13.79).
âŠ“âŠ”

13.7 Optimality Conditions
323
13.7 Optimality Conditions
Convention. Throughout this section, we assume that E and F are FrÃ©chet
smooth Banach spaces and f : E â†’R is a proper l.s.c. functional.
We consider the problem
minimize f(x) subject to x âˆˆA,
where A is a closed subset of E. From the discussion in Sect. 12.1 we know
that if Â¯x is a local minimizer of f on A, then it follows that o âˆˆâˆ‚F (f +Î´A)(Â¯x).
This implies
o âˆˆâˆ‚M(f + Î´A)(Â¯x).
(13.80)
We now formulate hypotheses (H1) and a qualiï¬cation condition (Q1)
ensuring that we may apply the exact sum rule of Theorem 13.5.5:
(H1) A is a closed subset of E, Â¯x âˆˆA, A is SNC at Â¯x or f is SNEC at Â¯x.
(Q1) âˆ‚âˆ
Mf(Â¯x) âˆ©

âˆ’NM(A, Â¯x)

= {o}.
Proposition 13.7.1 Assume that (H1) and (Q1) are satisï¬ed. If Â¯x is a local
minimizer of f on A, then
o âˆˆâˆ‚Mf(Â¯x) + NM(A, Â¯x).
(13.81)
Proof. Since epi Î´A = A Ã— [0, +âˆ), the functional Î´A is SNEC if (and only if)
the set A is SNC. Moreover, we have âˆ‚âˆ
MÎ´A(Â¯x) = NM(A, Â¯x) (Remark 13.1.10).
Therefore, (Q1) implies that the condition (13.61) is satisï¬ed for f and Î´A.
Applying Theorem 13.5.5 to (13.80) yields the assertion.
âŠ“âŠ”
From Proposition 13.7.1 we can deduce further optimality conditions. First
we formulate the assumptions:
(H2) For i = 1, . . . , r the set Ai âŠ†E is closed and SNC at Â¯x âˆˆâˆ©r
i=1Ai.
(Q2)
&
xâˆ—âˆˆâˆ‚âˆ
Mf(Â¯x),
xâˆ—
i âˆˆNM(Ai, Â¯x),
xâˆ—+ xâˆ—
1 + Â· Â· Â· + xâˆ—
r = o

=â‡’xâˆ—= xâˆ—
1 = Â· Â· Â· = xâˆ—
r = o.
Proposition 13.7.2 Let the hypotheses (H2) and the qualiï¬cation condition
(Q2) be satisï¬ed. If Â¯x is a local minimizer of f on âˆ©r
i=1Ai, then one has
o âˆˆâˆ‚Mf(Â¯x) + NM(A1, Â¯x) + Â· Â· Â· + NM(Ar, Â¯x).
(13.82)
Proof. We verify the assertion for r = 2; it then follows for r â‰¥2 by induction.
We want to apply Proposition 13.7.1 to A := A1âˆ©A2. From (Q2) with xâˆ—:= o
we obtain
NM(A1, Â¯x) âˆ©

âˆ’N(A2, Â¯x)

= {o}.
(13.83)

324
13 Extremal Principles and More Normals and Subdiï¬€erentials
This and (H2) imply by Corollary 13.4.8 that A1 âˆ©A2 is SNC at Â¯x. By The-
orem 13.6.4 and Remark 13.6.3, the condition (13.83) also implies that
NM(A1 âˆ©A2, Â¯x) âŠ†NM(A1, Â¯x) + NM(A2, Â¯x).
(13.84)
Now we convince ourselves that condition (Q1) holds. Take any xâˆ—âˆˆâˆ‚âˆ
Mf(Â¯x)
such that âˆ’xâˆ—âˆˆNM(A1 âˆ©A2, Â¯x). By (13.84) there exist xâˆ—
i âˆˆNM(Ai, Â¯x),
i = 1, 2, such that âˆ’xâˆ—= xâˆ—
1 + xâˆ—
2. Hence xâˆ—= o by (Q2). Refering to
Proposition 13.7.1 and (13.84) completes the proof.
âŠ“âŠ”
If f is locally L-continuous around Â¯x, then by Proposition 13.5.1 the con-
dition (Q2) reduces to
(Q2âˆ—)
&
xâˆ—
i âˆˆNM(Ai, Â¯x),
xâˆ—
1 + Â· Â· Â· + xâˆ—
r = o

=â‡’
xâˆ—
1 = Â· Â· Â· = xâˆ—
r = o,
which is a pure constraint qualiï¬cation. We show that (Q2âˆ—) is implied by a
classical constraint qualiï¬cation. Let the constraint sets be given as
Ai := {x âˆˆE | fi(x) â‰¤0},
i = 1, . . . , r,
where for i = 1, . . . , r the functional fi : E â†’R is strictly F-diï¬€erentiable
at Â¯x âˆˆâˆ©r
i=1Ai. Assume the following variant of the Mangasarianâ€“Fromowitz
constraint qualiï¬cation:
f â€²
1(Â¯x), . . . , f â€²
r(Â¯x)
are positively linearly independent.
(13.85)
By Theorem 11.6.1 we have
NM(Ai, Â¯x) = NCAi, Â¯x) = {Î»f â€²
i(x) | Î» â‰¥0}.
Suppose now that xâˆ—
i âˆˆNM(Ai, Â¯x) for i = 1, . . . , r and xâˆ—
1 +Â· Â· Â·+xâˆ—
r = o. Then
there exist Î»i â‰¥0 such that xâˆ—
i = Î»if â€²
i(Â¯x) for i = 1, . . . , r. Condition (13.85)
thus implies that for any i we have Î»i = 0 and so xâˆ—
i = o.
Finally we consider the problem
minimize f(x) subject to x âˆˆÎ¦âˆ’1(S) âˆ©A.
In this connection we make the following assumptions:
(H3) Î¦ : E â‡’F is a multifunction with closed graph, A âŠ†E and S âŠ†F
are closed.
x â†’Î¦(x) âˆ©S is inner semicompact at Â¯x âˆˆÎ¦âˆ’1(S).
A is SNC at Â¯x and graph Î¦ is SNC at (Â¯x, Â¯y) for every Â¯y âˆˆÎ¦(Â¯x) âˆ©S.
(Q3a) NM(S, Â¯y) âˆ©kerDâˆ—
MÎ¦(Â¯x, Â¯y) = {o} for every Â¯y âˆˆÎ¦(Â¯x) âˆ©S.
(Q3b)
#
xâˆ—âˆˆâˆ‚âˆ
Mf(Â¯x),
xâˆ—
1 âˆˆ
Dâˆ—
MÎ¦(Â¯x, Â¯y)(yâˆ—)
 Â¯y âˆˆÎ¦(Â¯x) âˆ©S, yâˆ—âˆˆ
NM(S, Â¯y)

, xâˆ—
2 âˆˆNM(A, Â¯x),
xâˆ—+ xâˆ—
1 + xâˆ—
2 = o
$
=â‡’xâˆ—= xâˆ—
1 = xâˆ—
2 = o.

13.7 Optimality Conditions
325
Theorem 13.7.3 Let the hypotheses (H3) and the qualiï¬cation conditions
(Q3a) and (Q3b) be satisï¬ed. If Â¯x is a local minimizer of f on Î¦âˆ’1(S) âˆ©A,
then
o âˆˆâˆ‚Mf(Â¯x) +

Dâˆ—
MÎ¦(Â¯x, Â¯y)(yâˆ—)
 Â¯y âˆˆÎ¦(Â¯x) âˆ©S, yâˆ—âˆˆNM(S, Â¯y)

+ NM(A, Â¯x).
Proof. Deï¬ne A1 := Î¦âˆ’1(S) and A2 := A. By Theorem 13.6.6 we have
NM(A1, Â¯x) âŠ†

Dâˆ—
MÎ¦(Â¯x, Â¯y)(yâˆ—)
 Â¯y âˆˆÎ¦(Â¯x) âˆ©S, yâˆ—âˆˆNM(S, Â¯y)

.
(13.86)
Moreover, A is SNC at Â¯x by hypothesis and Î¦âˆ’1(S) is SNC at (Â¯x, Â¯y) due
to Theorem 13.4.9. Finally, the qualiï¬cation condition (Q3b) together with
(13.86) ensures by Corollary 13.4.8 that Î¦âˆ’1(S) âˆ©A is SNC. Hence the asser-
tion follows from Proposition 13.7.2.
âŠ“âŠ”
Notice that (Q3a) depends on the constraints only. If f is locally L-
continuous around Â¯x and Î¦ : E â†’F is strictly F-diï¬€erentiable at Â¯x, then
by Propositions 13.2.3 and 13.5.1 the qualiï¬cation condition (Q3b) reduces to

âˆ’NM(A, Â¯x)

âˆ©Î¦â€²(Â¯x)âˆ—
NM(S, Î¦(Â¯x))

= {o},
(13.87)
which is now also a constraint qualiï¬cation; compare (Q2âˆ—). The optimality
condition of Theorem 13.7.3 in this case reads
o âˆˆâˆ‚Mf(Â¯x) + Î¦â€²(Â¯x)âˆ—
NM(S, Î¦(Â¯x))

+ NM(A, Â¯x).
In connection with the hypotheses (H3) recall that in ï¬nite-dimensional spaces
any nonempty subset is an SNC set.
Theorem 13.7.3 is a very general result from which various speciï¬c opti-
mality conditions can be derived. Assume, for instance, that the constraints
are functional inequalities and equations of the following form (compare, for
instance, problem (P5) in Sect. 12.5):
fi(x) â‰¤0,
i = 1, . . . , r,
fi(x) = 0,
i = r + 1, . . . , r + s,
x âˆˆA,
(13.88)
where fi : E â†’R for i = 1, . . . , r + s. We deï¬ne Î¦ : E â†’Rr+s by Î¦ :=
(f1, . . . , fr+s) and put
S :=

(Î±1, . . . , Î±r+s) âˆˆRr+s | Î±i â‰¤0 for i = 1, . . . , r
and Î±i = 0 for i = r + 1, . . . , r + s

.
Then (13.88) is of the form x âˆˆÎ¦âˆ’1(S) âˆ©A and so Theorem 13.7.3 can be
applied. For exploiting Dâˆ—
MÎ¦(Â¯x) we may write
Î¦(x) = (f1(x), 0, . . . , 0) + Â· Â· Â· + (0, . . . , 0, fr+s(x)),
x âˆˆE,
and apply one or the other coderivative sum rule.

326
13 Extremal Principles and More Normals and Subdiï¬€erentials
So far we considered optimality conditions of the Karushâ€“Kuhnâ€“Tucker
type. It is not diï¬ƒcult using, for instance, Theorem 13.7.3 to derive optimality
conditions of the John type. We shall not pursue this way. Rather we will
demonstrate how to obtain optimality conditions of the John type by a direct
application of the exact extremal principle. We consider the problem
minimize f(x) subject to the constraints (13.88).
In addition to the convention at the beginning of this section, we make the
following hypotheses:
(H4) The functions f1, . . . , fr+s are continuous.
All but one of the sets epi f, epi fi (i = 1, . . . , r), graph fi (i = r +
1, . . . , r + s), and A are SNC at (Â¯x, f(Â¯x)), (Â¯x, 0), and Â¯x, respectively.
Theorem 13.7.4 Let the assumptions (H4) be satisï¬ed. Assume that Â¯x is a
local minimizer of f subject to the constraints (13.88).
(a) There exist
(xâˆ—, âˆ’Î») âˆˆNM

epi f, ((Â¯x, f(Â¯x))

,
yâˆ—âˆˆNM(A, Â¯x),
(xâˆ—
i , âˆ’Î»i) âˆˆNM

epi fi, ((Â¯x, 0)

,
i = 1, . . . , r,
(xâˆ—
i , âˆ’Î»i) âˆˆNM

graph fi, ((Â¯x, 0)

,
i = r + 1, . . . , r + s
satisfying
xâˆ—+ xâˆ—
i + Â· Â· Â· + xâˆ—
r+s + yâˆ—= o,
âˆ¥(xâˆ—, Î»)âˆ¥+ âˆ¥(xâˆ—
1, Î»1)âˆ¥+ Â· Â· Â· + âˆ¥(xâˆ—
r+s, Î»r+s)âˆ¥+ âˆ¥yâˆ—âˆ¥= 1,
Î»ifi(Â¯x) = 0,
i = 1, . . . , r.
(13.89)
(b) Assume, in addition, that the functions f, f1, . . . , fr+s are locally L-
continuous around Â¯x. Then there exist nonnegative real numbers Î»,
Î»1, . . . , Î»r+s such that Î»ifi(Â¯x) = 0 for i = 1, . . . , r and
o âˆˆÎ»âˆ‚Mf(Â¯x) +
r+s
	
i=r+1
Î»i

âˆ‚Mfi(Â¯x) âˆªâˆ‚M(âˆ’fi)(Â¯x)

+ NM(A, Â¯x).
Proof.
(a) Deï¬ne the following subsets of E Ã— Rr+s+1:
B := {(x, Î±, Î±1, . . . , Î±r+s) | Î± â‰¥f(x)},
Bi := {(x, Î±, Î±1, . . . , Î±r+s) | Î±i â‰¥fi(x)},
i = 1, . . . , r,
Bi := {(x, Î±, Î±1, . . . , Î±r+s) | Î±i = fi(x)},
i = r + 1, . . . , r + s,
Br+s+1 := A Ã— {o}.

13.8 The Mordukhovich Subdiï¬€erential of Marginal Functions
327
Without loss of generality we may assume that f(Â¯x) = 0. Then (Â¯x, o) âˆˆ
E Ã— Rr+s+1 is a local extremal point of the system of closed sets B,
B1, . . . , Br+s+1. Therefore the hypotheses (H4) ensure that by Theo-
rem 13.3.14 the exact extremal principle holds for the above system, which
immediately yields the assertion except for the equations Î»ifi(Â¯x) = 0,
i = 1, . . . , r. Assume we have fi(Â¯x) < 0 for some i âˆˆ{1, . . . , r}. Then by
continuity, it follows that fi(x) < 0 for all x in a neighborhood of Â¯x. Hence
(Â¯x, o) is an interior point of epi fi. It follows that NM

epi fi, (Â¯x, o))

= {o}
and so Î»i = 0.
(b) By the deï¬nition of the M-subdiï¬€erential and by Lemma 13.1.8 we have
(xâˆ—, âˆ’Î») âˆˆNM

epi f, (Â¯x, f(Â¯x))

â‡â‡’
xâˆ—âˆˆÎ»âˆ‚f(Â¯x) and Î» â‰¥0.
Moreover, the deï¬nition of the M-coderivative and Proposition 13.2.6
imply that
(xâˆ—, âˆ’Î») âˆˆNM

graph f, (Â¯x, f(Â¯x))

â‡â‡’
xâˆ—âˆˆDâˆ—
Mf(Â¯x)(Î») = âˆ‚M(Î»f)(Â¯x).
Notice that âˆ‚M(Î»f)(Â¯x) âŠ†|Î»|

âˆ‚Mf(Â¯x) âˆªâˆ‚(âˆ’f)(Â¯x)

for any Î» âˆˆR. The
assertion now follows from (a).
âŠ“âŠ”
13.8 The Mordukhovich Subdiï¬€erential of Marginal
Functions
Convention. In this section, E and F denote Banach spaces.
In Sect. 9.7 we derived representations of the F-subdiï¬€erential of a mar-
ginal function f of the form f(x) := infyâˆˆF Ï•(x, y), x âˆˆE (see Proposi-
tions 9.7.1 and 9.7.2). In this section we establish a representation of the
(singular) M-subdiï¬€erential of the more general marginal function f : E â†’R
deï¬ned by
f(x) := inf{Ï•(x, y) | y âˆˆÎ¦(x)},
(13.90)
where the function Ï• : EÃ—F â†’R and the multifunction Î¦ : E â‡’F are given.
Marginal functions like f appear as value functions in parametric optimization
problems of the form
minimize Ï•(x, y)
subject to y âˆˆÎ¦(x),
where x denotes a parameter. We will make use of the multifunction Î˜ : E â‡’
F deï¬ned by
Î˜(x) := {y âˆˆÎ¦(x) | Ï•(x, y) = f(x)}.
(13.91)
In terms of parametric optimization, Î˜(x) consists of all y âˆˆÎ¦(x) at which
the inï¬mum of Ï•(x, Â·) is attained. Recall the notion of an inner semicompact
multifunction. We also need the following auxiliary function Ï‘ : E Ã— F â†’R:
Ï‘(x, y) := Ï•(x, y) + Î´graph Î¦(x, y).

328
13 Extremal Principles and More Normals and Subdiï¬€erentials
Theorem 13.8.1 Assume that Ï• : E Ã— F â†’R is l.s.c., Î¦ is closed, and Î˜ is
inner semicompact at Â¯x âˆˆdom f âˆ©Dom Î˜.
(a) One has
âˆ‚Mf(Â¯x) âŠ†
0
xâˆ—âˆˆEâˆ— (xâˆ—, o) âˆˆ

Â¯yâˆˆÎ˜(Â¯x)
âˆ‚MÏ‘(Â¯x, Â¯y)
1
,
(13.92)
âˆ‚âˆ
Mf(Â¯x) âŠ†
0
xâˆ—âˆˆEâˆ— (xâˆ—, o) âˆˆ

Â¯yâˆˆÎ˜(Â¯x)
âˆ‚âˆ
MÏ‘(Â¯x, Â¯y)
1
.
(13.93)
(b) If, in addition, Ï• is strictly F-diï¬€erentiable at any (Â¯x, Â¯y), where Â¯y âˆˆÎ˜(Â¯x),
then
âˆ‚Mf(Â¯x) âŠ†

Â¯yâˆˆÎ˜(Â¯x)

Ï• 1(Â¯x, Â¯y) + Dâˆ—
MÎ¦(Â¯x, Â¯y)(Ï• 2(Â¯x, Â¯y))

,
(13.94)
âˆ‚âˆ
Mf(Â¯x) âŠ†

Â¯yâˆˆÎ˜(Â¯x)
Dâˆ—
MÎ¦(Â¯x, Â¯y)(o).
(13.95)
Proof.
(a) (I) We verify (13.92). Take any xâˆ—âˆˆâˆ‚Mf(Â¯x). By Theorem 13.1.17 there
exist sequences xk â†’f Â¯x, xâˆ—
k
wâˆ—
âˆ’âˆ’â†’xâˆ—, and Ïµk â†“0 as k â†’âˆsatisfying
xâˆ—
k âˆˆ*âˆ‚Ïµkf(xk) for any k âˆˆN. Hence there exists a sequence Î·k â†“0
such that
âŸ¨xâˆ—
k, x âˆ’xkâŸ©â‰¤f(x) âˆ’f(xk) + 2Ïµkâˆ¥x âˆ’xkâˆ¥
âˆ€x âˆˆB(xk, Î·k).
Recalling the deï¬nition of f, Î˜, and Ï‘, we obtain for all yk âˆˆÎ˜(xk),
all (x, y) âˆˆB((xk, yk), Î·k), and all k âˆˆN the estimate
âŸ¨(xâˆ—
k, o), (x, y)âˆ’(xk, yk)âŸ©â‰¤Ï‘(x, y)âˆ’Ï‘(xk, yk)+2Ïµk(âˆ¥xâˆ’xkâˆ¥+âˆ¥yâˆ’ykâˆ¥).
From this we conclude that
(xâˆ—
k, o) âˆˆ*âˆ‚2ÏµkÏ‘(xk, yk)
âˆ€k âˆˆN.
(13.96)
Since Î˜ is inner semicompact at Â¯x, we ï¬nd a sequence yk âˆˆÎ˜(xk) that
contains a subsequence, again denoted (yk), that converges to some
Â¯y âˆˆF. Since xk â†’Â¯x, yk âˆˆÎ¦(xk) for any k, and Î¦ has a closed graph,
it follows that Â¯y âˆˆÎ¦(Â¯x). The lower semicontinuity of Ï• implies
Ï•(Â¯x, Â¯y) â‰¤lim inf
kâ†’âˆÏ•(xk, yk) = lim inf
kâ†’âˆf(xk) = f(Â¯x),
which together with the deï¬nition of f gives Ï•(Â¯x, Â¯y) = f(Â¯x) and so Â¯y âˆˆ
Î˜(Â¯x). This, (13.96), and Theorem 13.1.17 show that inclusion (13.92)
holds.
(II) The veriï¬cation of (13.93) is left as Exercise 13.13.19.

13.8 The Mordukhovich Subdiï¬€erential of Marginal Functions
329
(b) The representations (13.94) and (13.95) follow from (a) by applying
the sum rule of Proposition 13.5.1 to the function Ï‘ and recalling
Remark 13.1.10 and the deï¬nition of the M-coderivative.
âŠ“âŠ”
Now let Î¦ be a single-valued mapping which we denote T : E â†’F. Then
(13.90) passes into
f(x) = Ï•(x, T(x)) =: (Ï• â—¦T)(x),
x âˆˆE.
(13.97)
If, in particular, Ï• does not explicitly depend on x, then Ï• â—¦T is the usual
composition of Ï• and T. Recall that if Ï• is (strictly) F-diï¬€erentiable at (Â¯x, Â¯y),
then the partial derivative Ï• 2(Â¯x, Â¯y) is an element of F âˆ—and âŸ¨Ï• 2(Â¯x, Â¯y), TâŸ©:
E â†’R denotes the scalarization of T.
Applying Theorem 13.8.1 we now establish another chain rule (cf. Theo-
rem 9.2.9).
Theorem 13.8.2 (Chain Rule) Let T : E â†’F be locally L-continuous
around Â¯x âˆˆE and Ï• : E Ã— F â†’R be strictly F-diï¬€erentiable at (Â¯x, T(Â¯x)).
Then
âˆ‚M(Ï• â—¦T)(Â¯x) = Ï• 1(Â¯x, Â¯y) + âˆ‚M

Ï• 2(Â¯x, Â¯y), T
 
(Â¯x),
where Â¯y := T(Â¯x). (13.98)
Proof. Since Ï• is strictly F-diï¬€erentiable at (Â¯x, Â¯y), for any sequence Î·i â†“0
there exists a sequence Î´i â†“0 such that
|Ï•(z, T(z)) âˆ’Ï•(x, T(x)) âˆ’âŸ¨Ï• 1(Â¯x, Â¯y), z âˆ’xâŸ©âˆ’âŸ¨Ï• 2(Â¯x, Â¯y), T(z) âˆ’T(x)âŸ©|
â‰¤Î·i(âˆ¥z âˆ’xâˆ¥+ âˆ¥T(z) âˆ’T(x)âˆ¥)
âˆ€x, z âˆˆB(Â¯x, Î´i)
âˆ€i âˆˆN.
(13.99)
Now let xâˆ—âˆˆâˆ‚M(Ï•â—¦T)(Â¯x) be given. By Theorem 13.1.17 there exist sequences
xk â†’Â¯x, xâˆ—
k
wâˆ—
âˆ’âˆ’â†’xâˆ—, and Ïµk â†“0 as k â†’âˆsatisfying (Ï• â—¦T)(xk) â†’(Ï• â—¦T)(Â¯x)
and
xâˆ—
k âˆˆ*âˆ‚Ïµk(Ï• â—¦T)(xk)
âˆ€k âˆˆN.
(13.100)
Choose a strictly increasing sequence (ki) of positive integers such that âˆ¥xki âˆ’
Â¯xâˆ¥â‰¤Î´i/2 for any i âˆˆN. In view of (13.100), for any i we can further choose
ËœÎ´i âˆˆ(0, Î´i/2) such that for all x âˆˆB(xki, ËœÎ´i) and any i âˆˆN we obtain
Ï•(x, T(x)) âˆ’Ï•(xki, T(xki)) âˆ’âŸ¨xâˆ—
ki, x âˆ’xkiâŸ©â‰¥âˆ’2Ïµkiâˆ¥x âˆ’xkiâˆ¥.
(13.101)
Let Î» > 0 be a Lipschitz constant of Ï• in a neighborhood of Â¯x containing xk
for all suï¬ƒciently large k âˆˆN. Since x âˆˆB(xki, ËœÎ´i) implies x âˆˆB(Â¯x, Î´i), the
estimates (13.99) and (13.101) give
âŸ¨Ï• 2(Â¯x, Â¯y), T(x)âŸ©âˆ’âŸ¨Ï• 2(Â¯x, Â¯y), T(xki)âŸ©âˆ’âŸ¨xâˆ—
ki âˆ’Ï• 1(Â¯x, Â¯y), x âˆ’xkiâŸ©
â‰¥âˆ’(2Ïµki + Î·i(Î» + 1))âˆ¥x âˆ’xkiâˆ¥
âˆ€x âˆˆB(xki, ËœÎ´i)
âˆ€i âˆˆN.

330
13 Extremal Principles and More Normals and Subdiï¬€erentials
Hence the deï¬nition of the Ïµ-subdiï¬€erential shows that, with ËœÏµi := 2Ïµki +
Î·i(Î» + 1), we have
xâˆ—
ki âˆ’Ï• 1(Â¯x, Â¯y) âˆˆâˆ‚ËœÏµi

Ï• 2(Â¯x, Â¯y), T
 
(xki)
âˆ€i âˆˆN.
Letting i â†’âˆand recalling Theorem 13.1.17, we obtain
xâˆ—âˆ’Ï• 1(Â¯x, Â¯y) âˆˆâˆ‚M

Ï• 2(Â¯x, Â¯y), T
 
(Â¯x).
Thus we have veriï¬ed the inclusion âŠ†of (13.98). The veriï¬cation of the
opposite inclusion is left as Exercise 13.13.20.
âŠ“âŠ”
13.9 A Nonsmooth Implicit Function Theorem
Consider a multifunction Î¦ : E Ã— F â‡’G between Banach spaces E, F, and
G. Let (Â¯x, Â¯y) âˆˆE Ã— F be such that o âˆˆÎ¦(Â¯x, Â¯y). As in the classical implicit
function theorem (see Theorem 3.7.2), we want to locally solve the generalized
equation o âˆˆÎ¦(x, y) for y, i.e., we seek conditions ensuring that, for y near
Â¯y, the set {x âˆˆE | o âˆˆÎ¦(x, y)} is nonempty. Let
f(x, y) := d(Î¦(x, y), o).
Our approach is based on the observation that o âˆˆÎ¦(x, y) if and only if
f(x, y) = 0 or equivalently, f(x, y) â‰¤0. Consequently, we can treat the set-
valued problem by a single-valued one. Therefore we start with an implicit
function theorem associated with the inequality f(x, y) â‰¤0, where for the
time being the functional f is arbitrary. We set
Î¨(y) := {x âˆˆE | f(x, y) â‰¤0}
and
f+(x, y) := max{0, f(x, y)}.
Furthermore, âˆ‚F,1f(Â¯x, Â¯y) denotes the F-subdiï¬€erential of x â†’f(x, Â¯y) at (Â¯x, Â¯y).
We consider the following assumptions:
(A1) E and F are FrÃ©chet smooth Banach spaces, U is a nonempty open
subset of E Ã— F, and (Â¯x, Â¯y) âˆˆU.
(A2) f : E Ã— F â†’R is proper and such that f(Â¯x, Â¯y) â‰¤0.
(A3) The functional y â†’f(Â¯x, y) is u.s.c. at Â¯y.
(A4) For any y near Â¯y the functional x â†’f(x, y) is l.s.c.
(A5) There exists Ïƒ > 0 such that for any (x, y) âˆˆU with f(x, y) > 0,
xâˆ—âˆˆâˆ‚F,1f(x, y) implies âˆ¥xâˆ—âˆ¥â‰¥Ïƒ.
Assumption (A5) is a nonsmooth substitute for the bijectivity requirement
on f 1(x, y) in the classical implicit function theorem (see Theorem 3.7.2 with
x and y interchanged). This classical theorem yields, among others, a repre-
sentation of the F-derivative of the implicit function in terms of the partial
F-derivatives of the given function. In the following remarkable result, the
coderivative of the multifunction Î¨ is represented in terms of F-subderivatives
of f+.

13.9 A Nonsmooth Implicit Function Theorem
331
Theorem 13.9.1 (Nonsmooth Implicit Function Theorem) Suppose
that the assumptions (A1)â€“(A5) are satisï¬ed. Then there exist open sets
V âŠ†E and W âŠ†F such that Â¯x âˆˆV and Â¯y âˆˆW and that the following holds:
(a) For any y âˆˆW the set V âˆ©Î¨(y) is nonempty.
(b) For any (x, y) âˆˆV Ã— W one has
d(x, Î¨(y)) â‰¤f+(x, y)
Ïƒ
.
(c) For any (x, y) âˆˆV Ã— W such that x âˆˆÎ¨(y) and any xâˆ—âˆˆEâˆ—one has
Dâˆ—
F Î¨(y, x)(xâˆ—) =
0
yâˆ—âˆˆF âˆ— (âˆ’xâˆ—, yâˆ—) âˆˆ

Î»>0
Î» âˆ‚F f+(x, y)
1
.
Proof. Let Ïâ€² > 0 be such that B(Â¯x, Ïâ€²)Ã—B(Â¯y, Ïâ€²) âŠ†U and set Ï := Ïâ€²/3. Since
f(Â¯x, Â¯y) â‰¤0, it follows from (A3) that there exists an open neighborhood W
of Â¯y with W âŠ†B(Â¯y, Ï) such that f(Â¯x, y) < ÏÏƒ for any y âˆˆW. We show that
W and V := ËšB(Â¯x, Ï) have the required properties.
Ad (a). Let y âˆˆW be given. Suppose we had V âˆ©Î¨(y) = âˆ…. Then for any
Ï„ âˆˆ(0, Ï) and any x âˆˆB(Â¯x, Ï„) it would follow that f(x, y) > 0. Choosing Ï„
close enough to Ï, we may assume that f(Â¯x, y) < Ï„Ïƒ. The decrease principle
(Theorem 9.6.3) then implies
inf{f(x, y) | x âˆˆB(Â¯x, Ï)} â‰¤f(Â¯x, y) âˆ’Ï„Ïƒ < 0,
which is a contradiction to inf{f(x, y) | x âˆˆB(Â¯x, Ï)} â‰¥0. Therefore V âˆ©
Î¨(y) Ì¸= âˆ….
Ad (b). Let (x, y) âˆˆV Ã— W be given. First we assume that B(x, f+(x, y)/Ïƒ)
is not a subset of ËšB(Â¯x, Ïâ€²). Then âˆ¥x âˆ’Â¯xâˆ¥+ f+(x, y)/Ïƒ â‰¥Ïâ€² and so
f+(x, y)/Ïƒ â‰¥Ïâ€² âˆ’Ï = 2Ï > d(x, Î¨(y)),
where the latter inequality follows from (a). Now assume that B(x, f+(x, y)/Ïƒ)
is a subset of ËšB(Â¯x, Ïâ€²). Let Ï„ > f+(x, y)/Ïƒ be such that B(x, Ï„) âŠ†ËšB(Â¯x, Ïâ€²).
Since f(x, y) < Ï„Ïƒ, we can conclude arguing similarly as in the proof of (a)
that there exists Ë†x âˆˆB(x, Ï„) such that f(Ë†x, y) â‰¤0. Hence d(x, Î¨(y)) < Ï„.
Letting Ï„ â†“f+(x, y)/Ïƒ we again obtain (b).
Ad (c). Take any (x, y) âˆˆV Ã— W such that x âˆˆÎ¨(y) and any xâˆ—âˆˆEâˆ—. We
will show that
Dâˆ—
F Î¨(y, x)(xâˆ—) âŠ†
0
yâˆ—âˆˆY âˆ— (âˆ’xâˆ—, yâˆ—) âˆˆ

Î»>0
Î» âˆ‚F f+(x, y)
1
.
(13.102)
Thus let yâˆ—âˆˆDâˆ—
F Î¨(y, x)(xâˆ—) be given. Then
(yâˆ—, âˆ’xâˆ—) âˆˆNF (graph Î¨, (y, x)) =

Î»>0
Î» âˆ‚F d (graph Î¨, (y, x));

332
13 Extremal Principles and More Normals and Subdiï¬€erentials
in this connection we write âˆ‚F d(graph Î¨, (y, x)) for the F-subdiï¬€erential of
the functional (v, u) â†’d((v, u), graph Î¨) at (y, x). It follows that there exist
Î» > 0 and a C1 functional g : F Ã— E â†’R with gâ€²(y, x) = (yâˆ—, âˆ’xâˆ—) such that
for any (v, u) âˆˆF Ã— E we have (noticing that d((y, x), graph Î¨) = 0),
g(v, u) â‰¤Î» d((v, u), graph Î¨) + g(y, x)
â‰¤Î» d(u, Î¨(v)) + g(y, x) â‰¤(Î»/Ïƒ)f+(u, v) + g(y, x).
Since f+(x, y) = 0, it thus follows that the functional (v, u) â†’(Î»/Ïƒ)f+(u, v)âˆ’
g(v, u) attains a minimum at (y, x). Hence (âˆ’xâˆ—, yâˆ—) âˆˆ(Î»/Ïƒ)âˆ‚F f+(x, y) (ob-
serve the order of variables). This veriï¬es (13.102). Since the reverse inclusion
follows immediately from Î´graph Î¨ â‰¥Î» f+ for any Î» > 0, the proof is complete.
âŠ“âŠ”
We apply Theorem 13.9.1 to the special case
f(x, y) := âˆ¥T(x, y)âˆ¥,
(13.103)
where T : E Ã— F â†’G is a continuously diï¬€erentiable mapping. We consider
the following conditions:
(C1) E, F, and G are FrÃ©chet smooth Banach spaces, U is a nonempty open
subset of E Ã— F, and (Â¯x, Â¯y) âˆˆU.
(C2) T : E Ã— F â†’G is a C1 mapping such that T(Â¯x, Â¯y) = o.
(C3) There exists Ïƒ > 0 such that Ïƒ BG âŠ†T 1(x, y)

BE

for any (x, y) âˆˆU.
Proposition 13.9.2 Let the conditions (C1)â€“(C3) be satisï¬ed and let
Î¨(y) := {x âˆˆE | T(x, y) = o}.
Then there exist open sets V âŠ†E and W âŠ†F such that Â¯x âˆˆV and Â¯y âˆˆW
and that the following holds:
(a) For any y âˆˆW the set V âˆ©Î¨(y) is nonempty.
(b) For any (x, y) âˆˆV Ã— W one has
d(x, Î¨(y)) â‰¤âˆ¥T(x, y)âˆ¥
Ïƒ
.
(c) For any xâˆ—âˆˆEâˆ—one has
Dâˆ—
F Î¨(Â¯y, Â¯x)(xâˆ—) =

âˆ’

T 2(Â¯x, Â¯y)
âˆ—zâˆ— zâˆ—âˆˆGâˆ—,

T 1(Â¯x, Â¯y)
âˆ—zâˆ—= xâˆ—
.
(13.104)
If, in particular, T 1(Â¯x, Â¯y) is invertible, then Dâˆ—
F Î¨(Â¯y, Â¯x)(xâˆ—) is a singleton con-
sisting of âˆ’

(T 1(Â¯x, Â¯y))âˆ’1T 2(Â¯x, Â¯y)
âˆ—xâˆ—.

13.9 A Nonsmooth Implicit Function Theorem
333
Proof. Ad (a), (b). Clearly the functional f : E Ã— F â†’R deï¬ned by (13.103)
satisï¬es the assumptions (A1)â€“(A4). We show that it also satisï¬es (A5). Let
(x, y) âˆˆU be such that T(x, y) Ì¸= o. Applying the chain rule we conclude that
xâˆ—âˆˆâˆ‚F,1f(x, y) if and only if
âŸ¨xâˆ—, uâŸ©=

T(x, y) | T 1(x, y)u

âˆ¥T(x, y)âˆ¥
âˆ€u âˆˆE,
in other words,
xâˆ—= T 1(x, y)âˆ—v,
where v :=
T(x, y)
âˆ¥T(x, y)âˆ¥.
(13.105)
By (C3) there exists u âˆˆBE such that T 1(x, y)u = Ïƒv. Consequently,
âˆ¥xâˆ—âˆ¥= âˆ¥T 1(x, y)âˆ—vâˆ¥â‰¥âŸ¨T 1(x, y)âˆ—v, uâŸ©= âŸ¨v, T 1(x, y)uâŸ©= âŸ¨v, ÏƒvâŸ©= Ïƒ.
Therefore (A5) is also fulï¬lled. Conclusions (a) and (b) now follow immedi-
ately from Theorem 13.9.1.
Ad (c). We calculate the coderivative of the multifunction Î¨. Recall that
T(Â¯x, Â¯y) = o. Let Î» > 0 and (âˆ’xâˆ—, yâˆ—) âˆˆÎ»âˆ‚F f(x, y) be given. By Proposi-
tion 9.1.9(a) we have
âŸ¨âˆ’xâˆ—, uâŸ©+ âŸ¨yâˆ—, vâŸ©â‰¤Î»fG

(Â¯x, Â¯y), (u, v)

âˆ€(u, v) âˆˆE Ã— F.
(13.106)
Observe that
fG

(Â¯x, Â¯y), (u, v)

= âˆ¥T 1(Â¯x, Â¯y)u + T 2(Â¯x, Â¯y)vâˆ¥
= max
zâˆ—âˆˆBâˆ—
G
âŸ¨zâˆ—, T 1(Â¯x, Â¯y)u + T 2(Â¯x, Â¯y)vâŸ©;
(13.107)
concerning the latter equation see Example 2.2.6. From (13.106) and (13.107)
we conclude that
min
uâˆˆBE
vâˆˆBF
max
zâˆ—âˆˆÎ»BGâˆ—

T 1(Â¯x, Â¯y)
âˆ—zâˆ—âˆ’xâˆ—, u
 
+

T 2(Â¯x, Â¯y)
âˆ—zâˆ—+ yâˆ—, v
 
â‰¥0.
Hence there exists zâˆ—âˆˆÎ»BGâˆ—satisfying
xâˆ—=

T 1(Â¯x, Â¯y)
âˆ—zâˆ—
and
yâˆ—= âˆ’

T 2(Â¯x, Â¯y)
âˆ—zâˆ—.
Now Theorem 13.9.1(c) implies (13.104), from which the special case where
T 1(Â¯x, Â¯y) is invertible is immediate.
âŠ“âŠ”
As a consequence of Proposition 13.9.2 we obtain a classical result of
Lyusternik [128] and Graves [79].
Corollary 13.9.3 Assume that (A1) holds and that T : E Ã— F â†’F is a C1
mapping such that T(Â¯x, Â¯y) = o and the partial derivative T 1(Â¯x, Â¯y) is surjective.
Then the conclusions of Proposition 13.9.2 hold.

334
13 Extremal Principles and More Normals and Subdiï¬€erentials
Proof. In view of Proposition 13.9.2 we only have to show that condition (C3)
is satisï¬ed. Since T 1(Â¯x, Â¯y) is surjective, the classical open mapping theorem
implies that there exists Ïƒ > 0 such that 2ÏƒBF âŠ†T 1(Â¯x, Â¯y)(BE). Since T 1 is
continuous, there further exist open neighborhoods V of Â¯x and W of Â¯y such
that
âˆ¥T 1(Â¯x, Â¯y) âˆ’T 1(x, y)âˆ¥â‰¤Ïƒ
âˆ€(x, y) âˆˆV Ã— W.
It follows that
2ÏƒBF âŠ†

T 1(Â¯x, Â¯y) âˆ’T 1(x, y)

(BE) + T 1(x, y)(BE) âŠ†ÏƒBF + T 1(x, y)(BE)
and so ÏƒBF âŠ†T 1(x, y)(BE) for any (x, y) âˆˆV Ã— W. Hence (C3) is satisï¬ed.
âŠ“âŠ”
13.10 An Implicit Multifunction Theorem
We start with an auxiliary result. Let E, G be FrÃ©chet smooth Banach spaces
and U an open subset of E. With a given multifunction Î“ : U â‡’G we
associate the function g : U â†’R deï¬ned by
g(x) := d(Î“(x), o) = inf{âˆ¥zâˆ¥| z âˆˆÎ“(x)}.
(13.108)
It will be crucial for the following that g can be written as inï¬mum over a
ï¬xed set:
g(x) = inf
zâˆˆG Î³(x, z),
where Î³(x, z) := âˆ¥zâˆ¥+ Î´graph Î“ (x, z).
(13.109)
The lemma below establishes the relationship between the Fâ€“subdiï¬€erential
of g and the coderivative of Î“. In this connection, if S âŠ†G, Â¯z âˆˆG and Î· > 0,
we call
projÎ·(Â¯z, S) := {z âˆˆG | âˆ¥z âˆ’Â¯zâˆ¥â‰¤d(Â¯z, S) + Î·}
the Î·â€“approximate projection of Â¯z to S.
Lemma 13.10.1 Let E and G be FrÃ©chet smooth Banach spaces and U an
open subset of E. Further let the multifunction Î“ : U â‡’G be closed-valued
and u.s.c. and let g : U â†’R be deï¬ned by (13.108). Assume that there exists
Ïƒ > 0 such that for any x âˆˆU with o /âˆˆÎ“(x), one has
Ïƒ â‰¤lim inf
Î·â†’0

âˆ¥xâˆ—âˆ¥
 xâˆ—âˆˆDâˆ—
F Î“(Ë†x, Ë†z)(zâˆ—), zâˆ—âˆˆGâˆ—, âˆ¥zâˆ—âˆ¥= 1,
Ë†x âˆˆB(x, Î·), Ë†z âˆˆprojÎ·

o, Î“(Ë†x)

.
Then for any x âˆˆU with g(x) > 0, xâˆ—âˆˆâˆ‚F g(x) implies âˆ¥xâˆ—âˆ¥â‰¥Ïƒ.

13.10 An Implicit Multifunction Theorem
335
Proof. Since Î“ is closedâ€“valued and u.s.c., graph Î“ is a closed set. Hence Î³ is
l.s.c. Moreover, since Î“ is u.s.c., the function g is l.s.c. (Exercise 13.13.11) and
so coincides with its l.s.c. closure g. Let x âˆˆU with g(x) > 0 and xâˆ—âˆˆâˆ‚F g(x)
be given. Choose Î· > 0 such that g(Ë†x) â‰¥g(x)/2 for any Ë†x âˆˆB(x, Î·). By
Proposition 9.7.1 there exist (uÎ·, wÎ·) and (uâˆ—
Î·, wâˆ—
Î·) âˆˆâˆ‚F Î³(uÎ·, wÎ·) satisfying
0 < g(uÎ·) < Î³(uÎ·, wÎ·) < g(uÎ·) + Î·,
(13.110)
âˆ¥uÎ· âˆ’xâˆ¥< Î·,
âˆ¥uâˆ—
Î· âˆ’xâˆ—âˆ¥< Î·,
âˆ¥wâˆ—
Î·âˆ¥< Î·.
(13.111)
From (13.110) we see that wÎ· âˆˆprojÎ·(o, Î“(uÎ·)). By the sum rule of Theorem
9.2.6 there exist (xÎ·, zÎ·), (Ë†xÎ·, Ë†zÎ·) close to (uÎ·, wÎ·) and zâˆ—
Î· âˆˆâˆ‚Ï‰(Ë†zÎ·), where
Ï‰(z) := âˆ¥zâˆ¥, such that
zÎ· âˆˆprojÎ·

o, Î“(xÎ·)

,
âˆ¥Ë†zÎ·âˆ¥> 0,
(uâˆ—
Î·, wâˆ—
Î·) âˆˆ(o, zâˆ—
Î·) + NF

(xÎ·, zÎ·), graph Î“

+ Î·(BEâˆ—Ã— BGâˆ—).
Hence there exist (Ë†uâˆ—
Î·, Ë†wâˆ—
Î·) âˆˆÎ· (BEâˆ—Ã— BGâˆ—) satisfying
uâˆ—
Î· âˆ’Ë†uâˆ—
Î· âˆˆDâˆ—Î“

(xÎ·, zÎ·

(zâˆ—
Î· âˆ’wâˆ—
Î· + Ë†wâˆ—
Î·)
and so
uâˆ—
Î· âˆ’Ë†uâˆ—
Î·
âˆ¥zâˆ—Î· âˆ’wâˆ—Î· + Ë†wâˆ—Î·âˆ¥âˆˆDâˆ—Î“(xÎ·, zÎ·)
 zâˆ—
Î· âˆ’wâˆ—
Î· + Ë†wâˆ—
Î·
âˆ¥zâˆ—Î· âˆ’wâˆ—Î· + Ë†wâˆ—Î·âˆ¥

.
Since âˆ¥zâˆ—
Î· âˆ’wâˆ—
Î· + Ë†wâˆ—
Î·âˆ¥â‰¥1 âˆ’2Î· (recall that âˆ¥zâˆ—
Î·âˆ¥= 1), we obtain
lim inf
Î·â†“0
âˆ¥uâˆ—
Î·âˆ¥= lim inf
Î·â†“0
âˆ¥uâˆ—
Î· âˆ’Ë†uâˆ—
Î·âˆ¥
âˆ¥zâˆ—Î· âˆ’wâˆ—Î· + Ë†wâˆ—Î·âˆ¥â‰¥Ïƒ;
here the last inequality follows from the assumption concerning Ïƒ. Hence
(13.111) shows that âˆ¥xâˆ—âˆ¥â‰¥Ïƒ.
âŠ“âŠ”
Now we turn to the announced implicit multifunction theorem. For this,
we need the following hypotheses.
(H 1) E, F and G are FrÃ©chet smooth Banach spaces, U is a nonempty open
subset of E Ã— F and (Â¯x, Â¯y) âˆˆU.
(H 2) Î¦ : U â‡’G is a closedâ€“valued multifunction such that o âˆˆÎ¦(Â¯x, Â¯y).
(H 3) The multifunction Î¦(Â¯x, Â·) is l.s.c. at Â¯y.
(H 4) For any y near Â¯y the multifunction Î¦(Â·, y) is u.s.c..
(H 5) There exists Ïƒ > 0 such that for any (x, y) âˆˆU with o /âˆˆÎ¦(x, y), one
has
Ïƒ â‰¤lim inf
Î·â†’0
0
âˆ¥xâˆ—âˆ¥
 xâˆ—âˆˆDâˆ—
F Î¦

(Ë†x, y), Ë†z

(zâˆ—), zâˆ—âˆˆGâˆ—, âˆ¥zâˆ—âˆ¥= 1,
Ë†x âˆˆB(x, Î·), Ë†z âˆˆprojÎ·

o, Î¦(Ë†x, y)
1
.

336
13 Extremal Principles and More Normals and Subdiï¬€erentials
Further let
Î¨(y) := {x âˆˆE | o âˆˆÎ¦(x, y)},
(13.112)
that is, Î¨ : F â‡’E is the implicit multifunction deï¬ned by the generalized
equation o âˆˆÎ¦(x, y). Applying Theorem 13.9.1 and making use of Lemma
13.10.1, we immediately obtain the following result.
Theorem 13.10.2 (Implicit Multifunction Theorem) Assume that the
hypotheses (H1)â€“(H5) are satisï¬ed. Then there exist open sets V âŠ†E and
W âŠ†F with Â¯x âˆˆV and Â¯y âˆˆW such that the following holds:
(a) For any y âˆˆW the set V âˆ©Î¨(y) is nonempty.
(b) For any (x, y) âˆˆV Ã— W one has
d(Î¨(y), x) â‰¤d(Î¦(x, y), o)
Ïƒ
.
(c) For any (x, y) âˆˆV Ã— W with x âˆˆÎ¨(y) and any xâˆ—âˆˆEâˆ—, one has
Dâˆ—
F Î¨(y, x)(xâˆ—) =
0
yâˆ—âˆˆF âˆ— (âˆ’xâˆ—, yâˆ—) âˆˆ

Î»>0
Î» âˆ‚F d(Î¦(x, y), o)
1
.
(13.113)
This theorem characterizes the coderivative of the implicit multifunction
Î¨ in terms of the FrÃ©chet subdiï¬€erential of the scalar function (x, y) â†’
d(Î¦(x, y), 0). It is natural to ask how the coderivative of Î¨ can be charac-
terized directly in terms of Î¦. The following result gives a partial answer.
Proposition 13.10.3 Assume that the hypotheses (H1)â€“(H5) are satisï¬ed.
Then for any (x, y) âˆˆV Ã—W with x âˆˆÎ¨(y) (notation as in Theorem 13.10.2),
the following holds:
(a) For any xâˆ—âˆˆEâˆ—one has

zâˆ—âˆˆGâˆ—
0
yâˆ—âˆˆF âˆ— (âˆ’xâˆ—, yâˆ—) âˆˆDâˆ—
F Î¦(x, y, o)(zâˆ—)
1
âŠ†Dâˆ—
F Î¨(y, x)(xâˆ—).
(13.114)
(b) For any xâˆ—âˆˆEâˆ—, yâˆ—âˆˆDâˆ—
F Î¨(y, x)(xâˆ—), and Ïµ > 0 there exist (xÏµ, yÏµ, zÏµ) âˆˆ
graph Î¦ and (xâˆ—
Ïµ, yâˆ—
Ïµ , zâˆ—
Ïµ ) âˆˆEâˆ—Ã— F âˆ—Ã— Gâˆ—such that
âˆ¥x âˆ’xÏµâˆ¥< Ïµ,
âˆ¥y âˆ’yÏµâˆ¥< Ïµ,
âˆ¥zÏµâˆ¥< Ïµ,
âˆ¥xâˆ—âˆ’xâˆ—
Ïµâˆ¥< Ïµ,
âˆ¥yâˆ—âˆ’yâˆ—
Ïµ âˆ¥< Ïµ,
(âˆ’xâˆ—
Ïµ, yâˆ—
Ïµ ) âˆˆDâˆ—
F Î¦(xÏµ, yÏµ, zÏµ)(zâˆ—
Ïµ ).
(13.115)
(c) If, in addition, graph Î¦ is normally regular at (x, y, o), then (13.114) holds
with equality.
Proof.
(a) Let yâˆ—be an element of the left-hand side of (13.114). Then there exists
zâˆ—âˆˆGâˆ—such that

13.11 An Extremal Principle Involving Deformations
337
(âˆ’xâˆ—, yâˆ—, zâˆ—) âˆˆNF (graph Î¦, (x, y, o)).
Hence there further exists a C1 function g such that gâ€²(x, y, o) =
(âˆ’xâˆ—, yâˆ—, zâˆ—) and Î´graph Î¦ âˆ’g has a local minimum at (x, y, o). Since
Î´graph Î¦(Ë†x, Ë†y, o) = Î´graph Î¨(Ë†y, Ë†x) for any Ë†x âˆˆE and any Ë†y âˆˆF, it follows
that the function
(Ë†y, Ë†x) â†’Î´graph Î¨(Ë†y, Ë†x) âˆ’g(Ë†x, Ë†y, o)
attains a local minimum at (y, x). Therefore, yâˆ—âˆˆDâˆ—
F (y, x)(xâˆ—).
(b) Let yâˆ—âˆˆDâˆ—
F Î¨(y, x)(xâˆ—) be given. Then
(yâˆ—, âˆ’xâˆ—) âˆˆ

Î»>0
Î»âˆ‚F d(graph Î¨, (y, x)).
Thus there exist a C1 function h satisfying hâ€²(y, x) = (yâˆ—, âˆ’xâˆ—) and a
constant Î» > 0 such that
h(y, x) â‰¤h(Ë†y, Ë†x) + Î»d(graph Î¨, (Ë†y, Ë†x))
â‰¤h(Ë†y, Ë†x) + Î»d(Î¨(Ë†y, Ë†x) â‰¤h(Ë†y, Ë†x) + (Î»/Ïƒ)d(Î¦(Ë†x, Ë†y), o);
(13.116)
here the last inequality follows by Theorem 13.10.2(b). Since d(Î¦(Ë†x, Ë†y), o) =
inf Ë†zâˆˆG{âˆ¥Ë†zâˆ¥+ Î´graph Î¦(Ë†x, Ë†y, Ë†z)}, the estimate (13.116) shows that
(yâˆ—, âˆ’xâˆ—) âˆˆâˆ‚F

inf
Ë†zâˆˆG

(Î»/Ïƒ)âˆ¥Ë†zâˆ¥+ Î´graph Î¦(Ë†x, Ë†y, Ë†z)

.
Applying Proposition 9.7.1, we obtain the conclusion of (b).
(c) This follows from (13.115) by letting Ïµ â†“0.
âŠ“âŠ”
We now derive a suï¬ƒcient condition for metric regularity. In view of Theo-
rems 10.3.3 and 10.5.2 this is at the same time a suï¬ƒcient condition for linear
openness and pseudo-Lipschitz continuity (Theorem 13.10.2)
Given the multifunction *Î¦ : E â‡’F, deï¬ne Î¦ : E Ã— F â‡’F by
Î¦(x, y) := *Î¦(x) âˆ’y,
x âˆˆE,
y âˆˆF.
(13.117)
Proposition 13.10.4 Assume that *Î¦ : E â‡’F is a multifunction such that,
with G := F and Î¦ according to (13.117), the hypotheses (H1)â€“(H5) are sat-
isï¬ed. Then *Î¦ is metrically regular around (Â¯x, Â¯y) with constant 1/Ïƒ.
Proof. Notice that in this case we have Î¨
=
*Î¦âˆ’1 and d(Î¦(x, y), o) =
d(*Î¦(x), y). Hence the assertion follows from Theorem 13.10.2(b).
âŠ“âŠ”
13.11 An Extremal Principle Involving Deformations
The concept of an extremal system introduced in Sect. 13.3 refers to the trans-
lation of sets (cf. Remark 13.3.2). Now we introduce the concept of an ex-
tended extremal system which refers to the deformation of sets and so applies
to multifunctions.

338
13 Extremal Principles and More Normals and Subdiï¬€erentials
Deï¬nition 13.11.1 Assume that Si, i = 1, . . . , n, are metric spaces with
metrics Ïi, E is a Banach space, and Î¦i : Si â‡’E are closed-valued multi-
functions. A point Â¯x âˆˆE is said to be a local extremal point of the system
(Î¦1, . . . , Î¦n) at (Â¯s1, . . . , Â¯sn) âˆˆS1 Ã— Â· Â· Â· Ã— Sn if Â¯x âˆˆÎ¦1(Â¯s1) âˆ©Â· Â· Â· âˆ©Î¦n(Â¯sn)
and there is a neighborhood U of Â¯x such that for any Ïµ > 0 there exist
(s1, . . . , sn) Ì¸= (Â¯s1, . . . , Â¯sn) with
Ïi(si, Â¯si) â‰¤Ïµ,
d(Î¦i(si), Â¯x) < Ïµ,
i = 1, . . . , n,
Î¦1(s1) âˆ©Â· Â· Â· âˆ©Î¦n(sn) âˆ©U = âˆ….
If the system (Î¦1, . . . , Î¦n) admits a local extremal point, it is said to be an
extended extremal system.
Remark 13.11.2 Let (A1, A2, Â¯x) be an extremal system in the sense of Def-
inition 13.3.1. Deï¬ning
S1 := E, Î¦1(s1) := s1 + A1 âˆ€s1 âˆˆE, S2 := {o}, Î¦2(o) := A2,
we see that Â¯x is a local extremal point of the system (Î¦1, Î¦2) at (o, o) and so
(Î¦1, Î¦2) is an extended extremal system.
We now establish an extremal principle for extended extremal systems
that corresponds to the approximate extremal principle of Theorem 13.3.10.
The result will be applied in Sect. 13.12 to multiobjective optimization.
Theorem 13.11.3 Let E be a FrÃ©chet smooth Banach space. Assume that,
for i = 1, . . . , n, Si is a metric space with metric Ïi and Î¦i : Si â‡’E is
a closed-valued multifunction. Further let Â¯x be a local extremal point of the
system (Î¦1, . . . , Î¦n) at (Â¯s1, . . . , Â¯sn). Then for any Ïµ > 0 there exist si âˆˆSi,
xi âˆˆBE(Â¯x, Ïµ), and xâˆ—
i âˆˆEâˆ—such that
Ïi(si, Â¯si) â‰¤Ïµ,
xi âˆˆÎ¦i(si),
xâˆ—
i âˆˆNF (Î¦i(si), xi) + ÏµBEâˆ—,
max{âˆ¥xâˆ—
i âˆ¥, . . . , âˆ¥xâˆ—
nâˆ¥} â‰¥1,
xâˆ—
1 + Â· Â· Â· + xâˆ—
n = o.
(13.118)
Proof.
(I) We equip En with the Euclidean product norm. Choose Ï > 0 such that
U := B(Â¯x, Ï) is a neighborhood of Â¯x as in Deï¬nition 13.11.1. Now let Ïµ > 0
be given and choose Î· such that
0 < Î· < min
0
Ïµ2
5Ïµ + Ïµ2 + 12n2 , Ï2
4
1
.
Further let s1, . . . , sn be as in Deï¬nition 13.11.1 with Ïµ replaced by Î· so
that, in particular, d(Î¦i(si), Â¯x) < Î·. Put A := Î¦1(si) Ã— Â· Â· Â· Ã— Î¦n(sn) and
deï¬ne Ï• : U n â†’R by
Ï•(y1, . . . , yn) :=
n
	
i,k=1
âˆ¥yi âˆ’ykâˆ¥+ Î´A(y1, . . . , yn).

13.11 An Extremal Principle Involving Deformations
339
Since every set Î¦i(si) is closed, the function Ï• is l.s.c. Moreover, since Â¯x
is a local extremal point of the system (Î¦1, . . . , Î¦n), we conclude that Ï•
is positive on U n. Choose Ëœyi âˆˆÎ¦i(si), i = 1, . . . , n, satisfying
âˆ¥Ëœyi âˆ’Ëœyk| â‰¤d(Î¦i(si), Â¯x) + d(Î¦k(sk), Â¯x) + Î· â‰¤3Î·.
It follows that Ï•(y1, . . . , yn) â‰¤3n2Î· < Ïµ2/4.
(II) Applying Ekelandâ€™s variational principle in the form of Corollary 8.2.6,
we ï¬nd Ëœxi âˆˆB(Ëœyi, Ïµ/2) âŠ†B(Â¯x, Ïµ) such that the function
f(y1, . . . , yn) :=
n
	
i,k=1
âˆ¥yi âˆ’ykâˆ¥+ Ïµ
2
n
	
i=1
âˆ¥yi âˆ’Ëœxiâˆ¥+ Î´A(y1, . . . , yn)
attains its minimum over U n at (Ëœx1, . . . , Ëœxn). Obviously we may assume
that U n = En. Deï¬ne Ïˆ : En â†’R by
Ïˆ(y1, . . . , yn) :=
n
	
i,k=1
âˆ¥yi âˆ’ykâˆ¥.
We have Ïˆ(Ëœx1, . . . , Ëœxn) = Ï•(Ëœx1, . . . , Ëœxn) > 0.
(III) Applying the approximate sum rule of Theorem 9.2.6 (in connection with
Lemma 9.2.5) to the function f, we ï¬nd
xi âˆˆÎ¦(si) âˆ©B(Ëœxi, Î·) âŠ†B(Â¯x, Ïµ),
zi âˆˆB(Ëœxi, Î·),
(zâˆ—
1, . . . , zâˆ—
n) âˆˆâˆ‚F Ïˆ(z1, . . . , zn)
satisfying
o âˆˆ(zâˆ—
1, . . . , zâˆ—
n) + NF (Î¦1(s1), x1) Ã— Â· Â· Â· Ã— NF (Î¦n(sn), xn)
+ B(En)âˆ—
o, Î·(n + 1)

;
(13.119)
here we made use of the representation
âˆ‚F Î´A(y1, . . . , yn) = NF (Î¦1(y1), y1) Ã— Â· Â· Â· Ã— NF (Î¦n(yn), yn)
âˆ€yi âˆˆÎ¦i(si),
(13.120)
the veriï¬cation of which is left as Exercise 13.13.21. Putting xâˆ—
i := âˆ’zâˆ—
i
for i = 1, . . . , n we derive from (13.119) that xâˆ—
i âˆˆNF (Î¦i(si), xi)+ÏµBEâˆ—.
From (zâˆ—
1, . . . , zâˆ—
n) âˆˆâˆ‚F Ïˆ(z1, . . . , zn) we conclude that
(zâˆ—
1, . . . , zâˆ—
n)
â‰¤lim inf
Ï„â†’0
Ïˆ(z1 + Ï„h, . . . , zn + Ï„h) âˆ’Ïˆ(z1, . . . , zn)
Ï„
= 0
âˆ€h âˆˆE,
where the latter equation follows from the deï¬nition of Ïˆ by symmetry.
Hence we obtain
xâˆ—
1 + Â· Â· Â· + xâˆ—
n = âˆ’(zâˆ—
1 + Â· Â· Â· + zâˆ—
n) = o.
(13.121)

340
13 Extremal Principles and More Normals and Subdiï¬€erentials
It remains to verify that max{âˆ¥xâˆ—
1âˆ¥, . . . , âˆ¥xâˆ—
nâˆ¥} â‰¥1. We ï¬rst obtain
n
	
i=1
âŸ¨zâˆ—
i , âˆ’ziâŸ©
â‰¤lim inf
Ï„â†’0
Ïˆ(z1 âˆ’Ï„z1, . . . , zn âˆ’Ï„zn) âˆ’Ïˆ(z1, . . . , zn)
Ï„
= âˆ’Ïˆ(z1, . . . , zn).
In view of (13.121) we have zâˆ—
1 = âˆ’n
i=2 zâˆ—
i and it follows that
Ïˆ(z1, . . . , zn) â‰¤
n
	
i=1
âŸ¨zâˆ—
i , ziâŸ©=
n
	
i=2
âŸ¨zâˆ—
i , zi âˆ’z1âŸ©
â‰¤max{âˆ¥zâˆ—
1âˆ¥, . . . , âˆ¥zâˆ—
nâˆ¥} Ïˆ(z1, . . . , zn).
(13.122)
Since Ïˆ(Ëœx1, . . . , Ëœxn) > 0 and âˆ¥zi âˆ’Ëœxiâˆ¥â‰¤Î·, we may assume (shrinking Î·
further if necessary) that Ïˆ(z1, . . . , zn) > 0. Hence (13.122) implies that
max{âˆ¥zâˆ—
1âˆ¥, . . . , âˆ¥zâˆ—
nâˆ¥} â‰¥1, which also holds with zâˆ—
i replaced by xâˆ—
i .
âŠ“âŠ”
13.12 Application to Multiobjective Optimization
We want to apply the extremal principle of Theorem 13.11.3 to multiobjective
optimization problems. Let P be a nonempty subset of a Banach space F. We
deï¬ne a preference relation â‰ºon F by writing z1 â‰ºz2 (read z1 is preferred
to z2) if and only if (z1, z2) âˆˆP. Given z âˆˆF, we denote the level set of â‰ºat
z by L(z), i.e.,
L(z) := {y âˆˆF | y â‰ºz}.
Deï¬nition 13.12.1 The preference relation â‰ºis said to be:
â€“ nonreï¬‚exive if z â‰ºz does not hold for any z âˆˆF.
â€“ locally satiated at Â¯z âˆˆF if z âˆˆcl L(z) for any z in a neighborhood of Â¯z.
â€“ almost transitive on F if y âˆˆcl L(z) and z â‰ºzâ€² imply y â‰ºzâ€².
Example 13.12.2 Let Q be a closed cone in F. The generalized Pareto pref-
erence â‰ºis deï¬ned by z1 â‰ºz2 if and only if z1 âˆ’z2 âˆˆQ and z1 Ì¸= z2.
We have L(z) = z + (Q \ {o}). Hence â‰ºis a nonreï¬‚exive preference relation
that is locally satiated at any Â¯z âˆˆF. It is left as Exercise 13.13.22 to show
that â‰ºis almost transitive on F if and only if the cone Q is pointed (i.e.,
Q âˆ©(âˆ’Q) = {o}) and convex.
Now we make the following assumptions:
(A) E and F are Banach spaces, f : E â†’F, M âŠ†E,
â‰ºis a nonreï¬‚exive, satiated, almost transitive preference relation on F.

13.12 Application to Multiobjective Optimization
341
We consider the multiobjective optimization problem:
(MOP) Minimize f(x) with respect to â‰º
subject to x âˆˆM.
A point Â¯x âˆˆE is said to be a local solution of (MOP) if there is no x âˆˆM
near Â¯x such that f(x) â‰ºf(Â¯x).
Lemma 13.12.3 establishes the relationship between the problem (MOP)
and extended extremal systems.
Lemma 13.12.3 Let the assumptions (A) be satisï¬ed. Deï¬ne
S1 := L(f(Â¯x)) âˆª{f(Â¯x)},
Î¦1(s1) := M Ã— cl L(s1)
âˆ€s1 âˆˆS1,
S2 := {o},
Î¦2(o) := {(x, f(x)) | x âˆˆE}.
(13.123)
If Â¯x is a local solution of (MOP), then (Â¯x, f(Â¯x)) is a local extremal point of
the system (Î¦1, Î¦2).
Proof. See Exercise 13.13.23.
âŠ“âŠ”
Applying the extremal principle of Theorem 13.11.3, we now derive a neces-
sary optimality condition for (MOP) in terms of F-subdiï¬€erentials. Recall that
for yâˆ—âˆˆF âˆ—, the scalarization âŸ¨yâˆ—, fâŸ©of f is deï¬ned by âŸ¨yâˆ—, fâŸ©(x) := âŸ¨yâˆ—, f(x)âŸ©
for any x âˆˆE.
Theorem 13.12.4 In addition to the assumptions (A) let E and F be FrÃ©chet
smooth Banach spaces and let f be locally L-continuous around Â¯x âˆˆM. If Â¯x
is a local solution of (MOP), then for any Ïµ > 0 there exist x0, x1 âˆˆBE(Â¯x, Ïµ),
y0, y1 âˆˆBF (f(Â¯x), Ïµ), xâˆ—âˆˆNF (M, x1), and yâˆ—âˆˆNF (cl L(y0), y1) such that
âˆ¥yâˆ—âˆ¥= 1 and
o âˆˆxâˆ—+ âˆ‚F âŸ¨yâˆ—, fâŸ©(x0) + ÏµBEâˆ—.
(13.124)
Proof.
(I) We equip E Ã— F with the norm âˆ¥(x, y)âˆ¥:= âˆ¥xâˆ¥+ âˆ¥yâˆ¥and Eâˆ—Ã— F âˆ—with
the corresponding dual norm âˆ¥(xâˆ—, yâˆ—)âˆ¥= max{âˆ¥xâˆ—âˆ¥, âˆ¥yâˆ—âˆ¥}. Let Ï âˆˆ(0, 1)
be such that f is Lipschitz continuous on B(Â¯x, Ï) with Lipschitz constant
Î» > 0. Let any Ïµ > 0 be given and choose
Î· := min
0 2ÏµÎ»
1 + Î»,
1
8(2 + Î»), Ïµ
2, Ï
4
1
.
By Lemma 13.12.3, (Â¯x, f(Â¯x)) is a local extremal point of the sys-
tem
(Î¦1, Î¦2)
deï¬ned
in
that
lemma.
Therefore,
Theorem
13.11.3
(with Ïµ replaced by Î·) implies that there exist y0
âˆˆ
BF (f(Â¯x), Î·),
(xi, yi) âˆˆBEÃ—R

(Â¯x, f(Â¯x)), Î·

, i = 1, 2, (xâˆ—
1, yâˆ—
1) âˆˆNF (Î¦1(y0), (x1, y1)),
and (xâˆ—
2, yâˆ—
2) âˆˆNF (Î¦2(o), (x2, y2)) such that
max{âˆ¥(xâˆ—
1, yâˆ—
1)âˆ¥, âˆ¥(xâˆ—
2, yâˆ—
2)âˆ¥} > 1 âˆ’Î·
and
âˆ¥(xâˆ—
1, yâˆ—
1) + (xâˆ—
2, yâˆ—
2)âˆ¥< Î·.
(13.125)

342
13 Extremal Principles and More Normals and Subdiï¬€erentials
It follows that
âˆ¥(xâˆ—
i , yâˆ—
i )âˆ¥> 1 âˆ’2Î· â‰¥1/2,
i = 1, 2.
(13.126)
The deï¬nition of the F-normal cone implies that for any (x, y) âˆˆÎ¦2(o)
suï¬ƒciently close to (x2, y2) we obtain
âŸ¨xâˆ—
2, x âˆ’x2âŸ©+ âŸ¨yâˆ—
2, y âˆ’y2âŸ©âˆ’Î·âˆ¥(x âˆ’x2, y âˆ’y2)âˆ¥â‰¤0.
In this connection we have y = f(x) and y2 = f(x2). Hence the function
g : E â†’R deï¬ned by
g(x) := âˆ’

âŸ¨xâˆ—
2, x âˆ’x2âŸ©+ âŸ¨yâˆ—
2, f(x) âˆ’f(x2)âŸ©âˆ’Î·âˆ¥(x âˆ’x2, f(x) âˆ’f(x2))âˆ¥

attains the local minimum 0 at x = x2. It follows that o âˆˆâˆ‚F g(x2).
(II) Applying the approximate sum rule of Theorem 9.2.6 and the chain rule
of Theorem 9.2.9 to g, we conclude that there exists x0 âˆˆBE(x2, Î·) âŠ†
BE(Â¯x, 2Î·) such that
o âˆˆâˆ’xâˆ—
2 âˆ’âˆ‚F âŸ¨yâˆ—
2, fâŸ©(x0) + (1 + Î»)Î·BEâˆ—.
(13.127)
From this and the second relation in (13.125) we obtain
o âˆˆxâˆ—
1 + âˆ‚F âŸ¨yâˆ—
1, fâŸ©(x0) + 2(2 + Î»)Î·BEâˆ—.
(13.128)
We claim that âˆ¥yâˆ—
1âˆ¥â‰¥1/(4(1 + Î»)). To see this, take zâˆ—âˆˆâˆ‚F âŸ¨yâˆ—
1, fâŸ©(x0)
and uâˆ—âˆˆÎ·BEâˆ—such that o = xâˆ—
1 + zâˆ—+ 2(2 + Î»)uâˆ—. It follows that
1/2 < âˆ¥(xâˆ—
1, yâˆ—
1)âˆ¥â‰¤âˆ¥xâˆ—
1âˆ¥+ âˆ¥yâˆ—
1âˆ¥= âˆ¥zâˆ—+ 2(2 + Î»)uâˆ—âˆ¥+ âˆ¥yâˆ—
1âˆ¥
â‰¤âˆ¥zâˆ—âˆ¥+ 2(2 + Î»)Î· + âˆ¥yâˆ—
1âˆ¥.
(13.129)
From the choice of zâˆ—and the L-continuity of f on B(Â¯x, Ï) we obtain
âŸ¨zâˆ—, hâŸ©â‰¤âŸ¨yâˆ—
1, f(x0 + h) âˆ’f(x0)âŸ©â‰¤âˆ¥yâˆ—
1âˆ¥Î»âˆ¥hâˆ¥
âˆ€h âˆˆB(o, Ï/2)
and so âˆ¥zâˆ—âˆ¥â‰¤Î»âˆ¥yâˆ—
1âˆ¥. This, (13.129), and the choice of Î· imply
âˆ¥yâˆ—
1âˆ¥â‰¥
1
2 âˆ’2(2 + Î»)Î·
1 + Î»
â‰¥
1
4(1 + Î»)
as claimed. Now dividing (13.128) by âˆ¥yâˆ—
1âˆ¥and deï¬ning xâˆ—:= xâˆ—
1/âˆ¥yâˆ—
1âˆ¥
and yâˆ—:= yâˆ—
1/âˆ¥yâˆ—
1âˆ¥, the conclusion of the theorem follows.
âŠ“âŠ”
Remark 13.12.5 Theorem 13.12.4 is the starting point for deriving neces-
sary conditions for multiobjective optimization problems with speciï¬ed con-
straints. For instance, let the set M in (MOP) be of the form M = A1âˆ©A2âˆ©A,
where A is any subset of E and

13.13 Bibliographical Notes and Exercises
343
A1 := {x âˆˆE | g(x) â‰¤0}, A2 := {x âˆˆE | h(x) = 0}
with functionals g, h : E â†’R. Let Â¯x be a local solution of (MOP) in this case.
Then Theorem 13.12.4 implies the condition (13.124). Here, xâˆ—âˆˆNF (M, Â¯x1)
and the deï¬nition of the F-normal cone shows that
Ï•(y) := âˆ’âŸ¨xâˆ—, y âˆ’x1âŸ©+ (Ïµ/3)âˆ¥y âˆ’x1âˆ¥â‰¥0
for all y âˆˆM close to x1. Hence x1 is a local solution to the scalar optimization
problem
minimize
Ï•(y)
subject to
g(y) â‰¤0,
h(y) = 0,
y âˆˆA.
A necessary condition for this problem can be derived, for instance, with
the aid of the approximate multiplier rule of Theorem 12.5.1. It is left as
Exercise 13.13.24 to elaborate the details.
13.13 Bibliographical Notes and Exercises
The presentation of this chapter was strongly inï¬‚uenced by the seminal two-
volume monograph [136,137] of Mordukhovich, in particular by the ï¬rst vol-
ume. The second volume contains profound investigations of optimal con-
trol governed by ordinary diï¬€erential equations and by functionalâ€“diï¬€erential
relations. Concerning variational analysis in ï¬nite-dimensional spaces we rec-
ommend the comprehensive monograph [189] of Rockafellar and Wets.
The limiting objects, which we call here Mordukhovich normal cone and
Mordukhovich subdiï¬€erential, are called by Mordukhovich basic normal cone
and basic subdiï¬€erential, respectively. These objects as well as the idea of
extremal principles ï¬rst appear in [132]. We refer to the monograph cited
above for a detailed discussion of the development of this theory as well as
a lot of references. The exact sum rule of Theorem 13.5.5 was obtained by
Mordukhovich and Shao [142] in an arbitrary Asplund space. Further calculus
rules for F- and M-subdiï¬€erentials as well as necessary optimality conditions
were obtained, among others, by Ngai et al. [151] and Ngai and ThÃ©ra [154].
Proposition 13.4.3 is due to Mordukhovich and Wang [145]. Mordukhovich
coderivatives (called normal coderivatives by Mordukhovich) were introduced
in [133]. They were systematically studied in ï¬nite-dimensional spaces by
Mordukhovich [134] and Ioï¬€e [95]. The approximate calculus rules for F-
coderivatives in FrÃ©chet smooth Banach spaces (Theorems 13.2.7 and 13.2.8)
and their exact counterparts for M-coderivatives in ï¬nite-dimensional Ba-
nach spaces were taken from Borwein and Zhu [24]. Mordukhovich and
Shao [141, 143] derived exact calculus rules for M-coderivatives in Asplund
spaces. Example 13.2.12 (together with the concrete data of Exercise 13.13.8

344
13 Extremal Principles and More Normals and Subdiï¬€erentials
and further similar examples) was constructed by Borwein and Zhu [23].
Weakâˆ—sequential limits of proximal subgradients are studied by Clarke
et al. [39].
The results of Sects. 13.9 and 13.10, in particular the remarkable implicit
multifunction theorem (Theorem 13.10.2), are due to Ledyaev and Zhu [120].
Investigating multiobjective optimal control problems, Zhu [227] observed
that the approximate extremal principle holds for more general deformations
than translations of the set system. This observation ï¬nally led to the gen-
eral concept of an extended extremal system that was developed and applied
by Mordukhovich et al. [144]. Readers interested in multiobjective optimiza-
tion (also known as vector optimization) are referred to GÂ¨opfert et al. [77],
Jahn [102], Pallaschke and Rolewicz [156], and the literature cited in these
books.
Exercise 13.13.1 Verify Lemma 13.1.11.
Exercise 13.13.2 Prove Proposition 13.1.19.
Exercise 13.13.3 Verify Theorem 13.1.23.
Exercise 13.13.4 Let A be a closed subset of E and Â¯x âˆˆA. Prove the
following assertions:
(a) If Â¯x âˆˆA and U is a closed neighborhood of Â¯x, then NM(A âˆ©U, Â¯x) =
NM(A, Â¯x).
(b) If Â¯x âˆˆbd A, then NM(A, Â¯x) âŠ†NM(bd A, Â¯x).
Hint: Take any nonzero xâˆ—âˆˆNM(A, Â¯x) and ï¬nd a sequence (Ïµk, xk, xâˆ—
k), such
that, in particular, xâˆ—
k
wâˆ—
âˆ’âˆ’â†’xâˆ—. Since it follows that lim inf âˆ¥xâˆ—
kâˆ¥> 0, conclude
that xk /âˆˆint A for k large enough.
Exercise 13.13.5 Verify the assertions (a) and (c) of Proposition 13.2.3.
Exercise 13.13.6 Elaborate the details of the proof of Theorem 13.2.8.
Exercise 13.13.7 Prove Theorem 13.2.11.
Exercise 13.13.8 Let E be the sequence space l2. For any k âˆˆN, let uk
denote the kth unit vector of l2, let Î±k be a positive number such that
8
1 âˆ’1
k2 â‰¤Î±k < 1 and deï¬ne
yk := u2k,
zk :=
8
1 âˆ’Î±2
k u2kâˆ’1 âˆ’Î±ku2k.
Finally deï¬ne H1 := cl span{yk | k âˆˆN} and H2 := cl span{zk | k âˆˆN}. Show
that Hâ—¦
1 âˆ©Hâ—¦
2 = {o} and Hâ—¦
1 + Hâ—¦
2 is weakâˆ—dense but not closed in Eâˆ—(cf.
Example 13.2.12).
Hint: Verify that
Hâ—¦
1 = cl span{yâˆ—
k | k âˆˆN},
Hâ—¦
2 = cl span{zâˆ—
k | k âˆˆN},
where yâˆ—
k := u2kâˆ’1 and zâˆ—
k := Î±ku2kâˆ’1 +
!
1 âˆ’Î±2
k u2k.

13.13 Bibliographical Notes and Exercises
345
Exercise 13.13.9 Verify the statement in Example 13.3.3
Exercise 13.13.10 Prove Lemma 13.3.4.
Exercise 13.13.11 Let Î“ : E â‡’G be a multifunction between the Banach
spaces E and G. Deï¬ne g : E â†’R by g(x) := d(Î“(x), o). Show that if Î“ is
u.s.c., then g is l.s.c.
Exercise 13.13.12 Elaborate step (II) of the proof of Theorem 13.3.10.
Exercise 13.13.13 Show that the set A âŠ†E is epi-Lipschitzian at Â¯x âˆˆA if
and only if it is compactly epi-Lipschitzian at Â¯x, where the associated compact
set C can be chosen as a singleton.
Exercise 13.13.14 Verify Remark 13.4.6.
Exercise 13.13.15 Carry out step (III) in the proof of Theorem 13.4.9.
Exercise 13.13.16 For i = 1, 2 let Ai be a nonempty subset of the normed
vector space Ei and Â¯xi âˆˆAi. Prove that
NM(A1 Ã— A2, (Â¯x1, Â¯x2)) = NM(A1, Â¯x1) Ã— NM(A2, Â¯x2).
Exercise 13.13.17 Show that for any nonempty subset A of E and Â¯x âˆˆA
one has
âˆ‚MÎ´A(Â¯x) = âˆ‚âˆ
MÎ´A(Â¯x) = NM(A, Â¯x).
Exercise 13.13.18 Carry out the induction proof for Theorem 13.5.5.
Exercise 13.13.19 Prove the assertion (13.93) of Theorem 13.8.1.
Exercise 13.13.20 Verify the inclusion âŠ‡of (13.98) under the assumptions
of Theorem 13.8.2.
Exercise 13.13.21 Verify the representation of âˆ‚F Î´A(y1, . . . , yn) in (13.120).
Exercise 13.13.22 Verify the assertion in Example 13.12.2.
Exercise 13.13.23 Verify Lemma 13.12.3.
Exercise 13.13.24 Carry out the program indicated in Remark 13.12.5.

A
Appendix: Further Topics
In this ï¬nal chapter we brieï¬‚y indicate some concepts and developments in
nonsmooth analysis that have not been treated in the preceding text. For a
comprehensive discussion we refer to the monograph [189] by Rockafellar
and Wets (ï¬nite-dimensional theory) and the monograph [136, 137] by
Mordukhovich (inï¬nite-dimensional theory).
In the sequel, unless otherwise speciï¬ed, let E be a normed vector space,
f : E â†’R a proper functional, and Â¯x âˆˆdom f.
(I) Clarke [34] deï¬nes the subdiï¬€erential
âˆ‚â†‘f(Â¯x) := {xâˆ—âˆˆEâˆ—| (xâˆ—, âˆ’1) âˆˆNC

epi f, (Â¯x, f(Â¯x))

}.
This set is always Ïƒ(Eâˆ—, E)-closed but may be empty. However, if Â¯x is a
local minimizer of f, then o âˆˆâˆ‚â†‘f(Â¯x). Moreover, Corollary 11.3.2 shows that
âˆ‚â†‘f(Â¯x) = âˆ‚â—¦f(Â¯x) for any Â¯x âˆˆE whenever f is locally L-continuous on E.
(II) Rockafellar [184] (see also [186, 189]) deï¬nes the (regular) subderivative
f â†‘(Â¯x, Â·) : E â†’R of f at Â¯x as
f â†‘(Â¯x, y) := lim
Ïµâ†“0 lim sup
(x,Î±)â†’f Â¯x
inf
zâˆˆB(y,Ïµ)
f(x + Ï„z) âˆ’Î±
Ï„
.
In this context, (x, Î±) â†’f Â¯x means (x, Î±) âˆˆepi f, x â†’Â¯x, and Î± â†’f(Â¯x).
Rockafellar shows that f â†‘(Â¯x, Â·) is l.s.c. and that f â†‘(Â¯x, o) = âˆ’âˆif and only if
âˆ‚â†‘f(Â¯x) = âˆ…. If f â†‘(Â¯x, o) > âˆ’âˆ, then f â†‘(Â¯x, o) = 0, f â†‘(Â¯x, Â·) is sublinear, and
epi f â†‘(Â¯x, Â·) = TC

epi f, (Â¯x, f(Â¯x))

.
It then follows that f â†‘(Â¯x, Â·) is the support functional of the Clarke subdiï¬€er-
ential, i.e.,
âˆ‚â†‘f(Â¯x) = {xâˆ—âˆˆEâˆ—| âŸ¨xâˆ—, yâŸ©â‰¤f â†‘(Â¯x, y)
âˆ€y âˆˆE}.

348
A Appendix: Further Topics
The functional f is said to be directionally Lipschitz at Â¯x if epi f is epi-
Lipschitz at (Â¯x, f(Â¯x)). Moreover, f is said to be subdiï¬€erentially regular if
f â†‘(Â¯x, y) = f H(Â¯x, y)
âˆ€y âˆˆE;
this is equivalent to epi f being a tangentially regular set. If f is locally L-
continuous around Â¯x, then f is subdiï¬€erentially regular if and only if f is
regular in the sense of Clarke. Rockafellar shows that the sum rule
âˆ‚â†‘(f + g)(Â¯x) âŠ†âˆ‚â†‘f(Â¯x) + âˆ‚â†‘g(Â¯x)
(â‹„)
holds if g is directionally Lipschitz at Â¯x and dom f â†‘(Â¯x, Â·) âˆ©int domgâ†‘(Â¯x, Â·)
is nonempty. The sum rule holds with equality if, in addition, f and g are
subdiï¬€erentially regular. Certain chain rules are also established.
(III) Michel and Penot [129,130] study several types of directional derivatives
and associated subdiï¬€erentials. Their aim is to generalize the G-derivative
rather than the strict H-derivative as does the Clarke subdiï¬€erential (cf. Re-
mark 7.3.10).
Using the epi-limit convergence concept, Michel and Penot deï¬ne, among
others, the pseudo-strict derivative of f at Â¯x as
f âˆ§(Â¯x, y) := sup
zâˆˆE
eLim sup
Ï„â†“0,zâ€²â†’z
(Â¯x+Ï„zâ€²,Î±)â†’f Â¯x
1
Ï„

f(Â¯x + Ï„y + Ï„zâ€²) âˆ’Î±

.
The functional f âˆ§(Â¯x, Â·) is shown to be l.s.c. and sublinear. If f is locally L-
continuous around Â¯x, then f âˆ§(Â¯x, Â·) coincides with f â™¦(Â¯x, Â·). If the directional
G-derivative fG(Â¯x, Â·) exists, is ï¬nite and sublinear, then f âˆ§(Â¯x, Â·) = fG(Â¯x, Â·).
The associated subdiï¬€erential, deï¬ned as
âˆ‚âˆ§f(Â¯x) := {xâˆ—âˆˆEâˆ—| âŸ¨xâˆ—, yâŸ©â‰¤f âˆ§(Â¯x, y) âˆ€y âˆˆE},
thus satisï¬es âˆ‚âˆ§f(Â¯x) = {f â€²(Â¯x)} whenever f is G-diï¬€erentiable at Â¯x. If Â¯x is a
local minimizer of f, then o âˆˆâˆ‚âˆ§f(Â¯x). Under certain regularity assumptions,
the sum rule âˆ‚âˆ§(f +g)(Â¯x) âŠ†âˆ‚âˆ§f(Â¯x)+âˆ‚âˆ§g(Â¯x) and a chain rule are established.
Finally, multiplier rules are derived in [130].
(IV) Various other generalized derivative concepts were introduced and stud-
ied. Some of them are Halkinâ€™s screen [83], Treimanâ€™s B-derivatives [206,207],
and Wargaâ€™s derivate containers [213, 214]. Much was done by Hiriart-
Urruty [84,85,87] in clarifying and reï¬ning these derivative concepts.
(V) Concerning sensitivity analysis, we refer in the ï¬nite-dimensional case to
Klatte and Kummer [111], Luderer et al. [126], and Rockafellar and Wets [189],
and in the inï¬nite-dimensional case to Bonnans and Shapiro [16], Clarke et
al. [39], and Mordukhovich [136] as well as to the literature cited in these
books.

A Appendix: Further Topics
349
(VI) Following Borwein and Zhu [23], we started the diï¬€erential analysis of
lower semicontinuous functionals with Zhuâ€™s nonlocal fuzzy sum rule which,
in turn, is based on the Borweinâ€“Preiss smooth variational principle. The
basis of Mordukhovichâ€™s work constitutes his extremal principle. Another
fundamental result in nonsmooth analysis is a multidirectional mean value
theorem (such as Theorem 9.6.2) that originally goes back to Clarke and
Ledyaev [37,38]. In [39] this result is applied to establish, among others, non-
smooth implicit and inverse function theorems. Mordukhovich and Shao [140]
showed the equivalence of the extremal principle and the local fuzzy sum rule,
and Zhu [226] proved the equivalence of the latter to the nonlocal fuzzy sum
rule and to the multidirectional mean value theorem.
(VII) Ioï¬€e systematically investigated approximate subdiï¬€erentials; see,
among others, [94â€“98,100].
Let F denote the collection of all ï¬nite-dimensional vector subspaces of E.
If S is a nonempty subset of E, we write
f(S)(x) :=

f(x)
if x âˆˆS,
+âˆ
if x âˆˆE \ S.
Ioï¬€e starts with the lower directional Hadamard derivative, which he calls
lower directional Dini derivative,
f H(Â¯x, y) := lim inf
Ï„â†“0, zâ†’y
1
Ï„

f(Â¯x + Ï„z) âˆ’f(Â¯x)

âˆ€y âˆˆE.
He then deï¬nes the Hadamard subdiï¬€erential (or Dini subdiï¬€erential)
âˆ‚âˆ’f(Â¯x) := {xâˆ—âˆˆEâˆ—| âŸ¨xâˆ—, yâŸ©â‰¤f H(Â¯x, y) âˆ€y âˆˆE}
and the A-subdiï¬€erential
âˆ‚Af(Â¯x) :=
6
LâˆˆF
Lim sup
xâ†’f Â¯x âˆ‚âˆ’f(x+L)(x).
Here, the PainlevÃ©â€“Kuratowski upper limit is taken with respect to the norm
topology in E and the weak star topology in Eâˆ—. Observe that Ioï¬€e utilizes
the topological form of the PainlevÃ©â€“Kuratowski upper limit whereas Mor-
dukhovich utilizes the sequential form. The interrelation between the concepts
of Ioï¬€e and Mordukhovich is discussed by Mordukhovich and Shao [142], see
also Mordukhovich [136].
Ioï¬€e further deï¬nes the G-normal cone to the set M âŠ†E at Â¯x âˆˆM as
NG(M, Â¯x) := clâˆ—
Î»>0
Î»âˆ‚AdM(Â¯x)

350
A Appendix: Further Topics
and, respectively, the G-subdiï¬€erential and the singular G-subdiï¬€erential of
f at Â¯x as
âˆ‚Gf(Â¯x) :=

xâˆ—âˆˆEâˆ—| (xâˆ—, âˆ’1) âˆˆNG

epi f, (Â¯x, f(Â¯x))

,
âˆ‚âˆ
G f(Â¯x) :=

xâˆ—âˆˆEâˆ—| (xâˆ—, 0) âˆˆNG

epi f, (Â¯x, f(Â¯x))

.
The G-subdiï¬€erential and the A-subdiï¬€erential coincide for any function on
ï¬nite-dimensional normed vector spaces and for directionally Lipschitz func-
tions on arbitrary normed vector spaces. For convex functionals on any normed
vector space, the G-subdiï¬€erential (in contrast to the A-subdiï¬€erential) coin-
cides with the subdiï¬€erential of convex analysis. In general, the sets âˆ‚Af(Â¯x)
and âˆ‚Gf(Â¯x) are not convex. However, they are minimal in a certain sense
among all â€œreasonableâ€ subdiï¬€erential constructions. In particular, for any
proper functional f one has âˆ‚Cf(Â¯x) = coâˆ—
âˆ‚Gf(Â¯x) + âˆ‚âˆ
G f(Â¯x)

.
Ioï¬€e develops an extensive calculus for these objects. For instance, if M1
and M2 are closed sets one of them being epi-Lipschitz at Â¯x, then an appro-
priate regularity assumption ensures that
NG(M1 âˆ©M2, Â¯x) âŠ†NG(M1, Â¯x) + NG(M2, Â¯x),
with equality if NG(Mi, Â¯x) = T(Mi, Â¯x)â—¦for i = 1, 2. This result is veri-
ï¬ed with the aid of Ekelandâ€™s variational principle. It is then applied to
derive the following sum rule. If the functionals f and g are l.s.c. and one
of them is directionally Lipschitz at Â¯x, then under the regularity assumption
âˆ‚âˆ
G f(Â¯x) âˆ©(âˆ’âˆ‚âˆ
G g(Â¯x)) = {o}, the sum rule (â‹„) holds with âˆ‚â†‘replaced by âˆ‚G.
An analogous result is obtained for the A-subdiï¬€erential. For an extended
chain rule in terms of âˆ‚A see Jourani and Thibault [106]. We also refer to the
survey paper by Hiriart-Urruty et al. [90].
Multiplier rules in terms of G-subdiï¬€erentials were established by Glover
et al. [74]. For an alternative proof of these multiplier rules and an interesting
discussion of the absence of constraint qualiï¬cations we refer to PÂ¨uhl [172].
Modiï¬ed multiplier rules were obtained by Glover and Craven [73].
(VIII) In these lectures, we conï¬ned ourselves to ï¬rst-order necessary
optimality conditions (which are also suï¬ƒcient in the convex case). For
second-order necessary and/or suï¬ƒcient conditions we refer in the smooth
case to Bonnans and Shapiro [16] and the literature cited therein. Second-
order optimality conditions in terms of generalized derivatives are also treated
in many papers. As a small selection we refer to Ben-Tal and Zowe [14], Casas
and TrÂ¨oltzsch [29], Chaney [31], Cominetti [40], Mordukhovich [135], Mor-
dukhovich [136], Mordukhovich and Outrata [138], and Rockafellar [188].

References
1. R. A. Adams. Sobolev Spaces. Academic, Boston, 1978
2. C. D. Aliprantis and K. C. Border. Inï¬nite Dimensional Analysis. Springer,
Berlin Heidelberg New York, 1994
3. E. Asplund. FrÃ©chet diï¬€erentiability of convex functions. Acta Math., 121:
31â€“47, 1968
4. K. Atkinson and W. Han. Theoretical Numerical Analysis. Springer, Berlin
Heidelberg New York, 2001
5. J. -P. Aubin. Contingent derivatives of set-valued maps and existence of solu-
tions to nonlinear inclusions and diï¬€erential inclusions. In L. Nachbin, editor,
Advances in Mathematics, Supplementary Studies, pages 160â€“232. Academic,
New York, 1981
6. J. -P. Aubin. Optima and Equilibria. Springer, Berlin Heidelberg New York,
1993
7. J. -P. Aubin and I. Ekeland. Applied Nonlinear Analysis. Wiley, New York,
1984
8. J. -P. Aubin and H. Frankowska. Set-Valued Analysis. BirkhÃ¤user, Boston, 1990
9. V. Barbu and Th. Precupanu. Convexity and Optimization in Banach Spaces.
Sijthoï¬€and Noordhoï¬€, Alphen aan de Rijn, 1978
10. M. S. Bazaraa, J. J. Goode, and M. Z. Nashed. On the cones of tangents
with applications to mathematical programming. J. Optim. Theory Appl., 13:
389â€“426, 1974
11. M. S. Bazaraa, H. D. Sherali, and C. M. Shetty. Nonlinear Programming:
Theory and Algorithms. Wiley, New York, 1993
12. M. S. Bazaraa and C. M. Shetty. Foundations of Optimization, volume 122
of Lecture Notes in Economics and Mathematical Systems. Springer, Berlin
Heidelberg New York, 1976
13. B. Beauzamy. Introduction to Banach Spaces and Their Geometry. North-
Holland, Amsterdam, 1985
14. A. Ben-Tal and J. Zowe. A uniï¬ed theory of ï¬rst and second order conditions
for extremum problems in topological vector spaces. Math. Progr. Stud., 19:
39â€“76, 1982
15. E. Bishop and R. R. Phelps. A proof that every Banach space is subreï¬‚exive.
Bull. Am. Math. Soc., 67:97â€“98, 1961

352
References
16. J. F. Bonnans and A. Shapiro. Perturbation Analysis of Optimization Problems.
Springer, Berlin Heidelberg New York, 2000
17. J. M. Borwein and A. D. Ioï¬€e. Proximal analysis in smooth spaces. Set-Valued
Anal., 4:1â€“24, 1996
18. J. M. Borwein and A. S. Lewis. Convex Analysis and Nonlinear Optimization.
Springer, Berlin Heidelberg New York, 2000
19. J. M. Borwein and D. Preiss. A smooth variational principle with applications
to subdiï¬€erentiability and to diï¬€erentiability of convex functions. Trans. Am.
Math. Soc., 303:517â€“527, 1987
20. J. M. Borwein and H. M. StrÃ³jwas. Proximal analysis and boundaries of closed
sets in Banach space. I: Theory. Can. J. Math., 38:431â€“452, 1986
21. J. M. Borwein, J. S. Treiman, and Q. J. Zhu. Necessary conditions for con-
strained optimization problems with semicontinuous and continuous data.
Trans. Am. Math. Soc., 350:2409â€“2429, 1998
22. J. M. Borwein and Q. J. Zhu. Viscosity solutions and viscosity subderivatives in
smooth Banach spaces with applications to metric regularity. SIAM J. Control
Optim., 34:1568â€“1591, 1996
23. J. M. Borwein and Q. J. Zhu. A survey of subdiï¬€erential calculus with appli-
cations. Nonlinear Anal., 38:687â€“773, 1999
24. J. M. Borwein and Q. J. Zhu. Techniques of Variational Analysis. Springer,
Berlin Heidelberg New York, 2005
25. J. M. Borwein and D. M. Zhuang. Veriï¬able necessary and suï¬ƒcient conditions
for openness and regularity of set-valued and single-valued maps. J. Math.
Anal. Appl., 134:441â€“459, 1988
26. G. Bouligand. Sur les surfaces dÃ©pourvues de points hyperlimites. Ann. Soc.
Polon. Math., 9:32â€“41, 1930
27. D. Braess. Nonlinear Approximation Theory. Springer, Berlin Heidelberg
New York, 1986
28. A. BrÃ¸ndsted. Conjugate convex functions in topological vector spaces. Fys.
Medd. Dans. Vid. Selsk., 34:1â€“26, 1964
29. E. Casas and F. TrÃ¶ltzsch. Second-order necessary and suï¬ƒcient optimality
conditions for optimization problems and applications to control theory. SIAM
J. Optim., 13:406â€“431, 2002
30. L. Cesari. Optimization â€“ Theory and Applications. Springer, Berlin Heidelberg
New York, 1983
31. R. W. Chaney. A general suï¬ƒciency theorem for nonsmooth nonlinear pro-
gramming. Trans. Am. Math. Soc., 276:235â€“245, 1983
32. I. Cioranescu. Geometry of Banach Spaces, Duality Mappings and Nonlinear
Problems. Kluwer, Dordrecht, 1990
33. F. H. Clarke. Necessary Conditions for Nonsmooth Problems in Optimal Con-
trol and the Calculus of Variations. Ph.D. Thesis, University of Washington,
1973
34. F. H. Clarke. Generalized gradients and applications. Trans. Am. Math. Soc.,
205:247â€“262, 1975
35. F. H. Clarke. A new approach to Lagrange multipliers. Math. Oper. Res., 1:
165â€“174, 1976
36. F. H. Clarke. Optimization and Nonsmooth Analysis. SIAM, Philadelphia, 1990
37. F. H. Clarke and Yu. S. Ledyaev. Mean value inequalities. Proc. Am. Math.
Soc., 122:1075â€“1083, 1994

References
353
38. F. H. Clarke and Yu. S. Ledyaev. Mean value inequalities in Hilbert space.
Trans. Am. Math. Soc., 344:307â€“324, 1994
39. F. H. Clarke, Yu. S. Ledyaev, R. J. Stern, and P. R. Wolenski. Nonsmooth
Analysis and Control Theory. Springer, Berlin Heidelberg New York, 1998
40. R. Cominetti. Metric regularity, tangent sets and second-order optimality con-
ditions. Appl. Math. Optim., 21:265â€“287, 1990
41. M. G. Crandall, L. C. Evans, and P. -L. Lions. Some properties of viscosity
solutions of Hamiltonâ€“Jacobi equations. Trans. Am. Math. Soc., 282:487â€“502,
1984
42. M. G. Crandall and P. -L. Lions. Viscosity solutions of Hamiltonâ€“Jacobi equa-
tions. Trans. Am. Math. Soc., 277:1â€“41, 1983
43. B. D. Craven. Mathematical Programming and Control Theory. Chapman and
Hall, London, 1978
44. B. D. Craven. Control and Optimization. Chapman and Hall, London, 1995
45. B. D. Craven, J. Gwinner, and V. Jeyakumar. Nonconvex theorems of the
alternative and minimization. Optimization, 18:151â€“163, 1987
46. M. Degiovanni and F. Schuricht. Buckling of nonlinearly elastic rods in the
presence of obstacles treated by nonsmooth critical point theory. Math. Ann.
311, 675â€“728, 1998
47. V. F. Demyanov and A. M. Rubinov. Quasidiï¬€erentiable Calculus. Optimiza-
tion Software, Publications Division, New York, 1986
48. V. F. Demyanov and A. M. Rubinov. Foundations of Nonsmooth Analysis and
Quasidiï¬€erentiable Calculus. Nauka, Moscow, 1990 (in Russian)
49. R. Deville, G. Godefroy, and V. Zizler. A smooth variational principle with
applications to Hamiltonâ€“Jacobi equations in inï¬nite dimensions. J. Funct.
Anal., 111:197â€“212, 1993
50. R. Deville, G. Godefroy, and V. Zizler. Smoothness and Renormings in Banach
Spaces. Pitman Monographs and Surveys in Pure and Applied Mathematics,
No. 64. Wiley, New York, 1993
51. J. Diestel. Geometry of Banach Spaces. Lecture Notes in Mathematics.
Springer, Berlin Heidelberg New York, 1974
52. J. Diestel. Sequences and Series in Banach Spaces. Springer, Berlin Heidelberg
New York, 1983
53. J. DieudonnÃ©. Foundations of Modern Analysis. Academic, New York, 1960
54. A. V. Dmitruk, A. A. Milyutin, and N. P. Osmolovskii. Lyusternikâ€™s theorem
and the theory of extrema. Russ. Math. Surv., 35:11â€“51, 1980
55. S. Dolecki. A general theory of necessary optimality conditions. J. Math. Anal.
Appl., 78:267â€“308, 1980
56. I. Ekeland. On the variational principle. J. Math. Anal. Appl., 47:324â€“353, 1974
57. I. Ekeland. Nonconvex minimization problems. Bull. Am. Math. Soc. (N.S.),
1:443â€“474, 1979
58. I. Ekeland and R. Temam. Convex Analysis and Variational Problems. North-
Holland, Amsterdam, 1976
59. K. -H. Elster, R. Reinhardt, M. SchÃ¤uble, and G. Donath. EinfÃ¼hrung in die
nichtlineare Optimierung. Teubner, Leipzig, 1977
60. J. Elstrodt. MaÃŸ- und Integrationstheorie. Springer, Berlin Heidelberg New
York, 1999
61. E. Ernst, M. ThÃ©ra, and C. Zalinescu. Slice-continuous sets in reï¬‚exive Banach
spaces: convex constrained optimization and strict convex separation. J. Funct.
Anal., 223:179â€“203, 2005

354
References
62. H. Eschrig. The Fundamentals of Density Functional Theory. Edition am
Gutenbergplatz, Leipzig, 2003
63. L. C. Evans and R. F. Gariepy. Measure Theory and Fine Properties of Func-
tions. CRC, Boca Raton, 1992
64. K. Fan. Asymptotic cones and duality of linear relations. In O. Shisha, editor,
Inequalities, volume 2, pages 179â€“186. Academic, London, 1970
65. W. Fenchel. On conjugate convex functions. Can. J. Math., 1:73â€“77, 1949
66. W. Fenchel. Convex Cones, Sets and Functions. Lecture Notes. Princeton
University, Princeton, 1951
67. L. A. Fernandez. On the limits of the Lagrange multiplier rule. SIAM Rev.,
39:292â€“297, 1997
68. O. Ferrero. Theorems of the alternative for set-valued functions in inï¬nite-
dimensional spaces. Optimization, 20:167â€“175, 1989
69. D. G. Figueiredo. Lectures on the Ekeland Variational Principle with Applica-
tions and Detours. Springer (Published for the Tata Institute of Fundamental
Research, Bombay), Berlin Heidelberg New York, 1989
70. F. Giannessi. Theorems of the alternative for multifunctions with applications
to optimization: general results. J. Optim. Theory Appl., 55:233â€“256, 1987
71. M. Giaquinta and S. Hildebrandt. Calculus of Variations I. Springer, Berlin
Heidelberg New York, 1996
72. M. Giaquinta and S. Hildebrandt. Calculus of Variations II. Springer, Berlin
Heidelberg New York, 1996
73. B. M. Glover and B. D. Craven. A Fritz John optimality condition using the
approximate subdiï¬€erential. J. Optim. Theory Appl., 82:253â€“265, 1994
74. B. M. Glover, B. D. Craven, and S. D. FlÃ¥m. A generalized Karushâ€“Kuhnâ€“
Tucker optimality condition without constraint qualiï¬cation using the approx-
imate subdiï¬€erential. Numer. Funct. Anal. Optim., 14:333â€“353, 1993
75. B. M. Glover, V. Jeyakumar, and W. Oettli. A Farkas lemma for diï¬€erence
sublinear systems and quasidiï¬€erentiable programming. Math. Oper. Res., 63:
109â€“125, 1994
76. A.
GÃ¶pfert.
Mathematische
Optimierung
in
allgemeinen
VektorrÃ¤umen.
Teubner, Leipzig, 1973
77. A. GÃ¶pfert, Chr. Tammer, H. Riahi, and C. Zalinescu. Variational Methods in
Partially Ordered Spaces. Springer, Berlin Heidelberg New York, 2003
78. A. GÃ¶pfert, Chr. Tammer, and C. Zalinescu. On the vectorial Ekelandâ€™s vari-
ational principle and minimal points in product spaces. Nonlinear Anal., 39:
909â€“922, 2000
79. L. M. Graves. Some mapping theorems. Duke Math. J., 17:111â€“114, 1950
80. K. Groh. On monotone operators and forms. J. Convex Anal., 12:417â€“429, 2005
81. Ch. GroÃŸmann and H. -G. Roos. Numerical Treatment of Partial Diï¬€erential
Equations. Springer, Berlin Heidelberg, New York, to appear
82. H. Halkin. Implicit functions and optimization problems without continuous
diï¬€erentiability of the data. SIAM J. Control, 12:229â€“236, 1974
83. H. Halkin. Mathematical programming without diï¬€erentiability. In D. L. Russell,
editor, Calculus of Variations and Control Theory, pages 279â€“288. Academic,
New York, 1976
84. J. -B. Hiriart-Urruty. Reï¬nements of necessary optimality conditions in non-
diï¬€erentiable programming I. Appl. Math. Optim., 5:63â€“82, 1979
85. J. -B. Hiriart-Urruty. Tangent cones, generalized gradients and mathematical
programming in Banach spaces. Math. Oper. Res., 4:79â€“97, 1979

References
355
86. J. -B. Hiriart-Urruty. Mean value theorems in nonsmooth analysis. Numer.
Funct. Anal. Optim., 2:1â€“30, 1980
87. J. -B. Hiriart-Urruty. Reï¬nements of necessary optimality conditions in non-
diï¬€erentiable programming II. Math. Progr. Stud., 19:120â€“139, 1982
88. J. -B. Hiriart-Urruty and C. LemarÃ©chal. Convex Analysis and Minimization
Algorithms. I: Fundamentals. Springer, Berlin Heidelberg New York, 1993
89. J. -B. Hiriart-Urruty and C. LemarÃ©chal. Convex Analysis and Minimiza-
tion Algorithms. II: Advanced Theory and Bundle Methods. Springer, Berlin
Heidelberg New York, 1993
90. J. -B. Hiriart-Urruty, M. Moussaoui, A. Seeger, and M. Volle. Subdiï¬€erential
calculus without constraint qualiï¬cation, using approximate subdiï¬€erentials:
a survey. Nonlinear Anal., 24:1727â€“1754, 1995
91. R. B. Holmes. A Course on Optimization and Best Approximation. Springer,
Berlin Heidelberg New York, 1972
92. R. B. Holmes. Geometric Functional Analysis and Its Applications. Springer,
Berlin Heidelberg New York, 1975
93. A. D. Ioï¬€e. Regular points of Lipschitz functions. Trans. Am. Math. Soc.,
251:61â€“69, 1979
94. A. D. Ioï¬€e. Nonsmooth analysis: diï¬€erential calculus of nondiï¬€erentiable map-
pings. Trans. Am. Math. Soc., 266:1â€“56, 1981
95. A. D. Ioï¬€e. Approximate subdiï¬€erentials and applications. I. The ï¬nite dimen-
sional theory. Trans. Am. Math. Soc., 281(1):389â€“416, 1984
96. A. D. Ioï¬€e. Approximate subdiï¬€erentials and applications. II. Mathematika,
33:11â€“128, 1986
97. A. D. Ioï¬€e. Approximate subdiï¬€erentials and applications. III. The metric
theory. Mathematika, 36:1â€“38, 1989
98. A. D. Ioï¬€e. Proximal analysis and approximate subdiï¬€erentials. J. Lond. Math.
Soc., 41:175â€“192, 1990
99. A. D. Ioï¬€e. A Lagrange multiplier rule with small convex-valued subdiï¬€eren-
tials for nonsmooth problems of mathematical programming involving equality
and nonfunctional constraints. Math. Progr. Stud., 58:137â€“145, 1993
100. A. D. Ioï¬€e. Nonsmooth subdiï¬€erentials: their calculus and applications.
In V. Lakshmikantham, editor, Proceedings of the First World Congress of
Nonlinear Analysts, pages 2299â€“2310. De Gruyter, Berlin, 1996
101. A. D. Ioï¬€e and V. Tikhomirov. Theory of Extremal Problems. North-Holland,
New York, 1978 (German ed.: Deutscher Verlag der Wissenschaften, Berlin,
1979; original Russian ed.: Nauka, Moskow, 1974)
102. J. Jahn. Vector Optimization: Theory, Applications and Extensions. Springer,
Berlin Heidelberg New York, 2004
103. G. J. O. Jameson. Topology and Normed Spaces. Chapman and Hall, London,
1974
104. V. Jeyakumar. Convexlike alternative theorems and mathematical program-
ming. Optimization, 16:643â€“652, 1985
105. F. John. Extremum problems with inequalities as side conditions. In K. O.
Friedrichs, O. E. Neugebauer, and J. J. Stoker, editors, Studies and Essays:
Courant Anniversary Volume, pages 187â€“204. Wiley-Interscience, New York,
1948
106. A. Jourani and L. Thibault. The approximate subdiï¬€erential of composite func-
tions. Bull. Aust. Math. Soc., 47:443â€“455, 1993

356
References
107. A. Jourani and L. Thibault. Metric regularity for strongly compactly
Lipschitzian mappings. Nonlinear Anal., 24:229â€“240, 1995
108. M. Kadec. Spaces isomorphic to a locally uniformly convex space. Izv. VysÅ¡.
UÄebn. Zaved. Mat., 6:51â€“57, 1959 (in Russian)
109. W. Karush. Minima of Functions of Several Variables with Inequalities as Side
Conditions. Masterâ€™s Thesis, University of Chicago, Chicago, 1939
110. D. Klatte and B. Kummer. Contingent derivatives of implicit (multi-)functions
and stationary points. Ann. Oper. Res., 101:313â€“331, 2001
111. D. Klatte and B. Kummer. Nonsmooth Equations in Optimization. Regularity,
Calculus, Methods and Applications. Kluwer, Dordrecht, 2002
112. W. Krabs. Optimierung und Approximation. Teubner, Stuttgart, 1975
113. A. Y. Kruger and B. S. Mordukhovich. Extremal points and Euler equations
in nonsmooth optimization. Dokl. Akad. Nauk BSSR, 24:684â€“687, 1980 (in
Russian)
114. H. W. Kuhn and A. W. Tucker. Nonlinear programming. In J. Neyman, editor,
Proceedings of the Second Berkeley Symposium on Mathematical Statistics and
Probability, pages 481â€“492. University of California Press, Berkeley, 1951
115. G. KÃ¶the. Topologische lineare RÃ¤ume I. Springer, Berlin Heidelberg New York,
1960
116. M. Landsberg and W. Schirotzek. Mazurâ€“Orlicz type theorems with some
applications. Math. Nachr., 79:331â€“341, 1977
117. J. B. Lasserre. A Farkas lemma without a standard closure condition. SIAM
J. Control Optim., 35:265â€“272, 1997
118. P. -J. Laurent. Approximation et Optimisation. Hermann, Paris, 1972
119. G. Lebourg. Valeur moyenne pour gradient gÃ©nÃ©ralisÃ©. C. R. Acad. Sci. Paris,
281:795â€“797, 1975
120. Yu. S. Ledyaev and Q. J. Zhu. Implicit multifunction theorems. Set-Valued
Anal., 7:209â€“238, 1999
121. Yu. S. Ledyaev and Q. J. Zhu. Implicit multifunction theorems. Preprint
(revised
version),
http://homepages.wmich.edu/~zhu/papers/implicit.
html, 2006
122. U. Ledzewicz and S. Walczak. On the Lyusternik theorem for nonsmooth
operators. Nonlinear Anal., 22:121â€“128, 1994
123. P. D. Loewen. Optimal Control via Nonsmooth Analysis. American Mathemat-
ical Society, Providence, 1993
124. P. D. Loewen. A mean value theorem for FrÃ©chet subgradients. Nonlinear
Anal., 23:1365â€“1381, 1994
125. P. D. Loewen and X. Wang. A generalized variational principle. Can. J. Math.,
53(6):1174â€“1193, 2001
126. B. Luderer, L. Minchenko, and T. Satsura. Multivalued Analysis and Nonlinear
Programming Problems with Perturbations. Kluwer, Dordrecht, 2002
127. D. Luenberger. Optimization by Vector Space Methods. Wiley, New York, 1969
128. L. A. Lyusternik. On constrained extrema of functionals. Mat. Sb., 41:390â€“401,
1934 (in Russian)
129. P. Michel and J. -P. Penot. Calcul sous-diï¬€Ã©rentiel pour les fonctions lipschitzi-
ennes et non lipschitziennes. C. R. Acad. Sci. Paris, 298:269â€“272, 1984
130. P. Michel and J. -P. Penot. A generalized derivative for calm and stable func-
tions. Diï¬€. Int. Eqs., 5:433â€“454, 1992
131. H. Minkowski. Theorie der konvexen KÃ¶rper, insbesondere BegrÃ¼ndung ihres
Oberï¬‚Ã¤chenbegriï¬€s. Teubner, Leipzig, 1911

References
357
132. B. S. Mordukhovich. Maximum principle in the problem of time optimal control
with nonsmooth constraints. J. Appl. Math. Mech., 40:960â€“969, 1976
133. B. S. Mordukhovich. Metric approximations and necessary optimality condi-
tions for general classes of nonsmooth extremal problems. Sov. Math. Dokl.,
22:526â€“530, 1980
134. B. S. Mordukhovich. Approximation Methods in Problems of Optimization and
Control. Nauka, Moscow, 1988 (in Russian)
135. B. S. Mordukhovich. Sensitivity analysis in nonsmooth optimization. In
D. A. Field and V. Komkov, editors, Theoretical Aspects of Industrial Design,
volume 58 of Proceedings in Applied Mathematics, pages 32â€“46. SIAM,
Philadelphia, 1992
136. B. S. Mordukhovich. Variational Analysis and Generalized Diï¬€erentiation I:
Basic Theory. Springer, Berlin Heidelberg New York, 2006
137. B. S. Mordukhovich. Variational Analysis and Generalized Diï¬€erentiation II:
Applications. Springer, Berlin Heidelberg New York, 2006
138. B. S. Mordukhovich and J. V. Outrata. On second-order subdiï¬€erentials and
their applications. SIAM J. Optim., 12:139â€“169, 2001
139. B. S. Mordukhovich and Y. Shao. Diï¬€erential characterizations of cover-
ing, metric regularity, and Lipschitzian properties of multifunctions between
Banach spaces. Nonlinear Anal., 25:1401â€“1424, 1995
140. B. S. Mordukhovich and Y. Shao. Extremal characterizations of Asplund
spaces. Proc. Am. Math. Soc., 124:197â€“205, 1996
141. B. S. Mordukhovich and Y. Shao. Nonconvex coderivative calculus for inï¬nite-
dimensional multifunctions. Set-Valued Anal., 4:205â€“236, 1996
142. B. S. Mordukhovich and Y. Shao. Nonsmooth sequential analysis in Asplund
spaces. Trans. Am. Math. Soc., 348:1235â€“1280, 1996
143. B. S. Mordukhovich and Y. Shao. Mixed coderivatives of set-valued mappings
in variational analysis. J. Appl. Anal., 4:269â€“294, 1998
144. B. S. Mordukhovich, J. S. Treiman, and Q. J. Zhu. An extended extremal
principle with applications to multiobjective optimization. SIAM J. Optim.,
14:359â€“379, 2003
145. B. S. Mordukhovich and B. Wang. Extensions of generalized diï¬€erential calcu-
lus in Asplund spaces. J. Math. Anal. Appl., 272:164â€“186, 2002
146. B. S. Mordukhovich and B. Wang. Necessary suboptimality and optimality
conditions via variational principles. SIAM J. Control Optim., 41:623â€“640, 2002
147. J. -J. Moreau. Functions convexes duales et points proximaux dans un espace
hilbertian. C. R. Acad. Sci. Paris, 255:2897â€“2899, 1962
148. J. -J. Moreau. PropriÃ©tÃ© des applications â€˜proxâ€™. C. R. Acad. Sci. Paris,
256:1069â€“1071, 1963
149. M. M. MÃ¤kelÃ¤ and P. NeittaanmÃ¤ki. Nonsmooth Optimization. World Scientiï¬c,
Singapore, 1992
150. L. W. Neustadt. Optimization: A Theory of Necessary Conditions. Princeton
University Press, Princeton, 1976
151. H. V. Ngai, D. T. Luc, and M. ThÃ©ra. Extensions of FrÃ©chet Ïµ-subdiï¬€erential
calculus and applications. J. Math. Anal. Appl., 268:266â€“290, 2002
152. N. V. Ngai and M. ThÃ©ra. Metric inequality, subdiï¬€erential calculus and
applications. Set-Valued Anal., 9:187â€“216, 2001
153. N. V. Ngai and M. ThÃ©ra. A fuzzy necessary optimality condition for non-
Lipschitz optimization in Asplund spaces. SIAM J. Optim., 12:656â€“668, 2002

358
References
154. N. V. Ngai and M. ThÃ©ra. Error bounds and implicit multifunction theorem
in smooth Banach spaces and applications to optimization. Set-Valued Anal.,
12:195â€“223, 2004
155. D. Pallaschke. Ekelandâ€™s variational principle, convex functions and Asplund
spaces. In W. Krabs and J. Zowe, editors, Modern Methods of Optimization,
pages 274â€“312. Springer, Berlin Heidelberg New York, 1992
156. D. Pallaschke and S. Rolewicz. Foundations of Mathematical Optimization:
Convex Analysis Without Linearity. Kluwer, Dordrecht, 1997
157. P.
D.
Panagiotopoulos.
Hemivariational
Inequalities.
Springer,
Berlin
Heidelberg New York, 1993
158. N. S. Papageorgiou and L. Gasinski. Nonsmooth Critical Point Theory and
Nonlinear Boundary Value Problems. Chapman and Hall, Boca Raton, 2004
159. J. -P. Penot. Calcul sous-diï¬€erentiel et optimisation. J. Funct. Anal., 27:
248â€“276, 1978
160. J. -P. Penot. On regularity conditions in mathematical programming. Math.
Progr. Stud., 19:167â€“199, 1982
161. J. -P. Penot. Open mapping theorems and linearization stability. Numer. Funct.
Anal. Optim., 8:21â€“35, 1985
162. J. -P. Penot. The drop theorem, the petal theorem and Ekelandâ€™s variational
principle. Nonlinear Anal., 10:813â€“822, 1986
163. J. -P. Penot. On the mean value theorem. Optimization, 19:147â€“156, 1988
164. J. -P. Penot. Metric regularity, openness and Lipschitzian behavior of multi-
functions. Nonlinear Anal., 13:629â€“643, 1989
165. R. R. Phelps. Convex Functions, Monotone Operators and Diï¬€erentiability,
volume 1364 of Lecture Notes in Mathematics. Springer, Berlin Heidelberg New
York, 1993
166. D. Preiss. FrÃ©chet derivatives of Lipschitzian functions. J. Funct. Anal., 91:312â€“
345, 1990
167. D. Preiss and L. ZajÃ­Äek. FrÃ©chet diï¬€erentiation of convex functions in a Banach
space with a separable dual. Proc. Am. Math. Soc., 91(2):202â€“204, 1984
168. B. N. PÅ¡eniÄnyi. Convex Analysis and Extremal Problems. Nauka, Moscow,
1969 (in Russian)
169. B. N. PÅ¡eniÄnyj. Notwendige OptimalitÃ¤tsbedingungen. Teubner, Leipzig, 1972
170. B. N. Pshenichnyi. Necessary Conditions for an Extremum. Dekker, New
York, 1971 (German ed.: Teubner, Leipzig, 1972; original Russian ed.: Nauka,
Moscow, 1969)
171. H. PÃ¼hl. Convexity and openness with linear rate. J. Math. Anal. Appl.,
227:382â€“395, 1998
172. H. PÃ¼hl. Nichtdiï¬€erenzierbare Extremalprobleme in BanachrÃ¤umen: Regular-
itÃ¤tsbedingungen sowie die Approximation von Niveaumengen. Doctoral Thesis,
Technische UniversitÃ¤t Dresden, Dresden, 1999
173. H. PÃ¼hl and W. Schirotzek. Linear semi-openness and the Lyusternik theorem.
Eur. J. Oper. Res., 157:16â€“27, 2004
174. A. Roberts and D. Varberg. Convex Functions. Academic, New York, 1973
175. S. M. Robinson. Regularity and stability for convex multivalued functions.
Math. Oper. Res., 1:130â€“143, 1976
176. S. M. Robinson. Stability theory for systems of inequalities. Part II. Diï¬€eren-
tiable nonlinear systems. SIAM J. Numer. Anal., 13:497â€“513, 1976
177. R. T. Rockafellar. Convex Functions and Dual Extremum Problems. Ph.D.
Thesis, Harvard University, Cambridge, 1963

References
359
178. R. T. Rockafellar. Level sets and continuity of conjugate convex functions.
Trans. Am. Math. Soc., 123:46â€“63, 1966
179. R. T. Rockafellar. Duality and stability in extremum problems involving convex
functions. Pac. J. Math., 21:167â€“187, 1967
180. R. T. Rockafellar. Convex Analysis. Princeton University Press, Princeton,
1970
181. R. T. Rockafellar. On the maximal monotonicity of subdiï¬€erential mappings.
Pac. J. Math., 33:209â€“216, 1970
182. R. T. Rockafellar. On the maximality of sums of nonlinear monotone operators.
Trans. Am. Math. Soc., 149:75â€“88, 1970
183. R. T. Rockafellar. Directionally Lipschitzian functions and subdiï¬€erential cal-
culus. Proc. Lond. Math. Soc., 39:331â€“355, 1979
184. R. T. Rockafellar. Generalized directional derivatives and subgradients of non-
convex functions. Can. J. Math., 32:157â€“180, 1980
185. R. T. Rockafellar. Proximal subgradients, marginal values and augmented
Lagrangians in nonconvex optimization. Math. Oper. Res., 6:424â€“436, 1981
186. R. T. Rockafellar. The Theory of Subgradients and Its Applications to Problems
of Optimization: Convex and Nonconvex Functions. Heldermann, Berlin, 1981
187. R. T. Rockafellar. Extensions of subgradient calculus with applications to
optimization. Nonlinear Anal., 9:665â€“698, 1985
188. R. T. Rockafellar. Second-order optimality conditions in nonlinear program-
ming obtained by way of epi-derivatives. Math. Oper. Res., 14:462â€“484, 1989
189. R. T. Rockafellar and R. J. -B. Wets. Variational Analysis. Springer, Berlin
Heidelberg New York, 1998
190. H. -P. Scheï¬„er. BeitrÃ¤ge zur Analysis von nichtglatten Optimierungsproblemen.
Doctoral Thesis, Technische UniversitÃ¤t Dresden, Dresden, 1987
191. H. -P. Scheï¬„er. Mean value properties of nondiï¬€erentiable functions and their
application in nonsmooth analysis. Optimization, 20:743â€“759, 1989
192. H. -P. Scheï¬„er and W. Schirotzek. Necessary optimality conditions for non-
smooth problems with operator constraints. Z. Anal. Anwend., 7:419â€“430, 1988
193. W. Schirotzek. On Farkas type theorems. Commentat. Math. Univ. Carol.,
22:1â€“14, 1981
194. W. Schirotzek. On a theorem of Ky Fan and its application to nondiï¬€erentiable
optimization. Optimization, 16:353â€“366, 1985
195. W. Schirotzek. Nonasymptotic necessary conditions for nonsmooth inï¬nite
optimization problems. J. Math. Anal. Appl., 118:535â€“546, 1986
196. W. Schirotzek. Diï¬€erenzierbare Extremalprobleme. Teubner, Leipzig, 1989
197. L. Schwartz. Analyse II. Calcul Diï¬€Ã©rentiel et Ã‰quations Diï¬€Ã©rentielles.
Hermann, Paris, 1997
198. S. Simons. The least slope of a convex function and the maximal monotonicity
of its subdiï¬€erential. J. Optim. Theory Appl., 71:127â€“136, 1991
199. I. Singer. Generalizations of methods of best approximation to convex opti-
mization in locally convex spaces I: extension of continuous linear functionals
and characterizations of solutions of continuous convex programs. Rev. Roum.
Math. Pures Appl., 19:65â€“77, 1974
200. C. Stegall. The Radonâ€“NikodÃ½m property in conjugate Banach spaces. Trans.
Am. Math. Soc., 264:507â€“519, 1984
201. J. Stoer and C. Witzgall. Convexity and Optimization in Finite Dimensions.
Springer, Berlin Heidelberg New York, 1970

360
References
202. M. Studniarski. Mean value theorems and suï¬ƒcient optimality conditions for
nonsmooth functions. J. Math. Anal. Appl., 111:313â€“326, 1985
203. M. Studniarski. Mean value theorems for functions possessing ï¬rst order convex
approximations. Applications in optimization theory. Z. Anal. Anwend., 4:125â€“
132, 1985
204. A. I. Subbotin. Generalized Solutions of First-Order PDEs. The Dynamical
Optimization Perspective. BirkhÃ¤user, Basel, 1994
205. K. Sundaresan and S. Swaminathan. Geometry and Nonlinear Analysis in
Banach Spaces. Lecture Notes in Mathematics. Springer, Berlin Heidelberg New
York, 1985
206. J. S. Treiman. Finite dimensional optimality conditions: B-gradients. J. Optim.
Theory Appl., 62:139â€“150, 1989
207. J. S. Treiman. Optimal control with small generalized gradients. SIAM J. Con-
trol Optim., 28:720â€“732, 1990
208. S. Troyanski. On locally uniformly convex and diï¬€erentiable norms in certain
non-separable spaces. Stud. Math., 37:173â€“180, 1971
209. F. TrÃ¶ltzsch. Optimality Conditions for Parabolic Control Problems and
Applications. Teubner, Leipzig, 1984
210. H. Tuy. Convex Inequalities and the Hahnâ€“Banach Theorem. Number 97 in
Dissertationes Mathematicae (Rozprawy Matematyczne), Warszawa, 1972
211. C. Ursescu. Multifunctions with convex closed graph. Czech. Math. J., 25:438â€“
441, 1975
212. W. Walter. Analysis 1. Springer, Berlin Heidelberg New York, 2004
213. J. Warga. Derivate containers, inverse functions, and controllability. In
D. L. Russell, editor, Calculus of Variations and Control Theory, pages 13â€“
46. Academic, New York, 1976
214. J. Warga. Fat homeomorphisms and unbounded derivate containers. J. Math.
Anal. Appl., 81:545â€“560, 1981
215. D. Werner. Funktionalanalysis. Springer, Berlin Heidelberg New York, 1997
216. S. Yamamuro. Diï¬€erential Calculus in Topological Linear Spaces, volume 374
of Lecture Notes in Mathematics. Springer, Berlin Heidelberg New York, 1974
217. J. J. Ye. Multiplier rules under mixed assumptions of diï¬€erentiability and
Lipschitz continuity. SIAM J. Control Optim., 39:1441â€“1460, 1999
218. K. Yosida. Functional Analysis. Springer, Berlin Heidelberg New York, 1965
219. D. Yost. Asplund spaces for beginners. Acta Univ. Carol. Math. Phys., 34:159â€“
177, 1993
220. D. Zagrodny. Approximate mean value theorem for upper subderivatives. Non-
linear Anal., 12:1413â€“1428, 1988
221. E. Zeidler. Nonlinear Functional Analysis and Its Applications III: Variational
Methods and Optimization. Springer, Berlin Heidelberg New York, 1984
222. E. Zeidler. Nonlinear Functional Analysis and Its Applications I. Fixed-Point
Theory. Springer, Berlin Heidelberg New York, 1986
223. E. Zeidler. Nonlinear Functional Analysis and Its Applications II A: Linear
Monotone Operators. Springer, Berlin Heidelberg New York, 1990
224. E. Zeidler. Nonlinear Functional Analysis and Its Applications II B: Nonlinear
Monotone Operators. Springer, Berlin Heidelberg New York, 1990
225. Q. J. Zhu. Clarkeâ€“Ledyaev mean value inequality in smooth Banach spaces.
Nonlinear Anal., 32:315â€“324, 1998
226. Q. J. Zhu. The equivalence of several basic theorems for subdiï¬€erentials. Set-
Valued Anal., 6:171â€“185, 1998

References
361
227. Q. J. Zhu. Hamiltonian necessary conditions for a multiobjective optimal con-
trol problem with endpoint constraints. SIAM J. Control Optim., 39:97â€“112,
2000
228. W. P. Ziemer. Weakly Diï¬€erentiable Functions. Springer, Berlin Heidelberg
New York, 1989
229. J. Zowe and S. Kurcyusz. Regularity and stability for the mathematical pro-
gramming problem in Banach spaces. Appl. Math. Optim., 5:49â€“62, 1979

Notation
N, R, R+, R, 5
E[Ï„], 20
Eâˆ—, 6
Eâˆ—
Î², 45
L(E, F), 41
LÎ²(E, F), 45
Ïƒ(E, F), 19
xâˆ—
k
wâˆ—
âˆ’âˆ’â†’xâˆ—, 21
BE(Â¯x, Ïµ), B(Â¯x, Ïµ), 6
BE, B, 6
ËšBE(Â¯x, Ïµ), ËšB(Â¯x, Ïµ), 6
ËšBE, ËšB, 6
K(xâˆ—, Î±), 70
S(x), 78
Î±A + Î²B, 5
A + y, 5
R+A, 5
cr A, 6
int A, 5
cl A, 5
bd A, 5
co A, 24
cc A, 35
clâˆ—A, 20
coâˆ—A, 20
Aâ—¦, 35
Aâ—¦â—¦, 35
Ap, 34
ep A, 23
C(T), 80
C1(D, F), 46
C2(D, F), 48
Ck(G), 105
Câˆ
c (G), 105
Lp(G), 105
W1,p(G), 105
W1,p
0 (G), 105
ACâˆ[a, b], 50
Lp[a, b], 50
M(T), 80
L1, 269
Bn, 269
u
p, 105
u
1,p, 106
u
1,p,0, 106

364
Notation
dom f, 8
epi f, 8
infE f, 156
f â€²(Â¯x), 42
âˆ‡f(Â¯x), 42
f 1(Â¯x, Â¯y), 51
D1f(Â¯x, Â¯y), 51
âˆ†f(Â¯x, y), 39
fG(Â¯x, y), 39
f s
G(Â¯x, y), 39
f G(Â¯x, y), 40
f G(Â¯x, y), 40
fH(Â¯x, y), 39
f s
H(Â¯x, y), 39
f H(Â¯x, y), 40
f H(Â¯x, y), 40
f â—¦(Â¯x, y), 139
f â™¦(Â¯x, y), 139
âˆ‚f(Â¯x), 59
âˆ‚âˆ—f(Â¯x, y), 138
âˆ‚â—¦f(Â¯x), 142
âˆ‚â™¦f(Â¯x), 142
âˆ‚F f(Â¯x), 167
âˆ‚V f(Â¯x), 167
âˆ‚P f(Â¯x), 167
âˆ‚F f(Â¯x), 181
âˆ‚F,1f(Â¯x, Â¯y), 330
âˆ‚Mf(Â¯x), 288
âˆ‚âˆ
Mf(Â¯x), 288
*âˆ‚Ïµf(Â¯x), 289
A(f), 27
f Î“ (x), 27
f âˆ—(xâˆ—), 29
f âˆ—âˆ—(x), 31
f0 âŠ•f1(x), 32
Tr(A, Â¯x), 131, 231
T(A, Â¯x), 132, 231
TC(A, Â¯x), 231
Ir(A, Â¯x), 231
I(A, Â¯x), 231
H(A, Â¯x), 231
NC(A, Â¯x), 238
NF (A, Â¯x), 238
NV (A, Â¯x), 238
NP (A, Â¯x), 238
*
NÏµ(A, x), 285
NM(A, x), 285
L<
Î³, Â¯x

, 248
Lâ‰¤
Î³, Â¯x

, 248
I(Â¯x), 248
T +(Â¯x), 80
T âˆ’(Â¯x), 80
T(Â¯x), 80
L(x; Âµ1, . . . , Âµm), 93
*L(x; Î», Âµ1, . . . , Âµm), 93
L(x, q), 111
UCr(f, Â¯x), 136
UC(f, Â¯x), 136
dA(x), d(A, x), 10
pM(x), 10
Î´M(x), 9
ÏƒA(x), 9
Ï‰z(x), Ï‰(x), 78
projA(z), 96
Î¦ : E â‡’F, 63
Î¦âˆ’1, 195
Dom Î¦, 63
ker Î¦, 195
range Î¦, 195
graph Î¦, 63
ope(Î¦)(Â¯x, Â¯y), 209
DÎ¦(Â¯x, Â¯y), 252
Dâˆ—
ÏµÎ¦(Â¯x, Â¯y), 294
Dâˆ—
F Î¦(Â¯x, Â¯y), 294
Dâˆ—
MÎ¦(Â¯x, Â¯y), 294
âŸ¨xâˆ—, xâŸ©, 6
(x y), 6
[xâˆ—= Î±], 15
[Â¯x, z], 45

Notation
365
x â‰¤P y, 13
x â†’A Â¯x, 231
x â†’f Â¯x, 259
x â†’Î¦ Â¯x, 226
Lim sup
Î±âˆˆA
SÎ±, 225
Lim inf
Î±âˆˆA
SÎ±, 225
Lim sup
xâ†’Â¯x
Î¦(x), 225
Lim inf
xâ†’Â¯x
Î¦(x), 225
sLim sup
xâ†’Â¯x
Î¦(x), 226

Index
GÎ´ set, 69
P-convex mapping, 197
Î²-derivative, 41
Î²-diï¬€erentiable mapping, 41
Î²-smooth mapping, 46
Ïµ-coderivative, 294
C1-mapping, 46
C2-mapping, 48
absorbing set, 6
aï¬ƒne functional, 9
almost transitive preference
relation, 340
approximate extremal principle,
303
approximate subdiï¬€erential, 349
approximation
radial upper convex, 135
upper convex, 135
Asplund space, 70
Aubin property, 211
basic subdiï¬€erential, 288
basis, 103
biconjugate functional, 31
bilinear functional, 49
bipolar cone, 35
bornology, 41
FrÃ©chet (F-bornology), 41
GÃ¢teaux (G-bornology), 41
Hadamard (H-bornology), 41
boundary value problem
classical, 106
genralized, 106
bounded process, 209
bounded-valued
multifunction, 195
bump functional, 162
Clarke directional derivative, 139
Clarke generalized gradient, 142
Clarke normal cone, 238
Clarke subdiï¬€erential, 142
Clarke tangent cone, 231
classical boundary value problem,
106, 118
closed multifunction, 195
closed-valued multifunction, 195
coderivative
Ïµ-, 294
FrÃ©chet (F-), 294
Mordukhovich (M-), 294

368
Index
coercive functional, 100
coercive multifunction, 223
compactly epi-Lipschitzian set,
309
compatible topology, 20
condition
core, 208
generalized John, 274
generalized
Karushâ€“Kuhnâ€“Tucker, 274
John, 94
Karushâ€“Kuhnâ€“Tucker, 94
Kolmogorov, 98
Mangasarianâ€“Fromowitz, 275
regularity, 94, 250
Robinson, 208
Slater, 93
Zoweâ€“Kurcyusz, 208
conditions
local optimality, 94
cone, 13
bipolar, 35
Bishopâ€“Phelps, 70
Clarke normal, 238
Clarke tangent, 231
contingent, 132, 231
convex, 13
FrÃ©chet normal, 238
linearizing, 248
normal, 135, 237
of feasible directions, 231
of hypertangents, 231
of inner directions, 231
of radial directions, 131, 231
of radial inner directions, 231
polar, 35
proximal normal, 238
tangent, 231
viscosity normal, 238
conjugate functional, 29
constant
of metric regularity, 200
constraint
functional, 92
qualiï¬cation, 250
residual, 92
constraint qualiï¬cation, 94
contingent cone, 132, 231
contingent derivative, 252
continuously diï¬€erentiable
mapping, 46
convex cone, 13
convex functional, 8
convex multifunction, 195
convex set, 5
core, 6
core condition, 208
derivative
Î²-, 41
Clarke directional, 139
contingent, 252
directional G-, 39
directional H-, 39
F-, 42
G-, 42
H-, 42
lower directional G-, 40
lower directional H-, 40
Michelâ€“Penot directional, 139
partial, 51
second order, 48
strict Î²-, 42
strict F-, 42
strict G-, 42
strict H-, 42
upper directional G-, 40
upper directional H-, 40
Dini derivates, 41
distance functional, 10
dual pair
of locally convex spaces, 20
of vector spaces, 19
dual problem, 112
duality gap, 112
duality mapping, 80
eï¬€ective domain, 8
epi-limit
lower, 226
upper, 226

Index
369
epi-Lipschitzian set, 236
epigraph, 8
equation
generalized, 200
Eulerâ€“Lagrange equation, 268
exact extremal principle, 302
extended extremal system, 338
extremal principle
approximate, 303
exact, 302
extremal set, 23
extremal system, 301
extended, 338
extreme point, 23
F-derivative (=FrÃ©chet
derivative), 42
F-diï¬€erentiable mapping, 42
F-subderivative, 167
F-subdiï¬€erentiable functional, 167
Fenchel conjugate, 29
ï¬xed end point problem, 267
FrÃ©chet Ïµ-subdiï¬€erential, 289
FrÃ©chet (F-)coderivative, 294
FrÃ©chet (F-)subdiï¬€erential, 167
FrÃ©chet (F-)superdiï¬€erential, 181
FrÃ©chet normal, 238
FrÃ©chet normal cone, 238
FrÃ©chet smooth Banach space, 88
functional
aï¬ƒne, 9
biconjugate, 31
bilinear, 19
bounded bilinear, 49
bump, 162
coercive, 100
conjugate, 29
constraint, 92
convex, 8
distance, 10
F-subdiï¬€erentiable, 167
indicator, 9
Lagrange, 93
locally convex, 136
locally L-continuous, 11
lower regular, 291
lower semicontinuous (l.s.c.), 22
lower semicontinuous closure of
a, 25
marginal, 123
Minkowski, 10
proper, 8
quadratic, 9, 49
quasidiï¬€erentiable, 136
regular, 146
regularly locally convex, 136
sequentially lower
semicontinuous, 22
sequentially normally
epi-compact (SNEC), 317
stricly convex, 8
strongly positive bilinear, 67
sublinear, 9
support, 9
symmetric bilinear, 49
upper semicontinuous (u.s.c.),
22
value, 123
viscosity subdiï¬€erentiable, 167
G-derivative (=GÃ¢teaux
derivative), 42
directional, 39
lower directional, 40
strict directional, 39
upper directional, 40
G-diï¬€erentiable mapping, 42
Gamma regularization, 27
gauge, 10
general dualization principle, 114
generalized boundary value
problem, 106
generalized derivative, 105
generalized equation, 200
generalized gradient
Clarke, 142
generalized John condition, 274
generalized Karushâ€“Kuhnâ€“Tucker
condition, 274
generalized solution, 106

370
Index
generating set, 217
global minimizer, 91
global solution, 91
gradient, 42
H-derivative (=Hadamard
derivative), 42
directional, 39
lower directional, 40
strict directional, 39
upper directional, 40
H-diï¬€erentiable mapping, 42
Hamiltonâ€“Jacobi equation, 181
hemicontinuous mapping, 220
hyperplane, 15
supporting, 17
indicator functional, 9
inï¬mal convolution, 32
inner semicompact, 299
John conditions, 94
Kadec norm, 86
Karushâ€“Kuhnâ€“Tucker conditions,
94
Kolmogorov condition, 98
Lagrange functional, 93
Lagrange multiplier, 274
limiting qualiï¬cation condition,
320
linear rate
of openness, 201
linearizing cone, 248
linearly semiopen mapping, 213
local extremal point, 301
local minimizer, 91
local optimality conditions, 94
local solution, 91
local solution of a multiobjective
optimization problem, 341
locally compact mapping, 180
locally convex functional, 136
locally convex space, 5
locally convex subdiï¬€erential, 138
locally L-continuous, 11
locally satiated preference
relation, 340
locally uniformly convex space, 85
lower epi-limit, 226
lower regular functional, 291
lower semicontinuous (l.s.c.), 22
lower semicontinuous
multifunction, 64
M-subdiï¬€erential, 288
mapping
P-convex, 197
Î²-diï¬€erentiable, 41
Î²-smooth, 46
C1, 46
C2, 48
continuously diï¬€erentiable, 46
duality, 80
F-diï¬€erentiable, 42
G-diï¬€erentiable, 42
H-diï¬€erentiable, 42
hemicontinuous, 220
linearly semiopen, 213
locally compact, 180
metrically semiregular, 213
open, 196
radially continuous, 45
scalarization of a, 180
semi-pseudo-Lipschitz, 213
strictly Î²-diï¬€erentiable, 42
strictly F-diï¬€erentiable, 42
strictly G-diï¬€erentiable, 42
strictly H-diï¬€erentiable, 42
twice continuously
diï¬€erentiable, 48
marginal functional, 123
method of penalty functions, 131
method of tangent directions, 131
metric regularity
constant of, 200
metrically regular multifunction,
200
metrically semiregular mapping,
213

Index
371
Michelâ€“Penot directional
derivative, 139
Michelâ€“Penot subdiï¬€erential, 142
minimizer
global, 91
local, 91
strict, 156
strong, 156
minimizing sequence, 99
Minkowski functional, 10
mixed qualiï¬cation condition, 313
Mordukhovich (M-)coderivative,
294
Mordukhovich (M-)normal cone,
285
Mordukhovich
(M-)subdiï¬€erential, 288
multifunction, 63
Aubin property of a, 211
bounded-valued, 195
closed, 195
closed-valued, 195
coercive, 223
convex, 195
domain of a, 63
graph of a, 63
inner semicompact, 299
inverse of a, 195
locally bounded, 64
lower semicontinuous, 64
maximal monotone, 219
metrically regular, 200
monotone, 64
open at a linear rate, 201
openness bound of a, 209
pseudo-Lipschitz, 211
range of a, 195
strictly monotone, 64
strongly monotone, 64
uniformly monotone, 64
upper semicontinuous, 64
weakly metrically regular, 211
multiplier
Lagrange, 274
natural boundary conditions, 271
normal
FrÃ©chet, 238
proximal, 238
viscosity, 238
normal cone, 135, 237
FrÃ©chet, 238
Mordukhovich, 285
proximal, 238
viscosity, 238
normally regular set, 287
normed vector space
locally uniformly convex, 85
separable, 70
smooth, 84
uniformly convex, 85
open mapping, 196
openness
linear rate of, 201
openness bound
of a multifunction, 209
operator
strongly elliptic, 118
PainlevÃ©â€“Kuratowski lower limit,
225
PainlevÃ©â€“Kuratowski upper limit,
225
sequential, 226
parameter
metric semiregularity, 213
semi-pseudo-Lipschitz, 213
semiopenness, 213
partially sequentially normally
compact (PSNC), 312
peak point, 82
peaking function, 82
point
local extremal, 301
polar cone, 35
preference relation, 340
almost transitive, 340
locally satiated, 340

372
Index
preorder, 14
primal problem, 112
problem
classical boundary value, 118
dual, 112
ï¬xed end point, 267
primal, 112
Ritz minimum, 103
process, 209
bounded, 209
convex, 209
norm of a, 209
projection, 96
projector, 96
proper functional, 8
proximal normal, 238
proximal normal cone, 238
proximal subdiï¬€erential, 167
proximal subgradient, 167
pseudo-Lipschitz multifunction,
211
quadratic functional, 9
quasidiï¬€erentiable functional, 136
radial upper convex
approximation, 135
radially continuous mapping, 45
regular functional, 146
regularity condition, 94, 250
Mangasarianâ€“Fromowitz, 275
Slater, 93
regularly locally convex
functional, 136
residual constraint, 92
Ritz
equations, 103
method, 103
minimum problem, 103
Robinson condition, 208
saddle point, 93
scalarization, 180
selection, 64
semi-pseudo-Lipschitz mapping,
213
semiopenness parameter, 213
separable normed vector space, 70
separated sets, 16
sequence
minimizing, 99
weakâˆ—convergent, 21
weakly convergent, 20
sequentially lower semicontinuous,
22
sequentially normally compact
(SNC), 308
sequentially normally epi-compact
(SNEC), 317
set
absorbing, 6
bounded in E, 217
circled, 5
compactly epi-Lipschitzian, 309
convex, 5
cs-closed, 6
epi-Lipschitzian, 236
epi-Lipschitzian at Â¯x, 236
extremal, 23
generating, 217
normally regular, 287
partially sequentially normally
compact (PSNC), 312
sequentially normally compact,
308
SNC see sequentially normally
compact, 308
strongly partially sequentially
normally compact (strongly
PSNC), 312
tangentially regular, 250
weakly sequentially closed, 21
set of Ïµ-normals, 285
set-valued mapping, 63
sets
separated, 16
strongly separated, 16
singular Mordukhovich (M-)
subdiï¬€erential, 288
Slater condition, 93
smooth space, 84

Index
373
solution
generalized, 106
global, 91
local, 91
strict Î²-derivative, 42
strict F-derivative, 42
strict G-derivative, 42
strict H-derivative, 42
strict minimizer, 156
strictly Î²-diï¬€erentiable mapping,
42
strictly convex functional, 8
strictly F-diï¬€erentiable mapping,
42
strictly G-diï¬€erentiable mapping,
42
strictly H-diï¬€erentiable mapping,
42
strong minimizer, 156
strongly elliptic, 118
strongly partially sequentially
normally compact (strongly
PSNC), 312
strongly separated sets, 16
subdiï¬€erential, 59
approximate, 349
basic, 288
Clarke, 142
FrÃ©chet Ïµ-, 289
FrÃ©chet (F-), 167
locally convex, 138
Michelâ€“Penot, 142
Mordukhovich (M-), 288
proximal, 167
singular Mordukhovich (M-),
288
viscosity, 167
subdiï¬€erential mapping, 63
subgradient, 59
proximal, 167
sublinear functional, 9
superdiï¬€erential
FrÃ©chet (F-), 181
support functional, 9
support point, 17
tangent cone, 231
tangentially regular set, 250
topological vector space, 5
topology
compatible, 20
weak, 19
weak star, 20
weakâˆ—, 20
Treï¬€tz method, 121
uniformly convex space, 85
upper convex approximation, 135
upper epi-limit, 226
upper semicontinuous functional,
22
upper semicontinuous
multifunction, 64
value functional, 123
variational equation, 92
variational inequality, 92
variational problem, 106
vector space, 5
locally convex, 5
topological, 5
viscosity normal, 238
viscosity normal cone, 238
viscosity solution, 181
viscosity subderivative, 167
viscosity subdiï¬€erentiable, 167
viscosity subdiï¬€erential, 167
viscosity subsolution, 181
viscosity supersolution, 181
weak star topology, 20
weak topology, 19
weakâˆ—topology, 20
weakly metrically regular
multifunction, 211
Young inequality, 29
Zoweâ€“Kurcyusz condition, 208

Universitext
Aguilar, M.; Gitler, S.; Prieto, C.: Algebraic
Topology from a Homotopical Viewpoint
Aksoy, A.; Khamsi, M. A.: Methods in Fixed
Point Theory
Alevras, D.; Padberg M. W.: Linear Opti-
mization and Extensions
Andersson, M.: Topics in Complex Analysis
Aoki, M.: State Space Modeling of Time
Series
Arnold, V. I.: Lectures on Partial Differen-
tial Equations
Arnold, V. I.; Cooke, R.: Ordinary Differen-
tial Equations
Audin, M.: Geometry
Aupetit, B.: A Primer on Spectral Theory
Bachem, A.; Kern, W.: Linear Programming
Duality
Bachmann, G.; Narici, L.; Beckenstein, E.:
Fourier and Wavelet Analysis
Badescu, L.: Algebraic Surfaces
Balakrishnan, R.; Ranganathan, K.: A Text-
book of Graph Theory
Balser, W.: Formal Power Series and Linear
Systems of Meromorphic Ordinary Differ-
ential Equations
Bapat, R.B.:
Linear Algebra and Linear
Models
Benedetti, R.; Petronio, C.: Lectures on Hy-
perbolic Geometry
Benth, F. E.: Option Theory with Stochastic
Analysis
Berberian, S. K.:
Fundamentals of Real
Analysis
Berger, M.: Geometry I, and II
Bliedtner, J.; Hansen, W.: Potential Theory
Blowey, J. F.; Coleman, J. P.; Craig, A. W.
(Eds.): Theory and Numerics of Differential
Equations
Blowey, J. F.; Craig, A.; Shardlow, T. (Eds.):
Frontiers in Numerical Analysis, Durham
2002, and Durham 2004
Blyth, T. S.: Lattices and Ordered Algebraic
Structures
BÂ¨orger, E.; GrÂ¨adel, E.; Gurevich, Y.: The
Classical Decision Problem
BÂ¨ottcher, A; Silbermann, B.: Introduction
to Large Truncated Toeplitz Matrices
Boltyanski, V.; Martini, H.; Soltan, P. S.:
Excursions into Combinatorial Geometry
Boltyanskii, V. G.; Efremovich, V. A.: Intu-
itive Combinatorial Topology
Bonnans, J. F.; Gilbert, J. C.; Lemarchal, C.;
Sagastizbal, C. A.: Numerical Optimization
Booss, B.; Bleecker, D. D.: Topology and
Analysis
Borkar, V. S.: Probability Theory
Brunt B. van: The Calculus of Variations
BÂ¨uhlmann, H.; Gisler, A.: A Course in Cred-
ibility Theory and its Applications
Carleson, L.; Gamelin, T. W.:
Complex
Dynamics
Cecil, T. E.:
Lie Sphere Geometry: With
Applications of Submanifolds
Chae, S. B.: Lebesgue Integration
Chandrasekharan, K.:
Classical Fourier
Transform
Charlap, L. S.: Bieberbach Groups and Flat
Manifolds
Chern, S.:
Complex Manifolds without
Potential Theory
Chorin, A. J.; Marsden, J. E.: Mathematical
Introduction to Fluid Mechanics
Cohn, H.: A Classical Invitation to Alge-
braic Numbers and Class Fields
Curtis, M. L.: Abstract Linear Algebra
Curtis, M. L.: Matrix Groups
Cyganowski, S.; Kloeden, P.; Ombach, J.:
From Elementary Probability to Stochastic
Differential Equations with MAPLE
Da Prato, G.: An Introduction to Inï¬nite
Dimensional Analysis
Dalen, D. van: Logic and Structure
Das, A.: The Special Theory of Relativity:
A Mathematical Exposition

Debarre, O.: Higher-Dimensional Algebraic
Geometry
Deitmar, A.: A First Course in Harmonic
Analysis
Demazure, M.:
Bifurcations and Cata-
strophes
Devlin, K. J.: Fundamentals of Contempo-
rary Set Theory
DiBenedetto,
E.:
Degenerate Parabolic
Equations
Diener, F.; Diener, M.(Eds.): Nonstandard
Analysis in Practice
Dimca, A.: Sheaves in Topology
Dimca, A.: Singularities and Topology of
Hypersurfaces
DoCarmo, M. P.:
Differential Forms and
Applications
Duistermaat, J. J.; Kolk, J. A. C.: Lie Groups
Dumortier.: Qualitative Theory of Planar
Differential Systems
Dundas, B. I.; Levine, M.; Ã˜stvaer, P. A.;
RÂ¨ondip, O.; Voevodsky, V.: Motivic Homo-
topy Theory
Edwards, R. E.: A Formal Background to
Higher Mathematics Ia, and Ib
Edwards, R. E.: A Formal Background to
Higher Mathematics IIa, and IIb
Emery, M.: Stochastic Calculus in Mani-
folds
Emmanouil, I.: Idempotent Matrices over
Complex Group Algebras
Endler, O.: Valuation Theory
Engel, K.-J.; Nagel, R.: A Short Course on
Operator Semigroups
Erez, B.: Galois Modules in Arithmetic
Everest, G.; Ward, T.: Heights of Polynomi-
als and Entropy in Algebraic Dynamics
Farenick, D. R.: Algebras of Linear Trans-
formations
Foulds, L. R.: Graph Theory Applications
Franke, J.; Hrdle, W.; Hafner, C. M.: Statis-
tics of Financial Markets: An Introduction
Frauenthal, J. C.: Mathematical Modeling in
Epidemiology
Freitag, E.; Busam, R.: Complex Analysis
Friedman, R.: Algebraic Surfaces and Holo-
morphic Vector Bundles
Fuks, D. B.;
Rokhlin, V. A.:
Beginnerâ€™s
Course in Topology
Fuhrmann, P. A.: A Polynomial Approach
to Linear Algebra
Gallot, S.; Hulin, D.; Lafontaine, J.: Rie-
mannian Geometry
Gardiner, C. F.: A First Course in Group
Theory
GËšarding, L.; Tambour, T.: Algebra for Com-
puter Science
Godbillon,
C.:
Dynamical Systems on
Surfaces
Godement, R.: Analysis I, and II
Goldblatt, R.: Orthogonality and Spacetime
Geometry
GouvË†ea, F. Q.: p-Adic Numbers
Gross, M. et al.: Calabi-Yau Manifolds and
Related Geometries
Gustafson, K. E.; Rao, D. K. M.: Numerical
Range. The Field of Values of Linear Oper-
ators and Matrices
Gustafson, S. J.; Sigal, I. M.: Mathematical
Concepts of Quantum Mechanics
Hahn, A. J.:
Quadratic Algebras, Clifford
Algebras, and Arithmetic Witt Groups
HÂ´ajek, P.; HavrÂ´anek, T.: Mechanizing Hy-
pothesis Formation
Heinonen, J.: Lectures on Analysis on Met-
ric Spaces
Hlawka, E.; SchoiÃŸengeier, J.; Taschner, R.:
Geometric and Analytic Number Theory
Holmgren, R. A.: A First Course in Discrete
Dynamical Systems
Howe, R., Tan, E. Ch.: Non-Abelian Har-
monic Analysis
Howes, N. R.: Modern Analysis and Topol-
ogy
Hsieh, P.-F.; Sibuya, Y. (Eds.): Basic Theory
of Ordinary Differential Equations
Humi, M., Miller, W.: Second Course in Or-
dinary Differential Equations for Scientists
and Engineers

Hurwitz, A.; Kritikos, N.: Lectures on Num-
ber Theory
Huybrechts, D.: Complex Geometry: An In-
troduction
Isaev, A.:
Introduction to Mathematical
Methods in Bioinformatics
Istas, J.: Mathematical Modeling for the Life
Sciences
Iversen, B.: Cohomology of Sheaves
Jacod, J.; Protter, P.: Probability Essentials
Jennings, G. A.:
Modern Geometry with
Applications
Jones, A.; Morris, S. A.; Pearson, K. R.: Ab-
stract Algebra and Famous Inpossibilities
Jost, J.: Compact Riemann Surfaces
Jost, J.: Dynamical Systems. Examples of
Complex Behaviour
Jost, J.: Postmodern Analysis
Jost, J.: Riemannian Geometry and Geomet-
ric Analysis
Kac, V.; Cheung, P.: Quantum Calculus
Kannan, R.;
Krueger, C. K.:
Advanced
Analysis on the Real Line
Kelly, P.; Matthews, G.: The Non-Euclidean
Hyperbolic Plane
Kempf, G.: Complex Abelian Varieties and
Theta Functions
Kitchens, B. P.: Symbolic Dynamics
Kloeden, P.; Ombach, J.; Cyganowski, S.:
From Elementary Probability to Stochastic
Differential Equations with MAPLE
Kloeden, P. E.; Platen; E.; Schurz, H.: Nu-
merical Solution of SDE Through Computer
Experiments
Koralov, L.; Sina, Ya. G.: Theory of Proba-
bility and Random Processes
Kostrikin, A. I.: Introduction to Algebra
Krasnoselskii, M. A.; Pokrovskii, A. V.: Sys-
tems with Hysteresis
Kuo, H.-H.: Introduction to Stochastic In-
tegration
Kurzweil, H.; Stellmacher, B.: The Theory of
Finite Groups. An Introduction
Kyprianou, A.E.: Introductory Lectures on
Fluctuations of LÂ´evy Processes with Appli-
cations
Lang, S.:
Introduction to Differentiable
Manifolds
Lefebvre, M.: Applied Stochastic Processes
Lorenz, F.:
Algebra I: Fields and Galois
Theory
Luecking, D. H., Rubel, L. A.:
Complex
Analysis. A Functional Analysis Approach
Ma, Zhi-Ming; Roeckner, M.: Introduction
to the Theory of (non-symmetric) Dirichlet
Forms
Mac Lane, S.; Moerdijk, I.:
Sheaves in
Geometry and Logic
Marcus, D. A.: Number Fields
Martinez, A.: An Introduction to Semiclas-
sical and Microlocal Analysis
MatouË‡sek, J.: Using the Borsuk-Ulam The-
orem
Matsuki, K.: Introduction to the Mori Pro-
gram
Mazzola, G.; Milmeister G.; Weissman J.:
Comprehensive Mathematics for Computer
Scientists 1
Mazzola, G.; Milmeister G.; Weissman J.:
Comprehensive Mathematics for Computer
Scientists 2
Mc Carthy, P. J.: Introduction to Arithmeti-
cal Functions
McCrimmon, K.: A Taste of Jordan Alge-
bras
Meyer, R. M.:
Essential Mathematics for
Applied Field
Meyer-Nieberg, P.: Banach Lattices
Mikosch, T.:
Non-Life Insurance Mathe-
matics
Mines, R.; Richman, F.; Ruitenburg, W.: A
Course in Constructive Algebra
Moise, E. E.: Introductory Problem Courses
in Analysis and Topology
Montesinos-Amilibia, J. M.: Classical Tes-
sellations and Three Manifolds
Morris, P.: Introduction to Game Theory
Nicolaescu, L.:
An Invitation to Morse
Theory

Nikulin, V. V.; Shafarevich, I. R.: Geome-
tries and Groups
Oden, J. J.; Reddy, J. N.: Variational Meth-
ods in Theoretical Mechanics
Ã˜ksendal, B.: Stochastic Differential Equa-
tions
Ã˜ksendal, B.; Sulem, A.: Applied Stochastic
Control of Jump Diffusions
Orlik, P.; Welker, V.: Algebraic Combina-
torics
Poizat, B.: A Course in Model Theory
Polster, B.: A Geometrical Picture Book
Porter, J. R.; Woods, R. G.: Extensions and
Absolutes of Hausdorff Spaces
Procesi, C.: Lie Groups
Radjavi, H.; Rosenthal, P.: Simultaneous
Triangularization
Ramsay, A.; Richtmeyer, R. D.: Introduc-
tion to Hyperbolic Geometry
Rautenberg, W.: A concise Introduction to
Mathematical Logic
Rees, E. G.: Notes on Geometry
Reisel, R. B.: Elementary Theory of Metric
Spaces
Rey, W. J. J.: Introduction to Robust and
Quasi-Robust Statistical Methods
Ribenboim, P.: Classical Theory of Alge-
braic Numbers
Rickart, C. E.: Natural Function Algebras
Rotman, J. J.: Galois Theory
Rubel, L. A.:
Entire and Meromorphic
Functions
Ruiz-Tolosa, J. R.; Castillo E.: From Vectors
to Tensors
Runde, V.: A Taste of Topology
Rybakowski, K. P.: The Homotopy Index
and Partial Differential Equations
Sagan, H.: Space-Filling Curves
Samelson, H.: Notes on Lie Algebras
Sauvigny, F.:
Partial Differential Equa-
tions I
Sauvigny, F.:
Partial Differential Equa-
tions II
Schiff, J. L.: Normal Families
Schirotzek, W.: Nonsmooth Analysis
Sengupta, J. K.: Optimal Decisions under
Uncertainty
SÂ´eroul, R.: Programming for Mathemati-
cians
Seydel,
R.:
Tools
for
Computational
Finance
Shafarevich, I. R.: Discourses on Algebra
Shapiro, J. H.: Composition Operators and
Classical Function Theory
Simonnet, M.: Measures and Probabilities
Smith, K. E.; KahanpÂ¨aÂ¨a, L.; KekÂ¨alÂ¨ainen, P.;
Traves, W.:
An Invitation to Algebraic
Geometry
Smith, K. T.: Power Series from a Computa-
tional Point of View
SmoryÂ´nski, C.: Logical Number Theory I.
An Introduction
Stichtenoth, H.: Algebraic Function Fields
and Codes
Stillwell, J.: Geometry of Surfaces
Stroock, D. W.: An Introduction to the The-
ory of Large Deviations
Sunder, V. S.: An Invitation to von Neu-
mann Algebras
Tamme,
G.:
Introduction
to
Â´Etale
Cohomology
Tondeur, P.:
Foliations on Riemannian
Manifolds
Toth, G.:
Finite Mbius Groups, Minimal
Immersions of Spheres, and Moduli
Tu, L. W.: An Introduction to Manifolds
Verhulst, F.: Nonlinear Differential Equa-
tions and Dynamical Systems
Weintraub, S. H.: Galois Theory
Wong, M. W.: Weyl Transforms
XambÂ´o-Descamps, S.:
Block Error-Cor-
recting Codes
Zaanen, A.C.: Continuity, Integration and
Fourier Theory
Zhang, F.: Matrix Theory
Zong, C.: Sphere Packings
Zong, C.: Strange Phenomena in Convex
and Discrete Geometry
Zorich, V. A.: Mathematical Analysis I
Zorich, V. A.: Mathematical Analysis II

