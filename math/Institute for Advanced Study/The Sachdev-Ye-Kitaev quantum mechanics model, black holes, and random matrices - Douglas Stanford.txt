Yeah, I should, I guess, issue some kind of a warning that there are some people in the
physics department here who are somewhat mathematically sophisticated, and that's not me.
So I'm not trying to be humble, I'm just trying to acquaint you guys with the facts.
Yeah, right, right, so, okay, so yeah, I'm going to be discussing a quantum mechanics
model that does seem to have some interesting connections to at least somewhat recent areas
of mathematics, like from the 80s, some combinatorics questions, and Distramat-Hekman formula, and
hopefully a connection to random matrix theory.
So yeah, so it goes by the name of the Sachdev Yekhtayev model, so S-Y-K, and this is, it's
an ensemble of sparse random matrices, and when we think about elements of that ensemble
as the Hamiltonian for a quantum mechanics system, then it defines a quantum mechanics
system that shares some properties with a very simple black hole, a black hole in two-dimensional
spacetime, so a black hole in a theory with one time direction and one space direction.
So that's an interesting property of these, of these Hamiltonians, but okay, so the black
hole information problem, which is a big problem in my area in physics, leads us to
consider quantities in this theory, in this quantum mechanics system that are connected
to quantities that people often study in the context of random matrix theory, and we would
like to be able to calculate those quantities ideally for black holes, but less ambitiously
we would like to be able to calculate those for this particular ensemble of sparse random
matrices, so that's, that's what I'll discuss.
So I hope that you guys will interrupt me whenever, whenever you like, I have, I mean
I have the stuff to say, but I'm not, yeah, I'm not, I don't, I don't have an hour of
material prepared and I'm not committed to getting to the end of it anyhow, so I hope
that you guys will interrupt me, so, okay, well, so the basic, the basic, the basic
connection is that a black hole should be thought about as a quantum mechanics system,
where the time evolution is some, some matrix, some Hamiltonian, and yeah, and it should
be black holes are strongly chaotic systems, so we could discuss how we know that and how
we can compute that, but they should be strongly chaotic quantum mechanical systems, so they
should be described by Hamiltonians, the time evolution should be given by a matrix, which
has at least some, some, well,
yeah, this, I guess, is probably somehow a different limit in the landscape of quantum
chaotic systems, where the black hole would not be a system, it's not,
not a high frequency,
yeah, it's not a classical system that you've quantized, it's not a classically chaotic
system that you've quantized, it's sort of, from the get go, a quantum mechanical system,
but it's expected that that shares, that, that this also enjoys this random matrix
universality that, that has been understood, to some extent, in these,
the explicit connection, is that new, I mean, that's quite a big impression.
Yeah, it's, well, it's new that one is trying to take it seriously and that what's new is
that we have a quantum mechanics system, which is related to black holes, and where we
can actually compute the spectrum, the exact spectrum.
That's, yeah, yeah, I'll tell you what it is.
Okay, so the, it's, it's a quantum mechanics of, of n Myrona fermions.
So, Myrona fermions are, are, for our purposes, they're matrices, psi i,
where i runs from one up to n, so there's n of them, and they satisfy the following,
following algebra, that psi i times psi j, plus psi j times psi i is equal to two times
delta ij.
So we say that these things anti-commute, if i is not equal to j, and they square it
to a multiple of the identity, if i is equal to j.
Okay, now these things, this, the only important property of these is this relation, and you
can realize, you can realize this algebra in a space of dimension l, where l is two
to the n over two.
So this is the dimension of the Hilbert space.
Okay.
Yeah, so now we think of these, we should think from now on, we think of these psi
i's as completely explicit matrices, which are l by l matrices living in this, living
in this space.
So the simplest example would be if we have n equals two, yeah, I should mention that n
is even, we have to have an even number of these fermions.
So the first non-trivial case is n equals two, and then we could take as the matrices,
we could take psi one is one zero zero minus one, and psi two is zero one one zero, and
you can check that this, this holds, yeah, we should put, yeah, this, this holds for
these matrices.
Okay, but for larger values of n, there's, there's a procedure for generating these
matrices, and the minimum size would be two to the n over two, and we'll assume that representation.
Okay, so that's what, that's what Myron and fermions are in, in quantum mechanics.
Now the, the Hamiltonian is the following.
So we build a matrix, the sum over all possible products of four of these fermion operators.
And we sum over all possible products with a, with a set of coefficients, J, and these
coefficients J define the ensemble.
So we take these things to be random, and Gaussian distributed with a mean that's zero,
so J with indices here is zero, and J squared, so J squared, so the variance of an, of an
individual, one of these guys would be given by parameter J squared, it's convenient to
put in a particular normalization.
These factors aren't, aren't too essential.
The important point is that the mean is zero, and there's some variance for these, for these
coefficients.
Okay.
Yeah, that's right, that, yeah, it's important that here I'm not summing over indices, let's
say I, they're independent, yeah, they're independent, thank you.
Yeah, is this completely clear, maybe, yeah, if you want, so for example, suppose I want
to generate this, these matrices on the computer, I'll form an explicit representation for these
guys, then I'll sum over all products of four of them, and then I'll ask the computer to
generate for me a random Gaussian number with this variance, and I'll multiply it by that,
and then I'll move on to the next term, and I'll keep doing that.
Okay, so we'll do that roughly into the fourth times.
Yeah.
I heard someone say, maybe I misheard that this is a vector model, and how many variables
are there?
Vector model?
Yeah, it's a vector model in the sense that the variables that we consider have one index,
so they have one, so they're labeled by one index, I, I, yeah, often in physics people
consider, well, they consider degrees of freedom that have two indices, those are often the
more interesting theories, vector models are often very, very simple, but this one is interesting
even though it's sort of like a vector model.
This is a generalization of this that is often useful to consider, where we replace four
by Q, and we have a Hamiltonian involving all possible products of Q of the fermions.
So these, these should be thought of as Hamiltonians where we have these Myron fermions, they're
interacting in groups of Q.
Yeah, the, the sparsity, yeah, that's right, that's right.
So these, these matrices here, these, these psi matrices themselves are sparse.
They have roughly as many entries as just like a diagonal matrix, and we're not summing
over very many values, we're only summing over n to the fourth or, or n to the Q values.
So, yeah, a very, it's very important to keep in mind these two parameters here, L, L and
n.
So, yeah, that, it'll be important that the, the size of the matrices we consider are L
by L matrices, so the Hamiltonian is an L by L matrix, and we consider, no, he actually
developed this for the purposes of thinking about black holes.
So, yeah.
By the way, you told me that at the end, you will explain a problem to us.
A problem?
Yeah.
Yeah, well, okay, yeah, okay, okay, well, we can see, yeah, okay, good.
So this, this didn't mean field model, I mean, but it has no spatial structure.
That's right.
There's no, there's no space.
And, and, I mean, is there anything like, you know, replica symmetry breaking or that
kind of thing that occurs here, is it doesn't, in, in spin glasses?
Yeah.
This is an interesting question.
So, in the past, people have written down Hamiltonians that look structurally similar
to this.
Yeah.
Often, they write them down, not in terms of Myron and Fermions, but in terms of Pauli
spin variables.
Yes.
And those things are known to be, to have, at low temperature, to have spin glass behavior.
And this model is different.
So it looks quite similar, right?
Yeah.
There are different ways of explaining why it's different.
I'm not an expert in spin glass physics.
So I can tell you the, the arguments that people who know about this offer.
And yeah, there won't be any space in the replica symmetry break.
No, no, no.
And actually one can check, one can check for that by just assume, so you can assume there's
no replica symmetry breaking and compute, compute things like the free energy and compare
those to exact numerical computations, and you find excellent agreement, which you would
not have found for these spin glass models.
So.
If you say numerics, you call them at the L very often.
No, no.
So we'll get, we'll get to that.
Is that a fact?
Yeah.
So numerics.
You see anything?
Well, you couldn't get L to 100, 150,000 or something.
Yeah.
So that's, that's, that's the largest.
You make L at a certain time and you call it N more often.
Yeah.
N is at most 34.
Okay.
Okay.
So, yeah.
So just to be completely clear, what we mean by this Hamiltonian in the quantum mechanics
system is we think about this matrix as the, as the Hamiltonian.
And so we would evolve states with the Schrodinger equation.
So this would be a vector now that lives in the 2 to the, lives in the L dimensional space.
And we have this equation.
Okay.
So that's what we do with these, with these matrices when we think about them in the context
of quantum mechanics.
So we can discuss in more detail.
I'm not sure which aspects of this will interest you guys, but we can discuss in more detail
to what extent this system is similar to a two-dimensional black hole.
But maybe.
H is supposed to be self-adjoint.
Yeah.
Yes.
That's right.
H is Hermitian.
So you make some assumptions on, is it real or is it real?
The J's just have to be real.
Yeah.
Actually, I should have, I should write here a factor which is q over 2 here.
And if we do that, then the Hamiltonian is always Hermitian.
These sides themselves are Hermitian, but they're anti-commute.
So we have to check, and depending on how many of them are, there are, they might or
might not develop a minus sign.
And so this I counts for that.
Yeah.
That's right.
Hamiltonian is Hermitian.
Okay.
But this model is supposed to be an example of sort of a toy model for ADS-CFT, where
we relate quantum mechanical systems to quantum gravity systems.
So this is a quantum mechanical system living in a theory of zero space in one time, and
it's related to a quantum gravity problem in one space in one time.
That's the way that these-
The quantum mechanical system is between the e to the i and the h.
Yes.
Yeah.
It's a system without any spatial locality.
So, yeah.
Everything's linear algebra.
Setting up the linear algebra is what these guys are good at.
Oh, yeah.
No.
As I said, I'm not one of the mathematically sophisticated people, so linear algebra is
enough for me.
Yeah.
So actually, I would be interested to discuss this more.
So you could write exactly GUE or GOE as a sum over different values of Q.
I'm sure that if you average in any way over Q, you could get other GOE or GSE if you put
in extra-
For large values of-
For large, but fixed values of Q?
Okay.
Yeah.
I think probably when Q is of order n, there are-
I'm only saying Q goes between the n fixed and it's a bit other way.
Well, Q can never be bigger than n, because we have at most n fermions.
You can write exactly- you can write the exact GUE ensemble as a sum over this thing
with different values of Q.
But that- well, okay.
That's one fact.
Okay.
So now we could discuss the types of things that we compute in this model.
So one example of a thing-
Yeah, I can do that.
So yeah, maybe I can say that.
I can say that in words and we'll see a little bit in an equation later.
But this model can be analyzed- this model can be solved at large n in the 1 over n expansion.
And the way that one does that is one integrates over these couplings J, one does the disorder
average over J, and then you get a rather complicated theory, but it's a complicated
theory which has this large parameter n that allows you to solve it in an expansion in
1 over n.
Is this a solid point or is it not a manifold?
Yes, that's right.
And so you can think about this- this becomes now an integral of- with a solid point parameter
which is n.
And we study the 1 over n expansion.
And you can show that correlation functions of this model in the 1 over n expansion agree
with correlation functions that you would get in this theory of the two-dimensional black
hole.
The most- the most- well, one of the most interesting types of-
Yeah, so we would consider a black hole spacetime and we would compute correlation functions
of fields propagating on that space.
So-
Is this something in the local correlation?
These would be correlations of operators at different times, so as a function of the
time.
And here- well, the two-dimensional problem has space.
But-
There's no space here, really.
There's no space here, so what we compute here are quantities that depend only on time
and those would be quantities in the two-dimensional problem that are at the boundary of the space
at different values of time.
And so you can compute-
That's the holograph.
That's the holograph.
Yeah.
So you can compute those things for this black hole spacetime using gravitational perturbation
theory and compare that to the one-over-n expansion of this theory.
And while the thing that's been computed in detail is the one-over-n term, and this agrees
in a precise way.
We can make this more precise later.
There's of course much more to say about this.
This is the main thing that has been studied about this model.
But that's-
The coupling will be one-on-one times J squared.
Sorry?
The coupling will become lower and times J squared.
Which coupling?
The larger one.
Ah, no.
Good, good, good.
So I should, yeah, I should clarify this.
The regime where this model is related to a black hole is actually at large J, where
this parameter is large.
So we take this parameter to be large, or equivalently we can just study the model at
low temperature.
And then we do the one-over-n expansion.
And so the one-over-n expansion at large values of J is the thing that agrees with this two-dimensional
theory.
Okay.
So yeah, we could discuss these correlation functions that we compute, but maybe a simpler
thing to discuss is just the partition function.
So we can consider this quantity, which would be a sum over all of the energy eigenstates.
So that's a sum that runs from one to L, e to the minus beta times em.
So em is an energy, an eigenvalue of this matrix, of the Hamiltonian.
And we consider this type of expression.
Now it's a general feature of this type of sum.
Yeah, let's think about this type of sum for a second.
If t is small, let's say t is zero, then we're summing up a whole bunch of positive quantities.
But as we increase t, then these phases here cause some partial cancellations in the sum.
And this function will decrease as a function of time.
So it starts out large, we're summing up on positive quantities, then we're adding phases
and it starts to decrease.
But it doesn't decrease to zero.
Summs of this type are, I guess these are things that are called almost periodic functions.
So it will become rather small, but it will oscillate, and at very long times it will
have recurrences back up to its initial large value.
So that's the behavior one expects for this type of function, this type of partition function.
Now, you could also try computing this type of quantity in gravity, in the two-dimensional
gravity theory.
And there, in the perturbative expansion in the gravity theory, you find that this type
of expression should actually go to zero at late time.
So we know that in any quantum mechanical theory where we can write this as a sum over
energy eigenstates, they should not go to zero.
It should oscillate at late times.
But in a gravitational computation, you find that it does go to zero.
And this is a symptom of, this is maybe the simplest symptom of this thing called the
black hole information problem.
So understanding how these gravitational computations are misleading is a huge problem
in theoretical physics.
People don't have a lot of good ideas.
Because that's a classical calculation, or it doesn't include the quantum.
It does.
You would include the quantum effects in gravity theory perturbatively.
So you imagine that you have a small parameter that suppresses quantum effects, and you
could imagine computing this thing in a power series in that parameter.
And to any finite order in that parameter, you expect to find decay late times.
So in quantum mechanics, you do not.
Yeah, that's right.
So you know that the actual answer does not do that.
And you don't know how.
Yeah.
So the fact of the quantum mechanics, if you say it oscillates, I think it's a consequence
of finite dimensionality.
In finite dimensions, you can have continuous spectrum, which is actually delta k.
Yeah, it's not.
You're basically right.
It's not even so much that the dimension is finite or infinite, it's that the entropy.
Spectrum has no accumulation points.
Yeah.
Yes.
The spectrum can be infinite.
Yeah.
The spectrum can be infinite.
The Hilbert space can be infinite, and you still have this quasi-periodic behavior.
The important thing is that the entropy should be finite, the spectrum not have accumulation
points.
No.
Okay.
I mean, it's very common in quantum mechanics to have systems that will have almost periodic
partition functions, but have infinite dimensional Hilbert spaces.
We could take, like, yeah.
Okay.
Okay.
Okay.
Yeah, I'm sure.
Yeah.
I don't know.
Okay.
So the thing we would like to do is understand this function in the SYK model and see if we
can understand how this one-of-rand expansion is just simply the Fourier transform of the
measure, the spectral measure, and that's why it's just given in terms of the absolutely
continuous part with the k point spectrum part.
Okay.
Yeah.
Yeah.
From the physics point of view, the problem is that black holes appear to, the way that
we know how to compute things in black hole spacetimes, gives us expressions for this type
of quantity that would go to zero at large time.
But we believe that black holes are finite entropy quantum systems, and for finite entropy
quantum systems, this should not go to zero at late time.
It should be an almost periodic function, and it should have this oscillating behavior.
Yeah.
Now, of course, here we have an honest quantum mechanical system, and it will be a very,
and it will not decay.
So on the other hand, it shares some properties with black holes, so hopefully we can use
this to understand better how to.
Yeah.
The quantity that one is normally interested in is not this partition function quantity,
but a two-point correlation function, let's say, of two of these fermions at time zero
and time t.
And then we would take the time t to be very large, and we would have the same situation
where the gravity theory would predict that the two-point function should decay at large
time, and the quantum mechanics, the finite Hilbert space computation would show that
it would not decay.
This one also has a physical meaning, but it's sort of a funny fit.
It's an analytic continuation of the partition function.
It's not as clear as the two-point function, but it's simpler to write, to compute.
Okay, good.
So we could imagine computing this in the SYK model, and more precisely, we could imagine
computing this in the disorder average.
So we would compute z as a function of these couplings j, and then we would average them
over j.
Now there's a problem, which is that if we average this spectrum, we have a continuous
spectrum, and indeed this function can decay to zero, and it does.
So the disorder average of the partition function decays to zero at late time.
For a given realization of the model, the typical value will not be zero.
What that means is that we can consider a different quantity, which would just be z times
the complex conjugate of z, and then we can take the disorder average of that quantity,
and now cancellations are not possible from the average over j, and this is something now
that really should not go to zero.
So let me plot.
Yeah, okay.
Should I continue writing on these boards?
Is that better?
Maybe I should just do that.
Maybe I'll just do that.
So now the thing is we just numerically diagonalize this Hamiltonian, and we study this for many
different values of j, and we plot the answers.
We define a function g of t, which is the average over couplings.
You didn't numerically generate random couplings.
Yup.
So the numerical procedure is generate these random couplings j, diagonalize the Hamiltonian,
compute this thing, and then move on and do it again, and do it many times until we get
a nice smooth function.
That defines g of t, and here's what it looks like.
So I'll plot it as a function of log t, and here's log g.
So this is a log-log plot, and it looks something like this, okay.
So good.
So this is for the largest values that we can study numerically.
Our n is equal to 34, and l is equal to 2 to the 17, which is like 150,000 or something
like that.
So let me draw some rough indicators of the scales of the different places on this plot.
So the initial value here is when we have no phases entering in the sum.
This expression here would have been of order l, because we're adding up l things with no
phases.
We're squaring it here to define g.
So this thing is of order l squared.
So g.
Yeah, beta is fixed.
We could imagine maybe the simplest thing for the moment.
To get exactly the shape of plot, you would take something like beta times j is about
5 or something, some order 1 quantity like that.
We could study these functions when beta is 0, but let's not do that.
Well, that's just the largest number that we canâ€¦
Well, so 32 is, you have to diagonalize a matrix, which is 2 to the n over 2 by 2 to
the n over 2.
Why would a power of 2 help?
No, no, the n being a power of 2 doesn't help you.
We're studying e to the 2 to the n over 2.
So that is a power of 2.
That's 2 to the 17.
Yeah, this is the most important thing in the talk.
I should emphasize again.
n is the number of fermions.
We should think of this in these things as being n equals 34.
l is the dimension of the matrices that we're studying, the dimension of the Hilbert space.
This is 2 to the n over 2.
The fact that these things are very different from each other will be very important.
This is really the central aspect of this.
So l is 16 bits, and n could add l on 17 bits, that's it also.
Yeah.
Yeah.
I'm just a little surprised.
I mean, for these values of n, the limiting factor is time.
It's CPU time anyhow.
So I should have mentioned before I started that there's a long list of collaborators
I have that are working on this, and I'm not doing this matrix diagonalization.
So I know some small amount about that, but that work is being done by many, by other people.
I can list the people, but you guys probably don't know them, so maybe you don't care.
Do you have any collaborators you want?
Yeah, but he's not part of this project here.
Yes.
We need this recording to show it to you.
Okay, good.
So my esteemed collaborators, I'm not going to list them.
I will if you want, but okay.
We don't care with that, I don't care.
Yeah, that was my thinking.
Okay, so the initial value is g is of order l squared, so that's big.
The final value here, and we'll explain where this comes from.
g is of order l.
The time where this transition happens is a time that's of order l, and the time that
happens here is a time that we don't know very well.
So that's-
And when you say this, yes, you run it with different j's and it's always the same thing.
Ah, great.
Yeah, thank you.
I should have clarified.
Let me plot now on top of this a typical run with one value of j.
So instead of averaging over the j, it's just a typical thing.
That would look very similar here.
And then after this point, it would do something like this.
So the function here is- the technical term is that it's self-averaging before this time,
and it's not self-averaging after that time.
So given realizations look different from the average.
It looks like a regularization of a shock, right?
Is there a concentration of measure on to that?
Yeah, yeah, so we can understand why this is self-averaging at this point and not later
as well.
And it's half the two of the oscillations, doesn't it take care of you?
Yeah, no, the oscillations are always of order of the function itself.
So, yeah.
I mean, in the end, if you take t large enough, you're just getting the Gauss-Mitchell coefficients
here.
Yeah, I mean, it makes sense.
Yeah, that's right.
But it makes sense that this z-
What?
It's a function of me.
Yeah, the z's were very large values of time or a sum of a whole bunch of sort of random
things.
So, yeah, that's why it's being distributed at large time, and that's why these fluctuations
are of order the size of this thing itself.
Okay.
What's kind of the thing is, why does that thing happen when t is not over there?
Yeah, I will explain that, I will explain that.
But the, I'd like to draw a, okay, so the moral labels that I would like to attach to
this are the following.
Here's some time here which marks the transition between the part I'll call the gravity part
or more precisely the 1 over n expansion part where we can understand this curve by thinking
about the 1 over n expansion.
And then this part, I'll label the random matrix theory part.
And for this thing, we should think about a 1 over l expansion.
Okay, so I'll explain why we're thinking about these two different expansions.
So first we'll discuss this gravity part.
In this region, because this expression is self-averaging, rather than thinking about
the average of the square, we could just think about the average of z.
Yeah, yeah, the behavior, the fact that it's 1 over l is, yes, yes, yes, yes.
But explaining how you get that small parameter from starting from 1 over n expansion is,
Yeah, yeah, yeah, yeah, yeah, yeah, yeah, good, well, okay, good, I want to, I want to get
to that.
That's the main thing I would like to discuss.
But let me first comment on the gravity part.
So this is the, this is the part that we can understand.
This part we haven't really understood how to think about this correctly, directly in
the model.
This part we can understand from the model itself.
And there's a, right, so we will be thinking about the disorder average of the partition
function instead of the square in that region.
And basically we can just do the conventional thing for this type of model, which is the
1 over n expansion.
And so what one finds, there's actually, there's a long analysis that one has to go through
to compute the effective theory of this, of these fermions at large n and at low temperatures.
And it has actually, I just want to write this formula because it has a beautiful, it's
quite beautiful.
But this becomes an integral over, over this symplectic manifold, div s1 mod sl2r, of the
volume form, and then a particular action, which is n over beta j, where beta is now,
I should write beta plus it, times the integral of the Schwarzian derivative of some field
phi tau, where the Schwarzian is phi triple prime over phi prime minus three-halves phi
double prime over phi prime squared.
And phi here is a element of div s1 mod sl2r.
Yeah, this, yeah, this, this integral is a, yeah, this has a remarkable fact that this,
this integral, this functional integral can be computed exactly using this Duster-Mott-Hekman
theorem.
So this is an integral over symplectic manifold of the exponential, of an exponential of a
generator of a u1 symplectomorphism of that manifold.
And so the integrals of those things are easy to compute.
And so the answer for this functional integral is equal to exponential of n over, I should
write, yeah, beta plus itj over the same quantity.
Okay.
So this has a very simple answer.
Sorry?
What's n small in the first factor of the, where's n, oh, this, yeah, this is the dimension
of the space.
So what I, what I really mean here is the, what I mean here is the symplectic measure
on this space.
Diff s1 mod sl2r.
Okay.
Oh, I see.
Yeah, it's an infinite dimensional space so that little n would be infinity.
So this is, this is an equality.
Yeah.
This is.
This is an equality by Dorset-Mott-Hekman.
Yes.
It can reduce it to a, to the critical manifold.
That's right.
This action.
Yeah.
Divided by, then you have to look at the Hessian.
You have to look at the one-loop term that, yeah, that's right, the Hessian about that
point.
Yeah, that comes from the calculation and this part I, I don't have time to explain,
but this is, this is actually a long calculation that starts from these fermions and then in
the low temperature limit of that model, you get this, you get this effective theory.
And that's, that's not at all obvious.
So who did this calculation first?
So this, this, no, this was suggested in talks by Kitai, but it was worked out in detail
in the paper that I wrote with Maldesena.
But the, the, and there were some corrections to this that he talked about.
Yeah, yeah.
So he's, but those things are not important at low temperature.
So we can discuss.
The other reason that I wanted to write this formula here is that this theory here is exactly
the theory of this two-dimensional black hole.
That's also something that's not completely obvious, but this is, this is how that link
is made.
You study this problem at large n and at low temperature.
You have this effective description, this, this computation of the partition function,
and this is exactly the theory of the two-dimensional black hole.
So that's, that's, that establishes the link between, between this system of fermions and
the black hole.
This is the entire, this is the entire two-dimensional dilaton gravity theory is exactly this integral.
So that has a simple answer as well.
And the quantity of the left for the black hole would be?
Would be the partition function in the effective theory.
The, yeah.
It would be the same thing.
Yeah.
Well, the partition function for the space time of the black hole.
You don't have to, yeah, yeah.
So what does S long as function in the theory of black hole does in the space is compactified
or what?
Yeah.
So the black hole is, it's a, it's a theory in, in, yeah, we should think about the black
hole in Euclidean signature space.
So the finite temperature is related to the finite, to the, the periodicity of time in
units of the inverse temperature of beta.
So the time is compactified and the, the, the two-dimensional theory reduces to just
an integral over these diff s 1, 1, f l 2 r.
By the way, if anybody here is an expert on this space, I would be interested to discuss
it.
The expert is actually Kirolov and Upen.
Okay.
We can bring him up.
Okay.
Yeah.
I would love to, I think there's more, I believe there's more somewhat subtle mathematics lurking
in this thing here that I have not understood.
There's one very beautiful thing, which is that you can have exactly value at the integral,
but there are other things that probably can be evaluated exactly that I don't know
how to evaluate.
This is a bit like this old-screen theory becoming integrals over modular space in
this kind of polycop formula, which becomes, and it posts the infinite-dimensional integral
of the action, and then you apply your formal manipulations to get it down to some finite
integral that you cannot compute.
Yeah.
That kind of, see we have a, I mean we, I have a problem with functional integrals.
Yeah.
Yeah.
I understand there's this cultural divide, but yeah.
Well this one nobody has a problem with, so okay.
So anyhow, the one point is that the partition function here at large values of t is going
like 1 over t to the 3 halves.
Now we take this expression and square it, and we get 1 over t cubed, and that explains
this part of the curve.
So that entire, the part of the curve to the left of this point here is explained accurately
by this formula.
So now we can proceed, now we've understood the part of this that we can also compute
in gravity, and we see that it agrees with the numerics.
So now we can proceed to try to understand the rest of it.
And that, well we have some ideas for this, but we don't have much direct understanding
in terms of the, in terms of the original model.
So what I'm going to do instead is describe the computation of this same quantity in random
matrix theory, in particular in GUI.
So let me just, well, I don't have to draw the same figure again, but I can just tell
you that if you compute these, if you compute this, where we replace the Hamiltonian with
a random matrix, an L by L random matrix, then the curve looks to the precision of my
drawing exactly the same.
So now we can-
Yeah, that's right.
So actually the ensemble depends on the value of n.
It's periodic in n mod 8.
Yeah.
Yes, but let's consider a different problem, which is a random matrix, and just plot it.
And it gives something that looks very similar to this.
Now, those should be the same at late times.
So now let's discuss, let's discuss where this, so we need to understand what part of
the random matrix theory this, this curve comes from.
In particular, we'll be interested in this part of the curve from this point onwards
since we already know how to explain this, okay.
You get a different curve, which disagrees with the curve to the left of here, and agrees
quite well to the right.
It's different on the left.
It's not as different as you might think.
The reason it's not as different as you might think, in particular, it has the same slope,
one over t to the three halves.
The reason for that is that the random matrix, this could be described just by the partition
function, just by the single, the mean density of eigenvalues, which vanishes like a square
root for the random matrix.
Now, vanishing like a square root, if you plug that in and compute z, translates to
this power one over beta to the three halves.
It's the square root vanishing of the density of states that gives you these things.
You could ask then, what is the density of states that would give you this function instead?
I can just write that.
That would be the density of states rho of e is like cinch of square root ne over j.
It vanishes like a square root at e equals zero, but it's not the semicircle.
That would be the behavior for small energies in this model.
The fact that it's not exactly the semicircle tells you that it's somewhat different from
this part of the curve will be somewhat different than what you get in random matrix theory.
What would say the rho of j is du e?
That would be the width of the semicircle.
That's just the overall scale of the matrix.
You said something about whether this is du e or j o e or something else.
This depends on n mod 8.
Half the time it's du e, the other half is evenly split between j o e and g s e.
No, actually I don't understand those.
Let's think about how we would compute z, z star and g u e.
We would write this as an integral over a pair of eigenvalues, lambda 1 and lambda 2.
Then we would put the g u e average of this pair correlation function and then we would
have, let me set beta equals zero.
Then we have e to the i times t, lambda 1 minus lambda 2.
We would be looking at basically a Fourier transform of this pair correlation function
that would be giving us this z.
For g u e, the answer for this expression here is l squared.
The density of eigenvalues is large.
It's proportional to l.
We have two copies of these, so we get an l squared.
Now we would have rho naught of lambda 1, rho naught of lambda 2.
These are just the semicircle, mean density, and then we would have 1 minus the sine kernel
expression, where here lambda, let me write lambda, would be a rescaled version of lambda
1 minus lambda 2, it's this thing over something like this.
We would also have a delta function piece with a coefficient l.
This is a formula from random matrix theory and we can just evaluate this Fourier transform
now.
The large part of it, large l comes from this 1 here and there we would just take the product
or the Fourier transforms of the two semicircles and that would give you the thing I described.
That actually gives a Bessel function.
If we square the Bessel function and we get something that decays like 1 over t cubed,
it looks rather similar to the first part of the curve, but it's not exactly the same
because the spectrum, the mean spectrum is different.
Now we have to understand the rest of it.
This Fourier transform can be computed exactly, it gives actually this funny, this tent function
that is linear and then 0, and then the contribution of l gives just something that's constant.
These two terms together give a function that does this, that is linear in time, maybe I
should draw it here.
This expression is what's known as the spectral form factor in the quantum chaos and random
matrix theory literature.
This answer we would have something which was, I think it's J1 of t over t squared in
this region, and then we would have something which was, it would intersect this, this looks
like t over l, that's the Fourier transform of this guy, and then at a time of order l,
it would become constant, a value of l, sorry this is value, this is just t, I apologize,
the value of this thing is just t, the value here is l, this corner here is at a time of
order l.
So this is the answer for this curve in GUI.
You could ask about it in GOE or GSE, and there what happens is that this linear behavior
is modified a little bit in this region here.
You would have a whole power series of 1 over l corrections.
An important feature of this computation is that it's in the random matrix theory variables,
it's a perturbative computation in 1 over l.
So for example in GOE, you have a whole power series here in powers of 1 over l.
For this reason, this part of the curve is labeled 1 over l, you're supposed to think
about this in 1 over l perturbation theory instead of 1 over n perturbation theory, and
these are very different.
So this is the thing that we have not understood, well okay.
So of course you understand the random matrix theory because you've computed it.
That's right.
So what is missing?
Of course, so you don't know why it's the same.
We don't know that, but yeah.
So the overall thing that motivates us, at least it motivates me, is to try to understand
for the black hole why these functions don't go to zero.
And so for that, the only tool we have for thinking about black holes is the 1 over n
expansion, where n is the big parameter, and we can think about other types of corrections
as a function of n.
Here we would like to understand, in this model, where we also have this 1 over n parameter,
we would like to understand somehow how that expansion becomes bad, or how in this model
you eventually have to think about a 1 over l expansion.
Well, I think you just make one very big comment, which is the other way, is when people get
that perturbation theory, they could not see these oscillations that you can see with
random matrix theory because you have orthogonal polynomials.
You mean oscillations in the row of e?
Yeah.
If I take a random Schrodinger operator, when there's perturbation theory in Copland constant,
for example, then you see a lot of what you're talking about, but you cannot see these oscillations.
However, if you go to an integral representation, which is, there are many ways to see it, but
if you write it supersymmetrically, then these are the contributions in the zones which are invisible for perturbation.
Okay, you're thinking about the oscillating term as a function of l.
Yeah, this is this Andreev-Altruller instanton?
Yes.
You're right.
Right.
Yeah, that's, right, so that's good.
So we have 1 over l, you have, so to describe this ramp, this region here, you would do
1 over l perturbation theory, but to describe this corner region in detail, you would want
to do e to the minus l, you would have to include e to the minus l corrections.
So this is an even, this is another level of exponentiation that we don't understand
how to get starting from these, starting from the theory where n is the big parameter.
So this is the type of challenge is to, is to try to compute, try to, try to compute
this curve.
I mean, for example, would you say that if I looked at that Hamiltonian, and I looked
at the level spacing in the bulk, then I would see GUE or GSE or...
You're talking about, for example, the nearest neighbor?
Yeah, we can do that.
You get extremely good agreement with that.
Yeah, yeah, you get fantastic agreement.
But this is probing much more than that.
The fact that you have this...
That's not just local.
Yeah.
This is more.
You're looking at...
You're looking at spacings that are like one over t, at time t here.
So the fact that we get agreement with this linear behavior for a wide range of times
is indicating that the pair correlation function is approximately like in random matrix theory
for rather large, for large distances in the bulk of the spectrum.
So that's, yeah, this is a stronger statement than just the short distance universality.
Okay, I can tell you the thing, okay, I can tell you one other thing, which is, which
I hope will be a way that we can actually compute this curve.
And it's also interesting because it has some connections to some other aspects of mathematical
physics, which is that there's a limit of this, of this SYK model where you take the
parameter q to be very large, and you take the parameter n to be very large with the
quantity q squared over n fixed.
So this is the double scale, what we call the double scaling limit.
And the theory simplifies somewhat in this limit.
And...
Yeah, that's right, this had been discussed in the context of a spin glass Hamiltonian.
Yeah, I'm not sure if they consider...
But it's not the whole hierarchy of reference integration, which you get in usual nearest
matrices or in mean fields, SK model.
Here there's only one configuration.
That means it's one step per unit matrices or whatever?
Okay, yeah, but this simplifies the model somewhat.
And, well, I'm not sure how much detail...
Well, I'm not going to go into much detail here unless there are questions.
But one can compute in this model...
Well, you can translate the computation of this ZZ star quantity into some combinatorics
question that I think can be answered using some methods that I'm just learning about,
using these q-hermit polynomials.
Roughly, you're summing over perfect matchings weighted by some parameter to the power of
the number of crossings of this perfect matching.
And these are the types of expressions that can be summed using.
Yeah, I can illustrate the case that...
Yeah, so let me say...
Yeah, this is...
Well, should I illustrate how one gets that starting from this limit of the model or illustrate
what the problem is that one is dealing with?
The problem or the...
Okay, so the problem would be the following.
So we would want to study a set of perfect matchings where...
Let's imagine that we have a collection of variables here.
Let's say we have M1 of these guys and we have some other number M2 of these guys.
And we would like to consider a perfect matching of these so we can connect like this.
And we can also connect like this and we can connect like that and so on.
So this type of thing.
Yeah, we could have like that.
The lines can cross.
Yeah, the lines can cross.
So we would be studying the sum over these types of perfect matchings.
And now we would define the...
We would want to consider the crossing number of this collection.
So the crossing number is the number of lines that we have to pass through each other so that we get things...
Maybe you guys should explain what the crossing number is.
Yeah, yeah, yeah.
Yeah, so the crossing number is...
It seems to be realizing the plane.
Sorry?
We don't have to do the planar realization.
Yeah, well, I think to explain the crossing number it's useful to think about planar graphs.
Yeah, but we would think about these things as planar.
Those are not necessarily planar.
They're not necessarily planar, but we can represent them as double line graphs on planar double line graphs.
But we could define the crossing without saying that.
It's just the number of times that we need to, for example, move this.
So we think about moving this point past that point and then we have something like that.
And each time we have to move a point past another point,
we get a factor of e to the minus 2 q squared over n.
And this counts, this doesn't require any factors and graphs like this also don't require any factors.
So the crossing number is the number of times, right, the number of lines that are crossing here.
And these lines are also crossing.
So we would compute the crossing number of the graph.
We would weight it by this factor and then we would sum overall possible perfect matchings.
And so this is the type of thing that can be,
I believe this is the type of thing that can be analyzed using these q-hermit polynomials.
This is something I'm unfamiliar with, but I've been learning.
And one case, yeah.
Does the analyze mean get an exact value?
Yeah, get an exact value for the sum over these matchings.
It's related to the form of this weight.
Yeah, that's right.
Maybe I should call it this q variable.
This is the q in the q-hermit polynomial will be related to this expression in terms of the model.
So one case where we have been able to analyze this,
actually there was a nice paper where they, which was how we learned about this method for the spin glass Hamiltonians.
And there, if one is, this is the computation for z and z star for this two partition function quantity.
Where these vertices are associated to z and these ones are associated to z star.
There's a simpler problem where you just have z and then you just consider these types of,
just one copy and these types of graphs and the sums of these perfect matchings.
And there it's easier and one can indeed write an exact expression for the sum of these things
that gives the right answers.
I mean we can check that it's the right answer by comparison to the large n methods.
So we would like in this model to, it would be very nice to be able to evaluate this type of sum.
And hopefully in this double scaling limit compute this exact curve.
Well, you mean in the double scale limit?
Yeah, it's different.
So good.
It's different in the sense that we've taken n to infinity.
So actually the curve will have to back off the limit slightly to say that we're including some things that are 2 to the minus n.
But so that can actually be understood already from the fact that these graphs are proportional to 2 to the minus n.
So the fact that we're just including these graphs is slightly illegal in the double scaling limit.
But we know that we have to include something that's 2 to the minus n.
And this is the leading thing and we sum these graphs.
So I believe that, I think that procedure makes sense.
So we would expect the part of the curve that's of order 2 to the minus n to look the same.
We would expect to have a ramp and a plateau in that theory.
So this is a way of computing z, z star?
Hopefully so, yeah.
It's at least a way of computing z.
And the matching problem is harder for z, z star, but hopefully we can also compute that.
Okay, this is the end of the sort of prepared comments.
So thank you very much.
It was a formula that Kitayev said he wanted to use.
A formula which had a cinch, but he had an SL2R in it.
And he said you had just proved something and he was trying to give a different proof.
Okay, yeah, that's the formula.
That was the formula for the Duster-Heckman thing.
Yeah, that's right.
That reduction to the integral over the first one was explicitly.
Yeah.
He wanted to do it in a different way.
Yeah, so.
You said something about puncturel measure.
That's right.
He was thinking about, yeah, this is actually, it's funny.
The naively this problem with the short scene derivative is,
so we're integrating over def s1 mod SL2R.
And then we have this action,
the short scene derivative of the element with respect to time.
So this is the functional integral one wants to compute.
We're just thinking about this as a quantum mechanics problem
and trying to understand the Hilbert space.
And the Hilbert space is, well, the phase space here is non-compact,
but that's sort of because of the SL2R.
And he was trying to think about a way of regularizing that SL2R
by using the plancheurl measure.
And I'm not sure if he's succeeded in that by now, maybe so.
But this, yeah.
He came to ask me and then I said I'll wait for your lecture
and he said you would explain what the problem is.
Okay.
Yeah.
So the problem is what?
To make sense of this measure or to...
Maybe to give another derivation.
So he would like another derivation where you think about this path integral.
Yeah, where you think about the path integral.
He wants to think about the Hilbert space.
So here we have a path integral we're computing.
He wants to think about this.
He wants to think about this as a trace of e to the minus beta h.
This is derived using coherent states, I suppose.
Which is derived?
The path integral.
Evaluated or derived from the model?
Derived from the model.
Derived from the model, it's a long procedure,
but no, it involves this disorder average,
the large n approximation of this partition function
and then going to low temperature.
That's a...
Yeah, deriving this action from the fermions is a long story.
Yeah.
So it was the...
Evaluating this integral into the first form that you're talking about,
that you have done...
Yeah, yeah.
So this...
And your method?
So there were two methods, actually.
The first method where I...
So I thought...
I thought that this would be a complicated function of this parameter here.
In particular, when this parameter is small,
it doesn't suppress large fluctuations in this field
and you would think that you have to sum over large fluctuations
and that this would be a complicated theory.
Now, we had computed this by studying these perfect matchings
and the double...
In the double-scaled...
You can argue that this theory is part of the double-scaled limit.
You can take a further limit of that, the triple-scaled limit,
which just isolates for you this partition function
and you get out of that,
you get this sinh, sinh of square root of E.
And then...
So that's one method.
But that's sort of weird.
Sort of...
I was very surprised by this because it...
Well, okay.
Then the third method is that you can just use the Duster-Mutt-Heckman theorem,
which was basically...
It was designed to be used for this problem.
And it tells you that actually this integral is what's called one-loop exact
in this variable,
where the saddle point approximation plus the determinant about the saddle point
is the exact answer.
And so these give the same answer.
So from this way, you find it's 1 over beta j to the 3 halves,
e to the n over beta j.
And from the double-scaled limit, you directly compute this row of E.
And then I promise that if you compute...
If you compute dE, row of E, e to the minus beta E,
with that row, you get this answer.
So...
And I think that Kitayev is trying to find a third method
where he thinks about this in terms of Hilbert space
and directly computes this...
Yeah, you would think about...
You would like to think about this row of E as a regularized measure
on this Hilbert space.
I haven't understood exactly how he's thinking about this,
but that's the rough idea.
Of course, I suppose this expression that you've got written there is not exact in terms...
I mean, the answer is exact, but it's not the connection with the quantum model.
That's right. That's right. That's absolutely right.
There are all kinds of approximations being made to get it.
Yeah, low temperature.
And so I think it's exact for...
It should be exact for low temperature.
So this means that beta j is much bigger than 1,
but it should be much smaller than, like, e to the alpha n
for some value of alpha.
So I think there will be large corrections to this analysis
when beta j gets so small.
That would be at least one source of corrections.
There could be larger corrections.
So part of it is just trying to understand what these other corrections are.
So if you had a Hilbert space, perhaps perspective, you could get it.
Oh, yeah, but no, he's just trying to study this theory.
He's trying to...
Yeah, he's trying to do this.
He's also trying to relate it to the flatural measure of SL2r, which is...
Is it close to that?
Yeah, yeah, very close.
And so maybe there's some way of taking his model.
The representations of SL2r which are unitary.
Or infinite dimensional.
And then there's a weight.
And there's a weight there in what's called a puncturel formula,
and that was computed by Bogman, probably, or somebody like that.
But the question, maybe he's trying...
There's nobody trying to put this...
The very first thing you put down is mayorana algebra.
Maybe there...
I'm sure that that's been put...
I think he studied a lot the representation theory of Diff S1.
Okay. Diff S1 or Diff S1 and mod SL2r?
I think that probably is...
That's kind of a natural thing in the Schwarzianness.
Okay.
So, okay, there was a cryptic comment which was told to me by a mathematical physicist,
which I didn't understand, which I think would be helpful if I understood,
which was that the Schwarzian is...
There are a family of commuting functions,
symplactically commuting functions on the space Diff S1 mod SL2r
that includes the Schwarzian, and then a family of other things
that are built out of Schwarzians.
Okay, is that...
Okay.
So, when people were working on integrals of a mass,
it's one dimension smaller.
This is the boundary of the hyperbolic plane.
And so Diff S1 acts there, and a functional integral like that
should be much easier to work with.
Okay.
This looks like a doable, almost doable mathematical problem.
Anyway, one understands the representation theory of SL2r.
Then people are trying to understand representations of a theory
of something like Diff S1.
Okay.
About the only infinite dimensional group, I think,
that is any kind of mathematical theory.
And a lot of it involves extending functions from the boundary to the disk,
looking at the functions there.
There's some regularization.
So, you've got some De Rousseau algebra.
Yeah, probably.
Yeah, well, I'm not sure...
You can use...
Yeah, you can think of Diff S1 mod SL2r as a co-adjoint orbit of the verse or group.
Sorry, he invented...
Ah, okay.
Okay, so he's the person who would...
Okay.
Yeah, this stuff is all very new to me, actually.
This is not my...
Frankly, I was shocked by the fact that this simple theory,
without any supersymmetry,
ended up sort of coming into contact with sophisticated mathematics.
And this is...
I think probably there's more contact than has yet been uncovered,
but it was a real surprise for me.
The naturally invariance properties...
Maybe this interval can be almost evaluated
by just invariance properties up to a scalarism.
I keep writing this functional interval down and say, well, it's...
Is the SL2r the only natural invariance...
There's also a U1.
Okay.
But as far as I know, that's it.
Maybe there's something more lurking.
You mean so you can see this directly in the model, in the final model or not?
You can see what directly?
The SL2r or SL1...
Yeah, you can see that.
That SL2r, starting from the original model,
is a gauge symmetry of the problem.
Yeah.
Well, thank you very much for a wonderful exposition.
Yeah, thank you. This was fun.
