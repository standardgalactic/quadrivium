okay so you wrote algorithms cannot be
creative by definition the human brain
can be creative therefore the human
brain is not just algorithmic yeah
that's a that's this is the most
important point I think I still stand by
that that's quite a good statement next
me hey everybody Welcome to Doom debates
today I've got a special guest Professor
Lee Cronin in this episode we're going
to debate Lee's claims about the limits
of AI capabilities and my claims about
the risk of Extinction from super
intelligent AGI it's what you come here
for so a little bit about Lee's
background he's the regious chair of
chemistry at the University of Glasgow
his research aims to understand how life
might arise from non-living matter he's
developed Innovative approaches to
creating lifelike behaviors in chemical
systems and in 2017 he invented assembly
Theory as a way to measure the
complexity of molecules and gain insight
into the earliest evolution of life so
Lee H how is that and uh whatever you
want to say try to elaborate on the Arc
of your research and your current
passion yeah thanks the intro the intro
is great um I am interested in
understanding how life
has come about Through Chemistry it
seems that chemistry is in the Paradigm
which life has come through but I think
there's three big question questions I
think the origin of life and the origin
of intelligence and the origin of
Consciousness and they all seem to be
related however as a chemist I can only
do with the fan cells part Al I thought
um but I'm I'm interested in
understanding how life is creative I
think that's quite important and also
the limits of explanation and
explanatory theories and that's why you
know I'm coming on to help you out about
the emotion of superintelligence we show
MC Bostrom coin it's always great to
coin a term that everyone grabs on to
but then when you actually question it
and we'll get to the limits of
computation and Mathematics on this and
but anyway um we can I'll let you lead
on that because I have very specific
questions that turn into very um
specific experiments and the thing what
I want to say is I'm an experimentalist
my believe in do Theory with experiments
and we can talk but talk is cheap if
it's not grounded in some kind of
falsifiable framework which is why I'm
really happy to do this stuff because
the more I talk to people who have got
interesting ideas the more I can evolve
my own ideas and then do bit new
experiments and then either confirm or
change the ideas verus the process of
science I think it should be done more
openly with more humility and also with
a little bit of Wonder CU I haveen no
clue how the universe works Well you
certainly have my respect for coming on
this podcast because I do think that you
and I are going to disagree on
intelligence and doom and we've engaged
for one or two back and forth on Twitter
and most people will you know they they
won't come on or they'll even block me
on Twitter but you have done the
absolutely respectable thing and come on
to engag so thank you for that yeah I
mean the tweets are fine right as long
as people aren't snaky or you know it I
think it's important to be willing to
change your mind and I hope you're
willing to change your mind or at least
um open up to the possibility of other
things being happening because I do
think there's a very important thing to
engage with culturally I don't think
it's okay acceptable to me say you'll
simply Rong without explanation or to
Grand or to make a statement
about um AGI or AG as I call it
anti-gravity help in suddenly and it's
all floating away we need to think about
these problems in a in a reasonable way
so I think it's going to be fun
discussion if we agree it would be
really quite boring why would it come on
exactly right that's the SP youjin the
Cronin PL I mean you know I think that
the most important conversations must be
about why we disagreed so what I'd like
to get out of this is really interesting
point of disagreement while I can go
away and do my
homework great I think it might actually
be interesting to start from your world
view and in particular assembly Theory
uh I can't say I'm an expert on it but
I've listened to a couple podcasts where
you attempt to explain it to a lay
audience so maybe give a give us a
really quick shot at you know my
audience isn't exactly a lay audience we
tend to be familiar with uh AI Concepts
and computer science a little bit more
than average but maybe take a quick stab
at just giving this the high level
overview of assembly
Theory yeah sure I mean there's actually
a paper we published last year in nature
that's open access it's not although all
the discipline experts went crazy and
said it's a horribly written paper
actually all the non dis experts the do
non doist were able to read it and
understand it just fine and so I can
point that direction M me but and also
if sh's image would be complicated is
not all asembly Theory does is says hey
there's this thing called causation that
seems to be present in our universe and
it appears the causation at canect from
the bottom up from the atoms all the way
up so that's the thir thing right so
that's one to say this is this concept
of causation if if you're a
mathematician or a computer scientist
and a philosopher you might subscribe to
the bertran Russell view when he says
you know Co ocean has the is like the
monchy it looks nice but it has no use
and that phrase always kind of wor was
kind of like wow you know as a chemist I
only work in the causal Universe
reaction start reactions end every
reactions end things live things die you
know there's a beginning there's an end
so what is sem Theory does let's go back
to the the question right because I'm
interested in questions it's like how
complicated does a molecule need to be
like how many different parts does a
molecule need to be uh for me to
conclude if I detect it in an amount
that I can count an abundance but it was
made by some process which required an
act of causation if you like like not
just a random mstom of Adams coming
together somewhere like actively process
be it genetic or technological or you
know or in a in in well I mean genetic
and something in a Cell cuz the only
process I know that BR NE are causal in
the universe um with information and
that's a very loaded term we should go
there seem to be from living systems or
the consequences of living systems like
a factory that can build something so a
really simple question hey I found this
C molu where do they come from I've
detected a thousand I identical copies
and there's too many parts for it to
come together in that quantity that was
the
start faced with this say I all right
let me have a look at the molecule can I
deconstruct the molecule and I realized
they could deconstruct the molecule on a
graph keeping the causal components on
the graph and say no you can't just have
access to the causal components unless
of there's some ordering and what
assembly Theory allows you to do is
basically break down any given object
mathematically precisely and order the
parts
cly using recursion and that's really
quite nice because uh um and I haven't
been able to really explain this to a
computer science audience satisfactory
until actually last few days whereever
the C re worked answer why is this not
and why is it not commo and the reason
not commo it has um CAU a proper
ordering which is related to the
physical reality the bonds W kolov has
arbitrary ordering depending the
language in which you're working that's
kind of cool right and something I want
to be a go for computer scientist on
because it's quite interesting cuz the
assembly index looks like it's looking
at compression it's not quite says it
says the assembly index so then you have
Ass Say Hey I can now
predi if your object has more than x
parts that it must have been created now
that is a really loaded phrase you think
you have problems talking to people who
think Doom it doesn't exist think about
talking to Creation s who want to then
say these things are creative so that's
the kind of start of this m i can carry
on and when but calls there let you come
back great lots to unpack there um I
want to go back to when you said um you
can't have access to the causality
there's some ordering um it made me
think you know Judea Pearl says you can
infer causality from statistical
relationships are you familiar with that
and how does that relate to sbly there I
know jud's work really well jud's work
is really about kind of understanding
causation CR different perspective using
statistical approaches and that's really
quite nice it's more consistent with how
we deal with things in our reality in
stat me but it doesn't give a caal
mechanism okay it gives you something
else that allows you to take your
information and I'm actually working on
some some some comparisons with Judea
pearls work now Judea pearls work tries
to solve different problems it's not
better or worse it's just different and
but CH is quite a genius that he's
realized that causation is important in
the universe and you caner evidence of
cation statistically and through Point
VI I very much agree but um technically
he has done some very interesting things
that are way above my my conceptual
capabilities I would say and so I I
don't want to be able to kind of talk
about his work with authority i' love to
talk to him about his work and
understand it but they are different and
there is like a statistical inference
rather than
mechanistic and build it okay great
let's take an example CU you mentioned
that you can use assembly Theory to
analyze a particular molecule's assembly
index and then you can also generalize
it to analyzing other systems like maybe
a biological organism maybe even a
software system can we just do an
example that's just like a robust simple
example to just illustrate uh how
assembly Theory can analyze something
yeah I mean if you take the molecule um
so if you take the mo you take the drug
Viagra or you take the drug or you take
the natural product taxo taxo is a
natural product as Span in the Pacific U
tree it has about 69 bombs in about
about 70 odd heavy atoms and it is quite
a complicated natural product with 47
carbons and a nitrogen atom and 14
oxygen I think I don't know I should
know the formula off by far but is a
complicated what we call secondary
metabolite and it's it it is made the
consequence of the genes present in this
bark right so in all the cells that
compose the surface of this
tree it's a secondary metabol Force what
is the purpose of taxo well probably
it's a signaling molecule or a toxin for
fungus or things that grow on the tree
and they just stop it from growing it
also hackers to be a very good
anti-cancer drug that you can make it in
high enough quantities you can use it to
prevent a vascularization of tumors and
car this molecule a lot because it's one
of the hardest molecules to make and
many years and many efforts of people
trying to make a a semi synthetic R and
then a synthetic R to taxo cuz you're
literally talking about probably a 100
chemical stat I think they've compressed
it now down to 50 or 60 but this is a
hard molecule to make lots of parameters
concentrations temperatures resed bees
purification so makeing this molecule is
a feat of engineering a k to somebody
building a very you know intricate
sports car right by engineering
standards if you like right okay so what
does assembly Theory tell us for
assembly if you take taxo you decompose
it the assembly inection taxo is 23
and um and that is a very large number
compared to what you can get randomly
the fresh old refer coin for organic
molecules on earth when we basically
survey random Commissioners that we make
in the lab and look in the environment
you don't you struggle to get anything
that has an assembly index above
12 and every number that the assembly
index goes out the space is at least
double exponential so that the space
throughout 12 to 23 is a universe or
more of commentarial space it is truly
ginormous so what is it about taxel that
pushed the assembly number above 12 so
the number so the taxo is very
unsymmetrical so when you cut it up the
parts so you don't get reuse easily
there's lots of you know um unique qu in
the in in the molecule and so there's
not that many repeat units is really
unique so despite of you could have had
a maximum assembly index of actually 68
because the maximum assembly index for a
molecule is n minus1 where N is a number
of bonds so you could you had maximum
difference would have been it would have
mean 68 but actually nature still
compressed it down to 23 which is quite
good but 23 which means there's still
some reuse in that molecule there's just
23 irreducible Parts if you
like okay now and I see why you compared
it to kogo complexity because it's kind
of like looking how comp complex or
incompressible a particular design is
but I think if I understand correctly
the difference is it's not just about
the information represented by the
molecule but it's also about uh the
process that made the molecule I think
that's absolutely right and I think some
people who kind of attack assembly
Theory said this and M very much
inspired by korov complexi and logical
deaths and all these um a different
technique so common grow off complex is
of course to short as program you can
make to produce something in logical T
de is the about the wrong time for the
running program to generate the object
both of these are require computers and
require some infrastructure but more
importantly CU Li you know triggers
people saying no no everything's
computational so that's fine but it's
more about the intrinsic ordering and
the fact there is a causal structure and
what you I've kind of been showing the
last few weeks is showing how say
Shannon
information or Shannon entropy and
assembly are diff Roots because Shannon
entropy doesn't capture causal
structure well when you say taxel has a
causal structure are you referring to
the process that built it yeah so the
really interesting thing that goes with
a 70 theory
is you don't when you get this complex
object and you basically Didu to it
complex right and you look at the
minimum path to produce that object is a
minimum is a bound that need to say oh
probabilistically this is where this s
kind of with kind of judea's kind of
type reasoning probabilistically
couldn't just form but what it does is
it gives you a depth in time the amount
of time that had to allat for that thing
for the universe or the system let's put
it to learn how to make it and so you a
by cutting up and having that ordering
you have that minimum and that gives you
a starting point in reality most complex
objects will require more information
than in the minimum band allows you to
compare it with the random background of
from point of view is very pous and it
allows you to be much more objective and
be independent of the language the only
thing that constrains things in in in
assembly Theory molecular assembly
theory is the bond the the bonding and
that is related to the laws of physics
and quantum mechanics and you go up a
level from say assembly theory of
molecules to say proteins then you take
it up another level which will be
folding and then you go to cells look at
the surface of cells and you go up to
language and also dare I say
intelligence we can get to that you can
look at the reducible parts of a pro of
the thing that produces the object as
long you compare them correctly you can
do sem
Theory great can we try an example where
we look at a piece of language like a
sent or whatever or a human or just
something that's like more abstract and
high level than a molecule and calculate
its assembly index you can but what I've
got to do I mean this could take quite a
long time the thing when you think about
this sing on a keyboard and a monkey
keyboard is a good one right so someone
typ you on a keyboard and an individual
make making a number of different parts
what you want to be able to understand
is when you have that sentence where did
the cation come from for a sentence that
causation has come from someone typing
on a keyboard intending to press a say
the big brown dot jumped over the lazy
cow right so now you can then take that
sentence and then say well look I don't
know the person did it and some did the
molecule got moaned but I can look at
the assembly index off the sentence and
then what I need to be able to do is
assert the copy number because there's
two really interesting things in the
strs of semi Theory each molecule is a
kind of is a scre objects you know with
the beginning and end you can hold the
molecule in your hand if you like with
text you've got to decide where your
what Your dmets are there is possible
orable to take do assembly theory on it
and actually work out when when text has
structure just from the repeat units
which goes a little bit further than
just using compression because you get
these causal structures out but this is
something that's working progress right
now so in this example sentence the big
brown dog jumped over the lazy cow if I
give you that sentence do you have to
know more information about where the
sentence came from or can I just give
you the sentence with no other
context my impression is you should be
able to give me the sentence with no
other context but we do need to
understand the context of the messaging
so I'm really interested in looking at
this but looking at say radio
frequencies and looking for information
Carl San style right if you want to find
um if some has somebody encrypted
information or are you receiving noise
is I think the answer to that comes in
one thing or one phrase the copy number
if I give you random
noise it's random noise and you draw it
and then I give you random noise again
and he identical you like one is weird
and I give it to you again and the copy
number goes up and it's truly random but
actually is more random because it keeps
repeating you know the something have
produced that random
process I hear it's just I guess I'm
just trying to put an input output
framework around this so like in the
case of kog complexity um you your
background assumption is maybe like a
certain model of computation like Define
how what mathematical structure a turing
machine is or something like that but
once you have that the input is a bit
string and the output is it complexity
right like a single number so like yeah
um yeah sure but the bit string is
infinite with respect to the language
basis so that you then it becomes if you
do the analysis properly becomes is
really quite complicated but what is the
language you wish you're going to do it
because the bit string then increases in
length your Bim size becomes bigger and
then it becomes um rather unwieldly so
again we very confident in this the
reason why korov doesn't capture um
ordering is it language dependent and
even though it goes to a bit string and
that's fine right now our technology
uses bit strings that's fine if we want
things as big strings you can compare
them using from approximations kov cuz
remember kolov is not in the limit
computable kolov is yeah yeah no I hear
you I me I'm just trying to clarify so
you have this concept called the
assembly index and it's going to Output
a number right like you gave the example
of outputting a output ordering of
causal causal issue and you can count
the number of things that are in that
ordering and then gives you a number and
then the B that is with respect to a
copy number so you've got this kind of
almost like this vectorial
representation in object space right
something like this but I know we're
still working on whatever
representation so I'm still a little bit
confused on what inputs does this
function require right because like we
use the example of like okay a sentence
can be the input but it sounds like you
might need additional context besides
the sentence so I'm just curious what is
the sum total of all the context you
need in order to get this output oh the
beautiful thing about assembly theory
molec is you measure it
spectroscopically you don't need to do
anything so like so look the so the
theoretical framework is take a
graphical take a representation of the
molecule aesthetic represent as a graph
chop it up into the parts where you in
this case we chose that hydr atoms are
exploders and look at number of parts
right you can do that that's a
mathematical process you can make a you
can write a computer program to do that
you can do it precisely it can take a
long time fine do it no difference but
then what you can do is you can actually
measure the assembly in mi in physical
reality using spectroscopy and other
things so this then suddenly start you
start say oh I've got a theoretical
framework which tells me about this
thing and I then can go and measure it
in reality and there is a correspondence
not only I can find the assembly indexes
in variant with respect to the different
technical measurements I use to measure
it so there's lots of different
techniques you can use different types
of spectroscopy that don't depend on one
another and that's kind of interesting
and it tells us we we're really homing
in on something it's kind of my favorite
um inspired by one of my collaborat my
favorite book I'm read is called
inventing temperature it's about the
measurement of temperature cuz people
try to work out you know what is hot and
cold is it objective does it re then
this is kind of a similar problem it is
wild to me scientists and computer
scientists and philosophers are still
not really making sure
understand what measurements are and
what a theory is what a model does and
what a computation is they're all subtly
different but they should converge right
and and the assembly the assembly theory
was born as a abstract measurement idea
in my head actually and now I realized I
could measure it before I built the
theory and and what happened after I was
measuring oh de I can measure it and I
built a theory if you like or built the
the algorithm to index I like oh I've
got this thing I can calculate I got
this thing I measure and they correlate
that's kind of cool and then we kept
going and going going showing how
correlat across rise spectrum of
different measurements and then arow you
to conclude that the assembly index is a
intrusive property of the molecule
whereas the commor of complexity is not
an intrinsic property of the thing
because you can rep you can represent it
in different languages and get different
comth complexities and that's what
that's why is it's it's hard it's really
subtle right this is you're asking super
good questions that are pushing even me
I want to make sure I'm even me in terms
of thinking about this clearly trying to
make sure there's no BS in the response
is just kept very clear so that's very
good so I like it great okay thanks for
that um yeah I feel like I could spend
more time on assembly Theory because you
know I'm I'm still a little bit confused
but uh what this here don't understand
so I I just uh I couldn't tell you the
input output still even after all that
what do you mean what what I mean the
input is a molecule and put is a
number I so I think I do get that on the
level of molecules but I'm confused when
we talk about uh things that aren't
molecules right like a sentence is that
the only inut well I mean so we're
working on that right I could BSU but
the input if you look at say if you look
at a let's look at a gene sequence what
are the the input is the gene what is
the output the assembly index of the
sequence a TGC so what You' got the
reason why I'm reluctant to be nailed
down to language is language is the
variation of the causal structure that
gives that is is non-trivial and um
although I have some Frameworks for this
what act is an active um area of
research right now what I can say with
certainty if I can measure the assembly
index of molecules I can measure the
assembly index of genes of proteins of
cells when you get up fire abstractions
you've got very you got to define the
objects and the copy number really
precisely and we've done some is with
some cryptography which is super cool
but I'm not ready to talk about because
I think I'll add more confusion than
incitement to the conversation so I take
what you I don't know either what the
best representation of the inputs and
outputs are I know the input has to be a
sequence of some way and I know the
output has to be a count of the
irreducibility of that and there has to
be a copy number with respect to that so
maybe you know maybe you'll have some
ideas what anging can come back to your
FL what about this example so I give you
a strand of DNA and it's just all A's
okay except like a thousand A's in a row
so how would you calculate it assembly
index if there's a thousand A's in a row
then it basically and they're all the
same or reducible then the assembly
index will be
one because in some sense you could have
just copied and pasted a thousand A's
and that's one step mean well the way I
would do it is actually re wouldn't be
if you gave me precisely a th000 A's and
it wouldn't be wor cuz what you do is
you start with a you double it you
double it again you keep doubling it and
the minimum doubling is to get you
precisely
1,000 if you able to give me a copy
number of those 1,000 a like say a th000
1,000 a then I be I could calculate the
assembly index to say hey that's
interesting you just given me a polymer
which has no distribution no statistical
distribution you give me a th000
identical copies with a th000
A's I have to also give you the copy
number in addition to giving you the
string of a th a so like I give you a th
A's and then I just give you like the
number three yeah like how does that
work well what you mean you give me
three those or or can we do an example
so so I give you a thousand A's and
you're like okay you also have to give
me a copy number so which copy number
might I give you for example you you the
sample you give me the DNA you give me
you give me a sample and I have to
measure
to measure it I can't just do I'm not
just going to do single local D
measurement am
I I don't know I don't know what you're
going to do I mean it's hard right you
can have to gu statistics so this is
where the subtle interplay assembly
theory is there is no causation without
copy number otherwise it's just random
this is the thing which fries people's
brains all assembly Theory does is say
hey if I can find an object that's
precisely cite has an abundance of
precision and mor ersity of
lung and I have identical copies and the
index is worth paying attention to if I
don't don't pay attention to S random
nonsense I can give you 10 A's a th000
A's sers have you six A's it makes there
is no causal structure the god there so
I and I think that's all it does right
and I think that's a super important
clarification so thanks for persisting
with
me okay um so I feel like I might be
beating a dead horse but like in this
particular example if I give you a th000
A's
what is the output going to be of the
assembly index well again you need to
give me so if you give me a th days I
don't have and it's just one strand of a
thousand a how do I measure
it and you mentioned maybe it's like
maybe you're going to take like the log
base two of a th000 because it's how
many doublings so is is that the answer
you can you're in the limit you can
estimate that but again you is about the
measurement in this case if you want me
to calculate the assembly index exactly
I can do that but I think I I think that
there's something more interesting that
you've got to assess the copy number
where did you pick a th a from okay so
that's an important thing that I have to
give you right I have to give you like
some description of where I got the A's
no you just have to give me the
sample it you so there's two things here
and then we probably should move on okay
and you could give me an
arbitrary object they just give me a
representation of gr for say calculate a
single index so was a th A or th000 B it
doesn't matter we there's the ass Index
right and it's a irreducible
representation to get there we start
with a main and just double double
double double when you do you get a th
it's easy and in the limit you can
calculate that no problem but doesn't
mean anything inless you can actually
measure that object I you have the
assembly index of every anything I could
calculate the assembly index of the
number quarks in my
class and it would be a lot but it has
no meaning if I can't precisely measure
it with the Wither the resolution which
I've done the C counting of the assembly
index and that's really important that's
what grounds it in experimental
reality okay all right got it uh you is
that a good place to leave it yeah I
think so it's good good it's good I like
like the Cushing great great great all
right Professor CR are you ready for the
next
segment do it hit
itom so Professor Cronin what is your P
Doom
for what the end of the universe the end
of the Earth let's say essentially human
extinction or all the value that we
might like to have in the future wiped
out at least 99% or 99.9% to like
basically a huge disaster for Humanity
and let's say on the time scale of just
uh by 2100 so the probability of that
kind of catastrophe by the end of this I
mean there
zero so there's just zero chance that
humanity is going to get wiped out by 21
well I mean so that's but that's
thinking about this logically the only
way that Humanity would be lock but be
entirely wiped out is if a catastrophic
object hit the Earth for of the sun
suddenly exploded I could imagine s or
we had nuclear Wars and other things it
would be very difficult to wipe out all
Humanity by 2100 not inconceivable but I
wouldn't understand how to put a
statistic on that you know one of my
favorite apps I've got on my f is called
am I going down which is a plate which
is is basically you look at your plane
you go to fly and you basically you pick
the worst there call the worst air plane
and the worst carrier and all say right
you know statistically if you find this
fly you know once what every day for 600
years you'll go down once whereas if do
then basically you know pick the best
best airline the best airport the best
plane you never go that you go you have
to fly for 26,000 years the problem I
have with these P do things is is
forcing me
to have some indic of the PRI but let me
you know and I mean I Scott Aron was do
like there's a 1% chance I'm like we
thought a 1% chance right human beings
have undergone catastrophic extinction
level events in the past right so did
neander TOS so you gain me very
precisely at
2100 so we are in
2024 right so we're talking about 76
years away great we can do the
mathematics properly okay
so the chance of human beings going
extinct every single human on planet
Earth by 2100 I think is very low if not
zero okay so I think I know the answer
but I want to ask you anyway would you
sign the statement on AI risk that says
mitigating the risk of Extinction from
AI should be a global priority alongside
other societal scale risks such as
pandemics in their
or um I so look to be to if I was going
N I would say no but be thoughtful I
don't
no um they nuclear war is worrisome I
don't want nuclear war I don't want a
catastrophic Runa away climate change or
anything that's going to happen I think
AI is currently posed doesn't feel like
that type of problem however I do not
think it is reasonable for me to rule
out the invention of a technology that
wouldn't Merit me signing a document to
say hey stop doing that right great and
I think that that's me giving you a an
unexpected Branch just look I don't
think AI that we have right now is it be
scary at
all but I that doesn't mean that we
might not invent something that we do
need to think about as containment I
mean let me make something up I don't
know a and I don't think we'll ever be a
to do this but um a virus who's just
good enough to replicate and basically
only kills humans after certain amount a
certain incubation Theory so we can go
around and cover everybody a bit like
omnicron omnicron might think infected
everyone on the planet and then
basically hit the ribosome and everyone
drops
dead there is a nonzero chance somebody
could engineer something like that it's
very exactly so it it sounds like you
you subscribe to this background
Assumption of like look it is still kind
of a fragile world right like eventually
the sun's going to burn not or if we
give it like 100 million years
eventually there will be like a major
asteroid impact right yeah I mean if you
give me so I oscillate on this I'm like
well someday a super Optimist to say
there is no challenge we
cannot overcome but the think Aran
because I think you know there are that
might allow us to not plan right why not
have a satellite de sorry why not have
an asteroid defense system is a great
idea if you have the resource why not
have ability to stop nuclear weapons
from going off and why not if there is
some technological intelligence that we
can generate that let's say it's
possible to generate that we wouldn't
want to think about how we would release
that and how we would use that in the
same way you don't want to release a
load of shach chemists you don't to
release false genene his really masty
gas you don't want to do anything like
that so I do subscribe to local FR
fragility but not necessarily global
agility I think some things will survive
but I'd rather the humans no humans died
that basically were all fine so from
that point of view uh I'm I'm with you
great and then bringing it back to AI uh
just for the audience's benefit that
statement on AI risk that I read it was
signed in 2023 by some Heavy Hitters
right Sam Alman Dario amade from
anthropic Nobel Prize winner Jeffrey
Hinton Turing Award winner yosua Benjo
so a lot of serious people across F
sorry to trup dude Heavy Hitters people
will what not train in philosophy who
don't really who don't really understand
the scientific
methods oh I mean if they well I I will
say the late the late Daniel Bennett
signed it so I think you got one
exception
there not fair I love Dan he's great and
and I would love to have argued with him
about it and but I
think yeah that's really interesting why
the hell did Dan sign it
hisory but yeah just just to frame the
discussion here so so a lot of Heavy
Hitters sign the letter in in 2023 so
basically the position you're going to
take when we talk about AI is like well
these guys mostly aren't trained in
philosophy and so they're just wrong
about seeing AI as a potential
Extinction risk well let me let me make
something up for you I'm afraid of
anti-gravity right sure I think it's
physically possible that somehow that
gravity could be turned
off and and um If gravity gets turned
off with going to Flo away this is a
risk right we can I can imagine the
risk how yeah the problem with is this
it's a low sensical risk with respect to
what we know about the laws of physics
that doesn't mean and and but but it is
a bit arrogant for me to say there is no
chance of AG but I think youd probably
agree that AG is not something that we
should worry about cuz then there's
another what about spontaneous water
boing I'm Sor yeah yeah no absolutely
right I mean so I I mean I I agree with
your framework right that like all of
these theories might make logical sense
and at the end of the day we just have
to argue like okay what is the evidence
inate is like the correct Theory
right alism and of the world I mean and
Jeffrey Hinton I like he was just Bing
stuff up I mean I I have no idea where
they came from like the fact you don't
understand how a neuron network works is
W to me absolutely wild that the creep
why he didn't actually create it but
let's say he did that he basically now
thinks that these systems are
intelligent
is beyond parody all right well I'd love
to unpack that claim cuz I think that
sounds like you're going out out right
because you said Jeffrey H doesn't
understand how that neural network works
so maybe to unpack that what I'm just
going qualify okay so Jeffrey hint he
either understands how a neuron network
works and if he does the statements he's
making about intelligence are are
actually um
disingenuous and be happy to talk to him
about it and I'll explain why and he's
not here defend himself because he goes
on and says there is this genuine risk
that the systems are intelligent right
now and that is that is not true that is
f look that's easy to
falsify and it comes out these people
think they understand what intelligence
is and he goes back to this argument of
like can we Define intelligence no I
might be going some way the other way
say how am I who am I to say these
systems are not intelligent and what I
can do is take a is about the limits of
probability so what you're saying is
like I understand new networks that
Nobel Prize well done I think it's
awesome that you got it by the way but
how they're aan and they're going to
kill us quite those two things are just
really weird it's like high so some
context about Jeffrey hinton's views
from the public statements I've listened
to one thing he observed is that a few
years ago he said that he got shocked
when was playing with the AI and he was
shocked at its ability to learn and
generalize and he even got the sense
according to his own words that it's now
better at learning Concepts than the
human brain and he was just shocked how
deep learning got to that point faster
than he expected and then furthermore
the kind of thing that he's worried
about is he thinks within a few years uh
to use his words AI might become a
master manipulator because it would just
learn you know the art of manipulating
humans you know the Makia valan Arts
basically uh and and just essentially
out of control like he's he he's even
floated a number like roughly 50/50
chance that he's just worried about a
scenario where we just keep building too
fast and it it goes out of control so
what do you think about that scenario
and then we can talk about I guess what
is
intelligence I actually don't disagree
with jeffree's worry about something
going out of control but it's not the
AI right the thing is what is going out
control is the human beings using the AI
to manipulate people right these
Technologies are extremely powerful and
there's no question but the AI doesn't
have any intentions or any agency I
explain explain that very simply in a
way that will cause um very good
discussion the the thing is the AI don't
suddenly develop an
intent and I think that probably what
I've observed with these and again I
mean I don't mean to be rude about these
guys but it I see like I'm seeing
emergence with new
religion right and there is basically
people saying AI is good AI is going to
save you AI is bad AI is going to kill
you and no one's actually saying what is
AI as we use right now and you're
absolutely right you and I we could get
some Bots together and we could put this
information on on it to it correctly
about an election or we could manipulate
some images to make people outraged
about something that clearly is a threat
but that is not the a i there is a h
there's a naughty human being in the
basement doing the thing and that was
been going on time in Memorial so why
Shing it said there now I would get
behind cuz I'm this is this is where I
agree with Jeffrey and Sam and all the
guys to say we need well as you don't
think Sam will agree with this the thing
I want authenticated users and
authentica if I have these in the public
domain I will be willing to sign a doent
to say hey guys the biggest threat we
have is that we don't have authentic
users authentic data we just we're just
stealing all this data doing all this
stuff with it and it's are we using it
to incite violence or whatever that's a
b but that's not the same thing is an AI
turning all humans and doing bad things
okay let's drill down into where you say
you don't see uh software having agency
or intent and there has to be a prime
mover and I think you would argue that
the prime mover has to be like the human
who ran the software or who created the
software is that your
claim I mean there's so yeah so I mean
for me the reason why I feel so
interested in this is like for me I'm to
understand the origin of life right no
origin of life no biology no biologists
no biology right no philosopher no
philosophy so beta this is causal chain
that connects us all the way back if
there's
no of light there would be no there
would be no technology right now and
that's that's really interesting and so
it's not just about the programmer or
just take not just about the user or the
prompter it's a person developed the
model the The Mechanical Turk that
interrogated that the person who
designed the semiconductor the person
who did the lithography and there's this
causal chain of objects all the way back
the basically put it in now I don't know
where intent comes from macroscopically
right now it's one of my big questions
right origin of Life origin of inin
origin of Consciousness and and I I you
know I I don't know what that is but
what I'm pretty sure is that when people
see intention in these Alber because
they're running they are actually seeing
crowdsourced intentions from that
happened in the past Let's do an example
scenario and then we can see how your
model of agency and intent can apply to
the scenario so scenario is pretty
simple uh imagine somebody builds a
rescue bot in the next few years and
it's kind of like a Tesla Optimus you
know it's like a humanoid robot and what
it's built to do is like pick up
patients from like the the scene of a
fire like maybe they're helping a
firefighter and they just want to rescue
somebody and they want to carry them to
safety and maybe safety is even like a
block away away from the harm okay now
safety bot you know maybe it doesn't
have intent maybe it doesn't have
Consciousness it doesn't have a soul but
it gets pretty good at accomplishing the
mission even if you throw up obstacles
so for example if there's like a lot of
rubble it it's really good at like
climbing around the rubble and maybe it
can even like put the person down and go
clear some rubble and then pick the
person up again and then if somebody
tries to stand in its way maybe can can
even like shove the person out of the
way right so it starts getting really
good at just getting to the rescue
mission so do you think there's any
intent in that scenario
no okay take a clock I wind up I design
the clock and I wind it up and every day
it keeps ticking and gives me the
time where and and it keep giving me the
time so the the difference between just
giving you a time and the scenario I
described is that you can notice you can
vary the initial conditions through an
exponentially large space of initial
conditions like I can set up the the
battlefield for this bot in so many
different ways and no matter how I set
up that initial Battlefield it's always
going to somehow route a path to the
same destination I can put Quark in lots
of different emission commissions and it
will still do the same thing I mean it
it the clock if I could put lots of
clocks together right say that they
somehow got some weights on them and
they work one another they also have
kind of interesting deviations so no I
mean it it's it is really important that
that that um it's clear that what we're
talking about here is a program that's
been written or developed or evolved
depending on how you want to do right by
a person with an intention to do a thing
mean I love mechanical
robotics though i' you seen these robot
arms where you can have a robot arm and
you pick up an egg right and the and I
don't EG I'll pick up my my my my
earbuds here right let's just imagine
this is the egg if I do the full speed
back um I can crack the egg but one of
my colleagues at Harvard a years ago
made an inflatable robot where they
basically the arms go down and they
flate around the egg and he just had to
use wrong press pressure actuation and
then the the elastic scissored without
pick up the egg without any false feed
back it just didn't crack the EG now
that's a beautiful example of a kind of
what I would call morphological
computation
were the material scientist could the
more the thought about the computation
was going to be done there there was
undoubtedly a computation done and they
didn't need any feedback orir
Electronics but it was able to come this
to could pick the objective of picking
up the egg without breaking it and so I
and and and again it was designed and
created and so I think that this is a
really important point that we can spend
a lot of time digging into it's like you
know there is a commentarial space and
and we can talk about when that
commentor space becomes really
interesting because there's that is a
limit what we don't understand right
where is what and what is
intelligence let's go back to the
example because it's I think we can
still squeeze some juice out of this
example of comparing my rescue bot
scenario with your uh clock scenario so
the thing about a clock is that it a
clock you don't get the sense that a
clock is hellbent on telling you the
time for example if I reach into my if
it's an analog clock and I reach in and
I perturb the dial so I set it 5 minutes
forward in time or whatever it's not
going to then reset its own dot right
it's just going to keep telling the
wrong time whereas Rescue Bot if I push
it over in the scenario Rescue Bot his
program to realize oh I'm going to do
better if I stand up that's going to
help my rescue right so it's hellbent on
completing the rescue in a way that a
clock isn't hell bent on get giving the
right time let me give you a Converse
take a
boy I don't know what American and boy
in the ocean that has a weight on it to
stay upright P you push it over it comes
back up
it's just physics you
ENC right so this is an interesting
example so so you might think that I'm
saying well doesn't the buoy have intent
to rise to the surface and my answer
would be the space of initial
configurations it's like okay well you
can give it like latitude longitude
where you put on the ocean and you can
give it an initial depth but that's a
pretty low that's a pretty tiny State
space compared to what I'm describing
with rescue that but you you've just
answered your question you're talking
about and actually the state space AR
that different you say when we start to
look at why where human creativity comes
from decision making it comes through
the fact that the the state spaces that
you search or you you you you occupy
they're just so big and so I I I mean I
I have sympathy for if your argument is
the robot's got a big space space of
things it has to solve for that's cool
isn't it I'll be like sure but the
program is controlling that
and also to you have to build a
contingency into that program because it
has to anticipate the UN anticipatable
but what it does is a is a local search
problem where it says if this happens
then that happens and this happens
within that state space it's very
deterministic when you Nest them all
together and you allow some variability
it looks
non-deterministic which is cool it gives
us emotional feedback you could even put
Eyes On In and little smile got oh look
at that lovely little robot isn't it
doing a good job by saving that person
you know sure do you think Rescue Bot
can ever get to the point where it can
solve the rescue problem as good as a
human teleoperating it could
do yes and and but again the human
encoded it to do that rescue bot didn't
emerge out of the sand it came from a
origin of Life LCA technology neography
so sure we're going to make M Rescue Bot
is going to get better better and better
and better and it should be a Save All
Humans so I mean I agree with you to the
extent of like when you look at
something like a rescue bot I do think
we can make the inference of like ah
something programmed this to be a rescue
bot right so there there was a preceding
important piece of causality and this is
actually similar to the the watchmaker
argument um here I even wrote a note
about this you know William P's
watchmaker analogy you know what I'm
talking about yeah so so right so you
find a watch maker or you find a watch
on an island and you look and you're
like okay this didn't just like wash up
naturally right from from Sand mixing
right like this was there was clearly a
I think I feel like I'm in your
wheelhouse right like there was clearly
a long causal process that that led to
this watch so and so I agree that you
can do the same thing like yeah Rescue
Bot didn't just you know spontaneously
arise so I agree with you there but at
some point if I'm just like surviving in
an environment with a bunch of Rescue
Bot doesn't it become kind of irrelevant
to how we're going to interact the fact
that okay they yeah sure they were
initially created by human progr but no
they are just really effective Rescuers
and the world you know and everybody's
going to get rescued right like isn't
that the
correct are disagree with that oh okay
okay great so I I guess maybe we're just
at this point maybe it just comes down
to a semantic disagreement over the word
intent because for me when I look at a
human and I say that human has intent I
I'm I'm not feeling a difference in kind
between Rescue Bots intent to perform a
rescue and my own intent to go get
myself some chocolate when I'm hungry
right I feel like they both fit a
similar type of
intent I think you're touching on
something super important that I think
you the thing that human beings will
never cease to amaze I think was um and
I would love to talk to you in about a
year once we get bored of AI as
currently conformed right um is it that
of course there's a certain amount of
behavior that you can just model right
hung it make people angry when they're
hungry is good fun but but if you give
Sun
enough um if You observe someone from
long long enough they do this thing you
were not expecting was not in your in
the data set do an out of distribution
thing right and that and depending on
how far at a distribution not we would
call that creativity and that creativity
is really
weird and there is no question the
current AI would say are showing that
humans aren't cre as as much as we think
they are right on some levels but other
levels they are incredibly cretive they
do things very different and it and a
very primitive way it has something to
do about the size of combinatorial
spaces you have available right to be
surprised by um so sure I can I can
probably guess what you're going to do I
do we things like I take different roofs
to work I might go clockwise one day and
clockwise why do I make the decision to
do that
where that come from it still fascinates
me then just a cell like a couple of
cells that you could just B bir from
them for a
parent should do the same things for
they don't they like why where does
intend that variability that kind
of come from well it comes from
obviously from genetic differences and
microscopic environmental difference but
is that all there is is there no
hysteresis in the bra in the sorry in
the cell
yeah let me zoom out out of it because I
want to make sure that I understand and
the listeners understand kind of the
highlevel position where you stand on
artificial intelligence so maybe let me
ask the question like this like what do
you see as the barrier or the separator
between software intelligence and human
intelligence and do you think that
barrier is going to last forever or when
do you think that barrier is coming
down I do not know how to define incum
intelligence right now I mean I have a I
have an idea I'm writing a paper on
it with my colleague and I don't want to
give too much away but we should
definitely talk about it because it has
something to do with assembly Theory but
right now I would like to the fact that
we found it really hard to Define life
right this is what happened the oriz of
life I could see the same thing
happening in intelligence and think what
happens is because everyone had an
emotional response to what they created
so I'm say and and obviously you're not
these guys you'd have to really get the
Mellow and say look you had an emotional
response why did you have emotional
response and we do have feelings in
votes but coming back to what
intelligence is I find it hard to Define
what the human intelligence is and also
I do not think that the the word the
term artificial intelligence is actually
a gross
misrepresentation I would call it I
would just call it I don't know
autonomous
informatics now why do why autonomous
and why for well exactly go back your
your your rescue B thing I programmed it
I've made it autonomous then get Char
away and do stuff that's good and it's
processing information in the
environment it doesn't need to come back
to me it just doesn't say so three the
word autonomous infomatics removes all
the all the anthrop
anthropomorphisms removes the emotion
removes the things that are H that
humans are projecting onto things and
it's just the thing
now I think I can ask you I think I can
ask you a question where we don't even
the answer doesn't even depend on
semantics you know choice of definition
it's just a question about predicting
reality for instance a question like hey
100 years from now what is a human job
or task that you still think humans will
do better than
AI a human what task are
you all right right yeah exactly oh
poetry music um all all these things um
you know um creating new
technologies finding the next gener and
every there is not to the thing is and
this is my number one comment I have to
make which I really um I've thought very
carefully before coming on about how to
put this across where hopefully I would
win as many friends and influence people
in a good way rather just be obnoxious
and just say I I I I do like using AI
tools certain things what is AI to great
thing for is great for taking historical
data there and telling me all about it
and just interrogating it so ai's fault
is backward looking intrinsically right
and so I think that AI tools in the
future going to be you so will the
parrots of the future be using AI tools
sure why wouldn't you you be using it to
augment your your the processes that
we're going through the CES so I think
that and lots of tasks will look
automatable in the short term and AI
just fails to do them because the educ
cases are just there forever right and
and yeah can we unpack the the music
example uh because you know I find it
pretty surprising that you're predicting
that 100 years from now humans are going
to be better than AI at music but it
sounds like you're maybe you're making a
weaker claim to that maybe you're saying
maybe in 10% of times when you need
somebody to write you a song there's
going to be 10% of times that the AI is
not going to get but it sounds like
you're kind of admitting that maybe 90%
of the time the AI will be fine so let
me be qu qualifi I mean on my group away
day a few months ago they made an AI
generated song and it was brilliant and
but they they but they gave a prompts
they gave it prompts from the lab of
things they were doing and so what AI
will do like any CH it will lower the
barrier for Creative people to do things
and I think then you know you and I we
could go right at s light and I used to
write a lot of electronic music I like
doing it it's cool but why use AI tools
that hell yeah I can explore spaces I
use cursor right now because cursor just
allows me to not dig into a rabbit hole
dependencies just asly you're not paying
attention your ADHD is really bad today
here's quit you me run it and so these
are tools it's a bit like you were going
how did you use a test tube as a chemist
you should hold the hot stuff in your
hand I can only it burn right so going I
I I know you call it a toy guard yeah
what I mean is so going back to the jobs
I think that AI will basically are our
people to have much more access to doing
these creative things at a level it says
m s good and it's not saying that we
won't use them of course we'll use them
I mean we get textiles made of stuff I'm
not saying they're not there I'm just
saying the human is always going to be
in control okay well okay hum's going to
be in control but just the question I
was asking to be precise is like let's
say it's 100 years from now
and I just want a little jingle like the
segment of this podcast where it asks
what's your P doom and I made a jingle
for it I used AI to help me let's say I
use a human composer and I interact with
the human composer over slack or Discord
right because it's a virtual you know
they're working remotely and I just say
hey here's my requirements and maybe
they ask me a question and I answer the
question and they send over an MP3 and
that's the jingle now you're telling me
100 years from now I can't replace the
human with an AI and get an equally good
work product yeah I think so and here's
the thing right now I see a tendency
right now if you look online all the
websites are the same all the reg
generating art is the say if you want to
make a good podcast 100 years from now
sure you could get cheap stock stuff but
you want and and and you want that
little Edge that edge may look smaller
and more tangible I'm guessing so I'm
willing for you to change my mind but I
just w't see any evident so it just
feels like you're not extrapolating the
the progress of AI from like last year
today extrapolate that forward 100 years
it sounds like you're kind of just
acting like it's the same as it is now
yeah no I can prove on the back of of an
envelope why it isn't going to go up
it's a data training issue right like
we're just at this ASM toote of what we
can do with um the technology we have
right now now is that because there's a
technology technological limitation or
we only can get so far at faking some in
of creativity I don't know right what I
will say
is very happy to cons well not not
conceding it I would use the tools but I
think human beings will be doing what
we're doing today last week we might
have moral made we might not be doing
some things like what what job was
happening 50 years ago you wouldn't want
to do today right there's probably Lots
right you know lots of
Labor so I I think that there is that so
I think that there is on the creative
side human beings are going to be always
better than
AI fair enough okay that's another topic
I'd like to dive into here uh let's see
so you actually tweeted a couple years
ago so love that you're coming on the
podcast so I can bring up your old
tweets what did I say now oh so okay so
you wrote algorithms cannot be creative
by definition the human brain can be
creative therefore the human brain is
not just algorithmic so let's unpack
that why can't algorithms be creative
yeah that's that's so this is the most
important point I think I still stand by
that that's quite a good statement
that's me so what is an algorithm tell
me your definition of an algorithm so we
make sure we're grounded sure so high
level it's following a step-by-step
procedure and then we have to talk about
okay what is a procedure what is what
are the building block procedure yeah
we're not not wanting to like got here
this just like everything yeah yeah well
the nice thing is that today because we
have computers it's pretty easy to be
like hey we're not even talking
abstractly it's like I can just open up
a python editor and whatever I can type
that passes a syntax check that's an
algorithm yeah I I think that's fine um
and if you if you're talking about what
creativity is now let's define
creativity now for me sure
creativity or novelty we can do the two
things so if I find some or something
let me get as right iwh go be as precise
as possible if I let's say I discover an
object that is basically I have no
Preston in my data set right for me I
mean like that is the most novel object
that's come into my data set maybe I do
a distance measure when I say I start
with an empty set everything I put in by
definition model to start with but I put
in a pineapple I put in a banana I put
in an apple but then at some point I'm
like oh I'm starting to I've exhausted
the the the fruit so I can right they're
all they all look the same up picked up
another grave there just a slightly
different grave is moldy or whatever so
basically the elements I could in my set
right I when you're generating data
algorithmically or you're processing
data
algorithmically
creativity or is saying there needs to
be some creative input from somewhere
now I think this is where a lot of
machine Learners get them themselves
their P get them beit there get things
in a bit of a pickle because it's like
saying that it's a bit like good get
nothing something from nothing if I take
a data set and then I use that to create
another piece of data there's a causal
relationship between that using the AL
the inputs from
somewhere if that outcome has always
been Interpol from my data set it's not
really creative it's already there
now maybe I could interrogated the data
set in a creative way and I get
something out that every surprises
everyone that's possible right there's
some of them but in principle what I
think I'm saying is that is it the of
you you something creative has to happen
to you interact you with that data set
the systems are creative on their own
and because you don't you can't generate
something from nothing it's dependent
upon the data there in the system that
you've
built okay well so now I get curious
about like okay I wonder how did the
creativity even enter the human brain so
let me ask it to you this way can a
simulate ated brain on a silicon
substrate be creative it doesn't appear
so and I'll tell you
why the problem is a brain has about I
don't know is it is it 100 billion 120
billion year neurons say let's say
trillion neurons right and the way the
neurons work is that each neuron is
about 10,000
connections and those connections are
moving in real time so this statement is
kind of important there are more or
possible Connections in your
brain then there are atoms in the
universe more
possible and so what seem to be
happening is as you interact you you're
getting in sensory information your
brain is constantly shifting and shaping
and doing stuff right Thum boring some
Lovel but the fact your brain has access
to that configuration space produced by
Evolution grow morphologically and all
this stuff means your brain is literally
able to do things you cannot correctly
model yet
I had a project in my lab called kinet
where I'm trying to make a chemical
brain and I reckon the best way to get
to creative stuff is to actually make a
a chemical brain there's nothing magic
in the brain right now other than we do
not understand how the brain is able to
Traverse these korial spaces but silicon
is hard and you can't reconfigure your
silicon so the resources required to
basically simulate a brain and just just
just exually large so it's just a large
problem it's an energy problem as well
so I guess so I'm I'm a really deep
materialist I don't think brains are are
very very you know well they are the
most complicated thing in the universe
we know which is kind of amazing right
and I think that you know even Nvidia
you're making some damn good Hardware
are making Hardware anyway near the
complexity or the configurational
accessibility of the brain and that's my
only argument really I mean I I think
we're getting to the point where the a
trained modern AI uh you know with with
trillions of Weights potentially could
be thought of as a more complicated
object than a human
grain so let's unpack that bit I think
that a trained AI with trillions of
Weights lots of
parameters um is
certainly
incredibly um
powerful and it and
remember object is the compressed out
come all billions of people's creative
input put de on into there and recorded
and then and then and then interrogated
as so I I'm I'm as probably as excited
as you are about using these tools to
get to that stuff because there's so
much in there but I don't think
accessing that and novel wave
itself is any more creative cuz the poor
humans are probably now deceased there
put what information in there were the
people that did the creative
creation yep yep yep H yeah and and that
that's you know that that could be right
I mean I was just making the point about
how if you're just measuring by
complexity and you're saying look how
complex the human brain is I think that
argument is losing
steam no I I think the human brain can
do something quantifiably different to
these models right by many orders of
magnitude and I'm going to and hope what
it looks like I'll give you a tip bit
let me make a prediction within two
years for now I'll be able to able to
produced
technology that will be a to tell the
difference between human creativity and
AI
creativity wow that would be great
because we could really use that for a
capture I mean yeah and I think it's
super important is not so disimilar to
how assembly Theory tells difference
between um randomly produced molecule
and a moleculees go through lots of
steps and a copy number the way AI
interrogates the space by having enough
entropy or temperature gives you very
cuz Aros are probabilistic machines
right right now we G AI machines we use
okay and so there so that's as far as I
want to go to the moment I think it's I
think you've asked very good questions I
don't disagree with basically anything
you've suggested you haven't tried to
twist my words which is great and and I
do agree with you and maybe the only
point of disagreement and it's not even
that significant is I think that these
models are much less sophisticated to a
human brain but they do do great things
and there but there is a lot of captured
information in there that we aren't even
beginning to touch and that's why
Jeffrey hint and everyone else got so
excited and I want to clarify your
position so basically I mean so you say
you're a materialist so you definitely
think so you don't think that there is
some level where God is like Whispering
creativity into the human rign you you
do think it's all based on physics right
not the physics we have right now is not
quite right so the only thing that ever
say is different just to be clear is I
think that time is real to this is where
basically I can it aside like maybe this
is going sound pretty
insane Einstein invented relativity he
invented it introduced it there wasn't
for Einstein inventing relativity when
we started throwing satellites into
space we would see the stats frame
dragging and they were losing time be
like why is on that we would added
corrections to get there but there is
this abstraction this underlying
structure that we understand to be
relatively right now we are building
systems that look creative we don't
understand what's going on and there is
there is a missing thing and I'm going
to make a suggestion what it it sounds
very hugis and the people that don't
like what saying you're going to jum as
they be ar I don't mean to be I'm just
saying the universe is like this in time
and so this the future is always bigger
than the past so the future is always
nor cut able with respect to the Past
because it so be and that's where
creativity finds the edge the transition
from the past through the present to the
Future because the future is
open-ended it's so exciting to live in
the present and if you are going on and
that that's why I think that we are kind
of stuck cuz we've mind the past as R go
and it looks really great but I'm are
going to argue that we're never ever
going to be able to because time is a
physical thing and this is where a lot
of these problems come from so so the
only add-on to materialism is I think
that physics right now has a
misinterpretation of time and the only
thing that would change my materialist
I'm a materialist who thinks time is
fundamental not a emerging property so
sorry God yep it's just to repeat back
to your claim here you're saying that
and I think you said this explicitly
before that no matter what algorithm we
write even if it's a huge algorithm with
a ton of memory doing a ton of
operations the fact that it is an
algorithm means it can never do the kind
of creative outputs that you could
potentially get from a human brain
correct and I mean and the discontinuity
here is to say you know human brain is
not magic it's physical exists in time
and we should be a reduce everything to
some kind of algorithmic procedure
therefore so by the way also it it
sounds like you're disagreeing with the
church touring thesis is that
right and no so yes and
no in the limit of the universe
yes in little pockets where I C capture
things where have a resource available
no it works just fine and so this is a
thing the only reason the only reason
that creativity is not computable is
because we don't have sufficient
resources in the present to predict the
future that's all that's
it okay all right uh Fair us I I get
that that's your position and then going
back to what you said that you're hoping
to produce a program that can
distinguish human versus AI creativity
let's unpack that a little bit because
if I go to a website and they're worried
they want to make sure I'm a human right
so they give me the capture test and
today I think it works by detecting like
what do your mouse movements look like
and what information do we have about
your IP address right so they're
combining all these signals but those
are becoming more and more fak by AI so
you're hoping to essentially have a
better capture where maybe a text box
pops up and it says give me a creative
answer to this question and a human type
something in and then your program can
be like ah yes this was a human answer
is that basically what we're talking
about it possibly I think a little bit
more sophisticated or R but yeah I would
say I mean we're going to get better I
mean the the thing is computers are kind
of a low dimensional output right for
humans humans do lots of things
non-verbal communication singing sighing
rolling your eyes M progression backro
aggressions all this stuff you know um
but so I think that we might need to do
a bit more than that but yeah I mean I'm
really fascinated by this problem I'm
really excited that we have these tools
I you know I'm I'm not a and I I don't
think it's a problem I think the only
Pro thing I have a problem with is the
one concept that we should perhaps
discuss it's super
intelligent that is the only thing I
have a real problem with where people do
and there just because people just
making up okay interesting so I
guess we I I kind of got stuck on your
claim that you don't even think uh any
algorithm even a really smart algorith
that we take 100 years to invent you
think even that algorithm by virtue of
being an algorithm is not going to be as
creative as current humans because
something that the current human brain
is doing can't even be described as an
algorithm so once you said that I guess
I didn't even think to ask you about
super intelligence because you kind of
already said hey we don't even have
regular
intelligence let's practi it I
think I think algorith so any algorithm
that is
computable kind of now
right um with the resource
available is is never going to be as
creative as human brain cuz human brain
actually is the ultimate algorithm
novelty minor that is using the resource
available everything available the
problem you have with your current
algorithm is you don't have enough
resource and the only difference between
the human brain and your current
algorithm is is just a resource
accessibility you've got all my neurons
moving around doing all this
morphological neuromorphic Computing
whereas my my poor algorithm combined
and my silicon is constrained somewhat
so I think it's probably a difference of
um computability and resource
availability um and that I think I would
love to dig into and think about there's
so many research projects here so I
wanted to qualify that because I think
it's a really important I could be wrong
I need to think about it more but you
know was if through my brain that could
be a if I could do froze froze me now
look at my brain and took it apart and
you could express it as now and by the
way I think you do acknowledge that what
you're saying about brains I would say
this is a non-mainstream or even a
fringe position right because you agree
that the mainstream position about how
humans are intelligent is because
they're running a good algorithm
no I mean I think the whole problem with
this is like is that we're trying to put
our technological Concepts as an
ontology for understanding nature and I
think this is a one thing that I would
like to mention that I'm already
learning cuz I'm not a very good FL and
the Dan dennit would definitely agree
with this and maybe Dan dennet was
having a bad day we've going to you got
to tell the difference between the
anology and and the kind of the the way
that we use knowled is that you know the
universe is not a computer but the
universe allows us to build things to do
computation now some people say no
actually the universe is a computer and
and then you have this kind of argument
back and forth about what we mean by
computation
and so an algorithm for me needs to be
containerized in some technology and
needs to be executed and
run and I think and it isn't it you know
the braid is a l but is quite a large
size and I would argue to make a brain a
make a technology is kind of as good as
my brain or maybe not mean they say your
brain your brain is for a younger better
than mine it's going to require a lot of
resource probably more resource than
Humanity has access to right now
okay and you know as I'm trying to step
into your shoes and see the world
through your eyes about how Okay brains
are doing something that no algorithm
can do if I just think about an average
person in the last 24 hours what was
this non what was an example of a
non-algorithmic thing that their brain
did in a typical person's average 24
hours and the reason I'm asking about a
typical person's average 24 hours is
because you'd think if a natural
selection evolution by natural selection
would select this wonderful trait this
non-algorithmic intelligence think it
would show up in a typical day it's our
imaginations our ability to have the
counterfactuals and all that stuff
course damage human and B is doing this
all the time but we are being compressed
into low dimensions in our digital media
so we're becoming kind of obsessed with
what we say but no I mean with
counterfactuals imagining new things
coming up new stuff yeah but but but in
terms of outputs right like so for
example like let's let's say that my job
is to flip a burger and I'm like hey
when I flip that burger I just imagined
like I was flipping it over over the
clouds but that didn't really help me do
the job better than an AI right I guess
my question is like when when does the
average human on an average day use a
skill that AI don't have I think that
happens all the time and I think
counterfactuals happen to humans all the
time in selection you can see that
counterfactuals have causal power and I
mean I will think about this in combat
but I think let's not let's not insult
the average human average human is
thinking about maybe new partners a
birthday part
worry about trying to get money for
their education solving problems about
it whilst they're flipping the burger
there are mechanical things that AI can
do sure but the average human is doing
so many things in their mind with their
imagination maybe thinking about some
art idea they've come up with or maybe
thinking about how to solve a problem
because they've got this complex social
issue out when they got friends that
don't all of one another and try to find
a way that they can find an angle for
them to be at the party together there's
so many things the average human is
doing cognitively
psychologically and creatively it's not
possible to compress them down into
Burger flipping sure if everybody you I
mean I think that's kind of it's the
average human even when they're flipping
a BOS do so much
more great okay nice we're coming up on
the end of our time here um if if
there's any other topics you want to
cover I'm happy to go a few more minutes
or uh do do you think you you we hit on
everything you were hoping for well let
let me just tell you about
superintelligence why it's
ficing it's a superintelligence is a
fiction because what has happened is
someone has said there could be this
thing that just have access to some
Physics is able to solve problems in a
way that you can't conceive now what is
that saying that's saying that this
entity has access to Mo reasoning physic
mathematics that you can't even have
soly cuz if I take my you know my
favorite pocket calculat I love
calculators right I'm always buying
calator
is oh an HP
right I a few
other I love it school was there my C oh
nice another one you know look I didn't
think I'll be showing you my my my I was
a big fan of the ti 89 in high school
because it was right before anybody ever
had a smartphone and I love smartphones
so that was like my smartphone proxy
that that's cool I mean I love her these
calculators so the thing is
superintelligence is like saying this
new this s kind of faster than light
information transfer way of doing stuff
whereas actually what we know what we
mean is faster intelligence and when
everyone is use superintend me all they
can help sink and out do if you look at
that carefully that's not super that's
just far and we do lots of things faster
right you know Al Alpha go zero B you
know
um the best PR in the world it but
because they had infinite compute PS of
energy displayed it but if it was a like
for like s it wouldn't be as the the the
the the system did not do anything the
human didn't do cuz hum built it and so
what I'm trying to say is to say hey
guys when we talk about super
intelligence what is it we mean do we
mean the faster information processing
totally by that's possible do we mean
kind of access to data that we might
have access to in new sensors totally by
that's possible but do we mean breaking
your laws of physics and coming up the
new ontology that's not possible and
that's what Nick kind of puts into
everyone's Minds as a little is a little
mindworm which I think if you listen to
David Deutsch and I think David Deutsch
is probably the greatest living
philosopher right now physic he would
explain very elegantly much better than
I can that why supero is just
nonsensical from a very good epistemic
VI I was actually going to ask you
because a lot of your claims I noticed
do dovetail a lot with David de AI
claims so and in your mind David Deutsch
is basically right on all his AI
claims I mean right I know all these
claims I this makes sense to me and I I
so this is where we go into AI science
right because also you want to do AI
science here's a worry but people just
basically collect data or compress the
data down and infer something to me
science requires an idea a leak to
generate kind of and SP error actually
the section will give you and then you
got that idea you then mechanistically
work that out and the work of how to do
an experiment and collect data so I have
an idea I do an experiment I collect
data and then I and then if I use my AI
That's great CU it just helps me get the
data what I see right now is lots of
people are skipping the idea and the
abstraction and the framework and
they're just randomly getting stuff and
compressing it down and that is not
science and so I think that David and I
agree on that we agree on super
intelligence but I mean there are some
things that David thinks about the
multivox I don't think are right because
my conception of time and David are
different but I think is very thoughtful
it's very interesting I've been doing a
lot of thinking I'm just a chemist right
it burns stuff and and makes stops so
I'm no I'm no guru on this but what I've
tried to do is just say hey what do you
mean by a super intelligence help let's
unpack it if you mean it's just the
faster computer and GRE they thoughts of
K that's just a faster
computer yeah I I'll give you my
response to that which is like yes there
is a difference of just degree if you
zoom out far enough so if you zoom out
far enough when we talk about
intelligence yeah we're talking about
vast search spaces where yes if you
could crunch through every single
element of the search space if you had
enough time then you could have a dumb
algorithm solve it but the problem is
the dumb algorithm needs to run like 10
to the power of a Thousand Steps right
like way longer than there's ever going
to be time steps in the physical
universe so you need a shortcut and then
the caliber of the intelligence the IQ
is basically how good the shortcut it
always comes up with is like that's
basically what intelligence means to the
heart of our difference which is really
cool so you think there's a search space
and I can I think that the human beings
create a collapse search spaces all the
time and some of those search spaces
until they're cre on searchable and
there's a thing that we go for yet we
don't understand the physics of this is
not yet
done I'm close to it who Walker it's you
but it's not done and it's something
that is exciting for us and we could be
wrong right you know it's okay but I
think that the the cracking the origin
of life I mean I would say it's in such
a broken record the origin of the
problem of the origin of life is similar
to the problem of the oses of
intelligence and
Consciousness understanding all of that
will go will will get together and I
think that I love what people have done
in AI I love the the what people have
done I'm not a fan of Jeffrey him and
just basically carrying his goost
complex but now he's got a cry maybe
he's right maybe he invented the AI the
AI is like screw you I'm going to see if
I can give the my cre the Nobel Prize
and that's proof of
AGI right right right right um you know
I I guess I do want to throw in one last
question for you um if you can think
back to your mental state around let's
say
2019 have you been surprised by the
outputs AI is able to deliver it these
days like would you have predicted in
2019 that there was a decent chance that
AI can be writing these thoughtful
essays right responding like if you give
it a giant paragraph of text it can like
you know analyze uh you know your the
quality of your argument like all these
things AI is doing or like the image
generation right like generating a
picture that meets your requirements
like is this surprising to you no has me
surprises I 12 years old well 12 years
old I used stop sess in my backyard you
the pavement cracks I get tracing paper
and i' Trace the crack
and I try to minimize the I want a basic
take take the rough trajectory the crack
and I literally try and come up with
algorithms that we compress that crck
down and B and allow me to get there and
for me it's always be very visceral that
we're going to do this it's incredible
to be able to do it um am I
surprised oh so I guess I'm surprised by
the engineering Fe that it is the fact
that it works so well I think is is
somewhat surprising in the fact that we
went through this big leak in technology
it's almost like we went from just about
flying with the right Brothers in the
air as fly was possible we're just going
a lot further a lot faster so from that
point of view I guess if IED back I can
be surprised no I was very surprised at
all when chat when y marus saying chat
gpds and I was like what's that again I
was like Oh okay that's cool there's no
useful enough to use cool I'll use it
the reason I ask is because like today
when I ask you to draw the boundary of
what AI can do you give me answers like
hey in a 100 years that last 10% of
drawing a great picture or writing a
great song that last 10% AI still won't
be able to do it and I can't help
suspecting that if we were to go back to
2019 and I asked you to draw the
boundary to sort problems into things AI
can do by 2024 and things AI can't do by
2024 yeah I just feel like you probably
draw the line in a different place you
wouldn't be like ah yes by 20 for 90% of
image generation to spec will will be
solved you know no I so I think is about
different kinds so I think that um I
think that what we need to do in 100 G
if takeing AI right now with no
developments right or just kind of what
we have technologically without
understanding what intelligence is and
how the brain works we're not going to
make least in a 100 years time will we
have artificial consciousnesses in
inject chemical brains somehow
fabricated probably possible is it 100
year or 500 year problem I don't know
depends if we solve origin of life I
guess so what I'm say right now if I
extrapolate the current semiconductor
Revolution and we're just cranking and
just building more on models and
tweaking no nothing different can to
happen because the deck the data the
cost of compressing the data human minds
are able to build abstractions that
don't exist in the current and when you
say all the quality of the argument
there is no argument it is fake all the
AI is doing is reading other arguments
that other people have made and
presenting it back to you in a way that
you don't notice and that we will get to
it that is what we'll see and actually
will become quite stale quite quickly
like I mean you know I see students
writing aays and bullet points and just
like oh my God whoever put the bullet
point thing into chat GPT right you know
I used to use bullet points to describe
things not anymore because most his
bullet point is something out right
right but I think misses the point I and
I and I think the thing where I've got
the most out of AI tools is where I put
a lot of thought into generating with
the stuff I put into it and then use the
culus of human knowledge to correct it
or help it enhance it from that point of
view AI is an amazing tool and I I
wasn't quite expecting for that shift
but it but it's within the existing
category is not Elite we need to go to a
different kind of technology and I don't
know what that's going to come forol but
is it cting we you know we we're
discussing it we're thinking about it I
think there's a lot more to happen and
uh yeah you know it's been fun CH yeah
absolutely it's been great to hear your
world view now uh to wrap these things
up you know I never go in with the hope
that I'm actually going to change the
other person's mind just because I he
continuously disappointed uh but my hope
for these conversations is to uh
illuminate for the audience and for each
other what the other person's view is
because views can be very subtle so to
recap uh what I think I've learned about
your view and the Crux of disagreement
between your view and my view is you're
coming out it from an interesting
position I I would call it an early stop
on the Doom train I often talk about the
Doom train where you get to the end of
the train and you conclude that we're
doomed and at the beginning of the train
you have to first get through
assumptions like hey there's going to be
super intelligence it's going to be
better at pretty much everything than
humans so you seem to be getting off at
a very early stop on the Doom train
where you don't even think that an
algorithm could be as creative as humans
today and you're not expecting to ever
see super intelligence and you have a
lot of the same views as David deuts so
today I've learned that you get off on
such an early stop on the Doom train
that the normal concerns people talk
about like once you have super
intelligence it's going to show it's
going to be power seeking it's going to
manipulate humans those things just
aren't concerns because you've just
gotten off on the first steps where it's
just not even going to be that creative
in the first place Fair yeah yeah
absolutely but I think you you know you
we thought about a lot of other things
like hope hopefully my the Nuance of my
interpretations of things and what we we
agree on F or what we disagree on the
other thing I learned about your
perspective that was a little bit
surprising is you you you're connecting
a lot of things together that aren't
that I don't think are standard to
connect together so in particular you're
saying like solving the problem of the
origin of life on Earth is going to give
us insight about how the brain is
intelligent
right yeah absolutely something life is
doing about mining the future is what
we're doing right now and the Mystery
every that's the kind of sole purpose of
my kind of life if you like is to find
out what that mystery
is cool all right Noble purpose and once
again huge respect for coming on and
debating that definitely puts you in
rarified air that you were brave enough
to come into what I like to call the
Lion's Den so thanks again it's been
great chatting with you really nice to
take part I had fun and for you the
viewers I'll see you back here on the
next episode of Doom debates
