deliberately deceptive. Once they realize getting&nbsp;&nbsp;
than us, we'll be more or less irrelevant. We're&nbsp;&nbsp;
one of the world's most brilliant minds comes to&nbsp;&nbsp;
to humanity? Professor Geoffrey Hinton, winner of&nbsp;&nbsp;
President and Engineering Fellow at Google, spent&nbsp;&nbsp;
that power today's AI systems. Indeed, in 1981,&nbsp;&nbsp;
seminal attention mechanism. However, Hinton is&nbsp;&nbsp;
want to hear. Our assumption that consciousness&nbsp;&nbsp;
is patently false. My name's Curt Jaimungal,&nbsp;&nbsp;
part because my degree in mathematical physics&nbsp;&nbsp;
a professor and several of his former students,&nbsp;&nbsp;
my classmates. Being invited into Hinton's&nbsp;&nbsp;
honor. Here, Hinton challenges our deepest&nbsp;&nbsp;
Is he a modern Oppenheimer? Or is this radiant&nbsp;&nbsp;
are missing? What was the moment that you&nbsp;&nbsp;
our means to contain it? I guess in early 2023,&nbsp;&nbsp;
chatGBT, which was very impressive. And the other&nbsp;&nbsp;
about ways of doing analog computation to save&nbsp;&nbsp;
was just better. And it was just better because&nbsp;&nbsp;
Each copy could have different experiences, and&nbsp;&nbsp;
their weights or averaging their weight gradients.&nbsp;&nbsp;
system. Is there anything about our brain that has&nbsp;&nbsp;
much lower power. We run like 30 watts. And the&nbsp;&nbsp;
about a hundred trillion connections. The biggest&nbsp;&nbsp;
almost a hundred times bigger than the biggest&nbsp;&nbsp;
about scaling that is a disadvantage? So you said&nbsp;&nbsp;
nourishing or positive can spread. So can&nbsp;&nbsp;
can be replicated quickly. So we say that that's&nbsp;&nbsp;
If you have multiple copies of it, they can all&nbsp;&nbsp;
reason GPT-4 can know so much is you have multiple&nbsp;&nbsp;
And by averaging the weight gradients, they could&nbsp;&nbsp;
have one copy experience the whole internet. That&nbsp;&nbsp;
do that because we can't share efficiently. Scott&nbsp;&nbsp;
Hinton, I'd be very curious to hear you expand on&nbsp;&nbsp;
analog hardware so that they can't copy themselves&nbsp;&nbsp;
like. If I want to get knowledge from my head&nbsp;&nbsp;
change the connection strings in your head so that&nbsp;&nbsp;
And that's a very inefficient way of sharing&nbsp;&nbsp;
So we can only share about 100 bits per sentence,&nbsp;&nbsp;
bits. So the problem with this kind of analog&nbsp;&nbsp;
guess, if you're worried about safety, is it can't&nbsp;&nbsp;
about an AI takeover or AI dominating humanity.&nbsp;&nbsp;
exactly what it looks like. But to have AI agents,&nbsp;&nbsp;
sub-goals. And one path that's slightly scary&nbsp;&nbsp;
is to get more control. Because if you get more&nbsp;&nbsp;
if they're just trying to do what we ask them to&nbsp;&nbsp;
best way to do that. Once they realize getting&nbsp;&nbsp;
than us, we'll be more or less irrelevant. Even&nbsp;&nbsp;
irrelevant. We'll be like the sort of very dumb&nbsp;&nbsp;
people. Hmm. I want to quote you. You said that&nbsp;&nbsp;
say, can't we just turn off these machines? Like&nbsp;&nbsp;
we can just turn it off. Imagine these things are&nbsp;&nbsp;
read everything, everything Machiavelli has ever&nbsp;&nbsp;
literature of human deception. They'll be real&nbsp;&nbsp;
learn that from us. And they'll be much better&nbsp;&nbsp;
your words, then you can get whatever you like&nbsp;&nbsp;
That the AIs are already manipulating us? There's&nbsp;&nbsp;
that AIs can be deliberately deceptive. And they&nbsp;&nbsp;
data from on test data so that they deceive you&nbsp;&nbsp;
evidence they actually do that. Yeah. And do&nbsp;&nbsp;
that? Or that's just some pattern that they&nbsp;&nbsp;
still some debate about that. And of course,&nbsp;&nbsp;
up. So is it your contention that there's a&nbsp;&nbsp;
Okay. So most people, almost everybody in fact,&nbsp;&nbsp;
something that they don't have and will never&nbsp;&nbsp;
that. We have consciousness or sentience or&nbsp;&nbsp;
confident they don't have sentience. But if you&nbsp;&nbsp;
I don't know, but they don't have it. That seems a&nbsp;&nbsp;
don't have it without knowing what it is. So, I&nbsp;&nbsp;
of that as like the thin end of the wedge. If you&nbsp;&nbsp;
people would be less confident about consciousness&nbsp;&nbsp;
experience. When I say, suppose I get drunk,&nbsp;&nbsp;
of little pink elephants floating in front of me.&nbsp;&nbsp;
what that means, and I think it's a completely&nbsp;&nbsp;
an inner theater, and in this inner theater,&nbsp;&nbsp;
only I can see them. That's the sort of standard&nbsp;&nbsp;
perception is concerned. And I think that model&nbsp;&nbsp;
fundamentalist model of the material world. Maybe&nbsp;&nbsp;
made 6,000 years ago. That's just nonsense, it's&nbsp;&nbsp;
to believe, it's just wrong. So I think people's&nbsp;&nbsp;
take, again, I have the subjective experience of&nbsp;&nbsp;
I'll now say exactly the same thing without using&nbsp;&nbsp;
it goes. My perceptual system is telling me&nbsp;&nbsp;
word subjective. But if there were little pink&nbsp;&nbsp;
system would be telling me the truth. That's it.&nbsp;&nbsp;
subjective or experience. So what's happening is&nbsp;&nbsp;
that to you by saying subjective, and then in&nbsp;&nbsp;
system is trying to tell me, I tell you about a&nbsp;&nbsp;
that if the world were like that, my perceptual&nbsp;&nbsp;
let's do the same with the chatbot. So suppose we&nbsp;&nbsp;
can point, and it has a camera, and it can talk,&nbsp;&nbsp;
an object in front of it, and we say point at the&nbsp;&nbsp;
when it's not looking, we put a prism in front&nbsp;&nbsp;
front of it, and say point at the object, and it&nbsp;&nbsp;
the object is. The object's actually straight in&nbsp;&nbsp;
lens. And the chatbot says, oh, I see. The prism&nbsp;&nbsp;
there, but I had the subjective experience it was&nbsp;&nbsp;
subjective experience exactly like we use it. And&nbsp;&nbsp;
have subjective experiences. If you mess up their&nbsp;&nbsp;
one way, and it'll actually be another way. And&nbsp;&nbsp;
is, they'll say, well, they had the subjective&nbsp;&nbsp;
so they already have subjective experience.&nbsp;&nbsp;
other things. Consciousness is obviously more&nbsp;&nbsp;
they think it means, but it's got an element&nbsp;&nbsp;
element, which makes it more complicated. But once&nbsp;&nbsp;
experience, I think you can give up on the&nbsp;&nbsp;
about us, that they will never have. And that&nbsp;&nbsp;
there's a difference between consciousness and&nbsp;&nbsp;
self-reflexiveness to it, but some consciousness&nbsp;&nbsp;
this, and at present I don't want to get into&nbsp;&nbsp;
in there and say they have subjective experience.&nbsp;&nbsp;
does that not imply that it's conscious? Like&nbsp;&nbsp;
Where is the subjective experience being felt?&nbsp;&nbsp;
subjective experience being felt? That&nbsp;&nbsp;
experience that somehow, if you ask philosophers,&nbsp;&nbsp;
little pink elephants floating in front of me,&nbsp;&nbsp;
pink elephants? They say they're in your mind.&nbsp;&nbsp;
philosophers have told you they're made of qualia.&nbsp;&nbsp;
and floating qualia, and not that big qualia,&nbsp;&nbsp;
qualia glue. That's what many philosophers think.&nbsp;&nbsp;
mistake. They think the words experience&nbsp;&nbsp;
I've got a photograph of little pink elephants,&nbsp;&nbsp;
photograph? And what's the photograph made of? And&nbsp;&nbsp;
of little pink elephants, you can ask, well,&nbsp;&nbsp;
And what's it made of? It's made of qualia. But&nbsp;&nbsp;
the words experience of worked the same way as&nbsp;&nbsp;
the way that works, or subjective experience of,&nbsp;&nbsp;
the experience of is really an indicator that&nbsp;&nbsp;
by telling you about a hypothetical state of the&nbsp;&nbsp;
referring to something in an inner theater. When&nbsp;&nbsp;
an inner theater as well. Like if you say,&nbsp;&nbsp;
like there's this you that's seeing something on&nbsp;&nbsp;
that's the wrong model. Yes. You don't see your&nbsp;&nbsp;
in, your brain does a whole bunch of processing,&nbsp;&nbsp;
what's out there in the world, but you don't see&nbsp;&nbsp;
representation a percept. You don't see that,&nbsp;&nbsp;
forever trying to think that you have the external&nbsp;&nbsp;
then you look at what's in the inner theater. It&nbsp;&nbsp;
or neurologist who thought that the pons had&nbsp;&nbsp;
self-consciousness has to do with the default&nbsp;&nbsp;
is there a part of an AI system that has&nbsp;&nbsp;
understand even my own terminology when I'm saying&nbsp;&nbsp;
the GPU? Are we saying it's the algorithm? What&nbsp;&nbsp;
subjective experience? So where is it? I guess&nbsp;&nbsp;
running it, and it's going to be that system&nbsp;&nbsp;
to be conscious, software by itself, it has to be&nbsp;&nbsp;
be conscious. The Economist has actually spoken&nbsp;&nbsp;
before. Links are in the description. As you know,&nbsp;&nbsp;
of the most reality-spiraling concepts from&nbsp;&nbsp;
emerging technologies. To stay informed in an&nbsp;&nbsp;
a wellspring of insightful analysis and in-depth&nbsp;&nbsp;
and beyond. The Economist's commitment to rigorous&nbsp;&nbsp;
world's most significant developments, whether&nbsp;&nbsp;
tectonic plates of global politics. The Economist&nbsp;&nbsp;
the headlines. What sets The Economist apart is&nbsp;&nbsp;
and engaging, much like we strive to do in this&nbsp;&nbsp;
knowledge and gaining a deeper understanding of&nbsp;&nbsp;
recommend subscribing to The Economist. It's&nbsp;&nbsp;
you won't regret. As a listener of TOE, you get&nbsp;&nbsp;
Economist and all it has to offer for less. Head&nbsp;&nbsp;
TOE, T-O-E, to get started. Thanks for tuning&nbsp;&nbsp;
mysteries of the universe. Software by itself&nbsp;&nbsp;
I would have thought, to be conscious. What I'm&nbsp;&nbsp;
that was started. I think a good way to think&nbsp;&nbsp;
going to be like when they're embodied. So,&nbsp;&nbsp;
people are busy trying to build battle robots,&nbsp;&nbsp;
if a battle robot has figured out where you're&nbsp;&nbsp;
be in some dark alley by yourself late at night,&nbsp;&nbsp;
when you're least expecting it and shoot&nbsp;&nbsp;
reasonable to talk about what the battle&nbsp;&nbsp;
battle robot believes in the same way as you&nbsp;&nbsp;
robot might think that if it makes a noise,&nbsp;&nbsp;
think that, in just the way people think it.&nbsp;&nbsp;
to creep up behind you and shoot you. So,&nbsp;&nbsp;
to use words like believe and intend and think is&nbsp;&nbsp;
And already it's disappeared to quite a large&nbsp;&nbsp;
chatbot, and it starts recommending to me things&nbsp;&nbsp;
and then after a while, I figure the chatbot must&nbsp;&nbsp;
me all these things about makeup and clothes&nbsp;&nbsp;
so I asked the chatbot, what demographic do you&nbsp;&nbsp;
girl. When it says, I think you're a teenage girl,&nbsp;&nbsp;
thinks, right? In normal language, you say, okay,&nbsp;&nbsp;
say, you don't really believe that, okay, it's a&nbsp;&nbsp;
if it thinks I'm a teenage girl. You don't say&nbsp;&nbsp;
use thinks when we're dealing with these systems,&nbsp;&nbsp;
them or obvious hardware associated with them.&nbsp;&nbsp;
So we're already attributing mental states to&nbsp;&nbsp;
state. So we can attribute mental states to them,&nbsp;&nbsp;
is to have a mental state. We think of this inner&nbsp;&nbsp;
having a mental status. How much of your concern&nbsp;&nbsp;
were not conscious or did not have subjective&nbsp;&nbsp;
accelerate the catastrophe? I think the importance&nbsp;&nbsp;
relatively safe, makes most people think we've got&nbsp;&nbsp;
that makes us feel much safer, much more special.&nbsp;&nbsp;
not safe. We're certainly not safe because we have&nbsp;&nbsp;
the real problem here is not so much a scientific&nbsp;&nbsp;
misunderstand what is meant by having a subjective&nbsp;&nbsp;
show that you can use words. You've got a science&nbsp;&nbsp;
the words horizontal and vertical mean. I mean,&nbsp;&nbsp;
they mean. And if I show you something, that one's&nbsp;&nbsp;
difficult. So I'll now convince you you actually&nbsp;&nbsp;
wrong, but there were significant problems,&nbsp;&nbsp;
the terms horizontal and vertical. OK, here&nbsp;&nbsp;
of little aluminium rods, a large number, and I&nbsp;&nbsp;
turn and bump into each other. Then suddenly I&nbsp;&nbsp;
are within one degree of vertical or more within&nbsp;&nbsp;
Say it's approximately the same. Right, that's&nbsp;&nbsp;
they're surprised when I tell you there's about&nbsp;&nbsp;
horizontal. That's kind of surprising, right? How&nbsp;&nbsp;
is vertical too. One degree of rotational freedom.&nbsp;&nbsp;
But so is this. So horizontal has two degrees of&nbsp;&nbsp;
So, here's something you didn't know about&nbsp;&nbsp;
and horizontal's two a penny. That's a bit of a&nbsp;&nbsp;
2D, but in 3D they're very different. And one's&nbsp;&nbsp;
you know that? Well, I'm going to give you another&nbsp;&nbsp;
of little aluminum disks. And I throw them all up&nbsp;&nbsp;
into each other. And suddenly I freeze time.&nbsp;&nbsp;
vertical or more within one degree of horizontal,&nbsp;&nbsp;
times as many that are within one degree of&nbsp;&nbsp;
this is vertical, and this is vertical. This&nbsp;&nbsp;
only got one degree of freedom. So, for planes,&nbsp;&nbsp;
penny. And for lines, vertical's very special and&nbsp;&nbsp;
example of, you have a sort of meta-theory of&nbsp;&nbsp;
wrong, even though you use the words correctly.&nbsp;&nbsp;
state terms, terms like subjective experience of.&nbsp;&nbsp;
what other people mean when they use them. But you&nbsp;&nbsp;
this inner theater with things made of qualor&nbsp;&nbsp;
it then about a theory of percepts or subjective&nbsp;&nbsp;
for you to say, well, I'm more on the correct&nbsp;&nbsp;
them as, think that these subjective experiences,&nbsp;&nbsp;
have to be made of something. That neither of&nbsp;&nbsp;
experience, that's an indicator that I'm now&nbsp;&nbsp;
world that isn't true. So it isn't anywhere,&nbsp;&nbsp;
notice the big difference between saying,&nbsp;&nbsp;
just hypothetical and isn't actually anywhere.&nbsp;&nbsp;
the world. Versus, I'm talking about something&nbsp;&nbsp;
Those are two completely different models. And&nbsp;&nbsp;
funny stuff, I think is just completely wrong,&nbsp;&nbsp;
about someone like your fellow Nobel Prize winner,&nbsp;&nbsp;
tell you a story about Roger Penrose. A long time&nbsp;&nbsp;
of Toronto and give a talk about his new book,&nbsp;&nbsp;
introduce him. The dean called me up and said,&nbsp;&nbsp;
sure. And she said, oh, thank you very much.&nbsp;&nbsp;
should know what I'll say. And she said,&nbsp;&nbsp;
Roger Penrose is a brilliant mathematical&nbsp;&nbsp;
mathematical physics. And what he's going to&nbsp;&nbsp;
view of Roger Penrose's view of consciousness.&nbsp;&nbsp;
is, now I have to think how to say this carefully,&nbsp;&nbsp;
The issue is, can mathematicians intuit things&nbsp;&nbsp;
would be very worrying if mathematicians intuition&nbsp;&nbsp;
every time, that'd be really worrying and would&nbsp;&nbsp;
they can't. Mathematicians have intuitions,&nbsp;&nbsp;
So it doesn't really prove anything. It doesn't&nbsp;&nbsp;
how mathematicians work. And I don't see any&nbsp;&nbsp;
things like consciousness. AI is doing a pretty&nbsp;&nbsp;
These chatbots, as I just argued, if you give&nbsp;&nbsp;
There's nothing about people that requires quantum&nbsp;&nbsp;
the Penrose argument that relies on mathematicians&nbsp;&nbsp;
they could intuit correctly. If they're guessing,&nbsp;&nbsp;
it right, the answer to these questions that&nbsp;&nbsp;
answered within the system, then that would be a&nbsp;&nbsp;
Why don't you outline what his argument is,&nbsp;&nbsp;
as I understood it, the argument is, there's&nbsp;&nbsp;
computation isn't going to explain consciousness.&nbsp;&nbsp;
based on a funny notion of what consciousness&nbsp;&nbsp;
consciousness is. A second is that mathematicians&nbsp;&nbsp;
proved, and that shows there's something funny&nbsp;&nbsp;
funny going on unless they intuit it correctly&nbsp;&nbsp;
Chinese room experiment. I have. What are your&nbsp;&nbsp;
it for the audience. Okay. So, back in about 1990,&nbsp;&nbsp;
Searle, and I called up my friend Dan Dennett&nbsp;&nbsp;
you know, he will try and make you look stupid,&nbsp;&nbsp;
room argument. So, I agreed to be on the program&nbsp;&nbsp;
an hour-long interview. The very first thing he&nbsp;&nbsp;
so of course he has no problems with the Chinese&nbsp;&nbsp;
connectionist. And so he then says, so he&nbsp;&nbsp;
which was, we'd agreed not to talk about it, and&nbsp;&nbsp;
I've got a lot of problems with the Chinese room&nbsp;&nbsp;
a deliberately deceptive argument. I think it's&nbsp;&nbsp;
saying, there's this room full of Chinese people,&nbsp;&nbsp;
identify, yeah, we could make a system made of&nbsp;&nbsp;
other in Chinese, and as a result of all these&nbsp;&nbsp;
send in an English sentence, they'll send messages&nbsp;&nbsp;
of the argument. And they'll be able to answer&nbsp;&nbsp;
people sending these messages around understood&nbsp;&nbsp;
a program. But they do it by sending messages in&nbsp;&nbsp;
the argument is, he wants you to think that,&nbsp;&nbsp;
individual Chinese people sending messages. So the&nbsp;&nbsp;
Chinese people sending messages don't. He wants&nbsp;&nbsp;
understand English, because the people inside&nbsp;&nbsp;
system understands English. That's what I think's&nbsp;&nbsp;
something that many AI researchers didn't predict&nbsp;&nbsp;
terms of AI development. So how do you feel about&nbsp;&nbsp;
they're quite caught up yet. They're very close,&nbsp;&nbsp;
by trying to prevent them having the latest NVIDIA&nbsp;&nbsp;
And what that's going to do, if the embargo is&nbsp;&nbsp;
to develop their own technology. And they'll be&nbsp;&nbsp;
got better STEM education than the US. So they've&nbsp;&nbsp;
they're going to catch up. Do you know who Marc&nbsp;&nbsp;
him about more or less everything, I think. Okay,&nbsp;&nbsp;
that said, I don't understand how you're going&nbsp;&nbsp;
from the government about how the government&nbsp;&nbsp;
hand, we can lock it down, quote unquote. Right.&nbsp;&nbsp;
out there, it's being taught everywhere. To which&nbsp;&nbsp;
War, we classified entire areas of physics and&nbsp;&nbsp;
branches of physics basically went dark and didn't&nbsp;&nbsp;
going to do the same to the math underneath AI.&nbsp;&nbsp;
There's no way you're going to be able to. Now,&nbsp;&nbsp;
in 2017 could have decided not to publish&nbsp;&nbsp;
before anybody else came up with the same idea.&nbsp;&nbsp;
But I don't think there's much hope in, I mean,&nbsp;&nbsp;
information getting out there. It'd be very hard.&nbsp;&nbsp;
some, what would it be, linear algebra? No.&nbsp;&nbsp;
share certain kinds of information,&nbsp;&nbsp;
just think it's implausible that they could take&nbsp;&nbsp;
them, prevent anybody else creating them. What&nbsp;&nbsp;
there's a zeitgeist. And within that zeitgeist,&nbsp;&nbsp;
often happens that one person has a new idea,&nbsp;&nbsp;
independently, except they're sharing the same&nbsp;&nbsp;
version of the same idea. This is going on all&nbsp;&nbsp;
zeitgeist, you're not going to be able to have&nbsp;&nbsp;
years later, somebody else is going to come up&nbsp;&nbsp;
So that's a huge topic. Some people would say,&nbsp;&nbsp;
person who wants access to an atomic bomb. Yes,&nbsp;&nbsp;
say, well, that's what is required in order to&nbsp;&nbsp;
is where we have multiple different decentralized&nbsp;&nbsp;
decentralized. So let's talk about sharing&nbsp;&nbsp;
a bomb? It's because you need fissile material,&nbsp;&nbsp;
a lot of time and energy to produce the fissile&nbsp;&nbsp;
much easier to make a bomb. And so the government&nbsp;&nbsp;
there. You can't go on eBay and buy some fissile&nbsp;&nbsp;
atomic bombs belonging to tiny states. So if you&nbsp;&nbsp;
The equivalent is a foundation model. That's been&nbsp;&nbsp;
maybe a billion dollars. It's been trained on lots&nbsp;&nbsp;
If you release the weights of that model, you can&nbsp;&nbsp;
think it's crazy to release the weights of these&nbsp;&nbsp;
on bad actors. And Meta has now done it,&nbsp;&nbsp;
late now. The cat's out of the bag. But it was a&nbsp;&nbsp;
of our latest AI boom is because of Transformer,&nbsp;&nbsp;
other large breakthrough, either some paradigm&nbsp;&nbsp;
I think there will be other large breakthroughs&nbsp;&nbsp;
science works. I don't know what they are. If I&nbsp;&nbsp;
though? Well, I'm too old now. I have students&nbsp;&nbsp;
your past contributions to this field and you have&nbsp;&nbsp;
it? So here's the issue. AI is very good for lots&nbsp;&nbsp;
Like better healthcare, fighting climate change,&nbsp;&nbsp;
superconductors, where AI may well be involved in&nbsp;&nbsp;
out there. So there's so many things, good uses of&nbsp;&nbsp;
be stopped. So I don't think it's sensible to say,&nbsp;&nbsp;
development. It's not going to happen anyway&nbsp;&nbsp;
just not feasible. It might be the best thing&nbsp;&nbsp;
we should be doing is, as it's being developed,&nbsp;&nbsp;
So it's another thing to say that this is a&nbsp;&nbsp;
to also be responsible for pushing the boulder&nbsp;&nbsp;
was a breakthrough on the horizon that you see,&nbsp;&nbsp;
predictive quality, that you would actually put&nbsp;&nbsp;
was combined with working on how to keep it safe,&nbsp;&nbsp;
how dangerous it was going to be. I wish&nbsp;&nbsp;
Einstein about the atomic bomb. He said,&nbsp;&nbsp;
developing would lead to the atomic bomb. Do&nbsp;&nbsp;
should. I don't kind of regret what I've done. I&nbsp;&nbsp;
don't think back and think, oh, I wish I'd never&nbsp;&nbsp;
I don't think we have much choice about that,&nbsp;&nbsp;
and between companies. So I think we should focus&nbsp;&nbsp;
that's very different from trying to slow down&nbsp;&nbsp;
what does safe development of AI mean? Okay.&nbsp;&nbsp;
risks. And there's many of those, and they all&nbsp;&nbsp;
autonomous weapons. And to deal with that,&nbsp;&nbsp;
we're not going to get those until nasty things&nbsp;&nbsp;
images corrupting elections, particularly&nbsp;&nbsp;
with that, I think you need a much better system&nbsp;&nbsp;
an image. Initially, I thought you should mark&nbsp;&nbsp;
as fake. I don't think there's much future in&nbsp;&nbsp;
that there's a provenance associated with things&nbsp;&nbsp;
already with email, it says, don't trust this one,&nbsp;&nbsp;
There's discrimination and bias where you can&nbsp;&nbsp;
bias and then somewhat correct it. You'll never&nbsp;&nbsp;
you can make the system less biased than the data&nbsp;&nbsp;
by a less biased system. It'll never be unbiased.&nbsp;&nbsp;
biased systems, that's called gradient descent,&nbsp;&nbsp;
about that one. Possibly because I'm an old white&nbsp;&nbsp;
to do about that. So you don't get many people&nbsp;&nbsp;
much better at digging ditches than a person.&nbsp;&nbsp;
intellectual labor. An AI system is going to make&nbsp;&nbsp;
of really scary because of what it's going to do&nbsp;&nbsp;
richer because we're going to get big increases&nbsp;&nbsp;
go to? It's going to go to rich people. And poor&nbsp;&nbsp;
to do about that. Universal basic income helps.&nbsp;&nbsp;
solve the problem because people's dignity&nbsp;&nbsp;
talking about perception and then perception was&nbsp;&nbsp;
there's a wrong model there. But anyhow,&nbsp;&nbsp;
speaking about perception and thus we're speaking&nbsp;&nbsp;
No, when you use the word subjective experience&nbsp;&nbsp;
a hypothetical state of the real world. Not some&nbsp;&nbsp;
of the real world. These funny internal things&nbsp;&nbsp;
made of qualia. There's just hypothetical states&nbsp;&nbsp;
perceptual system is lying to you. And that's&nbsp;&nbsp;
these hypothetical states of the world. That's how&nbsp;&nbsp;
Oh, getting the issue of prediction into it is&nbsp;&nbsp;
altogether. The thing you have to get in your&nbsp;&nbsp;
called a subjective experience that's made of&nbsp;&nbsp;
of talking about how your perceptual system goes&nbsp;&nbsp;
had to have been like for it to be telling the&nbsp;&nbsp;
use the phrase subjective experience we indicate&nbsp;&nbsp;
the game of telling you about hypothetical states&nbsp;&nbsp;
system's going wrong. A subjective experience is&nbsp;&nbsp;
system? Can a book have a perceptual system? What&nbsp;&nbsp;
a perceptual system you'd have thought you&nbsp;&nbsp;
representation of something going on in some&nbsp;&nbsp;
like, a toad gets light in its eyes and it snaps&nbsp;&nbsp;
right? Because I see where the flies are. I don't&nbsp;&nbsp;
it's not sensing the world and having an internal&nbsp;&nbsp;
today's episode. If you're hungry for deeper dives&nbsp;&nbsp;
with my personal reflections, you'll find it all&nbsp;&nbsp;
new episodes, new posts as well, behind-the-scenes&nbsp;&nbsp;
thriving community of like-minded pilgrimers. By&nbsp;&nbsp;
helping keep these conversations at the cutting&nbsp;&nbsp;
subscribe, and let's keep pushing the boundaries&nbsp;&nbsp;
of knowledge together. Thank you and enjoy the&nbsp;&nbsp;
c-u-r-t-j-a-i-m-u-n-g-a-l.org, CURTJAIMUNGAL.org.&nbsp;&nbsp;
and having an internal representation. What&nbsp;&nbsp;
and rationality? Okay, so there's various kinds&nbsp;&nbsp;
of being rational, but a cat could be pretty&nbsp;&nbsp;
rationality, you typically mean logical reasoning.&nbsp;&nbsp;
most things, which is intuitive reasoning. So&nbsp;&nbsp;
AlphaZero that plays chess. I use chess because I&nbsp;&nbsp;
that can evaluate a board position and say,&nbsp;&nbsp;
can look at a board position and say, what's a&nbsp;&nbsp;
called Monte Carlo rollout, where it's, you know,&nbsp;&nbsp;
dear, that's bad. The Monte Carlo rollout is like&nbsp;&nbsp;
would be a good move, or this is a bad position&nbsp;&nbsp;
do most things by intuitive reasoning. Originally&nbsp;&nbsp;
reasoning and logical reasoning. And that was&nbsp;&nbsp;
They didn't have a way of dealing with things like&nbsp;&nbsp;
reasoning. So what's happened in the last 20 years&nbsp;&nbsp;
rather than human reasoning, and we've got much&nbsp;&nbsp;
intelligent you are, the more moral you are?&nbsp;&nbsp;
suggested it was, but of course I don't know&nbsp;&nbsp;
to believe it. I'm not convinced that's true.&nbsp;&nbsp;
very intelligent. I wouldn't accuse him of&nbsp;&nbsp;
and not terribly intelligent? I think so, yes.&nbsp;&nbsp;
weren't entirely sure, so what's the evidence&nbsp;&nbsp;
increase in intelligence, your morality increases&nbsp;&nbsp;
no idea whether there's a correlation at all. I&nbsp;&nbsp;
who are very bad, and there's highly intelligent&nbsp;&nbsp;
understand? Okay, that's a question I'm happy&nbsp;&nbsp;
wrong model of what understanding is. If you look&nbsp;&nbsp;
people, particularly people from the Chomsky&nbsp;&nbsp;
understand what they're saying. They just are&nbsp;&nbsp;
word. If you look at the first models like that,&nbsp;&nbsp;
model that used backpropagation to train the ways&nbsp;&nbsp;
error in predicting the next word, and the point&nbsp;&nbsp;
meanings for words, or to put it another way,&nbsp;&nbsp;
learn to convert the words into feature vectors&nbsp;&nbsp;
that's what understanding is. Understanding&nbsp;&nbsp;
feature vectors, so that you can use interactions&nbsp;&nbsp;
the next word, but also to do other things. So&nbsp;&nbsp;
Let's not talk about word fragments. I know these&nbsp;&nbsp;
they used whole words. It's easier to talk about.&nbsp;&nbsp;
all. They'd still work. So I give you a string&nbsp;&nbsp;
text. What you do is you convert those words&nbsp;&nbsp;
feature vectors in context, how the features&nbsp;&nbsp;
disambiguate the meanings of ambiguous words,&nbsp;&nbsp;
words, that is understanding. That's what&nbsp;&nbsp;
is both in a large language model and in a person.&nbsp;&nbsp;
they understand. It's not that when we understand,&nbsp;&nbsp;
understanding. I'm always trying to get rid of&nbsp;&nbsp;
things work. We're able, using our big neural&nbsp;&nbsp;
in such a way that the features all fit together&nbsp;&nbsp;
you want to model 3D shapes and you're not too&nbsp;&nbsp;
you can use Lego blocks. These are big shapes,&nbsp;&nbsp;
shape as a Porsche with Lego blocks. The surface&nbsp;&nbsp;
occupancy. So Lego blocks are a kind of universal&nbsp;&nbsp;
need many different kinds of Lego block. Now,&nbsp;&nbsp;
there's a whole bunch of different Lego blocks&nbsp;&nbsp;
has some flexibility to it. It's not a rigid shape&nbsp;&nbsp;
directions. It's not completely free. The name&nbsp;&nbsp;
there's some flexibility to it. Sometimes there'll&nbsp;&nbsp;
it can have, but it can't have any old shape. So&nbsp;&nbsp;
more complicated things than the 3D distribution&nbsp;&nbsp;
Lego blocks. So the Lego blocks with,&nbsp;&nbsp;
mathematician, you know thousand-dimensional&nbsp;&nbsp;
some flexibility. And I give you the names&nbsp;&nbsp;
is this thousand-dimensional underlying shape,&nbsp;&nbsp;
that's understanding. So that explains how you can&nbsp;&nbsp;
without any definitions. So if, for example,&nbsp;&nbsp;
have a sense of what scrummed means. It's partly&nbsp;&nbsp;
it's a verb. But you think it probably means she&nbsp;&nbsp;
that. It could mean something different. She could&nbsp;&nbsp;
such good omelets that that really impressed him.&nbsp;&nbsp;
means she hit him over the head or something like&nbsp;&nbsp;
get that from just one sentence. And nobody's&nbsp;&nbsp;
It's just that all the other Lego blocks for the&nbsp;&nbsp;
words, adopt shapes that fit together nicely,&nbsp;&nbsp;
you need for scrummed. So now that's giving&nbsp;&nbsp;
how I think of language. It's a modeling system&nbsp;&nbsp;
in each of these blocks. I give you a bunch&nbsp;&nbsp;
them together. But because they all have names,&nbsp;&nbsp;
can give them the names. And if they share enough&nbsp;&nbsp;
they all fit together. So are you suggesting,&nbsp;&nbsp;
what's going on in our heads, and that's what's&nbsp;&nbsp;
work the same as us. And that means they really do&nbsp;&nbsp;
that the language models work the same as that we&nbsp;&nbsp;
have to feed the internet to ourselves. So what&nbsp;&nbsp;
models are trained on much more data. They are&nbsp;&nbsp;
when children learn language, they don't just&nbsp;&nbsp;
by being in the real world and interacting with&nbsp;&nbsp;
if you train a multimodal model. It doesn't need&nbsp;&nbsp;
robot arm and a camera and it's interacting with&nbsp;&nbsp;
one argument. It still probably needs more than&nbsp;&nbsp;
backpropagation training algorithm is really good&nbsp;&nbsp;
where a few is a trillion, if you give it a lot&nbsp;&nbsp;
amount of experience, sucking the knowledge out&nbsp;&nbsp;
weights like a trillion. That's not the problem&nbsp;&nbsp;
a huge number of weights like a hundred trillion,&nbsp;&nbsp;
we don't have much experience. So we need to be&nbsp;&nbsp;
very limited amount of experience you get, which&nbsp;&nbsp;
We're probably using some other learning&nbsp;&nbsp;
that we learn based on less knowledge. But what&nbsp;&nbsp;
and how these features should interact. We want to&nbsp;&nbsp;
Jay McClellan said that in your meetings with&nbsp;&nbsp;
tend to not write equations on the board, unlike&nbsp;&nbsp;
Instead, you draw pictures and you gesticulate.&nbsp;&nbsp;
are the pros and cons of this approach? Okay,&nbsp;&nbsp;
Some people think with equations and derive&nbsp;&nbsp;
There's some people who are very good at both,&nbsp;&nbsp;
also very good at math. So they're just different&nbsp;&nbsp;
at thinking in terms of spatial things rather than&nbsp;&nbsp;
your undergraduate experience, how you changed&nbsp;&nbsp;
a long story, but I started off at Cambridge doing&nbsp;&nbsp;
was x-ray crystallography essentially. And after&nbsp;&nbsp;
lived away from home and the work was too hard.&nbsp;&nbsp;
And I got back in and after a day of that, I&nbsp;&nbsp;
I went back to science. But then I did physics and&nbsp;&nbsp;
physiology. And after a year of that, I decided I&nbsp;&nbsp;
philosophy would teach me that. So I quit science&nbsp;&nbsp;
some stuff about Wittgenstein and Wittgenstein's&nbsp;&nbsp;
happened was I developed antibodies to philosophy.&nbsp;&nbsp;
independent way of judging whether a theory is&nbsp;&nbsp;
if it sounds good. And that was unsatisfactory&nbsp;&nbsp;
more about the mind. And I found that very&nbsp;&nbsp;
is have a really stupid simple theory and have&nbsp;&nbsp;
this theory was true or false. And you could&nbsp;&nbsp;
So what's the point of the experiments? That's&nbsp;&nbsp;
into AI. And there we did computer simulations.&nbsp;&nbsp;
you became a professor, and to this day,&nbsp;&nbsp;
There's no reason why I should really know how I&nbsp;&nbsp;
people do. And I can pontificate about how I think&nbsp;&nbsp;
believe me. Feel free to confabulate, like LLMs.&nbsp;&nbsp;
where you think everybody's doing it wrong. You&nbsp;&nbsp;
And see if you can figure out how to do it better.&nbsp;&nbsp;
you discover why people are doing it the way&nbsp;&nbsp;
thought was going to be better isn't better. But&nbsp;&nbsp;
trying to use logic to understand intelligence,&nbsp;&nbsp;
core problem of understanding intelligence is&nbsp;&nbsp;
adapt. Just occasionally, you'll turn out to be&nbsp;&nbsp;
wrong, and the standard way of doing it is right,&nbsp;&nbsp;
do radically new things. And I have an argument&nbsp;&nbsp;
you should clearly stick with your intuitions. If&nbsp;&nbsp;
what you do, so you might as well stick with your&nbsp;&nbsp;
of Ray Kurzweil that ended up making a variety&nbsp;&nbsp;
him in the early 2000s and thinking there's no way&nbsp;&nbsp;
again, he's correct. Well, if you read his books,&nbsp;&nbsp;
a number of things he said that he doesn't&nbsp;&nbsp;
the main thing he said, as far as I can tell,&nbsp;&nbsp;
faster, they'll continue to get faster. And&nbsp;&nbsp;
do more things. And using that argument,&nbsp;&nbsp;
computers will get as smart as people. Do you have&nbsp;&nbsp;
disagree with, but your intuition says you're&nbsp;&nbsp;
and alignment and so on, but perhaps not that,&nbsp;&nbsp;
one is to do with what is subjective experience,&nbsp;&nbsp;
most people just have a totally wrong model of&nbsp;&nbsp;
now. In terms of technical things, I still believe&nbsp;&nbsp;
So synapses in the brain adapt at many different&nbsp;&nbsp;
models. And the reason we don't use it is because&nbsp;&nbsp;
that use exactly the same weights. And that's&nbsp;&nbsp;
efficient. If you have weights that adapt rapidly,&nbsp;&nbsp;
weights because they'll have rapidly adapted.&nbsp;&nbsp;
fast weights and slow weights. The slow weights&nbsp;&nbsp;
there's fast weights which are adapting rapidly.&nbsp;&nbsp;
extra properties, but it becomes less efficient on&nbsp;&nbsp;
were running things on analog computers. So I&nbsp;&nbsp;
weights because they lead to all sorts of nice&nbsp;&nbsp;
between brains and the hardware we have. You also&nbsp;&nbsp;
manic-depressive, in that you have large periods&nbsp;&nbsp;
periods of having extreme self-confidence.&nbsp;&nbsp;
Shorter periods of self-confidence. Okay,&nbsp;&nbsp;
a new idea, I get very excited about it. And&nbsp;&nbsp;
I have one-pound ideas, but sometimes I have&nbsp;&nbsp;
is I get this new idea, I get very excited,&nbsp;&nbsp;
down. Oh, I see. And so I can measure sort of how&nbsp;&nbsp;
went down. And, yes, really good ideas, I lose&nbsp;&nbsp;
the torch of your great-great-grandfather,&nbsp;&nbsp;
about this kind of inheritance, and it's a fun&nbsp;&nbsp;
high expectations that came from my father.&nbsp;&nbsp;
from my father. High expectations for yourself?&nbsp;&nbsp;
that, in your mind, you're passing the torch to?&nbsp;&nbsp;
impose that on anybody else. Why'd you say not&nbsp;&nbsp;
who are very good at quantitative stuff. I see.&nbsp;&nbsp;
No. Speaking of pressure, when you left Google,&nbsp;&nbsp;
your concern regarding AI safety. What&nbsp;&nbsp;
break and voicing your anxieties to the world?&nbsp;&nbsp;
say it was difficult. It was just, I was 75,&nbsp;&nbsp;
stay at Google and carry on working,&nbsp;&nbsp;
It was, I was ready to retire anyway. I&nbsp;&nbsp;
I kept forgetting what the variables stood&nbsp;&nbsp;
I kept forgetting what the variables stood for. I&nbsp;&nbsp;
forgetting what the variables stood for. Yes. And&nbsp;&nbsp;
just, as I went out the door, I could just mention&nbsp;&nbsp;
expecting what happened next. Now, you also did&nbsp;&nbsp;
you're now 75, 76, it keeps changing. It keeps&nbsp;&nbsp;
mentioned publicly that, yes, you keep forgetting&nbsp;&nbsp;
you think you're going to move to philosophy as&nbsp;&nbsp;
about quite a lot. Yes, yes. But it's basically&nbsp;&nbsp;
as when I was about 20. I'm going back to the&nbsp;&nbsp;
exploring those further. Got it. So what's on the&nbsp;&nbsp;
change a whole lot fairly quickly because of AI.&nbsp;&nbsp;
of it's going to be very bad. And we need to do&nbsp;&nbsp;
I think what I can still do usefully is encourage&nbsp;&nbsp;
So that's what I've been doing quite a lot of.&nbsp;&nbsp;
alignment. Now we as people don't have alignment.&nbsp;&nbsp;
problem? I kind of agree with that statement.&nbsp;&nbsp;
parallel to two lines at right angles. Yeah.&nbsp;&nbsp;
alignment. Like there's sort of human good. Well,&nbsp;&nbsp;
is bad. You see that a lot in the Middle East.&nbsp;&nbsp;
with whom? Now you just were speaking to young&nbsp;&nbsp;
researchers, young philosophers, young students&nbsp;&nbsp;
philosophy is not a STEM field. What is your&nbsp;&nbsp;
of the excitement in scientific research is now&nbsp;&nbsp;
In fact, the physicists sort of now want to say&nbsp;&nbsp;
a Nobel Prize in physics for their work in neural&nbsp;&nbsp;
anyhow, continue. You're serious? No, I'm joking.&nbsp;&nbsp;
actor, huh? Right. So yeah, clearly the Nobel&nbsp;&nbsp;
in science is now in AI. And so for both physics&nbsp;&nbsp;
people doing AI or using AI. So I guess my advice&nbsp;&nbsp;
of the excitement is. But I think there's also&nbsp;&nbsp;
progress, like if we could get room temperature&nbsp;&nbsp;
have solar power a long way away, things like&nbsp;&nbsp;
Nanomaterials are very exciting, but they will use&nbsp;&nbsp;
of science will at least use AI tools. Now,&nbsp;&nbsp;
explicit reference. You won the Nobel Prize last&nbsp;&nbsp;
nets, so. Right. How do you feel? How do you feel&nbsp;&nbsp;
in physics, do you consider yourself a physicist?&nbsp;&nbsp;
I was quite good at physics when I did it in my&nbsp;&nbsp;
based on being able to do things intuitively,&nbsp;&nbsp;
up physics because I wasn't good enough at math. I&nbsp;&nbsp;
in physics and I wouldn't have got a Nobel Prize.&nbsp;&nbsp;
at math. How do I feel about it? I still feel&nbsp;&nbsp;
that the work I did on neural nets that related&nbsp;&nbsp;
Boltzmann machines that I developed with Terry&nbsp;&nbsp;
nice way. So I can see why physicists would claim&nbsp;&nbsp;
current successful AI systems. It was a different&nbsp;&nbsp;
that gave rise to this huge new AI industry. So I&nbsp;&nbsp;
we got rewarded for Boltzmann machines, but it&nbsp;&nbsp;
they weren't the thing that was really successful.&nbsp;&nbsp;
into your home. I'm getting to meet your cats.&nbsp;&nbsp;
Writings on there are currently about language&nbsp;&nbsp;
mathematical details. Much more being written&nbsp;&nbsp;
It's not on Theories of Everything. It's not on&nbsp;&nbsp;
there at some point in the future. Several people&nbsp;&nbsp;
in the fields of theoretical physics, philosophy,&nbsp;&nbsp;
I remain impartial in interviews, this sub stack&nbsp;&nbsp;
these topics. Also, thank you to our partner, The&nbsp;&nbsp;
you for listening. If you haven't subscribed or&nbsp;&nbsp;
do so. Why? Because each subscribe, each like,&nbsp;&nbsp;
like yourself. Plus, it helps out Curt directly,&nbsp;&nbsp;
links count plenty toward the algorithm,&nbsp;&nbsp;
say on Facebook or even on Reddit, et cetera, it&nbsp;&nbsp;
this content outside of YouTube, which in turn&nbsp;&nbsp;
there's a remarkably active Discord and subreddit&nbsp;&nbsp;
TOEs, they disagree respectfully about theories&nbsp;&nbsp;
both are in the description. Fourthly, you should&nbsp;&nbsp;
It's on all of the audio platforms. All you&nbsp;&nbsp;
you'll find it. Personally, I gain from rewatching&nbsp;&nbsp;
that, Hey, TOE listeners also gain from replaying.&nbsp;&nbsp;
platforms like iTunes, Spotify, Google podcasts,&nbsp;&nbsp;
if you'd like to support more conversations like&nbsp;&nbsp;
visiting patreon.com slash CURTJAIMUNGAL and&nbsp;&nbsp;
PayPal. There's also crypto. There's also just&nbsp;&nbsp;
support from the sponsors and you that allow&nbsp;&nbsp;
access to add free episodes, whether it's audio&nbsp;&nbsp;
in the case of YouTube. For instance, this episode&nbsp;&nbsp;
a few days earlier. Every dollar helps far more&nbsp;&nbsp;
generosity enough. Thank you so much. Thank you.
