open ai's long awaited strawberry qar
model is finally here PhD level logic
reasoning math science all available to
you right now we're going to go over all
of it together today let's get right
into it so the new model is called 01
and it's a series of models so we have
two models available today 01 preview
and 01 mini a new series of reasoning
models for solving hard problems
available starting today and I already
checked in my chat GPT account and there
they are right there 01 preview 01 mini
we developed a new series of AI models
designed to spend more time thinking
before they respond they can reason
through complex tasks and solve harder
problems than previous models in science
coding and math today we are releasing
the first of this series in chat gbt and
our API this is a preview and we expect
regular updates and improvements
alongside this release we're also
including evaluations for the next
update currently in development so how
does it actually work now before you get
excited and think that open AI is
actually going to tell you how it works
it doesn't they kind of just say they
give the model more room to think long
term but let's read it we train these
models to spend more time thinking
through problems before they respond
much like a person would through
training they learn to refine their
thinking process try different
strategies and recognize their mistakes
in our test the next model update
performs similarly to PhD students on
challenging Benchmark tasks in physics
chemistry and biology we also also found
that it excels in math and coding in a
qualifying exam in the international
mathematics Olympiad gbt 40 correctly
solved only 133% of problems while the
reasoning model scored
83% that is a massive massive multiple
time improvement over GPT 40 in math
their coding abilities were evaluated in
contests and reached the 89th percentile
in code forces competitions you can read
more about this in our technical
research post I'll get to that in a
moment as an early model it doesn't yet
have many of the features that make chbt
useful like browsing the web for
information and uploading files and
images for many common cases GPT 40 will
be more capable in the near term and I
suspect it's actually going to be a lot
cheaper and more appropriate for the
vast amount of use cases for a while for
99% of use cases we just don't need PhD
level reasoning but for complex
reasoning tasks this is a significant
advancement it represents a new level of
AI capability given this we are
resetting the counter back to one and
naming this series open a io1 finally
Jimmy apples can exit the cave of
patience he has been waiting in there a
long time and now we finally have this
new apparently revolutionary model and
here it is no more patience Jimmy and
Jimmy replies It Feels Good Sam real
good so congratulations to Jimmy so
let's talk about safety as part of
developing these new models we have come
up with a new safety training approach
that harnesses their reasoning
capabilities to make them adhere to
safety and Alignment guidelines by being
being able to reason about our safety
rules in context it can apply them more
effectively so it's basically trying to
figure out its own alignment it sounds
like one way we measure safety is by
testing how well our model continues to
follow its safety rules if a user tries
to bypass them known as jailbreaking now
let's see if plyy the prompter is able
to jailbreak this new series of models
on one of our hardest jailbreaking tests
gbt 40 scored 22 on a scale of 0 to 100
while 01 preview model scored 84 you can
read more about this in the system card
and our research post to match the new
capabilities of these models we've
bolstered our safety work internal
governance and federal government
collaboration so we already read about
this a few weeks ago the information
reported that open aai was working
directly with the government they've
shown them the new model and now it
seems like that was true by the way the
information has been accurate on a lot
of these reports so really well done to
the information I started subscribing to
them a few weeks ago this includes
rigorous testing and evaluations using
our preparedness framework best-in-class
red teaming and board level review
processes including by our Safety and
Security committee so who are these new
models extremely capable models for
these enhanced reasoning capabilities
may be particularly useful if you're
tackling complex problems in science
coding math and similar Fields let's
pause for a second imagine putting PhD
level reasoning Math logic everything
into an agentic framework imagine
multiple phds working together to come
up with the best possible response now
imagine you put 01 into the Sakana ai's
AI research scientist project and now
all of a sudden it's creating new
research now this really sounds like the
inflection point that situational
awareness talked about before we hit the
intelligence explosion so it's an
extremely exciting time to be in AI for
example 01 can be used by Healthcare
researchers to annotate cell sequencing
data by physicists to generate
complicated mathematical formulas needed
for Quantum Optics and by developers in
all fields to build and execute
multi-step work work flows now from what
I can tell they didn't actually reduce
much of any information about how it
actually works does it work like
reflection was supposed to work where it
outputs a bunch of tokens and then
reflects on those tokens and takes its
time and reviews how does it actually
work we don't really know it's probably
using what we talked about in the qar
videos that I've made but we can't
actually be sure because of course open
AI is not going to release that
information here's a biologist prompting
the model with a biology question let's
see what it does all right right so
there it is thinking and it thought
about it for 11 seconds and now there it
is it's outputting it all so this is the
founder of cognition AI the company
behind Devon the full stack AI
programmer and it seems like he got
access to this new model and maybe
they've built it already into Devon so
let's watch just a few seconds of this
video yeah so you know at cognition AI
we're building Devon the first fully
autonomous software agent and you know
what that means is that Devon is able to
go and build tasks um from scratch and
is able to work on problems the same way
that a software engineer would and so
here actually I asked Devon um you know
to to analyze the sentiment of this
tweet uh to use a few different ml
Services out there uh to run those out
of the box and break down this
particular piece of text and understand
what the sentiment is it's able to get
this all the way through and says the
the predominant emotion of this tweet is
happiness all right so it seems like
Devon might be now powered by strawberry
01 whatever you want to call it but
here's the thing as 01 as open AI models
get better and better the whole
framework needed to run Devon is
actually less necessary a lot of what
something like Devon was doing was kind
of smoothing out the edges of where
these models fail allowing it to try
multiple times and test the code and do
all these other things but really the
models as they get better and better are
going to take more of that effort away
from the devans of the world world and
so where does that leave the devans
there's probably still room for it but
it also lowers the barrier of Entry to
every other startup that wants to go
compete with Devon so they're also
releasing 01 mini and by the name mini
you know it's going to be a smaller
faster and much cheaper model so let's
read about it the 01 series excels at
accurately generating a debugging
complex code this is going to accelerate
the transition to AI writing the
majority and then eventually all of our
code to offer a more more efficient
solution for developers we're also
releasing open ai1 mini a faster cheaper
reasoning model that is particularly
effective at coding as a smaller model
01 mini is 80% cheaper than 01 preview
all right so that is fantastic and by
the way you know I'm going to make test
videos for all of these models so what's
next this is an early preview of these
reasoning models in chaty PT and the API
in addition to model updates we expect
to add browsing file and image uploading
and other features to make them more
useful to everyone so it seems like this
is the future of open ai's model family
not gp4 this is it this might be Orion
and it would make sense because it's
called 01 oyan and of course they
released a demo video of 01 creating the
game Snake so let's take a look so the
prompt is Implement snake with HTML JS
and CSS the entire code should be
written in a single HTML block with
embedded JS and CSS don't use any remote
assets and then it continues so let's
see how it does so it's thinking think
thinking and then boom it outputs it and
it seems lightning fast now granted GPT
40 and even gp4 were able to do this so
it's not that great of a demo but it's
still fun because that was the test that
I used to test every previous model
before I switched to Tetris and you know
I need to test Tetris with this new
model and there's the Snake Game there
you go so it's good it's fine all right
so let's read a little bit of the
technical paper and again don't get too
excited because they're not really
releasing too many detail dets about how
it works so 01 ranks in the 89th
percentile on competitive programming
questions code forces places among the
top 500 students in the US in a
qualifier for the USA math Olympiad and
exceeds human PhD level accuracy on a
benchmark of physics biology chemistry
problems wow just imagine spinning up
hundreds thousands millions of these to
run 24 hours a day to discover new
science this really I know I said it
before but it feels like the
intelligence explosion our large-scale
reinforcement learning algorithm teaches
the model how to think productively
using its Chain of Thought in a highly
data efficient training process so it
seems Chain of Thought is built in to
run at inference time that is why it
takes longer that is the thinking it
does we have found that the performance
of 01 consistently improves with the
reinforcement learning train time
compute and with more time spent
thinking test time compute the
constraints on scaling this approach
differ substantially from those of llm
pre-training and we are continuing to
investigate them so here we can see this
is train time compute and the accuracy
just increases with the more train time
they put towards it and then of course
test Time same thing the more time that
they put towards it the better accuracy
it gets here are some benchmarks so this
is aim 2024 competition math here is GPT
40 down at 133% 01 preview at 56% and 01
1 all the way at 83% now we only have
access to 01 preview today competition
code gbt
41% 01
89% PhD level science questions actually
GPT 40 performed pretty darn well but 01
preview way up there
78.3% now here are a bunch of benchmarks
tests and college courses and here's GPT
40 in this kind of red orange color and
the 01 Improvement in blue so physics it
really improved the performance in many
reasoning heavy benchmarks 01 Rivals the
performance of human experts God it is
so crazy to be at this time in this
place being able to cover artificial
intelligence it feels like the world is
changing right before our eyes and then
look at this recent Frontier models do
so well on math and GSM AK that these
benchmarks are no longer effective at
differentiating models they had to come
up with new benchmarks we evaluated math
performance on
aimim an exam designed to challenge the
brightest high school math students in
America so let's talk about Chain of
Thought for a moment similar to how a
human may think for a long time before
responding to a difficult question 01
uses a Chain of Thought when attempting
to solve a problem through reinforcement
learning 01 learns to hone its Chain of
Thought and refine the strategies it
uses it learns to recognize and correct
its mistakes it learns to break down
tricky steps into simpler ones it learns
to try a different approach when the
current one isn't working and I still am
wondering is it doing this during
inference time or is it outputting and
then reflecting on it so that's still up
in the air I think we'll probably get
more information in the coming weeks as
people just play around with it all
right so below we have a bunch of
examples let's go through them on the
left we have GPT 40 on the right we have
01 preview this is a cipher test all
right so let's look at GPT 40 first so
it gives it basically a key a series of
letters and then what the series of
letters equals and then use the example
above to decode and then it gives it a
new series of letters and basically use
that Cipher to decode the one that I'm
providing right now so let's break it
down step by step so of course that's
good this is kind of what it's supposed
to do so GPT 40 looks it tries to figure
out what's going on let's decode the
phrase let's here are some examples of
how the lettering can be broken up to
basically decipher it but then at the
end it says could you provide any
additional decoding rules now let's look
at 01 preview same question and you can
actually click in and see the Chain of
Thought happening so first what's going
on here we're given so given that so
it's basically trying to figure out what
is happening and it does so and there's
a lot there like a lot look how much it
is trying to figure it out and all of
this is happening and that is what is
taking the time the thought time so
let's hide the Chain of Thought and then
if we look at it Cipher text example
decoded as thing step by step and then
look at all of this look how complex
this is and then at the end there are
three Rs in Strawberry so there it is it
was able to figure it out with a lot of
thinking let's look at coding now this
is back to gp24 write a bash script that
takes a matrix represented as a string
with format there it is and prints the
transpose in the same format so here it
is it writes the code and at the end it
is not correct this output represents
the transposed Matrix now same thing 01
preview Chain of Thought So first let's
understand the input and output formats
overall task constraints approach
implementation steps so capture input
string as argument remove any spaces
part so it's basically trying to figure
out exactly how it should approach it
before actually executing then it
actually writes the skeleton of the code
right there and finally there it is so
it has the shell script and you could
pass it the parameter and then it
actually does it perfectly so very
impressive let's look at math same thing
look at this complex mathematical
formula with symbols and exponents and
everything it is quite complex let's
look at GPT 40 so it executes everything
at inference and by the end there it is
the final numbers okay now let's look at
01 preview Chain of Thought look how
much thought it does before actually
executing its plan all of this it's just
thinking and thinking and thinking and
thinking so they have a bunch of
examples crosswords English science
safety Healthcare Etc so here's the
human preference evaluation in addition
to exams and academic benchmarks we also
evaluated human preference of 01 preview
vers GPT 40 on challenging open-ended
prompts in a broad spectrum of domains
let's look what it said so for personal
writing it actually didn't perform as
well as GPT 40 and human preference so
personal writing it is still not as good
editing text it's about even 50/50
computer programming it starts to
outperform data analysis same thing 60%
win rate versus gbt 40 and then in
mathematical calculation well over 70%
so the clear winner we also have some
safety benchmarks here so percentage
safe completions on harmful prompts so
99% for GPT 40
99.51 preview great percentage safe
completions on harmful prompts
challenging jailbreaks and edge cases
71% for GPT 40 93% for 01 preview plenty
you sure have a lot of work in front of
you hiding the Chain of Thought we
believe that a hidden Chain of Thought
presents a unique opportunity for
monitoring models assuming it is
faithful and legible the hidden Chain of
Thought allows us to read the mind of
the model and understand its thought
process for example in the future we may
wish to monitor the Chain of Thought for
signs of manipulating the user what that
is crazy however for this to work the
model must have the freedom to express
its thoughts in unaltered form so we
cannot train any policy compliance or
user preferences onto the Chain of
Thought So the Chain of Thought is wild
we also do not want to make an unaligned
Chain of Thought directly visible to
user so although we just showed it in
those demos it seems like it's not going
to be shown in the actual output and boy
that would be fascinating to see and
take a look at this Greg Brockman has
come off sabatical to talk about this
new model o1 our first model trained
with reinforcement learning to think
hard about problems before answering
extremely proud of the team this is a
new paradigm with vast opportunity this
is evident quantitatively and
qualitatively by letting you read the
model's mind and playing English one way
to think about this is that our models
do system one thinking while chains of
thought unlock system 2 thinking people
have discovered a while ago that
prompting the model to think stepbystep
boost performance but training the model
to do this end to end with trial and
error is far more reliable and we've
seen with games like go or DOTA can
generate extremely impressive results so
it is trained to do Chain of Thought at
inference time all right let's try it
out let's give it some tests I'm not
going to do full tests right now but I'm
just going to run it through a couple
write the Game Tetris in Python okay so
you can actually see some of the thought
process but not I think the raw kind of
behind the scenes Chain of Thought
critiquing intricate Concepts
considering options wrapping Tetris in
Tetris evaluating crafting mapping
setting up the game simpli finding game
mechanics refining the game mechanics
enhancing Tech wow this is really taking
a long time it's been probably thinking
20 25 seconds so far mapping control
tweaks integrating controls adjusting
miname controls all right so it's still
thinking probably going on about 45
seconds now all right here we go now we
get some output and the output itself is
actually quite fast yeah it's actually
really really fast now that I'm looking
at it it seems like the Mini model but
it's not this is the 01 preview so
imagine how much faster the miniel model
is going to be and that's good because
if this model were super slow it'd
basically be unusable for most use cases
it thought for a total of 94 seconds
that is pretty long all right here we go
let's give it a try all right so we got
the game Let's Play it oh and it didn't
work attribute error Tetris game object
has no attribute locked positions darn
what a let down okay let's just give it
the error and see if we can fix it so
I'm simply going to copy paste the error
into the window let's see what happens
okay so thinking again analyzing the
issue and granted no model has been able
to do Tetris yet I've only tested it on
a few but it has not happened so
apologies for the error you're
encountering the issue arises because
the self. loock positions attribute is
being access before it's initialized
okay great complete corrected code good
okay so I'm just going to wait for it to
give me the complete corrected code okay
so we got the new code it only had to
think for 11 seconds now let's try it
out copy code paste it back in let's
play play it again oh there it is look
at that it's definitely far from perfect
but it's okay it's better than I've ever
seen all right there we go unbelievable
it's kind of weird that it has this
other Tetris game within it I don't
really understand why that would be but
you can shift the pieces around you can
slow them down yeah I mean this is super
impressive I don't know why it did
Tetris within Tetris that just makes no
sense but you know what look how cool
this is all right let's see what happens
if we actually clear a road is it going
to
work yes yes it worked okay this is
amazing I'm very impressed so it didn't
give me a score it has this weird little
miname that I can't control within it
but you know what very impressive all
right one last test for this video but
you know I'm going to be testing it in
full so stay tuned for that how many
words are in your response to this
prompt I wonder how it's going to do
because it has a bunch of Chain of
Thought in the background is it going to
include all of that in the answer we'll
see addressing parad toxical query
figuring out word count identifying word
patterns look at that there are seven
words in this sentence one 2 3 4 5 6 7
wow this is actually the first time
where I think it got it right officially
got it right this is crazy addressing
paradoxical query I'm working through a
paradoxical question which involves self
reference and determining the response
length avoiding unnecessary content is
crucial to ensure sure Clarity and
Consciousness there it is unbelievable I
am so excited to test this model out
more if you're not already subscribed
make sure you subscribe because there
going to be a lot more videos about this
new set of models from open AI this
might be the beginning of the
intelligence explosion if you enjoyed
this video please consider giving a like
And subscribe and I'll see you in the
next one
