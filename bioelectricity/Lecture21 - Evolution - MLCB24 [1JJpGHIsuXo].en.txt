all right uh welcome everyone so today
we're going to be talking about
phenomics so uh the you know this comes
at the end towards the end of the class
so we are we have two more lectures on
um metabolic flux and Analysis and today
we're kind of
completing the second part of the
evolution lecture so in the first half
we talked about how we can use Evolution
to study genomes so we can use Evolution
to sort of make sense of functional
elements in genomes and we talked about
functional elements within
proteins functional elements in
non-coding regions and how we can use
evolutionary signatures to distinguish
different classes of functions
between protein coding versus you know
RNA microrna regulatory motifs Etc and
we also saw how these very powerful deep
learning approaches allow us to actually
go a step further in traditional
analysis of comparative genomics by
studying not the changes in the letters
but the changes in the interpretation of
the letters and we focused a lot on the
conservation of that interpretation in
other words even when
the letters themselves were changed we
could see still see
conservation at the level of function at
a higher level of abstraction if you
wish and that's where all of this
representation learning that we've been
doing on the machine learning part of
the class came in handy everybody with
me here so far so today we're Switching
gears and we're looking at the other
part of the arrow Nam can we use genomes
and many many species genes and
alignments to study the process of
evolution itself okay and we're going to
be talking about three types of analysis
at increasing layers of complexity if
you wish first we're going to look at
phenetics namely how do we study the
changes not just in an alignment but in
the tree that is responsible for this
alignment so this is going to be taking
comparative genomics to the history
level to the series of Divergence events
then we're going to talk about
phenomics where you now
have thousands of trees evolving inside
thousands of trees in other word in
other words understanding every
duplication and loss event Beyond just
simply can we build an accurate
alignment of the the sequences that were
given so in the first part of phog
gentics we're not going to care where
the genes come from but in the second
part on phenomics we're actually going
to use the species tree along with the
gene tree to basically distinguish Gene
duplication and loss events based on the
reconciliation based on the agreement
between these two trees everybody with
me here and then then the third part
we're going to you know go beyond just
the constraint of trees basically in
Parts one and two will'll be given a set
of regions or genes or elements that we
call orthologus or paralus
and in part three we're going to look at
how do we even get these to be on top of
each other we're going to look at genome
assembly we're going to look at you know
all kinds of other uh ways of alignment
and we're going to also look at
Evolution very very near and very very
far we're going to look at
Evolution between different homine
lineages or within the modern human
lineage as well
as the beginning of Life and our in
World okay so a lot of stuff to cover
today but again this is not on your quiz
the goal is to expose you to all this
extraordinary wealth of uh different
types of data say different type of of
questions many of which are still very
active areas of research everybody
excited so again three parts so three
outlines and the three outlines are
going to be number one phog gentics
number two phenomics so we're going to
look at reconciliation we're going to
look at Gene and species trees we're
going to look at how Evolution happens
within populations we're going to look
at at incomplete linear shorting and how
to blend population and species models
and then we're going to look at the
Modern symes namely the evolution of
evolutionary theory itself then in part
three we're going to look at genome
assembly all genome alignment whole
genome duplication we're going to look
at human selection multiple time scales
human demographic history and also the
world before DNA and proteins were even
invented okay all right so that's our
goal for today so part one phog gentics
how do we build trees how do we score
trees how do we build distances and so
on so forth so first we're going to talk
about the basics of phogy then we're
going to go see how we can go from the
multiple sequence alignments that we saw
in the earlier lectures in the earliest
lectures of the class to distances by
modeling sequence Evolution then we're
going to see how we can use these
distances to build trees and tree
building algorithm that start from SE
from distances and then we're going to
look at tree building algorithms that
start from
alignments so we can either build a tree
from the
distances after having figured out
distances from the alignments and
modeling Evolution or we can build a
tree from the alignments directly okay
and then we're going to see how in fact
this is when we build trees from
alignment this is basically just
alignment scoring given a tree
but then we have to actually iterate
over trees okay let me uh make this more
concrete but uh first we're going to
dive in okay so what what are the basics
of phogy so phogy is not a new thing
phogy did not start with DNA sequences
phogy started well well before when
scientists were looking at fossils and
were trying to figure out the history of
Divergence events that separated these
fossils and those traditional traits
were basically morphological data you
would look at a skull of a lizard or a
dinosaur or a crocodile and you would
basically say okay what are the
different parts of that
skull and can I infer philogenetic
histories that allow me to have the
least number of events is everybody with
me here that allow me to group species
together and group fossils together
based on the number of trees or based on
the shape or based on you know where
whether that particular bone is there or
not and so so forth okay so these are
what we call traditional traits these
are morphological data and these
traditional traits have very distinct
properties from the modern traits of
molecular data so molecular
data has a lot of uh you know
differences first of all we have very
very large numbers of traits every DNA
position and every protein residue is a
different
trait okay these traits are very
frequently ill behaved namely they have
back mutations that are very frequent
this is what we call convergent
evolution because most evolution is
Divergent you have a common
ancestral phenotype and also genotype
and then you diverge from each other but
very rarely would you see
convergence at least in some of those
tradition
traits so for example you can assume
that you know this particular bone here
only evolved once and therefore every
species that has it is a descendant of
that same event where that bone was
developed is everybody with me
here so this is traditional phenis and
our goal in traditional phenis was to
build species trees we had a small
number of traits these were hoofs and
nails and teeth and horns and they were
very well behaved every single event
arose one
and therefore we could use parsimony
principle we could use aom's razor and
basically say among many different um
hypothesis that all explain the data
equally well I'm going to choose the
simplest
hypothesis namely that something evolved
once rather than evolved here was lost
there re-evolved here was Rel lost there
and so so forth everybody with me here
so this is aom's Razor and basically
says you know if I have multiple expl
explanations I'm going to choose the
simplest one as long as they explain the
data equally well
with modern phenetics we have to worry
about correcting for back mutations
namely having an a at that position is
very easy to rearise you just make that
mutation again okay so these back
mutations where you go from an A to a T
and back to an a there's only four
options you mutate chances are you're
going to you know sometimes go back so
we're going to have to correct for this
everybody with me here awesome and then
there's also a very small number of
letters and therefore they could arite
many many times independently okay so
now in the lecture for today we're going
to be or at least the first part we're
going to be thinking about how do we
infer a
tree from alignments so alignments we
already saw how we can build okay you
just basically have this dynamic
programming Matrix and you can use that
to figure out where should I position
the gaps to maximize the score of the
alignment okay there's a of course a
back and forth between them because if I
have a pairwise alignment between two
species then I can use that to infer the
position of the most likely
ancestor and then I can use a tree that
that I can infer to basically walk up
and figure out in what order should I be
assembling these most common recent
ancestors and so so forth so there's a
big interplay but for now we're going to
separate them and say we're given the
alignment can we infer a tree of course
once you have your tree you might re
build your alignment to get a better
tree and so on so forth
yeah no no if you have n species you're
starting an alignment you're you're
starting with an alignment of all n
species on top of each other here are
the positions along a protein and here's
the um every row is a species every
column is a
letter so we're starting with that
and then we we want to figure out the
tree that relates the
species
okay so basically the data is going to
be sequence data it's going to be either
nucleotide alignments or prot protein
alignments and then all of our
Divergence events are going to be binary
even though sometimes we might not
really be able to tell whether say in a
very close philogyny whether these two
separated first or those two separated
first or you know whether this one Etc
but we will assume that everything is
binary and you know sometimes we'll have
some confidence value in each of these
branches that basically tells us if I
resample the positions in my alignment
how often do I get exactly the same
topology okay everybody me so far yes
awesome so again we're going to either
first from the alignment of n rows of
different species
first we can infer an N
byn pairwise distance Matrix that
basically says I already have my
alignment but now I'm going to use this
to calculate how far is a from B A from
C A from d a from E B from C B from D B
from E Etc and that's my n squ distance
Matrix and then I'm going to completely
throw away the alignment and only use
the distance Matrix to the tree or if I
worry about every
character and I don't want to lose away
I don't want to throw away
information and summarize it in single
distance between every of species or
sequences then I will be able to go from
the alignment directly into the tree and
basically ask how well does that tree
capture the events that I observe in my
alignment
and then I
will couple that with a tree proposal
and scoring that allows me to now
fine-tune an initial proposal and make
it into a better
fogy everybody with me here can I get a
543 to1 how well you're falling okay
super part Sur all right so these are
going to be the four parts of you know
part one of the lecture so basically one
how do we go from sequences to distances
two how do we build trees using these
distances three how do we go from
alignment to phogy and four how do we
propose uh trees topologies okay so Dive
Right In everybody with me here
awesome so what do we want we want to
figure out how to turn pairwise sequence
alignments into pairwise distances and
as I mentioned earlier there's back
mutations okay so that's where it
becomes interesting that's where we need
a model for sequence Evolution we can
just simply count events but we need to
actually model EV
everybody with me here great so how do
we model evolutionary rates if I see a
number of changes how do I infer a rate
from those changes so let's distinguish
different types of events I could just
simply measure how different are the
nucleotides I could use a uniform rate
and just simply count the overall
percent identity that's a fine distance
there's been 133%
changes or I could use transition and
trans transversions I could have two
parameters one parameter for how often
is a changing to G and C changing to T
and one parameter for how's often a
changing to C or T and G changing to c
or
t everybody with me here so I could also
include within protein re coding regions
a synonymous rate and a non synonymous
rate so I don't know if you remember in
the last lecture we talked about
measuring not just amino acid changes
but also synonymous changes we found
some regions that had dual constraint we
had constraint not just for the protein
sequence but also for the nucleotide
sequence and those were regions where
the synonymous rate was in fact very
very
low and of course we should realize
that there are many mutations that don't
change the amino acid sequence at all
and those are basically blind like
selection is blind to those mut
basically if the only selection is at
the amino acid level then changing
between any of these nucleotides will be
fine so basically changing an AG into a
cgg you know both translate to
Arginine okay and now the the last part
is that the number of actual
mutations is actually
typically much larger than the number of
observed substitutions in other words if
I observe 80
events some of those are likely to be
back
mutations okay where I changed into a t
and then back into a c and then you know
I have 100 positions I see that 80 of
them are
changed the other 20 might appear
unchanged but some of them will actually
be changed twice and the reason for that
is that if I have for example a 60%
Divergence from a into each of the other
nucleotides I have to be actually quite
cautious that the next time I change you
know from an A to a c the next time I
change from a c to
another position I have to be very
cautious that I don't change back into
an a everybody with me here in other
words for every
substitution to be representing only
basically for for the only mutations to
actually be the observed changes that I
seen I have to be very cautious in other
words most of the time I will have more
events than what I observe okay let me
illustrate what that means suppose that
I have only one parameter the parameter
is how often do I change from any letter
to any other letter so here I'm not
dealing with Transitions and
transversions between you know PID is
and Pur and purin okay so at every time
state I'm going to start with the letter
a and I'm going to stay at an a with 70%
frequency I'm going to change into each
of the other letters with 10%
frequency at the first time point
you know when I start let's say time
point0 I'm at 1 z0 Z but at the next
time point I'm already at 7.11 Al so far
so good and then the next one I'm not at
049 I'm not just at 7 squar I'm at 7
squar
plus 01 squar or 0.1 squar okay in other
words I can stay at an a by changing to
a c and back into an A and therefore my
probability of changing of of staying in
a is not just 7 squar which would be
049 but instead it's 049 plus .1 * .1 .1
* .1 .1 * .1 where I basically switch
from an A to a c and back into an a
that's 0.1 squ that's
0.1 at Short evolutionary distances it
doesn't matter at all or at least it
matters very little but as I go further
and further and
further say I get to 10% 20% 30% 40%
observe
changes then if I observe
40% I've actually done almost
60% okay so if I observe 10% I've
actually done 11 if I if I observe 20
I've actually done 23 if I if I've done
60% change I've actually changed nearly
every position on
average okay and if I observe 70%
Divergence I have on average two
substitutions per site
everybody with me here what if I observe
80%
Divergence who can comment on 80%
Divergence how far do you think that
gets
now what does 80% Divergence mean how
many letters do I have in the
DNA four letters a c
GT if I take a random sequence and I put
put it on top of another random sequence
what percent difference I'm going to
observe good the limit is basically 75
if I have 80% Divergence I'm I'm
basically doing something wrong with my
alignment okay my alignment basically
sucks if I if I have a good alignment
algorithm there's no way I'm going to be
able to align 75% or you know more than
75% and the reason that the alignment
itself is going to just like move some
locations and it's going to say well you
know I have three A's here I have three
a here I'm going to move them together
so everybody with me here so basically I
saturate at 0 75 and then basically I
hit
Infinity okay so basically at that
point you hopefully can see that like as
I go further and further and further I
ASM toot towards 75%
Divergence sounds good and that
basically means that I need a way to
correct I need to basically say Okay I I
never I never have the actual I only
observe mutations and therefore I need a
way to correct from the observation to
the actual number of
mutations and that involves simply
taking that equation expanding it out
and just saying you know as I as I move
further my forward process is going to
be that the number of um you know
conserved amino acids is going to
be one4 * 1 + 3 e to minus 4 a t which
is simply if I run the stationary
process to completion or at least to
time T then I'm going to basically end
up if I onun this Mark of process I'm
going to end up with you know some curve
and then I can just read off the curve
what the actual number of mutations is
by reversing this equation so this is
you know the number of conserved and the
number of
substitutions and now the reverse
process simply tells me here's you know
how do I solve for T given that I have
this and then the actual distance is
going to be you know 3/4 log of that
which is reversing that equation is
everybody with me here so I have this
ASM toote this exponential driving
towards
0.25 and then I need to reverse that
exponential to basically figure out
what's the actual and therefore if I
observe you know. 34 .5 Etc I can infer
this can I get a 543 to1 who's following
me here awesome great any
questions can I get everybody's hand up
please okay awesome good good good good
all right so that's the simplest model
this is known as the J's counter model
and it has only one parameter and that's
basically the part about actually
modeling Evolution so how do we turn
pair wise sequence alignments into pair
wise distances what we need is a
probabilistic model model of Divergence
and the simplest one is the juk counter
model everybody so far awesome so that's
the simplest model I can be a little
more complicated I can basically say
that a to G and c2t change with each
other at a transition rate which is uh
sorry at the transversion rate Which is
less frequent than the transitions
between you know
um sorry the colors are off here so a to
G are transition C to T are transitions
a to c a to t you know Etc the rest is
transversions okay so basically
the substitution rate between purins and
between pmids or within purins and
within peridance is actually much higher
than the substitution frequency
between the two
categories and therefore I will have two
parameters and I will need to estimate
those two parameters based on the
observed uh mutations okay and then this
is the simplest model where I have only
one substitution type this is the Kimora
two parameter model where I have one
transition parameter one transversion
parameter and all of these are assuming
equal based
frequencies I could then have two
different transversion frequencies one
between say A and C and one between you
know a and t or something like that uh
or I could have a fully metric model
basically where I have you know 1 2 3
four five six parameters or nine
parameters or something like that and
then I could basically have um all of
this is with equal frequencies and I can
also have with unequal base
frequencies additional substit
substitution types is everybody with me
so far so this is all about modeling
sequence Evolution okay so now I've
basically aligned my sequences I've
figured out all of the distances between
every pair by simply counting on the
alignment I remove any kind of joint
gaps which are gaps on both and I simply
count for every position that's on top
of each other what is the actual
distance based on the aligned positions
for now none of these are dealing with
gaps none of this is dealing with sort
of fancer events like duplications
losses or segmental changes Etc it's
just counting the number of events okay
question
okay everybody with me okay now let's
look at how we can go from distances
that I've just computed using my model
of sequence Evolution to actually trees
okay so I now have my n s Matrix of
distances and I want to build a
phogy what does that mean that means
that I want
to I want to figure out a tree such that
moving from species a to species I don't
know M over here or species p over
there along the
tree is recapitulating the distance that
I have between species a and species M
or species p is everybody with me here
so to be able to infer a tree that
matches quote unquote my Matrix of
distances simply means that I will be
able to compute any pairwise Distance by
basically just walking up and down the
tree try to F figure out the distance
between human and Cat it's this Branch
plus this Branch plus that Branch plus
that
branch and if that matches exactly the
tree distance that I had between uh the
the the Matrix distance that I had
between human and Cat then I'm doing
great can I get a 543 to one on this
concept awesome so that's basically
fitting a tree to a
matrix sometimes it's possible sometimes
it's not possible and when it's not
possible we're going to have to figure
out what is the best tree that matches
those
distances okay so we have the goal of
minimizing the
discrepancy between the observed
pairwise distances which are completely
un constrained I don't have to walk
along any roads I I can just go from the
dog I don't know house to the rat house
by teleportation which calls me the dog
rat
distance or I can walk along the paths
that connect all these houses and then I
have to pay the tree
distance
okay everybody with me here great so now
when the Matrix is such that it can be
perfectly
encapsulated in this sum of
paths then that's known as an
ultrametric
distance and moreover actually I should
say that that's that's known as an
additive
distance so an additive distance
basically means that I can just add up
all of these distances and then my
Matrix was basically generated by adding
up these segments everybody with me here
now I can impose an additional
constraint which is that all species
evolved at the same rate since they're
common ancestor so basically I can fold
up the tree in a way that says that the
trees actually represent Divergence
times not just number of
events and therefore that I don't know
65 million years ago you had a
Divergence of or like 90 million years
ago you had a Divergence of all the
mammals then I don't know 65 million
years ago you had a Divergence between
human mouse and rat and then I don't
know 30 million years ago you had a
Divergence between dog and cat is
everybody with me here so if the Matrix
is such that it can be represented as a
series of times elapsed since a common
time of Divergence then that's known as
an ultrametric
distance okay so an additive distance is
simply a distance that can be bu by a
tree and an ultramatic distance is
simply a distance that can be made by
traversing from a common ancestor down
to every Branch with the same exact
number of steps so far so
good good so again an additive distance
can be checked simply by satisfying this
fourpoint condition but all the
fourpoint condition says is that for any
four points I can find a midpoint
branch that you know satisfies this and
notice A and B don't need to be the
same whereas for an ultrametric tree
every single time I have three points
there is you know two of the distances
are always identical and the reason is
that this must be a tree and guess
where's the root exactly at the
midpoint
okay but of course most of the time I'm
just going to have General
distances
okay
so if I have an ultrametric Tree in
other words if the distances were indeed
generated by a clock model where every
single one of these species diverged at
a specific time from the common ancestor
and and from today then I can basically
use
upgma which is unweighed
pairs grouping with arithmetic
mean so upgma is effectively a
clustering algorithm that says I'm going
to find the two closest species group
them and put the midpoint I'm going to
find the next closest group them and put
the midpoint I'm going to find the next
closest group them and put the midpoint
I'm going to find the next closest group
them and put the
midpoint and if indeed my tree was
generated by such a process then this
algorthm is guaranteed to find the
correct
tree if it wasn't absolutely no
guarantees so far so good okay so this
is upgma also known as hierarchical
clustering basically unweighted pair
group method with arithmetic mean and
it's what I just said you just take
every closest pair group it make a
cluster out of it
Etc and then in the case of you know
human Mouse right do dog you basically
just keep you know averaging and then
you build a tree progressively and then
you're very happy okay now there's a
problem with upgma it assumes a
molecular
clock and it implies that the time is
constant for all
species and
therefore in a case where the correct
tree has some species that
accelerated for example I don't know
this is a tiny little species it might
migrated to a new climate it now needs
to you know adapt very rapidly or this
is a very slow generational species you
know every species live till 300 years
and then you know there's very few
mutations okay they say that's a turtle
and that's a I don't know Chipawa or
something okay everybody with me
here so if the correct tree looks like
this what's upgma going to do it's going
to assume that they were generated by a
clock and therefore you going to say oh
well two and three are clearly the first
on that should merge because they're the
closest and their midpoint is exactly in
between them and then the next one is
going to be I don't know four and I'm
going to group that there Etc so upgma
is basically guaranteed to have the
wrong tree if there are some branches
that are shorter and some branches that
are long so far so
good so that's where neighbor joining
comes in neighbor joining says okay well
why don't I deal with this situation how
am I going to deal with it by saying
that if a species species is repeatedly
far from all of the other species I'm
just going to assume that that species
is antisocial and has a Long Branch and
if a species is repeatedly close to all
the other species I'm going to assume
that it's very promiscuous and it has a
very short Branch so I'm going to do a
correction factor that basically says
what is the sum of distances from my
species to all of the other species let
me just simply correct by that when
Computing my distances so I'm going to
have a promiscuity index
for
every species and I'm going to adjust my
distances to be revise the distances
where I'm just going to subtract the
promiscuities of the two distances from
the distance is everybody with me here
can I get a 5 for 3 to1 awesome good and
that's what neighbor joining is all
about and the idea here is we're going
to define the set of leaf nodes we're
just going to sort of progressively
merge but using this refined you know
distance okay and that's great for the
additive distances in other words
neighbor joining is going to do
fantastic for additive distances upgma
is going to do fantastic for ultrametric
distances but most of the time we're
going to be here in the general distance
scenario okay so what are we going to do
in the general distances
well we we can still use neighbor
joining and that will probably be a fine
tree most of the
time or we could be a little fancier and
say well let's define an optimality
Criterion and that optimality Criterion
could be either character or distance
based I could basically say maybe I want
a least squares solution where I can
basically simply see what is the
deviation that I have from adding these
distances between adding these distances
and then the original Matrix distances
and I'm just going to Simply set all of
these
parameters to minimize the sum of square
distances between what I get for each of
those does everybody with me here so
then I have an optimality Criterion
which is basically I want to just
minimize the distances and then I'm just
going to have some kind of fitting
algorithm that's going to try to select
these and you know maybe I will have
some kind of gradi in descend that
basically says if I adjust this distance
how is it changing and so on so forth is
everybody with me here awesome so that's
in the general case where basically um
you know we could minimize the distance
discrepancy with Le squares or with
minimum Evolution okay as for character
based well let's talk about it next okay
so what have we talked about we've
talked about the basics of hogen we've
talked about how to go from alignments
to
distances how to go from distances to
trees we looked at different tree types
ultrametric where there's a clock
additive where it was generated by a
tree and general distances where all
bets are off we talked about upgma that
works great for ultrametric we talked
about new neighbor joining that works
right for add at it and these have
guarantees but also have limitations in
the case of the general distance and we
also talked about this optimality idea
of maybe we could adjust the tree
branches to to minimize the least error
or minimize
Evolution okay and then again all of
these require a search which is what
we're going to talk about number
four okay so now let's talk about how we
can go from alignments directly to trees
so how do I go from an alignment to a
tree okay everybody with me here so what
are we going to do we're going to look
at different approaches for doing that
the first approach is
parsimony where I could be either set
based or use dynamic programming and
then the third approach is maximum like
okay so again we saw how we can go from
sequences to distances from distances to
trees or from sequences directly to
trees and that's what we're going to do
now but remember that this everything
we're going to say now in section three
is for a given tree how well does it
match a given alignment but then we're
going to sort of have some tree proposal
and scoring couple to that
okay so character based philogyny is
essentially about scoring not
necessarily about tree finding so we
need to couple them with a tree finding
algorithm okay so and that tree finding
algorithm is going to be some kind of
tree proposal and update and that's
going to be part four and there's two
approaches which use the same
architecture one seeks to minimize
events and that's parsimony and the
other one is probabilistic and that's
maximum likelihood or maximum aerior
we have an alignment an alignment is
made out of many columns of the
alignment so suppose that we're looking
now at one of The Columns of the
alignment everybody with me so in one of
the columns I see B for one species a
for another species B for one species a
for another
species and I want to know how bad or
how good is that tree for capturing the
states of these variables for each of
the
species okay so how good is it well if
this is my tree I have to infer a cost
what is a cost a cost is the number of
events so I can say here's how many
events I need to explain my
tree and to get that there's a very
simple algorithm which is a parsimony
algor that basically says I'm going to
look at the nearest neighbors and I'm
going to walk up the tree and I'm going
going to infer the most likely or at
least a good ancestral state for every
one of those so if I have an A and A B
here what's the what are the
possibilities for the
ancestor either A or
B okay so I'll just choose the set a or
b and what is the cost the cost is one
either because I Chang that ancestral a
into a b here or because I chose that
ancestral I changed that c b into an a
by mutation event along this
Branch 54321 who's following with me
awesome great now if I have an A or a
B at that position here and I have an A
here what should I put
there probably
a okay so then the next step after that
is if I have a non empty intersection
between the set of possible characters
here and the set of possible characters
here then I'll just take that
intersection okay and then I have an A
or a B here then I'll take the union
again is everybody with me here so this
is the simplest possible algorithm if
the intersection is empty then I choose
the union if the intersection is not
empty then I choose the intersection end
of story
yeah so this could be an a a g an A and
A
G uh so here I've conflated the concept
of a species and a character in this
particular case I'm looking at one
column of the alignment and in that
column of the alignment I have character
a that could be rounded hoofs character
B could be pointy hoofs so I have
rounded hoofs pointy hoofs rounded hoofs
pointy hoofs or it could be the actual
letter a g a g and so on so forth these
these are all great questions so you
know don't don't feel bad for asking
something that probably other people
were wondering as well okay and then as
for the species yeah you you could call
this bucket the human bucket the chimp
bucket the rat bucket and the mouse
bucket or something
okay everybody with me here awesome so
there's a problem the problem with this
Union intersection approach is that it
doesn't actually capture all possible
trees in other words it will only
explain this particular Tree by having
an a at that position but when you look
further up you basically realize that
wait a minute there's a b here and
there's a b here so I could have gone B
all the way and then just changed into
an a once and an a twice in this
particular
scenario okay this is equally optimal
it's still only two
events where the Anor was a
b but it's simply not accessible to the
union intersection approach because it
doesn't look
ahead okay so what are we going to do do
instead we're going to use dynamic
programming what dynamic programming
allows you to do is to remember all of
the possible scores for all of the
possible paths
find the maximum score and then Trace
back to find the optimal path in other
words it will postpone making that
decision until the end of the search so
instead of just saying oh there's a
nonzero intersection great I'm going to
just set it to that it's going to
maintain all four characters so it's
going to say at every position I can be
an a c g or
T and my observable species are Mouse
right human and dog
so my mouse costs if I set the mouse to
a my cost is
zero if I set the mouse Branch to CG or
t my cost is one because I need to
change it from that back to the
observable a is everybody with me here
so I can do that for the observed
variables mouse rat human dog and I can
just set it to exactly what's observable
the one that's observed is the zero cost
one
and now at every merge I just simply add
up the
costs so at position
B1 if I said B1 to be an
a then I have a cost of one if I have if
I said B1 to be a g I have a cost of one
so in both cases I have an optimal cost
and I'm maintaining the fact that
there's two possible solutions both with
cost one one step above I now have the
costs for B1 and I just simply add up
the cost for the
human and then the cost for B2 is one if
it's all set to one or three events if I
set it to c three events if I set it to
T or two events if I set it to G so far
G doesn't look good at
all but at the next iteration when I go
to B3 based on the states and costs of
B2 and the state of D and cost of d
then at
B3 one now becomes a two but then the
two becomes a two again because there's
no cost and suddenly I have two Optimal
Solutions one is an A and the other one
is a g at that an can I get a 54 32 1 so
who's following awesome great so that is
a parimon approach but using dynamic
programming going up the tree okay and
that's actually going to be the
foundation for many of the other
approaches this concept of dynamic
programming to basically infer a cost
function for every possible state of the
intermediate
variables okay great so we basically
looked that a greedy approach of Union
intersection that doesn't access all
solutions but still is guaranteed to
find an optimal score or a dynamic
programming approach that actually sums
up the costs as it goes up the
tree okay now let's look at
a maximum likelihood and a maximum
posterior more probabilistic approach
that also includes back mutations Etc
okay so what are we going to do we're
going to build a generative model and
that generative model is going to have
some kind of process through which it is
generating
trees I can have a duplication loss
process that generates the topology and
I have a mutational process that
generates the actual sequences given the
topology that basically says that I will
have some Maximum likelihood
interpretation of the sequence alignment
data
D
given the branch lengths B and the
topology t with which I am generating my
sequences so I'm
sampling a set of data I'm sampling
characters
using a topology of a tree and using
Branch
lengths and what I want to do is
maximize basically do a search over all
possible Branch lengths and
topologies to find B hat and T hat the
optimal Branch length and the optimal
topology that best explain my
data can I get a 543 to1 here awesome
beautiful
alternatively I could say that I don't
want to just maximize the probability of
getting rating the data given my branch
and
topology what I want instead is to scale
that by a prior this should say
prior I want to scale that by a prior of
what are some completely unrealistic
Branch length and
topologies okay so I want to have a
basan approach that basically says what
is my prior over all branches and
topologies and what is the likelihood
and together I'm going to get the
posterior okay another way to think
about that is the posterior is having
observed the data in other words
posterior to observing the data what is
the maximum probability branches and
topology okay and this is just using
basal can I get a 543 to1 here awesome
beautiful
okay so that's the likelihood of the
data given the model and then this is
the prior on the trees and Branch lanes
and how do I generate this I can have
some kind of duplication loss model I
can have a birth death process or a u
process and so so forth that generates
topologies and branches and here the if
I if I know the branches and the
topologies then the probability of
generating my data I.E the quences is
simply the evolution model that we
looked at
before namely I have a forward process
that generates data According to some
probability and I can just say given a
J's cancer model a CH parameter model
Sky model what is the probability of
generating The observed
sequences why is that helpful because I
can say given topology a and topology B
which topology better explains my data
okay and that probability is going to be
what I'm going to be using to choose the
maximum likelihood or the maximum a
posteriority tree everybody with me here
who here that they're learning stuff
yeah
good again this is taking a lot of
concept that we've seen already and just
applying them in the context of f loging
so we can compute that
recursively using the exact same idea of
dynamic programming that we did before
in other words in instead of just doing
a very simple score of plus one we're
going to do a slightly fancier score as
I go up my tree everybody with me here
all right so what are we going to assume
we're going to assume that every colum
of the alignment evolves independently
it's a very simple assumption we're
going to treat that column in isolation
and then we're going to do the product
over all of the
columns okay everybody can hear so far
that's step one step two we're going to
assume that every Branch evolves
independently from all other branches in
other words it doesn't matter what
happens in T6 t7 is going to have its
own evolutionary
process that's fine as
well so we're going to condition on the
parent and just say if I observed the
parent I don't care what happens in T6
I'm just going to evolve down my t7
Branch okay so I'm going to expand the
total probability into some product of
each of the children condition upon its
parent and the time elapsed along that
Branch so far so
good and the only thing that remains is
this probability of an ancestor which is
some kind of root prior which is
basically just the background nucleotide
frequency now how do I compute each of
these branches for a single column it
basically says I have a g here and I had
an a here that's just my juke scanter
orim parameter model and so on so forth
just a single event or at least a single
Branch isolated from all the branches I
know the parent I know the child and I
know you know how many changes there
were so how do I compute the probability
of a child given a parent in a time well
that's just you know the model that we
have already and we can easily calculate
it for any given assignment of the
internal
nodes and because the internal node
values are known are not known they're
they're unknown we're going to basically
marginalize we're going to basically do
is we're going to compute the dynamic
programming algorithm going up that tree
up these
branches maintaining the
uncertainty and we're going to sum over
all possible values of all internal SL
root nodes and that will
be what will represent the sequences of
all of the internal
nodes okay so basically the joint
probability of observing all of my
sequences X1 through X5 aligned to each
other given my topology and the branch
length is going to be simply that in
isolation which we're given this Branch
Independence we're going to assume that
it's just going to be you know each
child given its parent and the
corresponding Branch length which is
going to be simply that product can I
get a 543 to1 here awesome beautiful all
right so again side evolution of a
single sequence we know how to do that
evolution of a single Branch we know how
to do that just multiply all of the
sides together Evolution over the entire
tree we just walk up the tree and then
marginalizing over the hidden ancestral
sequences this is basically the dynamic
programming Matrix which I set up
exactly like before and when I put it
all together I have this very efficient
marginalization over all of the tree and
I have this dynamic programming
algorithm for you know Computing the
scores for every one of the characters
in every one of the ancestral nodes
which I'm going to be adding up
according to this case analysis and in
the end what do I end up with I end up
with scores at every
position and what did I do for my very
simple sum before I just took the
maximum score and I just ran down with
it okay just like
before I basically
had my minimum score my minimum cost two
here I set that value to a and then I
basically said okay well how did I get
here I need to remember the arrows I
don't know if you guys remember that
from dynamic programming earlier in this
in the course but basically every time I
say I got a two here I'm going to
remember what were the states that gave
me that two and I'm going to do the same
thing here as I go back down the tree to
basically compute the overall cost
okay so we're going to fill in all of
the internal node likelihood vectors
when we reach the root we're going to
multiply the base frequencies and that's
going to give me all of the states and I
can kind of go back and compute
that okay so this is this third part
here where I basically said I can go
from sequences to distances I can go
from distances to trees and I can go
from characters
two
trees score different trees and figure
out which tree gives me the best
likelihood or the best a posterior
probability but now I need to actually
suggest some trees how many trees are
there it's an exponential number
again because for every one of them I
could sort of choose which one of those
I want to go up and
then that gives me you know way too many
choices so what are we going to do
instead we're going to basically
iteratively refine the trees using some
kind of stochastic process for walking
through tree
topologies so I'm going to initialize
maybe with a neighbor joining tree
because that's a fine algorithm works
well a lot of the time and then I will
compute the probability of that tree
given what we just talked about and then
I'm going to modify the tree using some
kind of operations what are these
operations well I could do nearest
neighbor interchange that basically says
you know I have a b c d this way I'm
going to change it so that it becomes b
d
a sounds good so that's a nearest
neighbor interchange event or I can do
subtree pruning and regrafting that
basically says well you know C is
connected here I'm not going to move it
to to connect it here and so so forth
okay so and then I'm going to score the
likelihood of the modified tree
compare it to the likelihood of the tree
that I had
before and if it's better I'm going to
keep it with some
probability if I keep it all the time if
it's better then it's basically some
kind of greedy hill climbing approach
and I'm going to end up at some local
maximum If instead I keep it with some
probability that means that I might be
able to get out of this local
maximum okay and explore more of the
space moreover if I keep it with a
probability that's exactly the
difference in the likelihood ratio
between the two trees then I guarantee
that I will be exploring my space
according to the posterior probability
distribution of all three
topologies okay and that's what we call
Mark of chain
montard it basically says I can take any
proposal rule as long as it's connected
that as long as I can explore every
topology from nearest neighbor
interchange and sub tree pruning and
regrafting I can take that proposal Rule
and when it's worse I could basically
decide to take it or not take it when
it's better I can decide to take it or
not take it and based on exactly the way
that I do these decisions that I make
these decisions based on the
probabilities I can basically estimate
that posterior probability distribution
effectively sampling from the universe
of three spaces in a probabilistic way
okay
the last component is that I want to
estimate some kind of reliability
because every single time I have an
alignment that alignment is a sample
every time I have a species that species
is actually a sample every time I have a
pick an individual from that species
that individual it's a sample and so on
so forth so what I want to know is if I
had chosen a slightly different
alignment if I had chosen a slightly
different part of the genome if I had
sequenced a different Gene would the
topology be different so for that what I
can basically do is
resample Columns of my alignment and
redo this type of operation at those
different
columns
okay awesome so that completes part one
of this very ambitious
lecture that basically says how do we
build fogs we basically can go from
sequences to distances from distances to
trees from alignments to trees as long
as I have these three proposal in score
can I get a 54321 on this part awesome
guys are great all right so this was
part one let's go to part two part two
basically says that up until now we've
only worried about one type of object it
didn't matter we were comparing species
or genes or you know every hemoglobin or
only one ribosomal sequence from each of
100 species Etc
or God forbid a bunch of hemoglobins
from a bunch of
mamm so suddenly I can do a lot more if
I have knowledge of what every element
in my tree
represents okay and that's what we're
going to do now now we're going to deal
with
phenomics the first part is to basically
realize that Gene trees evolve inside
species trees what does that mean that
means that every time that I have a
speciation event say between mouse and
rat the mouse is walking around with a
bag of 20,000 jeans as soon as
itates from rat all of the genes that it
carries have to
speciate everybody with me here so
basically that every genan
tree if I label the branches remember
before I hadn't even labeled my branches
but now I've labeled my branches dog
human mouse rat
and if I build a tree topology that is
discrepant from the species
topology then I have to imply that there
were some duplication and loss
events okay so that basically means that
if I have any kind of Gene tree that I'm
trying to study I can label the
corresponding
branches according to the species that
they came from whether that that Gene
was sequenced in a dog in a human in a
mouse in a rat okay and now if I have a
duplication event as I mentioned
earlier all of the 20,000 genes in the
bag of mouse have to diverge sorry if I
have if I have a speciation event all of
them have to diverge but now if I have a
duplication
event that duplication event means that
on the common ancestor of mouse and
rat that Gene
was duplicated what does that mean that
means that at every speciation event the
two the two copies are going to be
speciated okay so that basically means
that all of the descendants of that
duplication event will now have to
copies is everybody with me here awesome
so let's make some definitions a gene in
dog that has one and only one copy in
human that fulfills the same function
and that arose from the same common
ancestral Gene that also fulfill that
same function is an
orthologue ortho means right up straight
up in Greek so orthologue basically
means it's a gene that descended by
vertical descent from that other common
ancestral
G now if I have a duplication event and
I now have two copies
say you know um hemoglobin a and
hemoglobin B those are paralogs of each
other because they arose from a
duplication
event and paralogs have all kinds of
properties paralogs might have different
functions PS might take on new functions
pyes might each keep a subset of the
ancestral functions of the pre-
duplicated Gene is everybody with me
here and paralog means on the side so
Ortho means write down par means on the
side everybody here so an orthologue and
a paralog can basically be defined
functionally just like I did orthologue
has the same function paralog oh arose
from dup gen
duplication and I can
also Define them based on their
philogenetic relationship now pay
attention
here an
orthologue pair is a pair who common
ancestor is a speciation
event a
paralog is a pair whose common ancestor
is a duplication event what does that
mean for R1 and R2 trace the history of
R1 and R2 R1 and R2 coales coalescing
basically means as I walk up the tree I
meet so they coales at a duplication
event everybody with me
here so the that means that they're
paralogs now what about M1 and R1 are
they orthodog or
paralogs Shout It Out M1 and
R1 they coales at a speciation event
therefore they're
Orthodox M2 and R2 are Orthodox but let
me give a tricky one M1 and R2 what are
they they're in different species but
they're different copies of these gen in
fact R2 and M1 coales at a duplication
event and therefore M1 is a paralog of
both M2 and
R2 R1 is a paralog of both R2 and M2 but
R1 is an orthologue of M1 and M2 is an
orthologue of R2 everybody with me here
awesome so now I want to Define what are
orthologues and what are
parallels for this I better
have a a a correct philogyny and we're
going to worry about that b a correct
species tree and we're going to worry
about that as well and
see a correct mapping of my Gene tree to
my species
tree and let's talk about that now okay
so how do I map a gan tree to a species
tree this is known as
reconciliation basically says that I
have a bunch of branches labeled by
species and I'm going to reconcile them
on the species
branches that's not obvious the way that
I'm going to do that is I will basically
map every single one of them as low as I
can go but no
lower okay basically that simple M and R
I'll map it to the mouse R common
ancestor but no lower Mr same same thing
this one same thing this one well what
do I have underneath I have
dmmr so basically I I better map it all
the way there but no lower everybody
with me here so that's basically a very
simple explanation for what
reconciliation is so I basically build
my species tree I build my Gene tree and
then I reconcile them by simply mapping
to the least possible height so I
recursively call call uh solve this
particular um algorithm which at the
root of it has this least common
ancestor in other words the most recent
common ancestor of all of the branches
of all of the species that are
represented in the children of that
node can I get a 543 to1 here yes
awesome
beautiful okay so that's the
reconciliation problem and now here's
here's where it gets tricky if I
reconcile the wrong way if for example M
and R reconciled here by mistake then
that implies all kinds of duplications
and losses that's why a Reconciliation
algorithm is very important okay all
right now that we have distinguished
Gene trees from species
trees we can do all kinds of new cool
things okay so first of all if I'm
trying to build a correct species tree
and I'm going to color those blue as
always then I could average a bunch of
Gene trees together in other words I'm
trying to figure out in what order did a
bunch of mammals diverge from each other
is the red panda closer to Panda or is
it closer to a
bear or a raccoon and so so forth okay
so how do I do this well I can take
every every Gene in all of these Maman
species and build a topology for each of
those using the methods that we saw in
the first part of the lecture part one
then I can somehow combine them to infer
the species stream how can I do that
well there's again many methods I could
use a super Matrix method that basically
looks at the Matrix of relationships and
then you know fig figures that out or a
super tree method that looks at the set
of all possible splits of two uh
branches I could minimize the deep
coalesence that basically means that as
I walk up my tree that all the pairs
coales as close as possible to their
Branch but not they do not Traverse
species Divergence
events or I can explicitly model
coalesence and I can use that to
basically
infer the most likely scenario for all
of these ancestral trees and again I I
want you to sort of get out a key
Insight here which is that I can
represent every split between a group of
n species
in this n s Matrix that basically tells
me what are all of the possible splits
and then I can count every topology as
simply what split does it induce if I
look at that
topology okay so the way to reconcile
topology is by start thinking that every
Branch simply separates AB from c e DC
every Branch here AB from CDE and so so
forth so even though
every Gene tree could have a different
subset of species represented the splits
that it induces can be compared across
these different topologies everybody
with me here
awesome all right now we should
basically realize that I can actually
use this information to build better
Gene trees I can use this information to
now have a better model for how Gene
evolution happens remember before I was
sampling topologies I was sampling
Branch lengths I can now have a much
more sophisticated model if I understand
that they're species trees and Gene
trees what are we going to do now we're
going to basically build a generative
model for learning what a gene tree
should look like if I already know the
species tree so we're going to use the
concept of a common species tree across
thousands of Gene
trees to improve Gene tree
reconstruction everybody with me here to
what we're trying to do trying to
leverage this common information to
learn some common properties of the
evolution of genes in that lineage of
species and use that to improve um
reconstruction in other
words if I have a known species tree of
dog human mouse and
rat and I end up with a topology of my
Jee tree where the human diverges before
the dog okay so that lineage here
diverges there I've just swapped two
branches doesn't sound like a big deal
but swapping those two branches
infers that there was in fact an
ancestral duplication
event in the common ancest of those four
species followed by speciation another
speciation and then a loss here a loss
here a and and so so forth okay so
basically what I need is one two three
losses and one
duplication which are very
costly whereas the cost difference
between you know branching here or
branching right above that might be very
small does everybody with me here about
the intuition so therefore if I know
something about the species topology
that can constrain my Gene topology do I
always want to follow the gene topology
no but when there's sufficient evidence
I'll be able to overrule the species
topology and that's what we want to
model everybody with me
here so this is um this is what we call
phenomics and this is something that
that my student M Matt rasmon and I uh
developed oh gosh a few lifetimes ago so
we want to develop a rat model that
basically said what is the probability
of a given tree given number one
the topology number two the
reconciliation and number three some
parameters that
are uh that are representing the
evolutionary rate of that Gene
okay so what did we notice we noticed
that as we took different genes in the
drosophila uh philogyny of 12 species
that we had different genes basically
showed a
scaling that was uniform across all of
the species
why because some genes are very
constrained and other genes are very
fast evolving but when a gene is
constrained it tends to be constrained
similarly across all of the
different species where it
evolves and when a gene is fast evolving
it tends to fast evolve in all of the
lineages where it's evolving so
everybody with me here with this concept
so that's the gene Centric view which
basically says that these Gene will
evolve fast or slow let me now take a
different view which is the species
Centric view this species here is has a
very long branch because it evolves
rapidly I don't know it sort of was
separated by a volcano it suddenly
adapted to a new environment and all of
its genes were more rapidly evolving or
that species has a shorter gen
generation time or a slower mutation
rate so you could think of it conversely
as there's a there's an overall species
tree which is a normalized version of
all of the gene trees where this species
here is always longer than those three
species here and it doesn't matter how I
What gene I throw in there that Gene
will end up evolving slower in that
lineage everybody with me here so again
these are the two forces the two forces
are on one hand you basically have a
species rate and on the other hand you
have a gene rate okay let me put it a
different way the branch between dropa
grimshawi and dropa ananasi which
actually as you can guess Dr grows on
ananas like pineapple um so grim shawi
and ananasi are
basically
correlated when you look at the absolute
lengths that you measure but if you look
at the normalized lengths they're almost
uncorrelated and you can see that on
average the correlation is 6 compared to
0.01 sorry 0.1 for the normalized string
length in other words there's this
common force that's driving all of these
correlations and you can think of that
Force as simply the fact that a gene
evolves at a given rate and a species
evolves at a given rate and when you
look at them together together they're
just the product of the two everybody
with me here awesome so what can we do
we can basically model the evolution of
individual
genes as sampled from some inverse gamma
distribution and the evolution of
individual species their relative
acceleration if you wish as sampled from
some gamma
distribution and therefore the branch
length is simply these you know
properties together there's a gene rate
there's a species specific rate and then
there's the time
elapsed everybody with me here can I get
a 54 321 awesome now suddenly that
allows me to completely change the
phenomic pipeline so before I would just
do an all by all blast I would cluster I
would align I would build the trees I
would reconcile and then you know I
would have some kind of reconcile tree
but now if I have the species tree I can
actually do much better at tree building
than that
why because I now have a probabilistic
model that basically says I'm given a
species tree I'm sampling topologies
from within that species tree when I
have the topologies I'm sampling
rates and when I have the rates I'm
sampling
sequences okay so it's a generative
model that explains every aspect of this
duplication loss Evolution topology and
mutation process everybody with me here
cool
and that suddenly had this you know
extraordinary Improvement in accuracy so
basically if you look at neighbor
joining it had 60% recovery of orthodog
we now had had suddenly 96% recovery
neighbor joining would infer um two
22,000 duplication events we could
suddenly infer you know 5,000
duplication events and so so forth okay
is everybody with me here so suddenly we
can get much much more accurate trees
that infer many many fewer duplication
laws
events okay all right so all of that is
modeling Gene duplication and loss but
there's another component which is that
Evolution doesn't happen in the whole
species separating at the same time but
there's a diversity within a species
remember before when I said that the
mouse is carrying a bag of 20,000 genes
and the rat is carrying a bag of 20,000
gen and as soon as they speciate all of
their gen speciate at the same time well
in practice it's not exactly that and
the reason is
that species are made out of populations
of
individuals and there's variation
between that
population specifically there might be a
duplication
event that happens in the common
ancestor of all of the mammals and the
species that carry that duplication
event have some variation some
individuals have it some individuals
don't and that standing variation might
persist along a speciation event and
another speciation event and now the
standing variation is finally resolved
when you get to a lower lineage so all
of that is thinking about Evolution
going forward but when you run Evolution
forward you have an exponential number
of possibilities
instead you could say well let's run
Evolution backwards I know that I have
observed these four
sequences the question when you run
Evolution backwards is when do they
coalesce and coalescence is when they
meet up on the path to the common
ancestor okay and here you you have
regular coalesence but then here you
have deep coalesence what does that mean
that means that the
topology of this tree is in
congruent from the topology of the
species that it came from in other words
if I look at A and B they coales after
CND D
coales do you see that so on the gene
tree cndd meet up first and then they
meet up with A and
B but in the species tree A and B meet
up with C first and only then they meet
up with
d you see that this is an example that
if you look at backwards in evolution is
known as deep coalesence in other words
these two lineages the a lineage and the
C lineage don't coales until after the D
lineage so here you have regular
coalesence and here you have deep
coalesence everybody with me here
conversely you can think of this going
forward in Revolution as incomplete
lineage sorting that basically means
that these lineages are sorting here but
haven't completely finished sorting when
the next speciation event happens is
everybody with me here who thinks this
is kind of cool I hope you guys are
enjoying this as much as I do so this is
this is like you know understanding the
subtleties of evolutionary processes so
now we have a problem because the same
tree can be interpreted in two different
ways if you only care about coalescence
and if you only care about duplication
laws if you only care about coalesence
and you see an in congruent topology oh
no problemo that's a deep coalesence
event but if you only care about
duplication laws and you see deep
coalesence you say oh well that's a
duplication and loss event is everybody
with me here so now the question is how
do you model both together and again
with my student Matt rason we basically
develop this two-step reconciliation
event that basically says I have a
coalescent tree that evolves inside a
Locus tree which in turn evolves inside
a species tree and I sample Loi where
here I have a Locus which was duplicated
and then I can have my coalescent Tre
have deep coalescence within that Locus
so suddenly I'm able to model both deep
coalescence
and duplication and loss in a single
joint model everybody with me here
awesome
yeah beautiful question and um that's
the topic of part
three where things can go you know all
over the place okay so the last thing
that I want to deal with is this
recombinations and this concept
that recombination events effectively
mess up the tree with which regions have
evolved in other words I have inherited
now a gene from my mom who was here and
a gen from my dad but my sibling has
inherited a gene from the paternal
grandma and the maternal Grandpa and so
so forth is everybody with me here so in
other words the moment I include
coalesence
events uh you know up a tree in a
population and the moment I include Rec
combination events then suddenly I have
the possibility of
switching from position to position in
the
genome the topology of ancestral Rec
combinations that or ancestral
coalescent events that explain any
position and that's known as an
ancestral recombination graph or an ARG
that basically tells you that these
genes in the human population at this
Locus have this
topology so basically you know very
often we say okay what's the ancestry of
this
person but then I'll ask you yeah but at
what position because the ancestry
of say one person in the
class at this Gene here might be oh I
don't know Asia Africa and you name it
in that other position it might be a
different ancestry because they
inherited a different Gene from their
parents does that make sense so the
moment I have recombination events I
can't just talk about a single philogyny
relating all people in this classroom I
have to think about all of the possible
topologies based on all of their
combination events that have separated
us everybody with me here so then you
can build this ancestral Rec combination
graph that goes through all of this all
right so um the last uh thing that I
wanted to leave you with is uh sort of
this Evolution near and far uh question
and so I'm going to I'm not going to
talk about how we build alignments or
how we infer these but I will tell you
about this
um very strange phenomenon where
where if you compare the species the the
the genomes of um you know four closely
related ye species you end up with more
or less a straight
line but with that fourth species here
you end up with a broken up line and the
key Insight here is what could have led
to that where you can zoom in here and
open it up and what you can see is that
every location of this one species you
have a whole alignment spanning two
complete regions in chromosome 7 and
chromosome 10 of that other species and
the same thing happens at every one of
these places where basically you have
some kind of collinearity here but then
that segment is also here and that
segment is also there and that segment
is also here and that segment is also
there and so so forth so at every
position you you end up
with a region of one species mapping to
two different regions of another
species but then the way that this
mapping happens is not that all of the
genes are in both regions there's only
two genes that are in two copies but all
the other genes are just simply
interdigitated with each
other so what goes on here what goes on
is that there was in fact a complete
duplication of that segment
after which this Gene that Gene that
Gene that Gene that Gene and that Gene
were lost in one copy and then this Gene
this Gene this Gene this Gene this Gene
this Gene this Gene and that Gene were
lost in the other copy so everybody with
me here so when you see this
interdigitation it basically means that
there was in fact a complete
duplication followed by
loss is that cool so so so this actually
happened to me I basically was staring
at these sequences and I was trying to
figure out what the heck happened and
then what we uncovered is that this is
an example of complete duplication
followed by loss and that's not true in
just one region but it was true in every
single region of the pomis Genome of
Baker yeast the modal organism that
everybody has been studying for you know
decades and decades
is in fact a descendant of a whole gen
of duplication from a species that we
just happened to sequence frankly
because they sent us the wrong sample we
had asked for four closely rated species
they mixed up the bottles they sent us a
further species and thanks to that
mistake we're able to uncover a whole
genal duplication event and what's
really extraordinary is that in some
locations you don't have a single Gene
that's maintained in two copies because
the vast majority of genes were lost
after that whole genome duplication
event
but in this region you also see that the
centrom mirors were in fact preserved
and that there's a one to two mapping
between every pair of chromosomes
between the ancestral pre-duplication
Gene order and then the derived
post-duplication Gene order of course
both species are alive and with us today
but cmis walty represents that ancestral
Gene order and you can see here that
there was a gene here that was lost and
there was another Gene here that was
lost and we can now study dramatic
episodes of evolution using that okay so
that allows us to now reconstruct the
ancestral Gene order but also infer that
there was a whole Gene duplication
followed by Gene law even though only 8%
of genes are actually maintained into
copies we can still
unambiguously argue that there was a
whole genome duplication and it also
allows us to now infer the fate of genes
post whole Jun duplication so we had
5,000 Gene before we went to 10,000
genes and the vast majority of them 90%
of them were actually lost in the second
copy retaining only 500 duplicated genes
and what's really cool now is that we
can ask given that rooting from that
common
ancestor which copy evolved faster or
slower and in some cases we're basically
finding that there was this dramatic
acceleration event giving rise to new
functions that the silencing protein sir
three evolve from a duplication of the
origin of replication function that was
there before or this antiviral defense
evolv from this translation initiation
function and so so forth and what we
found is that these derived function
genes were never lethal they were very
specific in their expression and they
were specific in their
localization okay so that's uh I think
where I'll have to stop
today um but there's just so so much I'm
going to leave you with one final story
of the RNA World okay we all study all
these species and you know we love
everything about them and we love the
central dogma of DNA mix RNA mies
protein but when you look a little more
deeply you basically see that RNA
actually has a lot of functions RNA can
basically uh play roles of you know
translation they it plays roles of
splicing it plays roles of catalysis it
plays roles of sens
and you know ribo switches and all kinds
of stuff and that points to this
ancestral world where RNA invented
proteins and together RNA and proteins
invented DNA okay so that there was once
an RNA world where RNA was used for
information storage through
self-replication it was used for for
modifications and it was also used for
catalysis where everything in that world
was carried out by
RNA and eventually there was this
specialization of functions where DNA
took over the boring task of storing
information proteins took over the
extraordinary versatile task of folding
in three dimensions and carrying out
functions inside the cell and
RNA at least still serves as the
intermed between DNA and proteins but it
also plays all kinds of other functions
okay and that RNA World basically is one
where um RNA basically in invented
splicing and you can still see that a
lot of splicing is made by rnas RNA
invented proteins and that's the most
Extraordinary Machine known as the
ribosome where you have this giant
Machinery where you have
um at the catalytic core lies only RNA
It's a combination of RNA and protein
and people thought for a long time that
maybe you know the catalysis happens by
the proteins but the structure of the
ribosome basically showed us that the
catalysis is all based on RNA that
proteins were only added later in
evolution to stabilize that whole
structure and then the adapter molecules
themselves are trnas which on one H side
function as DNA by basically binding by
complementarity and reading the triplet
code and on the other side the function
by structure bringing together a
particular amino acid for a given
Transfer RNA molecule so that
extraordinary invention basically
allowed now RNA to invent proteins and
what you see is that in all of the
operations that involve DNA RNA didn't
bother inventing DNA by itself RNA first
invented proteins and then together they
invented DNA through reverse
transcripts so basically transcript
itself happened only later but reverse
transcription came before transcription
and reverse transcription was basically
the process of taking this RNA
information and storing it in a more
stable
molecule and then together they you know
they make all kinds of additional
functions okay all right with this I
will leave you with this extraordinary
topic of evolution we only have one
lecture unfortunately given how much
other stuff we want to cover but
hopefully gives you some glimpses of uh
this extraordinary diversity of first
understanding phylogenetics the basics
of phylogeny going from alignments to
distances from distances to trees and
from alignments to trees and this tree
exploration the complexity that arises
from understanding that genes evolve
inside species and this phylogenomics
approach and also evolution in
populations in complete linear shorting
and these extraordinary events these
evolutionary jumps that can happen by
hologen duplication
and then the slides that I kind of
skipped in the in the middle are about
the evolution of evolutionary thinking
itself basically this you know
introduction of natural selection by
Darwin and you know the Advent of
genetics with mendal and you know all of
these different discoveries and I really
encourage you to just spend a little bit
of time studying that slide because it's
still an evolving field as you could see
like even students like you can sort of
have
you know an impact in understanding how
to bridge together all of these
different types of events but um you
know it's it's truly an extraordinary
field and I hope you guys um go on and
study all right that's where we'll stop
here and uh we'll continue on Tuesday
after Thanksgiving break with uh
metabolic modeling so thank you all have
a nice uh Thanksgiving r
