we are heading out to San Francisco this
morning I feel like I have to go on this
trip because
um all of the
experts that know about artificial
intelligence say the same thing that we
are on a default course to all die
Holly so nice to meet you I mean this is
like one of the worst possible outcomes
if we do this they this is like how we
die if we each China and the US are both
racing to make a bomb that could just
explode in their faces that it e time
and kill
everyone up there what is up all right
nice to meet you brother what's up man
how are you good to see you yeah awes
getting arrested is nothing if we're all
to die your family is in Miami you've
left your family to come
here uh how did that go what what you
know how is that how do you feel being
away from them it's heartbreaking right
I
mean I feel
like I wish I wasn't here I wish I
didn't need to be here and I wish I
could be doing my old life and you know
going forward with a normal future that
I had planned you know is this is this
the AI safety
conference do you par oh we parked right
up there that's amazing thank you so
much thank
you great to  me great to me like
I don't really expect to die in 2028
like I expect to die some in the 2030s
we are at open
AI I just don't understand I just don't
understand how anybody could walk
through that 
door and do that
work welcome to a special edition of for
Humanity an AI risk podcast episode
number 55 near midnight in suicide City
I'm John Sherman your host thank you as
always for joining me in today's show
travel with me to Suicide City San
Francisco at the edge of the singularity
as the Doomsday Clock nears
midnight I'm just a dad in Baltimore who
believes the big Frontier AI labs when
they tell us their technology could
Slaughter all life on Earth that they do
not understand how to control this
technology that they do not understand
how it works and that they spend all
their time and money making it stronger
not safer for Humanity is the AI risk
podcast for the general public no Tech
background required this podcast is
solely about the threat of human
extinction from artificial intelligence
AGI artificial general intelligence the
kind of advanced smarter than a human AI
that could kill us all could be created
in as soon as 2025 or 2026 according to
Sam and Dario amade two of the leading
AGI lab CEOs many if not most leading AI
risk experts believe once we pass that
point there can be no return and so
there is no time to waste so when I
heard in early October there was going
to be an AI safety conference in San
Francisco at the end of November I said
I'm going I don't need an invitation I'm
just going I need to
we are heading out to San Francisco this
morning
um we're going to the place where they
are making artificial intelligence I've
never been to San Francisco in my life
didn't think I'd be going um under these
circumstances but it is what it is
uh I um
I don't want to be going I don't want to
be doing any of this
 I really just want to be living my
life uh but I feel compelled
to do something um so like I'm just a
regular person no technology experience
other than using technology as a
consumer uh and like a year and a half
ago I was I was um
browsing the internet as I do and I came
across an article in Time Magazine
written by a man named ell alria Kowski
that basically said that uh our default
setting um with artificial intelligence
as it is currently being built is that
it's going to kill all of us uh like
literally Slaughter every single person
on Earth sometime in the next few months
or few
years I know know that sounds 
insane like that sounds literally crazy
like if I told that to the guy walking
that dog he would be like you're nuts
you should probably um you know see
someone
uh so I spent I've spent the last year
and a half
um spending a ton of my time on this
stuff learning as much as I can about it
and uh at no point in the entire year
and a half did I ever come across any
evidence that was like this proves that
Ellie eer is wrong that we're going to
be okay
um there's no evidence of that there's
only people wanting to make money who
kind of say that and they don't even
really say that
so the last year and a half I've making
a podcast um for the first 52 weeks I
did it once a week and and I've just
changed up the pace a little bit now to
do some different stuff to work on AI
risk Communications but um
it's basically like we're going to San
Francisco to see what is
happening at the edge of the end of
humanity everybody who is anybody in
artificial intelligence agrees that
there's a very strong chance the
technology that they are building in San
Francisco is literally going to
slaughter Us in the next few months or
few years
um there's a conference happening in San
Francisco this week uh that I was like
you know we'll go to San Francisco and
we'll go to this AI safety conference
it's super important it is um
delegations of AI safety institutes from
all over the world getting together to
coordinate how they are going to
approach AI risk and AI safety in the
year 2025 this most critical year when
all of this stuff is coming to a head uh
it is run by the
um uh Commerce Department's us AI safety
Institute which is a new government
agency created last year to deal with
all this stuff and so it's this super
important Global conference about how
we're going to deal with the most
important issue in the history of
humanity and they're not even telling
anybody where it is there's not even
going to be any media coverage of it
really like nobody even knows about this
 none of these people lined up in
their cars understand what is the
greatest threat to them and their family
we spent all our time dealing with with
all of this  and none of it is the
most important thing none of it is the
real thing that is actually the most
urgent threat to all of our lives and I
know it seems so inconceivable right
like people think how could a computer
program kill me i' I've been using
Microsoft Word I've been using Gmail for
a decade for 20 years and it's and how
could How could a computer software
program kill me so all of this stuff you
see on Earth is stuff we made to suit
our
goals if we build an intelligence that
is greater than ours it's going to build
stuff to suit its goals that will be
different than ours and we won't be able
to stop
it that's the future we're heading
towards where we're
building an intelligence an artificial
intelligence which is an alien species
right there's nothing human about it
absolutely nothing human about
it we are inviting and building our
alien successors to Earth by
choice and here's the most  up
part about it the choice is being made
by about 2,000
people this choice about the future the
fate of humanity affects 8 billion
people on our
planet and the choic is being made by
fewer than 2,000 people most of them are
in San Francisco and Silicon Valley and
they are doing it without our
consent right nobody here has said I'm
willing to risk the slaughter of all
living things on Earth for some
technology to increase workplace
efficiency or make cool images or make
robots do cool  nobody said I'm cool
with that nobody said hey Tech dudes go
ahead it's fine make make your
technology if it's a 30 50% chance we
all die that's fine we really just want
this sweet ass technology go ahead that
 conversation never
happened so we're going to the place
where these people work under the
assumption that they have our consent to
build this stuff that could kill us all
so when we bring a species to earth when
we create a species on earth that is
superior to us in intelligence it's
going to build tunnels but its tunnels
not our tunnels whatever suits its goals
right like humans no one could have told
you when cavemen were at the fire that
humans would go on to discover the laws
of physics that would create
refrigeration and humanss would go on to
like a combination of salt sugar and fat
known as ice cream that's a human goal
right humans figured out that ice cream
making ice cream selling ice cream
eating ice cream is a goal of ours so
when we bring in an alien intelligence
the question is what will be its ice
cream what will it want to
do we don't know the answer to that we
only know one thing it won't want to do
what we want to do because there's only
one species in the Galaxy that wants to
do what humans want to do think about it
like this if you took spiders on earth
and gave them an intelligence that was
100 times better than humans spiders
would kill all the humans in 2 seconds
they take all our Bridges and all our
roads and all our buildings and turn it
into spidery
things any species it's very simple if
you have a superior
intelligence you can then retrofit the
earth and the world around you and make
it how you want to suit your
goals I feel like I have to go on this
trip because
um all of the
experts that know about artificial
intelligence say the same thing that we
are on a default course to all
die that artificial intelligence is
going to kill you and me and my
kids your friends your family your pets
everything on Earth the fish the whales
the trees all biological life that if we
go ahead and build an intelligence that
is Superior to
ours our future on the earth is
over I'm on this highway today if you
look out at these cars
nobody cares or knows about artificial
intelligence risk it's the craziest
thing in the world like nobody knows
about this stuff and even when I try to
tell people about this stuff A lot of
times most of the time they don't absorb
it so you know you know I am a part of a
very very small number of people on the
planet Earth who fully understand what
is the most urgent threat facing any of
us artificial intelligence is different
than anything that has ever come before
nothing else is like it
uh we have the urge to compare it to
things all the time oh it's like the
printing press it's like you know uh
it's like the the invention of the
Internet it's like invention of TV or
radio
no it's like the invention of a nuclear
bomb no it's not like any of that
imagine a nuclear bomb that can
replicate itself make endless copies of
itself and decide on its own where and
when to
detonate that's what we're talking
about this is not like any other nuclear
bomb this is not like any other thing
that humans have ever dealt with any
other existential threat climate change
nuclear any of that stuff 99% of all
artificial intelligence is safe if you
use it as a consumer chat GPT it's safe
the problem is the 1% the frontier AI
development that is the most advanced
models those are the ones that the
experts all say can kill us all and when
I say the experts say they can all kill
us all let's talk about who these
experts are so there was a letter in May
of 2023 signed by thousands of leading
uh corporate AI
Executives safety leaders academics the
letter says that mitigating the risk of
Extinction from artificial intelligence
should be dealt with just like the risk
of Extinction from nuclear war or from
pandemic so that is all of the leading
experts on the globe saying that
artificial intelligence is as
existential a threat as nuclear war or
pandemic nobody knows
this how is is this possible with
nuclear weapons we have robust
International organizations to deal with
it that's why we haven't blown ourselves
up yet same thing with pandemics robust
International
coordination with artificial
intelligence there is more regulation on
the sale of a  ham sandwich than
there is on anything related to
artificial intelligence right now so
this is the moment we're in Sam Alman
the CEO of open AI says that we are
going to achieve artificial general
intelligence the dangerous form of AI
the form of AI that can kill us all next
year he says in
2025 he his company is going to achieve
artificial general intelligence Dario
amade the CEO of anthropic another
company that will be visiting on this
trip he says that it's coming in
2026 so let's be really clear this thing
that all the experts say can kill all
biological life on on Earth could come
in 2025 or
2026 nobody is doing  about it so
we're going to San Francisco to see it
in person to
see the brutal state of the moment
humanity is in well we are at the
edge of
Extinction and no one is even aware of
the problem we are just going to look
off the edge of the cliff right humanity
is at the edge of a
cliff right here 2025 2026 when is it
happening we're going to fly out to the
place where it's happening we're going
to meet the people who are involved with
it I want to put my hands on the front
gate of open AI I want to feel that
metal that is the place where these
people are walking in every day knowing
that their work could kill them and
their neighbors and they come back to
work the next
day I can't imagine I can't imagine this
whole world it's like there's a giant
party of 8 billion people on Earth and
in a small Corner 2,000 people the
people involved in making AGI are
plotting the destruction of everyone
else at the party and the part's just
going drinks are happening drinks are
happening and these 2,000 people in
their small little corner keep building
their Death Star to  come kill us
all
I've had people ask me like do you think
you can change the world John do you
think you can change the world and I'm
like  yes I do I think I can change
the world I do people have changed the
world individuals have changed the world
groups of people have changed the
world
and certainly the people who did not
change the world are the ones who said
you know what you're right I can't
change the world I'll just  sit
home and wait for the end
 that I know I may feel like I do
feel like sometimes the guy walking
around with the  we're all going
to die the end of the world 
clapboard 
and I don't care like I don't care
that probably people in my life people
in my family think I've lost my 
mind I don't 
care
um the evidence is overwhel in there is
no controversy it's
only what are we going to
do there is no debate about what's going
to happen if we build a  super
intelligence we're all going to
die and we're choosing to build
it a small group of people making the
choice for everyone
else and I am not okay with that so I'm
not a tech guy I'm a Communications guy
I work with cameras and microphones I'm
taking my camera taking my microphone to
San Francisco to the edge of the
world and going to look over the edge
with
you when we landed the plan was to go
meet Holly Elmore the founder of pause
AI us and talk about the protest she had
planned in front of AGI lab anthropic
but as you'll see on this trip nothing
really went according to plan
we are in San Francisco uh this place
looks different every billboard we've
driven by on the highway so far is
somehow related to AI we literally just
drove by a billboard get literally said
don't hire anybody else just use
AI um so we are on our way over to the
Berkeley campus where we're going to
meet Holly I'm excited to meet Holly for
the first time in person you look at the
difference between the organization of
the people who are making AGI and the
organization of the people who are
opposing AGI
um it is a
daunting uh hill we have to climb but
there is no choice we either climb the
hill or uh fall down so I'm here to
climb
hly so nice nice to meet you you are
actually a real person we're not we're
not pixels of of people we're not
anymore not for not yet not
yet chances are like possible heavy rain
heavy rain on Friday in San Francisco so
I am one of the most important meetings
in the world was happening they're
figuring out how to coordinate so that
we don't all
die and they're not even telling
everybody where it
is I still I was shocked actually how
difficult it was to get information for
this I had to like do a little SLE thing
before for protest actions but um yeah
this was a a big secret so somewhere in
this city international delegations are
gathering to discuss coordination and
this happened at a crazy time so I know
you saw this last night with that us
China racing towards AGI Manhattan
Project Madness like when you think
about  moving quickly I was like
literally in the airport reading about
how I guess the government is now
supporting racing to AGI what was your
take on that I mean this is like one of
the worst possible outcomes if we do
this they this is like how we die if we
each China and the US are both racing to
make a bomb that could just explode in
their faces at any time and kill
everyone I mean that's horrible also
even if that doesn't happen we're at War
you know we're in like a war it's and
China has given a lot of signs of being
willing to cooperate in slowing down uh
even China is the only uh country in the
UN to bring up the possibility of
pausing um I just think the assumption
that we're in this race with China is
very premature ex that this
is a sign that somebody
made
you yeah so uh I was going to write
something on this free space here um
about but actually I all morning was
like what even would be the message now
like
given given everything that's happened
you know with the election like things
are really going to change with what are
like National direction is with AI
safety and uh so I'm really not sure my
the plan for being here uh or wherever
this conferences originally was uh to
provide like a supportive presence that
said that people want Global cooperation
and uh because it's kind of like in the
policy World especially and like among
like insiders with AI there's
this idea that it's it's naive like oh
it's inevitable like no people aren't
going to go against their incentives and
there's like a real lack of familiarity
with like they're pretty out of touch
with just how much the public doesn't
want this to happen and the public does
have power you know via government and
the people at conferences like these
should know that and I think they should
feel encouraged and feel that they have
many of them think that will for
operation is the best solution but they
think it's unrealistic and so whatever
we could do to show them the truth of
like here are members of the public and
we are in favor of this uh we want it to
do but honestly things have moved so
fast with this whole thing it's all
moving so damn fast it's it's impossible
right so just to play re let's just C
recap a little bit right so last year at
some point they formed the USAA safety
Institute new in new agency under the
Commerce Department um you and I are
hopeful that it's going to be doing all
sorts of great things with AI safety it
has Paul Cristiano at the head of IT who
is a very encouraging selection someone
who sees the world a lot like we do I
feel like
um Trump wins there's this conference
that is scheduled for the next two days
here in San Francisco nobody knows where
it is there's no media coverage of it
anywhere that I can see and we don't
even know what's the future of the
actual agency that's hosting it itself I
think I got a false lead like literal
like possibly to keep people off the
scent I don't know obviously this is the
most important problem in the world
right there's nothing like there's
really nothing else that anybody should
be paying attention to and nobody is
paying attention to this thing here at
all it seems it's this is my like base
hope for POS is there are when you pull
people uh the majority they don't want
to go too fast with AI many just
outright say we should pause until we
know what we're doing uh I want those
people to know that the other people
exist I want them to know like this is
actually a huge voting block this should
be a voting block we should be aware
like we don't have to change anybody's
Minds in order to access to have the
majority of Americans on our side they
are on our side uh but they don't know
that you know like there's not an
awareness of that and so protests are
one way to raise awareness of that uh
and we do have other protests that don't
require quite as much in this inside
knowledge uh uh that are and I think
that's uh a Way Forward is simple just
the AI companies are doing dangerous
things and we don't improve of it um so
our next protest is at anthropic which
is normally considered like the good guy
lab right uh it they're not they are
building they are actually now you know
pushing at the head like pushing this
arms race to create this incredibly
dangerous technology before we know what
they're doing are they like better than
the other labs as far as uh you know
like the safety benchmarks they're
supposed to meet yes are they still
going ahead with an incredibly dangerous
technology that nobody knows how to make
safe yes it's not okay 8 billion people
on Earth 2,000 people working on this
thing that has the power to kill us all
and almost everybody just going about
their daily lives totally unaware of it
the the the size of this movement of the
pause AI movement of you know the the
whole movement to control AI so so so so
tiny how what what what the hell can we
do about it I am focusing our P us which
I run is focusing on protesting and
lobbying as our interventions there's
also uh like a much lower tier of
commitment which is just like being
online in the mix talking about about it
with people you know there's a great
website run by posi Global pa.info that
covers just all aspects of this issue
everything you'd want to know the
pa- us.org website is soon going to have
more specific things about what you can
do in the US the pause solution is
something that's pretty obvious and so I
think that like starting from there like
let's pause and what would we need to
figure out during the pause for things
to be safe like during the pause we'd
have lots of time to think about that
and so so a lot of this is a reason that
like a majority of people can get it
because it's sure people have different
values you know about like how we should
live what would be the ideal future if
we could achieve it but I think we can
all agree or if we become educated we
can all agree that we need more time to
achieve safety with any of those ideal
Futures and maybe some of them aren't
possible
so we are off right now to go to the San
Francisco main courthouse and we are
going to meet Sam and Guido of stopped
AI who have a court appearance this
morning for having been
arrested uh for either blocking traffic
or blocking the front door at open AI um
these guys using their very aggressive
tactics to uh try to do something try to
attack the same problem um I'm trying to
attack so I'm super excited to meet
Guido and Sam I've I've uh zoomed with
them I've talked with them I've had them
on the uh Sam on the show and and his
friend remel
um and so we're going to go to court
with them so everywhere go we go out
here we see these Billboards about AI
I've never seen a billboard anywhere in
any other city in my life about AI but
in San Francisco thank you nice people
we love them um every single billboard
you see is somehow referencing AI so
like these people here are just living
in this bubble of like everything is AI
everywhere you look
up there what is up all right nice to
meet you brother what's up man how are
you good to see yeah awesome all right
so we're in front of the San Francisco
Courthouse with Sam and Guido guys so
what is going on this morning here in
this courthouse uh we're going to court
to uh see if we're potentially going to
go to jail but I don't think we will
we'll probably just have our charges
dismissed and what was the arrest for uh
we blocked the entrance to open AI back
on uh October
something and uh yeah I think 21 yeah
just for the charge is just obstructing
pedestrian flow so and how many times
have you guys been arrested uh for
activism related to stopping
AI yeah uh three times for me three
times yeah and is this this is the court
from the first arrest just sort of
processing through uh no the first
arrest uh those cases have already been
dismissed same with the second one um
I've already G to court for those so
this is we're going to court now for the
third which is back in October okay and
it's pretty uneventful they just sort of
process you you get out yep pretty much
all right and and what is the idea with
just getting arrested again and again
and again uh well we got to raise
awareness you know that no one's really
uh getting arrested is nothing if we're
all going to die so someone's got to get
out there and do direct action to raise
awareness cuz other you know activist
groups do direct action and it helps get
awareness out like you know black lives
matter and just uple in the UK people
know about them because they do direct
action also we got to take this to trial
um because our position is that these
this is not an illegal act right this is
a legally defended act this is
proportionate h a proportionate response
to the threat that these AI companies
are imposing on society the threat of
annihilation right they're cogn
innocently in full knowledge risking the
existence
of our society Humanity yeah um and this
is like absolutely unacceptable there's
nothing
that gives them the authority or the
right to do that totally no consent
whatsoever yeah yeah absolutely so I
mean this is like this is what
sayane normal people should be doing
right if the government whose purpose is
to protect the security of our Society
is failing to do that as they currently
are they're they're they're in fact
protecting these companies yeah when we
went to blockade open AI the last time
um you know I spoke to the police
officers and said we need your help here
we need your help shutting this company
down they're a threat we explain the the
nature of the threat um the police are
acting as the Agents of the government
right they are and currently the
government is extending that physical
security and protection to these
companies which are risking our lives so
this is like a
crisis um yeah government is constituted
to protect the safety of society right
to protect the well-being of society and
they're failing that
responsibility We the People right this
is like the contract that forms the
legitimacy of representative government
we've delegated that responsibility to
the government if they refuse to accept
it it returns us it's our responsibility
to take care of each other to protect
the Society of buying for the people
yeah that's what's the this is what
we've been reduced to essentially and um
yeah so the goal is to bring this to the
primary goal is to encourage people to
join these actions to physically
obstruct and shut down dangerous AI
development everywhere I love it with
the demand that we that the government
needs to shut it down nationally and
negotiate an international treaty to
stop this and um pursuant to that we
want to take this to
trial and present that defense right
that that this action is necessary and
proportionate yeah because I believe
that normal people get this contrary to
you know misconceptions normal people
understand when it's explained to them
they understand the implicit danger
and you really radical evil of this
project to risk the existence of
humanity and so I would rather be judged
put put that to a jury of my peers maybe
no I'm
Sisco no AB I mean I talk to people the
street I've talked to hundreds of people
on the street many people in here in
this city get it yeah so let me ask you
guys this neither one of you guys are
from San Francisco right you have both
moved here left your lives and you were
in Miami yeah yeah were you were in
Seattle left your lives left your your
families and come here to spend your
whole Lives full time to stop AI right
yeah that's why we're here I I don't
know that there's I don't know that I
know anybody in this whole game that has
really put themselves their own flesh
and blood on the line in the game the
way you guys have and and I think it's
crazy we're the only two people doing it
like I you know wake up every morning I
can't believe that we're all going to
die how are how is not this is your
choice also right I mean you could be
the third person and you're your
audience no I'm I'm not joking it's
right I'm absolutely serious
like is this real or isn't it
real like why did you fly out here in
San Francisco because this is 
real and I'm worried that my kids are
going to be killed by this  exactly
yeah so there you go we need to be here
that's why I'm standing here in the
 bomb cyong with my brothers here
yes yeah yeah there isn't it's not a
question of
like I mean fundamentally it's a
question of understanding what needs to
be done and doing it regardless
of expectation of success it's because
this
is like internally subjectively what
this felt like understanding that it
needed to be done I couldn't stay at my
desk making jewelry like I've done for
the last 24 years it's
just doesn't make sense right this is
what makes sense to try everything that
I can do to make sure that my children
have a future right to make sure that
this world keeps on going so like part
of the theory
of nonviolent civil disobedience is
creating the visual it's
like trying to bring some fraction of
this suffering or
yes disaster that is going to occur in
the future if it's not sto bring it into
the present and bring that conflict
forward to where it can be meaningfully
grappled with by Society yeah and that's
what it's going to take you I've seen
you ask many times what's it going to
take it's going to take people acting
consistently with what it means right
actually sacrificing materially tangibly
their comfort their prosperity their
Futures their lives right this this is
exactly what it's going to take and
nothing less all right so we are in the
courthouse interior in San Francisco and
Sam and Guido are going in to uh be
processed for their arrest here at the
uh Criminal
Division and it seems like they'll just
be released like super quick like no big
deal but uh I guess with these things
you got to wait and see oh 17 so so okay
you just went and saw the clerk yes and
what he say so they did not dismiss the
charges so one step closer to the
truth and it's good that they didn't
dismiss them because you want to keep
pushing it so that they precedent yeah
yeah so this is a good
thing yeah absolutely that's why we're
that's why we're doing it all right so
off to the Next Room yep okay
all right I don't know they added the
charges that were dismissed yeah yeah
and is this like a DA that's making
these decisions I have that's where like
a prosecutor that's the UL where the
ultimate decision comes
from wow so someone was like we're not
going to let these dudes off quite so
easy right yeah
interesed all right so tell me this part
of this thing so you guys left your
lives you've come here to San Francisco
where are you living while you're here
well I got here uh I started camping out
uh on the beach uh waiting to get into
homeless shelter and
uh so I've been living yeah probably
about 3 weeks now in a homeless shelter
yeah yeah and Sam you've been living
there too mhm yeah I've been there for 6
months so what is that like that's not
horrible I mean there still s with 50
people in a room um
I mean it it's a lot cheaper than like
living in co-living spaces cuz you don't
have to pay some overpay for like food
rent stuff like this so we would have
gone bankrupt if we had tried to do that
I had tried to do that so and this place
is so expensive to list most expensive
in the country or one of yeah yeah so
but now we actually have enough money to
go get a place we're just looking and
okay all
right uh again just more
impressive putting your own skin in the
game putting your own
Comfort it have you guys ever done like
that before have you ever like been
around a hom shelter before not really
at all now I went I went to into the
Marines when I was 18 into the reserves
so it's not much different than basic
trainings it just WS with a bunch of
guys wow yeah it's safe people are nice
I mean there's you know they're normal
people people like and me and it's safer
than sleeping outside and just to to be
so real like your threshold for being
like I'm going to ditch my whole life
and come here wasn't like I can lead a
similarly comfortable life here you were
like I am willing to leave Comfort
behind whatever needs to be done I tried
that it the money would have dried up
extremely fast yeah who was trying to
stay here um and continue protesting
where the compes are cuz if you try to
live comfortably here with the way money
was you know a few months ago that just
wouldn't have worked so it's just it's a
pragmatic Reason Not Like A any other
thing yeah what is that and I say this
because like like uh I've never I've not
gotten to that level you know like like
we had we not to din last I like wait
like I've not gotten to the level of
like dropping personal comfort and and
uh well I admire it go for it do it I
mean it's like that's how you do things
right yeah you just have to get started
and do yeah I mean I guess by you know
it's all levels it's a choice it's all
in your head but you guys are your head
right I mean what is I don't know if
it's about self image or your
expectations about what other people
think about you or but I mean all this
is Fades into IR relevance in comparison
to what we need to do
right and it is really hard for like
most people that Del live at Holy
shelter I understand this and we are
trying to set up a space where uh we can
accommodate like 20 people okay um and
hope you that's people that want to come
out here and live and do this protesting
and get like just wake up every
focus is like raising the funds to
create the material structure to support
people full
time your family is in Miami you've left
your family to come
here uh how did that go what what you
know how is that how do you feel being
away from them it's heartbreaking right
I
mean I feel
like I wish I wasn't here I wish I
didn't need to be here and I wish I
could be doing my old life and you
know going forward with the normal
future that I had planned you know but
that's the situation that we're in
is being imposed on us from outside
and we have to
react appropriately to it you know which
means not ignoring what's actually going
on not
pretending reality doesn't exist yeah
and so you are waking up in a homeless
shelter every day away from your
family every day starts with like what
can I do today yeah I mean we've got we
talk we've got we plan out we've got a
general plan that working so
it's uh moving as expeditiously towards
it as we can yeah man I don't want to
 be here either right yeah oh for
sure for
sure so we just spent a few hours in the
courtroom here at the uh San Francisco
Criminal Court division courthouse and
and honestly like I felt like I was W
witnessing history a little bit like
we're just sitting in this kind of
lonely courtroom and you guys are going
before the judge and and uh it's like
who on Earth is taking AI risk seriously
enough to put their own literal personal
Liberty and freedom on the line there
was a chance you all were going to jail
today it didn't happen we'll go through
why and everything but
um it it it was uh powerful to sit in
that courtroom and and watch you guys do
your thing so there's going to be a
trial and the subject matter of the
trial is not going to be did these guys
chain themselves to the fence that'll be
a part of it but we're hoping that the
trial is actually going to be about is
AI risk something that justifies you to
do what you did right and there's some
sort of carve out in the law some way
based on climate acted action before
that there's this is a basic common law
it's the it's the defense of necessity
um that's what it's called defense of
necessity yeah necessity defense it it's
the basic I mean everyone's familiar
with the idea that if you're walking
down the street and you see a car with a
child locked inside
and they're in danger of Suffocation
because of the Heat or
something morally we understand the
right thing to do is break the window
break the window save the child the law
recognizes that that is legally defended
by the need to prevent a greater harm
yeah that's the basis of the necessity
defense normally actions which on their
face may seem illegal or violate the law
can be defended by this need to prevent
a greater harm and so that's our
contention and we literally have 8
billion of us locked in the  car
yeah exactly we are we're we are right
now our entire Society is in imminent
harm of death or severe injury that's
what that's what's going on that's this
that's the situation that's obtains
right now yeah as long as the process of
research and develop towards artificial
general intelligence and artificial
super intelligence is going on yeah
right and so your point some climate
groups have successfully used the uh
necessity defense to defend their
actions um and have gotten off on that
uh but just to be clear like even if
we're not successful in pleading
innocent with a necess defense we're
going to keep doing this until we're all
dead in prison or achieve a permanent
stop to the development of AI so it's
one of those three
options wow um and so you're going to
try to bring in some experts to testify
at this trial yeah so at this point it's
like yeah um I was talking with the so
you know I've never done any kind of
like I've kind of I've kept my nose
clean my whole life right I don't I
don't really know much about how the
whole legal system works but um yeah
just briefly discussing with the public
defender you know we're going to try and
get all the expert testimony we can to
establish that AI development towards
very capable systems is a is a danger to
the public that it's an imminent danger
because there's no road map nobody knows
what's going on in the models so nobody
knows what new innovation or Insight is
necessary to make really dangerous
systems yeah also can't have indefinite
proof of safety like that's impossible
to it's impossible to prove
experimentally that something smarter
than us will never want something that
will kill us all it's not possible Right
these companies cannot give an assurance
that what they're doing does not risk
the destruction of humanity and the CEOs
of these companies very publicly and
self-consciously understand and have
stated publicly that they understand the
actions that they're taking risk the
existence of our society yes and I take
them at face value and so do they signed
they they the the CEOs of these
companies along with hundreds of other
experts signed a statement on AI risk
that this represents an existential
threat yeah and just to be clear we have
no vested interest in any of these
companies like some people say oh these
these CEOs are saying this because it's
a marketing stunt they want to you know
rally up investors I've ever heard we
don't have any STI in in any of these
companies like we're not and I don't
even get that like that is a whole thing
like when people are like oh the CEOs
openly admit that their product can kill
everyone what the accelerationist will
tell you is oh that's just a sales
tactic they're doing that so they can
sell more software whoever sold more
stuff by saying it kills everyone right
what is that it's not just the CEOs it's
the academics it's the founders of the
field of deep learning right it's it's
hundreds of experts yes yes yes yes yes
yes but just to that one response they
have is like oh no Sam alman's just
saying his stuff can kill everybody
because he wants to sell more stuff what
logic is that low grade low grade uh L
human intelligence human intelligence
yeah yeah all right um so what's next
for you guys where do you go from here
oh we got to talk about it we got some
other things in the pipeline so I asked
I talked with a public defender about
what are the proper steps like what
would you do if your neighbor was
building a bomb in their garage and the
police didn't answer your call right
they wouldn't they didn't wouldn't do
anything and so he's like who's you know
she said you know you got to you would
make what what what would we do in this
situation you make a police report you
would report this activi is going on
this you know I'm not like an expert in
what the law is but it seems pretty
clear
that if someone is undertaking an
activity which they understand to end
the entire Society this has got to be
it's got to be covered by something
right like reckless endangerment or
something why do we have a government if
that can't be stopped right and so yeah
um she said probably the da won't uh is
not going to like act on that report
because you know they're a big company
and they're the da this just not the way
things typically work in the world this
is why we have to get a large group we
need to get a lot of people to make that
report right if we've got you know and
then we've got to bring it to we've got
to bring the DA's decision into the
public sphere yeah like show up on their
front doorstep maybe why are you not
taking this serious totally like I've
said for a long time why are they not
charged with attempted murder like
literally the executives of open AI with
attempted murder of all of us yeah or
reckless endangerment endanger uh
totally like the government's not really
going to listen to any of that until
they see a large number of people on the
street I think the first step maybe is
encouraging people we need to find you
know I I'll talk to try and get more
legal advice about how to do this
precisely
but they need to be reported to the
police right and not just by one dude
like we everyone who understands this
needs to report this to the police and
generate pressure on the da to take
these charges seriously oh my God it's
got to it's got to be brought into the
public sphere it's not going to be like
solved with two guys in some courtroom
somewhere yeah right that's the whole
point of this is involving the public in
the struggle for our rights and our
lives because we have a right to live
peaceably and not like be threatened
with Annihilation by this completely
outrageous activity by these AI
companies totally and when I said to you
earlier I was like I I felt like we were
witnessing history in there you said
something that I thought was important
like history is not a spectator sport
like yeah yeah you're witnessing the
history that you choose to make right
like you me everyone every moment of
every day of Our Lives we make that
choice about what history we're going to
witness and so it's not a Spector for
right you've got to step up everyone out
there's got to step up yeah and then
we'll have the history we want otherwise
we're going to get another version of
history and not doing anything is an
action yeah if you sit back and you
watch and you give up your right and
your power to change
history you're going to have to deal
with what other people decide
let me be completely clear I strongly
support stop Ai and I strongly support
pause AI please support them links to
their organizations in the show notes
donate your time donate your money it's
important um and I strongly believe we
need many many more anti- AGI
organizations than those two for example
I've started dads against AGI a
nonprofit X risk Communications
organization to save our kids email me
at forh Humanity podcast gmail.com if
you want to get involved in that okay so
next we did actually find the AI safety
Summit it wasn't hard to find because
there was an Associated Press article
after the first day check it out the
headline seems like it's pretty
important stuff us gathers allies to
talk AI safety as Trump's vow to undo
Biden's AI policy overshadows their work
and there were many many important
people there Commerce Secretary Gina
Bondo us AI safety Institute director
Elizabeth Kelly anthropic CEO Dario
amade himself I had sent in a request
for media credentials to the Department
of Commerce press office for the summit
no response followup no response
followup no response it turns out the
event was at the Presidio and by the
time we got there it was late on the
second day and it was very clear we were
not welcome or invited I'll look at that
in just a second but first a few quotes
from the AP article just to show how
important this meeting was and how
insane it was that there was not so much
more media coverage around the vent
where were the satellite trucks where
were the live shots from the cable
networks
nothing to be
clear there is no video on the internet
I can find of this event at
all but just listen to what the US
Commerce Secretary said about AI risk at
this uncovered
conference quote we have a choice said
the US Commerce Secretary Gina Rondo to
a crowd of officials academics and
private sector attendees on Wednesday we
are the ones developing this technology
you are the ones developing this
technology we can decide what it looks
like like other speakers Rondo addressed
the opportunities and risks of AI
including the possibility of human
extinction and asked why would we allow
that why would we choose to allow AI to
replace
us why would we choose to allow the
deployment of AI that will cause
widespread unemployment and societal
disruption that goes along with it why
would we compromise our Global Security
she said we shouldn't in fact I would
argue we have an obligation to keep our
eyes at every step wide open to those
risks and prevent them from from
happening let's not let our ambition
blind us and allow us to sleepwalk into
our own undoing end
quote that is not the pause AI or stop
AI people that's the US Secretary of
Commerce who oversees the US AI safety
Institute saying why would we do
this why would we do this
why was that not live on CNN there's no
video of it on the internet a panel
discussion between the director of the
US Safety Institute and AGI lab CEO
Dario amade who gives us a 10 to 25%
chance that his work kills us all no
video of it
anywhere so we showed up uninvited on
day two and we didn't stay very long um
um here's a little look at
that do I work here no
uhuh where you want to station yeah we
just want is this is this the AI safety
conference yes sir yes do you want to
park closer do you need to park closer
oh we parked right up there that's
amazing thank you so much thank
you okay
I'm walking into the
summit I think
yeah hi how are you I'm sorry are you
here with we're I just saw podcasting we
were just looking for yeah safety
something oh did you speak with anyone
on I have not show up I just showed up
right
yeah hi I'm John shman how are you nice
to meet you nice to meet you I'm Alexis
I'm with the Department of seat are you
do I have a podcast I I sent a letter to
Department of Commerce asking for media
credentials they never said anything so
we here kind yeah it was Open Press
yesterday Open Press yesterday yesterday
so today was all close press okay all
right um okay
you're all
good hey guys sorry Hi are I'm John nice
to meet you hi so so I just have a
podcast and we uh uh I I like tried to
get media credentials and uh didn't it
responded to so we're just looking for
this a Clos session and we just wrapped
up for the day you the podcast called
for
Humanity give you a card or something I
don't have a card now but but if it's
over that's fine good it's overk all
right thank
you it did not seem like they were ready
to take questions from the Press at any
point during that
meeting LOL um it kind of reminded me of
my days as a news reporter showing up
Uninvited for government officials who
didn't want to answer our questions and
freaking out their press
AIDS oh nostalgic uh I would have loved
to ask hard questions to Dario oh holy
hell I would have loved that and the
most ridiculous thing is that I'm in
full support of what they're doing at
the conference our goal was to support
and amplify the work of the conference
strange they seemed to want neither
which only shows me that the government
officials deciding Our Fate want as much
secrecy as the companies racing to
Doom
why okay so on Friday the Pai protest
that we had planned was canceled for
Heavy Rain then the flying event that
was going to take its place was canceled
because the rain was so bad the city was
literally having flash flood warnings
all around us that was a bummer but a
little water can't stop us from saving
the damn world am I right so we had had
two more stops on our trip next I had to
meet Lon shapira in person Lon has
become a friend and is the host of the
brilliant uh AI risk podcast Doom
debates Lon is just like me and that
he's a dad for whom AI risk alarm bell
ringing has become a second job a
calling truly both of us wake up every
day working to help more and more people
understand the zero human AI future we
are hurdling towards
and that you have agency in this that
you can help us save the world
great great to meet you yeah
amazing look at how thick he's got look
at this look that work it's great we're
going to blow our our viewers Minds with
this this is what everybody's been
waiting
for uh so and it's so great to meet your
person yeah I know all the way from
Baltimore huh yeah yeah got on a plane
came out here like the basic idea is
like I've been talking about this stuff
for a year and a half this is where it's
all happening and I just want to get a
sense of what it's like out here yeah
yeah yeah well that's right and this is
kind of my stomping grounds you know
I've just been marinating into that
Community my life yeah so you know what
what is it like to to be here immersed
in the people who are doing this work
like you see them in the supermarket you
this is what it is at the I mean for me
it's totally familiar because I just
spent my whole adult life in this area
and I see tech people walking around
talking talking about the latest tech
stuff so this doesn't feel any different
right it's just the idea that super
intelligent AI is coming and there's a
few more insights to get there like
that's kind of all hypothetical or
theoretical or mental right so like I
know it's the case but I totally
understand from their perspective it's
like yep yet another hot Tech job yeah
and and like do you think they know like
like like like we were in a coffee shop
today and there's three guys sitting at
a table and they talking about models
and training and this and this and this
and they're obviously working in AI
working at Tech and it's like I just
wonder do these three guys know that
like
the stuff they're doing um a lot of
really credible people think can kill us
all it's really hard to get viscerally
scared right like I think it's there's
not that many I mean it's you know
you're a rare breed I but I I mean I
don't know like the average
non-technical person they're scared but
they're not viscerally scared right
they're like yeah I'm I'm scared in the
future but I'm not literally scared
today I'm just going to pay my bills
today right so it's just it's really
hard to transform people into like the
appropriate mindset yeah and like what
does that even look like so we spent
yesterday with Sam and Guido from stop
AI who went to court with them that's
great yeah we spent three hours in like
the Criminal Court division where they
were you know and they're going to have
a trial that's coming up and they're
just you know pursuing this very
aggressive course um what are your what
are your thoughts on on that whole thing
on on very aggressive tactics I mean I
definitely empathize with why they're
doing it right they're just like look
this is an emergency for Humanity you
have to treat it like an emergency yeah
um I just hope their movement grows
right because it's it's definitely weird
to be like okay here's a tiny amount of
people who really get the stakes and
then everybody else is like so far away
from them right there's like such aasm
it's like you think maybe you can like
lead people step by step like okay let's
try to pause AI right okay let's let's
use violence I mean they're they're not
using violence but they're using you
know they're breaking the law right
nonviolent uh you know protest Civil
Disobedience Civil Disobedience civil
disobedience is a Next Step Up Above
just protesting there's a couple steps
uh and it's just crazy that they're
they're going all the way like this is
how bad it is whereas we can't even get
a big protest together I know I and it's
it's really crazy like
um what would it take to get the like a
large number of people activated you
know that I just think about this all
the time um I mean I I I think just more
visceral fear right that's why I call
myself the fear Monger fear is good Fe
here okay yeah yeah um so so that's the
question and I think the biggest cause
of the fear could just be some something
that causes a disaster right like I
don't know it's it's tough basically our
highest hope is like a warning shot
disaster yeah maybe the warning shot
could be like you know power outages
right just like thing infrastructure
really stops working and it's like hard
to fix yeah and everybody wakes up one
morning and they're like today is very
different than every other day and AI is
the reason yeah AI really  it up
exactly fair to say if you're here and
you're working um that if you're not in
AI you're not with the cool kids I mean
Y combinator is mostly talking about AI
for instance right and and they've gone
through all kinds of different Cycles
you know they've gone through like
mobile social right like all these
different Trends even crypto right there
was like a batch of V combinator when it
was like all crypto and now the batches
are just all AI which to some degree is
very cool to the extent that they're
like taking existing AI technology and
applying it like I respect that right
like oh helping lawyers be better using
today's AI there's nothing wrong with
that but it's just yeah AI is really
cool and if you've got a job in Valley
and there's no big AI piece then yeah
then you're second tier you're not one
of the cool kids right
now and where does AI risk safety work
fall into this it's it's I've heard it's
like lame well I mean one issue with it
is it it's not perceived to pay as well
I mean people like you and me what are
we making on this job right we both have
second jobs
here yes the the lowest paying second
job in the world right right right uh so
I mean so I think that that's your
answer right there right is I think to
the degree that it's it's cool I mean I
guess there's some jobs like maybe
journalists that don't get paid very
much but are still like kind of cool in
some circles oh wait that was your
former job too right no yeah yeah it
wasn't even that cool believe and I I
mean I guess it's my job now like I'm
kind of a journalist I'm a podcaster
whatever that is a citizen yeah exactly
citizen journalist so but yeah I mean
these are traditionally I guess so our
current line of work I guess is cooler
than the amount of money we make but
it's still not as cool as somebody who
makes a ton of money and is on The
Cutting Edge of
tech in my dream world like some somehow
this guy who's you know the open AI
mid-level executive and he's the God all
he's doing all his cool  some point
like his kid or his wife or someone is
going to come to him and be like but
what is up with this and it's our stuff
and he's going to be like oh like if I
if if the school children of Silicon
Valley would go home to their parents
and be like but what about alignment
right so I mean if it's Sam Alman though
he's just going to be like look I'm the
one to handle it right I'm going to
navigate us through this I'm the captain
of the ship of course the waters are
getting choppy that's why I'm the
captain right so they're going to have
that ego trip about it where it's such
an eego trip it's they they're not going
to realize that the wave that they're
trying to navigate the ship through it's
just too big it's way too big and
there's such a thing as you're entering
Waters that your boat can't handle like
that is generally a possibility in Sea
navigation and it's also a possibility
in like new tech fields and the AI Labs
that's my biggest complaint about them
is that possibility never gets raised
right that's like my beef with Dario
because he comes off so likable as if
he's so responsible but he never talks
about here's the part of my podcast
where I want to talk about what if this
is an unsolvable problem and here's the
plan that we take when we all come to
consensus that this is an unsolvable
problem in like the next 20 years here's
the plan we take he never talks about
that it's always like oh yeah we're
going to take taking it one step at a
time it's Unstoppable we're going to do
our best yeah yeah um so we've been
riding around San Francisco for three
days me and Bo in the car Bo holding the
camera there and he has an idea his hope
is that that it is a bubble like the
tech bubble that's just going to burst
and it's just going to go away yeah I
mean I mean it could be right now right
so there's rumors that the scaling is
hitting wall I mean look first of all
it's it's been like a month since people
have rumored that right I mean it's it
doesn't really count as hitting a wall
unless there's like a couple years of
stagnation I mean there were a couple
years between gbd3 and gbd4 yeah right
or even yeah a couple years two and a
half years something like that so it's
just like way premature rumors and the
people who say that they also don't know
what other projects are cooking right
now right so they're saying okay this
one particular project isn't going as
fast as people thought like you know
open Ai and anthropic the next model
they train okay they got disciplining
results with that particular Next Step
but there's other next steps in the work
so you got to wait minimum of two years
before being like hey look progress
seems to be slowing down so so there's
that but I mean that said if we get
lucky and progress continues slowing
down and we have two more years of like
oh wow GPD 4 is still close to Cutting
Edge I mean that's the ideal scenario
right it can't get any better than that
and then or I mean I guess the ideal is
also if gp5 comes out but it's like so
safe somehow I mean so but that's close
to the ideal scenario right is as before
stays Cutting Edge and and yeah in that
case you might start seeing pressure on
open AI where it's like look you guys
are making money but you're not covering
your costs but at the same time I think
that they can make their costs more
efficient and they do have a lot of
users but like I guess the Holy Grail is
like look open AI well your valuation
should be like $10 billion it shouldn't
be like $200 billion so you need to like
lay off people like you guys the tech
industry should like start focusing on
other stuff so yeah I mean that could
happen and that could be pretty sweet so
that's possible it's possible it could
be a a bursting bubble just due to some
technical factors that we can't really
see yeah kind of like the 90s. comom
right remember like pets.com right so
they're like look the internet's going
to revolutionize everything so you're
going to get all your groceries
delivered so we're going to invest
hundreds of millions in like pets.com
and you know all these companies that
are way ahead of their time building out
infrastructure and then there was a big
crash and then like 20 years later now
we do have like door Dash and instacart
and it's like you know that's I think
that's actually somewhat likely to
happen with AI right because nobody's
timing it everybody's just Investing For
exponential growth so there is like I
don't know a 30% chance that it's like
oh you kind of went too fast and you
need to give it like another 5 years
there's going to be like a mini AI
winter you guys need to do like down
rounds right like your stock is going to
go down for a while yeah um so I
definitely think that could be like a
happy five years right like I don't
really expect to die in 2028 like I
expect to die sometime in the 2030s how
about this that's honestly encouraging I
I'd like that yeah uh because um there
are timelines that are shorter than that
right yeah when I say I expect in3 I'm
just saying that's like my main line
scenario but there's definitely like a
20% chance I'm going to before 2030
don't get me
wrong I feel like if it does go where
where there's a window 5 10 years yeah
that's a great play for you and I and
people like us to like Advocate and like
try to try to push that window further
the problem is without the AI actually
behaving differently I'm not sure how
easily we can build momentum because the
fear will go away right it's like there
has to be like a source of fear right
cuz like a bunch of intellectuals
beating the drum I mean I think it's
helpful right it's helpful to get the
Overton window moving but with without
an extra spark of fear I just don't know
how far we're going to
get okay um
so what's your highest hope for 2025 boy
um I mean maybe the ideal warning shot
comes out right like imagine like a
bunch of hacking and power outages where
there's like strong AI hackers where and
then it's like our best like antivirus
companies like it actually takes them
like a lot of days to fix the power
outage and like people die I mean I
always hate to wish for people dying but
it could be like like people hospitals
or something or you know yeah I mean and
look I would never cause this right I'm
never one I'm not one of those like
those weird utilitarians who are like
it's greater utility to like press the
button to kill people now like that's
not me okay I'm not going to I'm not
going to be blowing up the dams or
anything like that but if it does happen
it might have positive utilitarian
consequences to have some people die
from a power outage or something like
that um and imagine it's something where
it's like wow the internet like for the
first time we have like a major internet
outage like here in the United States
and it's totally caused by Ai and then
the best case scenario would be like
okay we found a way to fix it but now
every company needs like a force of
people who are like constantly fighting
AI so like some sort of gradual
transition into this thing of like wow
this AI is really like a force to be
reckoned with and that might get people
in the mind set of like so what are we
doing to slow this down yeah all right
um last question would you ever what is
the line where you would be like  it
uh we can't stop this thing I have a
limited number of days left with my
family I'm going to just punch out of
all of it and just be with my family oh
is I mean I don't know I just you know I
I just don't have that many hobbies or
so it's just like you know if if I see
Doom coming I'm going to be pretty
attracted to the idea of just like
fighting the Doom but if Doom weren't
coming I would just pick other problems
but as long as Doom is coming I I don't
think I'll say like f let me spend time
with my family even if I'm even if it's
just like look Humanity we you guys all
have one year to live it's your fate is
sealed it's 99.99% chance to Doom you
might as well give up but it's like very
clear uh it's like you know like imagine
like an asteroid coming where it's like
going to deflect we don't even have the
technology to deflect as I mean at that
point sure I'd spend some time with my
family but if there was like any way I
could help I'd still try to be obsessing
over that 0 1% chance you keep fighting
yeah yeah
yeah nobody here is really considering
the actual consequences of the work
they're
doing um so there is a bit of like I
don't know if it's the
rain I don't know what it is I don't
know if it's just being here with seeing
it all but there's definitely like a
heaviness I feel
um about the hill we have to climb um
you just get a sense here of like the
inertia of this whole
project and how difficult it's going to
be to convince people that no we cannot
continue we really just need to stop we
really just need to pause we just we we
cannot continue this project
um because you get a sense out here of
how much money is being made how many
people are
involved how they're naturally just
enthusiastic for this new technology
this pursuit of science this excitement
of it
uh all of which runs directly
counter to the obvious fact that
everybody from Allan touring to stepen
Hawking to Jeffrey Hinton to you know
going years and years and years and
decades back understood that if you
create an intelligence smarter than a
um very very bad things probably happen
next to the humans and it seems like
nobody here gives a 
so like who are these people who are
these people that without our consent
work every day on a project that
threatens to kill all of us who can do
this work I don't understand it I've
never understood it
um it's funny in the conversation I had
with Connor Ley a couple weeks ago he
was talking about how it's actually
quite conceivable that people can go to
work at a suicide company every day
people went to work at the tobacco
companies for decades people went to
work at the oil companies for decades
knowing exactly what they were doing um
so you know if you're saying to yourself
oh we're totally safe because Sam Alit
would never work on a project that could
kill
everybody humans have done projects that
could kill everybody for a long time and
everybody goes to work just fine as long
as the checks are just
fine you know like a  thing is
literally the tech dudes of this city
brought us social media the First
unaligned Technology with
humans uh I think it's pretty clear that
social media has a net negative effect
on
society and those dudes who were in
their 20s when they brought us social
media are now in their
40s and they're bringing us AI
um the thing that nobody 
wants so we are here at 575 Florida
Street in San Francisco
California I have seen it on the
internet many times we are at open AI
that gate is the gate where they chain
themselves to that person walking in
there is probably an open AI employee so
I I've had this like vision of what this
gate these scenes look like what this
place looks like this whole time um and
I I wanted to just go and like literally
put my hands on those metal bars and
feel something about what it's like to
be in this place where the people in
this building are literally building the
technology that can kill every living
thing on Earth it's
um it's pretty Unthinkable right that
you would go to work in a place where
your boss says the work you're doing can
kill your friends your neighbors your
dogs everything but somehow the people
that work
here do this
work like this guy
yeah mhm I saw some guilt in his
eyes but he knows he's working on the
 Death
Star it's pretty unbelievable to faint
it's in a neighborhood with like a
bakery and a  pet shop right
across the
street
like does the bakery over here know what
the  they're doing in
here honestly as as a reporter I covered
a lot of murder trials I've looked a lot
of murderers like straight in the eyes
in a courtroom
the amazing thing about murderers is
they look just like everybody else
there's nothing you can tell different
about
them this is where we are like there's
nothing different about this this could
be a building anywhere in America any
office workers going to do anything but
at this building in this place they're
making technology that can end all life
on
Earth it it's unthinkable
I just don't understand I just don't
understand how anybody could walk
through that 
door and do that work
it was a powerful experience for me this
trip I meant it about murderers looking
just like everybody
else in a recent comment on a for
Humanity video on YouTube someone wrote
about what they are doing to stop Ai and
added that if we fail it's their fault
personally
I like this framework and I wanted to
share with it with you if we fail it's
my
fault I find that strangely motivating
if each of us acts like that takes
personal
responsibility I don't think we can be
stopped okay friends thank you so much
for going on this journey with me this
week as you know it's 2024 still and we
don't know how much longer we have to
live so we choose to live every day like
it could be our last and end everyone
these shows with a celebration of life
this week it is all about San
Francisco this is one of my favorite
favorite songs of all time uh going to
Daddy company again this is a 2016
performance a massive achievement the
song is called standing on the moon
standing on the
moon I got no C with on the
sh stay on the
moon I'm feeling so long and
blue I see the G of
Mexico it's tiny as a
tear the cross to
can you must be somewhere over here
over
here standing on the
moon I see the battle reach
Bel standing on the mo
I see the
solders come and
go there's a made of flame beside me
someone planted long
ago oh gling standing
stiffly Crimson white and
Inigo oh CL
standing
stily Crimson white and in It
Go With It
Go I see your Southeast
St I can see sou
door I hear the cries of children
and the ear
sounds like in my
M and rs down from the
sky standing here upon the moon I
watching
I all R back
oh
God oh God
oh
oh
a
standing on the
moon I see it Shadow
on standing on the
more the stars go fading one by
one I hear the Cry of victory
and now of
defe and scrap of
AEL
L down some
forgot
Street standing on the
moon with talking Che in Vision
true standing all the
more but I would rather be with
you somewhere in San
Francisco on a back porch in
July just looking up to heaven and this
cring in the
sky in the
sky standing all
the with nothing left to
do and Lely you of
heaven but I rather be with
you L you of
Heaven I ra be with
you be with
you I'd rather be with
you I'd rather be with
you I'd rather be with you
I'm
oh
you
n
you
somewhere in San
Francisco on a back porch in
July words from that place from a better
time please hit subscribe on YouTube set
the alarm um at as you may know I'm
making a new YouTube short video every
single day for the next year and most of
them are aimed at people searching for
anything but AI risk I'm trying to break
the algorithms and help people
understand AI risk who are not seeing it
at all so please remember like share
comment subscribe and it would mean a
great deal to me if you'd sign up for a
monthly donation subscription Link in
the show notes please help me spread the
word okay okay friends please remember
AI risk is not someone else's problem it
is yours and it is mine and there is no
way we are going to let 2,000 people
kill the other 8 billion of us no
 way for Humanity I'm John
Sherman I will see you
tomorrow for
