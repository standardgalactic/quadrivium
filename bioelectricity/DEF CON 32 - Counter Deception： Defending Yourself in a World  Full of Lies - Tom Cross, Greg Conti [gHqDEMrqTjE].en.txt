uh good morning Devcon thanks for coming
out appreciate it uh we have two
speakers this morning uh Tom cross and
Greg KY and their talk is going to be on
deception and counter deception please
give them a good Devcon
welcome so uh good morning everyone
Thanks for uh making it out this morning
um so we're uh we're excited about this
talk um I uh I I've been coming to
Defcon you know since it got started and
when um you know early Defcon uh you
know at that time the internet was just
beginning to become publicly available
um to Consumers right and we were
thinking about you know what what how is
the Internet going to affect society
like how what is going to happen right
um and we were sort of imagining a world
that we now live in today and I think
it's interesting to look back at how
what we thought would happen and
question you know sort of you know where
We've Ended up right I think people in
this community could see both the like
promise and Peril of the internet um I
remember going to lunch at Defcon going
to a food court and everyone's paying
with cash and we're thinking you know in
the future we're probably going to pay
electronically for everything and a
little record will be kept every time we
buy something and like it will create
this model of our behavior and how will
that get used against us right um but at
the same time I think people were genu
genuinely excited about the idea that
everyone will have the world's knowledge
at their fingertips right and maybe that
will make people a little smarter it
might up level Humanity um and so as you
know time has gone by and we've actually
got all these capabilities and
everyone's using them um you know
there's certain facets of human nature
that have come roaring forth uh and have
a huge impact on how this stuff actually
affects us uh I I think the part the
problem is that people don't come to the
internet because they want to get
smarter they come to the internet
because they want to be told that
they're already smart um they seek
validation right um and there's a lot of
people who recognize this and they're in
what I call the funhouse mirror business
so they present you a world in which
you're a good person in which you should
get what you want and in which the
people that you dislike we're going to
show you those people in the most
negative light possible over and over
again again um and this world view that
is centered around you and why you're
special um is highly compelling to
people's egos um this is what we on some
level mean by deception and we find
deception not just in the like
narratives that appear on social media
but also um at every level like in the
fishing emails that people are getting
in the malware that's running on their
computers um ultimately the internet has
become this massive deception engine uh
in which these uh false narratives are
appearing at every level of abstraction
um and you can't trust anything that you
see in the screen um it's I think people
have recognized this they've recognized
that the internet is not giving us what
we wanted it's not making us smarter uh
and in fact um the theme of this year's
Defcon is is how do we engage with the
an Internet that isn't giving us what we
want how do we make things better um so
before I get into the overview of the
talk um let me introduce us uh so my
name is Tom uh I've been coming to
Defcon for a long time uh I've done a
few social media projects over the years
my current uh project is called feed
Seer it's a newsreader app for masted on
so uh it shows you the top links that
have been posted on your feed in the
past 24 hours and what people are saying
about each link uh and um there's lots
of infosec folks on Macedon um I've also
you know generally had a career in infos
and I've looking at a lot of cons on
information security uh topics often
with this gentleman
Craig hi I'm Greg KY thank you for
joining me here on araus for Defcon 32
um my background is uh I was long-term
faculty at West Point where I ran their
cyber security research and education
programs also worked at NSA twice and US
cyber command twice um and then I've
developed and taught the information
operations course at black cap training
7 years ago and been running it uh since
there and in private sessions and also
run the military strategy and tactics
for cyber security course for 10 years
same deal okay thanks Tom oh and Greg
and I are teaching a class on
adversarial thinking at Defcon training
after Defcon is over if you guys want
more in Vegas um so uh what are we going
to cover in this talk um the first thing
we're going to do is we're going to tap
into Sumit Greg's deep expertise with
military Doctrine and thinking
militaries have been thinking about
Conflict for hundreds of years um and
deception in particular is an area where
they have um identified maxims that
teach you how to craft effective
deceptions so we're going to talk about
how uh to do deception effectively um
and then we're going to flip the coin
over and ask well if we understand
offense really well what does that teach
us about defense um are there counter
deception principles that we can drive
uh that tell us how to fight deception
and um the the deception and counter
deception principles what we're going to
cover are they're useful in any context
where this could be occurring it could
be useful for malware attribution or in
a security operations context um but you
know this year's Defcon is about
engaging with the internet um and so
we're going to spend the third part of
the talk um trying to apply some of
these counterdeception maxims and ask
what sort of capabilities um you know is
the internet lacking that might be
useful or might help us defend ourselves
against deception that we're facing so
um why are we talking to you guys about
this like why is this relevant I think
you know hackers have the ability to
identify better than like a lot
of you know General people so you guys
have a unique talent at that uh and uh
um you know I I also you know I mean I I
listened to Corey Dr O's talk last year
which inspired this year's theme and his
talk yesterday um it's he's engaged in a
very important discussion about like
policy issues um and uh I I think you
know what I do is I write code and I
break code um and I want to talk about
you know how I can apply those skills uh
um to engage with this problem as well
so um you know hopefully uh um you know
we we we add to the discussion a new
dimension um so uh Greg let's talk about
deception so deception has been around
for millennial and the key idea is that
it's the act of hiding the truth to get
yourself an advantage and what you're
trying to do is influence your target to
make an incorrect decision right or it
to take an action that you want or fail
to take an action all to your advantage
and we've seen examples from our
five-legged troan horse AI uh generative
AI delivers when you need a five-legged
troan horse um to the Civil War where
people painted logs black to create the
to try and fake cannons to the um Cuban
Missile Crisis hiding medium- range
ballistic missiles and concealing them
in uh ships to the uh Persian Gulf War
where the invading Iraqis were concerned
about an attack by the Sea by the
Marines and instead were surprised by an
attack by land from the opposite
direction we see it in the uh Russia
Ukraine conflict the ghost of keev uh
which was a mythical fighter pilot Ace
fighter pilot fighting the Russian
aggressors over the city which was later
you know proved to to be a deception
operation so we've seen this uh for
Millennia and when we think about the
targets of deception humans are first
come first to mind and you you know in
in information security users of you
know things like fishing typo squatting
do domain mimicry spoofed login pages
but also experts think malware analysts
false Flags fileless malware deceptive
metadata
um let uh code injection rotating
command and control infrastructure so
Specialists can be targets for deception
as well but more than that it's not just
the humans it's our code so our code
think malware DET uh detection systems
people try and deceive that through
fileless malware polymorphic malware
rotating command and control
infrastructure and as we move into the
era of ai ai is also a deception Target
think poisoning the training data of the
AI or jailbreaking techniques to
overcome safeguards that people have put
in
place and deception can occur at all
levels it can occur at all levels of the
network stack it can also occur in think
more broadly at the Tactical operational
and strategic level uh the Tactical
level you're actively deceiving someone
you're engaged in conflict with all the
way up to a strategic level where you
try to hide your basic you know National
objectives your intentions your
strategies and your capabilities or put
forth uh maybe to put forth an alternate
reality that's more
beneficial so humans process data
through this idea of the diw hierarchy
we begin with data and with by adding uh
context we can create information by
adding meaning we can create knowledge
and we can by adding Insight we can
create wisdom well deception can poison
our ability to you know by poisoning the
data that we can have incorrect
information knowledge wisdom that we
think is entirely accurate so deception
poisons our ability to
think and it's a professional discipline
uh deception uh what we have here the
orange document is a uh Declassified CA
CIA document uh that includes the de
deception maxims that we're going to uh
be discussing and also there there are
manuals like this is the Department of
Defense joint publication on Military
deception it comes out every few years
updated so this the key takeaway here is
it's a a professional
discipline and looking at some of the
maxims we're just going to run through
these pretty quick and then we're going
to flip them and show how you might
counter but one of the most important is
it's easier to maintain a pre-existing
belief um in in your target than to
force a change right so if someone
believes the World is Flat you can help
encourage them to continue thinking the
World is Flat but if you want to have
them think the world is round well
that's much
harder so yeah I really think mcgruder's
principle is sort of the golden rule of
deception it speaks to this like
fundamental aspect of human nature um
you know say there's a politician you
hate there might be different answers in
the room for who that person is but
everyone hates some politician right and
if I walk up to you and I say well you
know that politician you hate did you
hear about the stupid thing they did
this morning whatever I say next
whatever it is you are going to believe
it because it's aligned with what you
already think and it feels good to be
right um and so uh I if if any of you
have read um azimoff's Foundation series
he has a really good um model um I think
of deception that he presents in those
books there are these robots that can
manipulate people's emotions um and uh
that they're constantly explaining that
they can't radically change people's
worldview and the way that they function
is by trying to understand what that
person thinks and identify some specific
belief that they have that they can
emphasize or reinforced just enough to
get that person to take an action that
they might have otherwise not taken I I
think that's a really good
representation of like effective
deception in a
nutshell so one of my favorites is the
idea of exploiting the limits of human
and machine sensing uh and information
processing so you think we have as
humans have senses right and that are
limited and like known parameters of
what we can uh sense we have limitations
in our ability to process information
machines do the same they have sensors
and they have information processing so
if you can exploit those limits for
example uh think self-driving cars
there's been some really interesting
talks that you can exploit the sensing
and processing of a self-driving car and
make it think see things that aren't
there uh in a heist movie uh where
there's usually a motion sensor and
someone moves really really slowly to
slip past the motion sensor that kind of
thing and and a variation of that is
here's a picture of an inflatable tank
from Ghost Army uh in World War II it
was a group of creatives uh and they
were a formal deception unit and it's
their ability to create inflatable tanks
and fake enemy or fake troop uh imp
placements uh was because the
capabilities at the time to sense what
was you know sense the environment these
tanks looked real from a distance now
they'd be they'd obviously be not um
then uh the third maximum is Jones's
dilemma when uh the idea is that in this
competitive information environment of
competing narratives that if you're
going to try and deceive someone and you
you have to ideally have more false
sources than real so it's this battle of
uh quantity and quality of of competing
narratives another strategy is the idea
that you want to carefully uh create a
story that you don't just have single
data points but you're putting puzzle
pieces out there for the deception
Target to connect together that tell the
story that you want that you're trying
to to portray uh another is the idea of
carefully designed um planned placement
of deceptive material the idea is you
want to make your target work for it if
you if uh think if you wanted to have a
fake diary in in your room right if you
leave it on their desk that that is an
obvious place and that could be like
your um that probably what you want to
do is make it hard have a lock on it
have it hidden in a ventilation duct
have it written in Code by the time they
find that and they've unpacked all that
then they think this has absolutely got
to be the real diary and we see that in
malware as well right that's certainly a
strategy if you make them work for
people will be more likely to believe it
the flip side of this is an orgy of
evidence where things are you know many
incriminating things are obviously found
well that should raise
suspicions so yeah Olympic Destroyer is
a really good example of the use of of
some of these techniques in order to
fool malware analyst as to attribution
doing attribution on ioc's is Frau with
risk as with respect to uh you know the
manufacturing of those ioc's um in this
case uh there was a rich header in a
binary uh that uh you know captures
information about the developer
environment and they they literally
copied a rich header from a Lazarus
sample and put it in their their sample
um and so someone who knows Rich headers
and like uh has a collection of them and
knows that they could be used to you
know attribute malware might find this
and you know be excited that they
connected the dots right and so now
they're emotionally invested in the idea
that this is true um and uh you know
they they go out with this narrative it
turns out that in fact in this this case
the rich header didn't match the rest of
the binary and the attribution was
completely deceptive um so again uh you
know avoid uh if you're trying to
protect yourself against deception
situations where you're emotionally
invested in the consequences of your
work so I particularly like this one U
maximum 6A 6B there are two sides of the
same coin the first is ambiguity so the
idea is you want to increased doubt in
the person's mind in your Target's Mind
by providing many possible truths okay
make sense they're they they're UNC
there's this cloud of uncertainty the
flip side of that is you want to
decrease doubt and focus the Target on a
particular um falsehood so you want them
instead of being in a sea of doubt you
want them absolutely positively sure
that they're right uh that they sure
about this falsehood they think that
they you know that it's true
another ideas that
in in professionalized deception that
there's the idea of husbanding deception
assets that they're always limited
resources you need to save them for the
time and at the best time and the best
place to be effective you can see that
in cyber in information security
capabilities OD day right uh but imagine
if you had the ability to place
deceptive material on a web server you
can't if you use it you're using that
that capability uh and he might not be
able to use it again so you save these
for the time and place you think will be
most effective uh Maxum 8 is the idea of
feedback in a professional uh deception
operation organization the attackers are
monitoring their target audience looking
for feedback that the deception has been
believed and they're also so they want
that feedback loop uh and they're also
monitoring their friendly organization
to see if they are being dis
so all right so now that we've talked a
little bit about the principles of
effective deception let's flip the coin
over and talk about how you practice
counter deception um so uh um at a high
level I think there are four um General
ways to counter deception one is through
intelligence collection so if you're
actually monitoring your adversary and
just watching them create their
deception then you know exactly what
they're doing and why they're doing it
and what the truth is right um and US
cyber command has this defend of forward
uh um uh uh concept which has to do with
like just going out and and directly
spying on the people that are committing
the act so that you know exactly what
they're up to um another thing you could
do not we don't always have intelligence
capabilities um is disruption um if uh
so we talked about husbanding assets if
uh you know someone has to go to certain
effort to inject um deceptive narratives
um you know in places and and you can
take ction to to interfere with their
capabilities um then that prevents them
from being successful um a simple
example is like if they have to build a
bot net and order to spread something
online and you're able to take the botn
net down then you're interfering with
their deceptive capability um another
thing you can do is is analytic
sometimes that's your only option um
you're looking at the information you're
collecting and you're critically
analyzing it in order to figure out
whether or not it's deceptive um and a
lot of our talk will focus on that
because that's often the only option
that you've got um another thing you can
do is deterent so if you can if you can
demonstrate uh that the deception will
not be effective um perhaps your
adversary will not bother to do it um so
uh in let's talk a little bit about
analytic processes um in infosec we're
really good at Devil's advocacy right um
and so this is the same thing it's about
Playing devil's advocate with respect to
things that you are that you are
deciding or that you believe um and you
have to have the discipline to do that
and that's one of the hardest things
about it um but uh you know if you have
a belief or intelligence related
conclusion and there's a set of um facts
that underpin that belief you can look
at each of those facts and ask yourself
how hard would it be for my adversary to
simulate that fact am I am how many ways
have I measured that um you know like is
it possible to fake that uh and um you
know even in malware attribution you
know a rich header is easy to fake uh
you know maybe you know could they get
access to a particular Source IP address
or how hard would that be uh for them to
to simulate in order to fool me right um
so let's talk about some of the
deception maxims and I'm going to sort
of flip them around and um and create
counterdeception maxims based on them
and I kind of organized them into
categories so the first category uh is
um maximums that suggest when deception
may be present so your human intuition
is both an asset and a liability when
you're dealing with deception this is
the context where it's an asset you want
to develop a kind of spidey sense that
tells you uh things aren't quite right
here it this looks fishy and that might
prompt you to dig deeper um and explore
the hypothesis that what you're seeing
might be a deception um so for example
we've talked about carefully sequencing
um events to tell a story so it builds
up in the target's mind um so flip that
over what happens if there's all kinds
of evidence that gets disclosed all at
once if you find the diary sitting out
on a table where it shouldn't be um you
you know that might be a sign to you
that like hey someone's trying to you
know manipulate me that the this is this
is possibly deceptive right um so the
the the person operating in the
deception must either do ambiguity or
misdirection and in each case we can try
to counter that right so if they're
engaged in ambiguity deception there's
going to be a lot of narratives that are
available right and if you see multiple
narratives then that might be a sign uh
that deception is taking place that some
of these narratives are simulated um
that was certainly the case with Olympic
Destroyer there were a bunch of
organizations that had different
attribution that they were publishing um
and and that's because the Mau was a
intentionally sort of misleading analyst
into thinking that that that that
different narratives were correct um
misdirection in a misdirection deception
the attacker is trying to get you to
believe a particular thing which is
false and so so um if you analyze it
carefully perhaps you can discover that
it's not true uh the the plus minus rule
is this idea that nothing that is an
imitation or a simulation can be exactly
the same as the real thing otherwise it
is real and so identifying those
characteristics which are added or
removed from the uh from the thing it
helps you identify that it is deceptive
and again you have to have the
discipline to say okay this isn't right
it's in congruent and therefore I must
accept that it is not real
the place where your human intuition
operates against you has to do with
mental discipline humans are really good
at jumping to conclusions based on not
necessarily enough evidence we kind of
have to do that in order to function in
the complicated civilization that we
have um but um you know that's how uh
deceptive deceptive operations get you
and so you kind of have to have the
discipline to slow down and not listen
to sometimes to your intuition um so
this is mcgruder's principle is is the
the biggest one here um it's important
to apply the same critical analysis to
facts that support your assumptions that
you do to facts that challenge them and
that's really hard for people to do um
you know also with respect to carefully
designed placement of deceptive material
don't assume if fact is true just
because you had to work hard to get it
ask yourself could the adversary have
simulated that um I love this quote from
a book on professional counterdeception
operations um the vulnerable mind fits
ambig uous information to its own
preconceptions and expectations I think
that's a really clear statement of of
vulnerability to
deception so humans are not that
complicated which probably part of the
problem right psychologists have been
studying uh biases in humans for for
hundreds of years and I have a list of
examples here and if you're wondering
The Prompt was uh humans swimming in a
sea of piranha The Prompt that gave us
that um but I wanted to highlight two
one is the idea of selection bias and
just one instance of selection bias is
where you can choose um from a variety
of facts truths to paint a picture but
you don't share all the truths you're
just selecting certain truths and I
think we see that in many news agencies
today a lot of what they say is true but
which ones they choose uh paint a
picture so that's selection bias confir
information bias sounds a lot like
mcgruder's principle the idea that um we
are Mo are biased toward things that
already um reinforce our preconceived
beliefs so the third set is uh maximums
that suggest methods of preventing
deception um so the two maximums that
have to do with the limits of human and
machine sensing and information
processing like speak to the need to be
able to measure reality from multiple uh
perspectives um you know and think about
this on in a technical sense if you if
you're in a security operations function
and you have sensors out there that like
look at your network um you know if
there's only one kind of a particular
sensor then that sensor could be uh it's
data source could be manipulated it
could be be be presented with false
facts if you've got multiple ways of
looking at the situation then it gets
harder and harder for the person that's
operating the deception fool all of the
sensors that you have um with respect to
husbanding deception assets again
deception operations professional ones
um involve effort and resources and if
you can disrupt and Target those
capabilities um then you can undermine
the ability for them to be successful um
feedback is also interesting a
professional deception operation is
going to be watching you to determine
how you behave you may choose to behave
as if the deception was effective
because you don't want the deceiver to
know that you were not deceived uh you
may also choose um to uh to show the
adversary that you you are debunk that
you are um aware of their deception
which is a deterent method um one of the
things that um you know folks in DHS and
sis are talking about is pre-b buunk so
we think that this deceptive narrative
is going to be placed out there so in
advance we're going to go ahead and
explain to everyone that it's false so
that you know people just don't bother
trying to uh push that narrative in the
first
place so in in developing this set of
trustworthy sources of data like when
we're looking at things on the Internet
it's really important for for us to uh
you know collect different places where
we can get different points of view uh
that are credible and uh objective um
and so like curating collections of
experts I think is really important uh
and but also a weakness that we have is
we have a tendency to believe experts
who um you know are telling us what we
already think and so we have to find
objective criteria for evaluating who we
want to listen to um and so I I think
this is a real challenge um like even
with uh with respect to experts experts
sometimes uh deceive us right so let's
say there's a set of facts one two 3
four and five and they add up to a
conclusion which is 15 right um so I
what I can do is I can present you some
of those facts one two and three and a
conclusion which is six each one of the
facts I've presented to you is
absolutely true and the conclusion I'm
presenting to you is a natural
consequence of the facts that I've
presented right so when you're listening
to an expert the challenge is that you
depend upon them not just to tell you
what the conclusions are but also what
the underlying facts are to educate you
about the issue um and so you're You're
vulnerable to the fact that that without
knowing more than they do about the
subject that you can't see the other
facts that they're omitting that may
lead you to a different conclusion um
and so uh you know I I one of the things
that people ring their hands about a
little bit is journalistic objectivity
there's this idea that like in the
American civilization in particular
where we have two political parties that
what should happen is that uh
journalists should present both sides
and we know that like getting both of
these perspectives does not get us
closer to the truth right um and so
perhaps there's this role for journalism
as a a professional resource that goes
out and finds the other facts that are
missing and adds them into the equation
to get the complete truth right um this
is something that people have been
talking about for a very long time this
is not an internet problem Walter Litman
was writing about this stuff in the
1920s um and he had these interesting
ideas about what journalism could be but
then he also uh you know he he was um uh
he was concerned that it won't be that
uh because the business model of
newspapers doesn't support this kind of
work um and and if if the news media
isn't going to go out and find the
additional facts for me my question is
can my computers do that can I can the
internet give me the facts that I need
in order to objectively understand
reality and so that relates to the third
part of our talk and our Call to Arms um
you know like hackers have an
independent view of reality that's
somewhat outside of mainstream thinking
um and that enables you to see things
with different eyes um there are
interesting capabilities and I'm going
to talk about some examples of them um
that might be useful to people to help
combat uh deception and disinformation
and I think also we're we're tool makers
and Breakers um and so uh you know I
think we we're not entirely cynical
about the value that that new tools can
can
bring um so I'm going to focus on four
areas one area I it's just something
that I need to mention it's that model
the adversary's capabilities and
neutralize them I've mentioned that
several times um there's been tremendous
work over the years here at Defcon in
the misinformation Village um and
there's also this thing called the
disarm framework which is essentially a
kill chain for internet uh you know botn
Nets and deception operations this is
fantastic work we love it uh and um you
know I want to endorse it here there's
lots of things that people can do in
that area um because there's so much
going on in that space we're not going
to delve deeper into it uh we're going
to focus on some other stuff uh um
particularly building tools for
information
triangulation um you you know knowing
like when questions have been raised
about what we're reading uh and uh
identifying and collecting those that
network of experts that you can use to
determine whether or not something is
real
so a really simple example I want to
include because it's a project that was
um the first one Wiki scanner was a
project that was done by somebody in
this community it was a it was a small
focused project and it had interesting
consequences so it shows that like you
can do some hacking over a few weekends
and make something useful um so wik
scanner um looked for anonymous edits to
Wikipedia and checked the um you know
like who is information associated with
the IP address and identified situations
where people were editing Wikipedia
anonymously from the IP blocks assigned
to large organizations and so you can
kind of see what narratives were being
pushed in Wikipedia by certain large
orgs um there were certainly interesting
results that came out of that analysis
um by the way it's mothballed somebody
else made a thing called Wiki Watch Dog
the source code is available for that
but it's also mothballed so like this is
a thing anyone in this room could pick
up and you know you know do something
with um immediately and there are
interesting results to be found um
sticking to the top of of Wikipedia
briefly um the idea behind Wikipedia is
that um with enough eyes all bugs are
shallow right so um you know everyone's
reading this article and they're
removing uh fake things from it and so
we get this objective truth um the
problem with it is that when you visit a
page it might have been edited two
seconds ago by someone pushing an agenda
and you can't really tell right so um I
I wrote a paper in 2006 in which I
suggested that we highlight passages
that are new so that when you're reading
the article you can kind of tell which
passages are less trustworthy because
they haven't gone through that editing
process um there were some academics
that built a thing called Wiki trust uh
which like implemented a very similar
set of ideas and uh with some added
analytics underneath and uh it was
usable for a while so this is kind of an
interesting thing and this is also moth
bald I I believe in this set of ideas uh
and there's work to be done in this area
uh um but I'm also I like the highle
concept that maybe my computer should
tell me when I should be care about what
I'm reading um because um some objective
objective criteria suggests that uh you
know this information might not be
reliable right so I want to return to
some of the like core information
resources that inspired the creation of
the web um because uh there's a whole
lot of ideas in here for things that we
don't have today um and it's a way of
seeing the negative space in the
internet um so the First Resource here
is a paper called we may think by vavar
Bush so vavar Bush was the guy that ran
all defense related research during
World War II um so he was an incredibly
important guy he wrote a paper in the
40s um which might be the most important
academic paper of the 20th century um
and it's it's it's about using microfish
to create um to link documents together
and create Knowledge Management Systems
this guy's got a camera on his head
because he imagined he wanted to take
screenshots of books he was reading and
so he imagined having a camera in his
head so he could screen shot documents
right um so it's it's a weird Tech um
but the ideas are super interesting and
he um you know had a lot of influence
over to other people who are incredibly
important one is douglas engelbart
douglas engelbart gave the mother of all
Demos in which like he demonstrated
things like mice and modems um uh at
Stanford University in the 60s um he
wrote a book about augmenting human
intelligence and one of his sort of
press UPS is that computers will always
augment human intelligence better than
they replace it and that is an idea that
I think is it makes sense to remember
these days given everything that's going
on with AI and also I think social media
companies sometimes forget that the
purpose of computers is to make us
smarter if you forget that you'll make
the wrong things um so uh Ted Nelson is
the guy who coined the term hypertext um
he did so the it first appears in print
in this book which is called computer
lib it's an extra- large book that's
handwritten and Illustrated like a
uh it's a really interesting uh document
um and you can buy a copy of it um they'
they've got it printed again um a
scholarly read through these three
resources will reveal a whole lot of
ideas that these people had for things
that the internet should do that the
internet does not yet do um late in
engelbart's life uh um he was sort of
frustrated with the web and like felt
like it didn't achieve its potential and
Ted Nelson is still ranting about that
on YouTube and you can find him uh doing
so um so if we look at some of the stuff
that these guys did so um zanado do is
Nelson's project um hyperscope is
something that the Douglas angelart
Institute has been working on to try to
implement some of his ideas there's a
bunch of things in there that we don't
have today and it's interesting to think
or maybe we do but only a narrow limited
context right so it's interesting to
think about like what would it take to
make this a part of the internet um uh
you know why why don't we have it um in
the context of deception and counter
deception I'm particularly interested in
back links all these guys wanted
backlinks so a web document can link out
to another document from a phrase um in
their systems also when you're reading a
document you can see which people Link
in and what phrases they link into to so
you can see if someone built upon the
ideas that you're reading um and you can
also see if someone is criticizing the
thing that you're reading why don't we
have that in the internet um well the
answer is that it's a Content moderation
problem if anybody could annotate a web
page in any way that they wanted and
we'd have a bunch of spam and abuse
right um and so we need to think about
the tools that we've built for managing
content moderation and see if we can
couple them to uh backlinking in order
to create something that's useful there
have been some interesting projects over
the years that played around with
backlinking either in narrow context or
you know to varying degrees of success
um you know I think a key thing here is
that all opinions are not created equal
um there are certain opinions again I've
curated my experts whose opinions I that
matter to me those are the ones that I
want to see so when I choose to follow
somebody on social media I'm indicating
that that what they say is relevant to
me even if I don't agree with it right
so I've selected that group it would be
useful to me if I could see anytime I'm
viewing a document if those people have
ever commented on it right I I'd love to
build
that the a challenge that we face is
that in order to build and innovate on
top of our social media systems we need
systems that are technically financially
and culturally open to Innovation um and
unfortunately many of the systems that
we uh collectively use like fail at one
or more of those criteria and therefore
it makes it difficult for people to
create new things that sit on top of
them and we need to create new things in
order to make the internet
better um so I've talked about curating
collections of experts um there are some
interesting protocols that exist that
people have built over time uh for um
for endorsing people like I really like
LinkedIn endorsements not as a tool but
as a concept um you know you can say I
follow this person and this is why right
um but unfortunately that's a closed
system um some of these things out there
aren't machine readable uh you know I
think it would be cool if I when I'm
following somebody on social media if I
could say why and that endorsement
sticks to them if they accept it uh and
uh um as long as I continue to follow
them and if we did that then I could do
this I could say who do the people I
follow follow who are endorsed for this
particular thing like law and I could
get back a list of a bunch of people who
are endorsed for this particular topic
and I could ask what are these people
saying about this thing right it gives
me the ability to sort of like um you
know identify the reputation of people
on the internet and utilize that in
constructive ways to help me figure out
what's real um so I I think there are a
lot there's lots of work to be done in
that space there's lots of like open
potential there uh another area is llms
um you know llms have some built-in
biases there's challenges dealing with
them they hallucinate so it's there's
lots of caveats to what I'm saying here
and I know what they are um but at the
same time it is a dispassionate computer
right so can it go out and find those
missing facts for me that aren't
included in a narrative by reading all
the things right uh and and disp
present them to me um that's a
potentially interesting thought um and I
think it's harder than it sounds um but
you know there are other things we could
do with llms uh I uh you know one of the
things is that that I mentioned on the
last page is that there are um like if
you're a university professor at an
accredited University in a particular
subject area um your University website
indicates that like this guy is the
professor of this right but then your
social media profile there's it's not
machine readable your University website
is not Mach machine readable I can't
tell uh you know um automatically that
you have this expertise but an llm could
go read every University website find
all the professors find all their social
media profiles and create a machine
readable uh you know system that allows
me to again ask this question who knows
Lots about economics here they are right
um and so I think that those are
interesting possibilities LMS are really
good at turning human unstructured
information into like very structured
information that's machine readable and
we can do with
it
thanks so so beyond these Technical
Solutions we we have to think like how
can we scale this um so for humans right
uh one is the idea of teaching Med media
literacy in schools to try and have a
better informed consumers of information
uh media literacy now who I have
highlighted here they have a nice depth
of resources from K through 12 uh for
for classroom instruction and the other
idea is to emphasize critical thinking
both in school and in our day-to-day
lives and this is from and I can't quite
see it Justin right um the idea there
are certain questions we ask uh that we
ask and help us probe through and see
through deception one is who benefits
right where did this originate there's a
48 questions here and they're very
thought-provoking and
useful yeah so so we've um put a bunch
of uh references in the the slides uh
you know which are like look look at
this from a bunch of different
perspectives I'm sure that there are
ideas that you have that relate to maybe
the principles that we've articulated
that are different from the ones that
I've come up with um and that's what I'm
excited about and why I wanted to talk
to all of you about this so um hopefully
uh you know somebody out there has been
maybe inspired to work on something uh
and um uh you know there's there's lots
more to read about all of this stuff um
you know these are our email addresses
uh you know we'd love to hear from you
um we're going to be hanging out outside
after the um Talk is over so if you want
to talk to us or poke at some of the
things we're saying we'd love to talk to
you more um and uh again I really
appreciate your time and attention this
morning uh um and the fact that you made
it here on the last day of uh of Defcon
for a morning
session thank you
