hi everyone as interest in generative AI
has surged so too has demand for NVIDIA
gpus briefly making Nvidia the most
valuable company in the world a large
part of nvidia's success has been due to
its Cuda ecosystem which has long been a
massive moat against other companies
however that Advantage is starting to
disappear and Nvidia isn't the only
player in the GPU game keep watching to
learn more this video has three parts
nvidia's Cuda Moe the competitor's View
and and should Nvidia be worried part
one nvidia's Cuda Moote if you're
involved in AI models at all you
probably already know that pretty much
all deep learning is occurring on Nvidia
gpus this includes both training and
inference this fact is the reason why
nvidia's stock price has climbed
stratospherically recently and even made
Nvidia the most valuable company in the
world as of this video I think it's the
third most valuable company in the world
but still not bad of course and Nvidia
makes great gpus but their Hardware is
not the only reason for their dominance
Nvidia has what people call an AI
software Moote basically Nvidia controls
enough of the AI software ecosystem that
they can keep competitors out what
exactly is this software stack well
let's start with a bit of history about
gpus originally gpus were only suited
for graphics hence their name meaning
Graphics Processing Unit gpus had a
fixed function pipeline that was defined
in hardware and couldn't be changed by
the end user eventually gpus started to
get a little more flexible when Shader
programming came along Shader languages
like glsl for opengl and hlsl for
DirectX allowed portions of the graphics
pipeline to be changed programmatically
these languages effectively compiled
down to GPU assembly code which meant
that gpus had to start becoming more
general purpose until GPU companies
realized they could actually expose a
fully General and fully programmable
interface without too much effort so
they introduced GP GPU or general
purpose GPU programming languages as
usually happens in technology the market
leader defined their own proprietary
solution which they kept closed Source
while everyone else tried to Define an
open standard which never really caught
on the open standard was opencl and the
proprietary solution was Cuda by Nvidia
so Nvidia leveraged an initial lead that
they had in the gaming GPU market and
has built upon and maintained that lead
ever since what what made Cuda so
powerful several important Design
Elements it's designed to reveal
low-level details about how the GPU
actually works in particular the memory
hierarchy and also the computation
structure just like a CPU a GPU has many
different layers of memory arranged in a
sort of pyramid where the smallest is
also the fastest and if you really want
to use the entire gpu's memory that's
going to be really slow but a GPU is
particularly sensitive to the way in
which you use its memory and its
different levels of hierarchy if you
make a mistake for example you end up
accessing memory in a pattern that's
very inefficient then the performance of
your system can really tank so that's
why Cuda explicitly exposes this pyramid
of different types of memory so that you
can access the right portion for your
needs in terms of computation structure
while CPUs basically just have threads
in Cuda you work with grids and blocks
and threads because gpus have a much
more complicated execution environment
in contrast the open CL standard has has
been pretty slow to evolve and open CL
code is meant to be written once and
then run on a GPU or a CPU which
necessarily means hiding many aspects of
how the GPU actually works that also
makes it really hard to get the best
possible performance out of your
Hardware when you're using open CL but
this may have been inevitable when you
get a lot of different companies coming
together trying to make compromises and
decide on a standard but I really think
they should have kept the CPU and GPU
portions very separated these days the
newer versions of opencl like opencl 2.0
and 3.0 are actually optional because
they don't have any staying power
amongst GPU companies anymore I think
the other part of cuda's success comes
from PTX which is the machine code that
it outputs Nvidia is not afraid of
change and so the PTX machine code that
the Nvidia gpus support has changed a
lot I think there have been something
like 12 or 22 different versions of it
so far this basically means that there
are multiple different binary apis that
Cuda can Target which is very similar by
the way to how the Android SDK works if
you've ever made Android apps you know
that there are like 18 25 even 30
different versions of the Android API
this is also what arm assembly code
looks like arm being the CPU
architecture that powers virtually every
phone on this planet including Androids
iPhones and even Apple laptops these
days assuming you have a good compiler
infrastructure which Cuda certainly does
I think this is the right model to
enable rapid Innovation if Nvidia tried
to make maintain backwards compatibility
with its PTX machine code that would put
a lot of constraints on future
generations of gpus and how they could
be optimized this approach does force
people to recompile their code whenever
a new version of Cuda comes out but you
can impose that when you are the market
leader Cuda has become so popular that
it was very natural for other Frameworks
to actually Target it meaning other
Frameworks or other programming
languages output Cuda which then gets
compiled by the Cuda compiler into PTX
that can actually run of course if
something targets Cuda that means it
only works on Nvidia gpus because there
are two main problems for competitors
first is that Cuda is closed source and
Nvidia really really doesn't like anyone
trying to copy it and second even if you
do try to copy it Cuda has had a lot of
features added to it over the years so
it's a really massive task to try to
reimplement Cuda the PTX language keeps
changing because Nvidia just has to make
a new compiler in that case but Cuda
itself never changes at least not in a
way that breaks backwards compatibility
that's how Nvidia makes sure that its
customers don't have to keep changing
their code for new generations and Cuda
has had such a huge market share and
it's so complicated that if there are
any bugs or quirks in the implementation
then that's actually what people rely on
which makes it even harder for someone
to replicate because they would
literally have to replicate all of the
bugs as well just as an example pytorch
the most popular machine learning
framework out there used to Target Cuda
exclusively so even even though Nvidia
doesn't control pytorch which was
originally created by meta they
effectively guaranteed vendor locking
for pytorch and therefore for everyone
that uses pytorch which means the entire
machine Learning Community basically
outside of Google which creates a huge
amount of momentum that's really hard
for any competitor to imagine changing
and there's also just the simple fact of
human nature where if your previous
cluster was built entirely of Nvidia
gpus your next cluster probably will be
as well part two the competitor's view
let's take the perspective of an Nvidia
competitor for the moment it's really
hard to break into the GPU Market
especially the machine learning part
Nvidia has been involved in arguably
anti-competitive practices to make sure
they control the software stack so if
you're AMD or Intel or some other
producer of Hardware accelerators how
would you approach this issue actually
nobody likes the Cuda Monopoly except
for NVIDIA even pytorch which I
mentioned wouldn't have restricted
itself to Cuda unless there was no other
good alternative out there company
companies like to have additional
options Beyond just the primary provider
for example Google wanted to build
stadia their online gaming platform that
eventually flopped but anyway when they
were building it they decided to use
entirely AMD gpus and it makes perfect
sense Google would get better
performance per dollar and a partner
that was presumably more willing than
Nvidia to share details of how their
drivers were really working companies
also just hate relying on a single
company because they see it as a single
point of failure right if that company
messes up or can't meet production
targets or whatever then you have
nowhere else to turn to so there's
definitely a market for NVIDIA
competitors even if the hardware isn't
as good if you can just break this Cuda
nut so we're going to talk about four
different ways that companies could
address this issue first companies could
try to have Hardware compatibility it's
definitely the simplest way to approach
this problem for example AMD CPUs are
Hardware compatible with Intel
processors which means that AMD doesn't
have to have a completely isolated
market for its CPUs because a program
compiled for an Intel CPU can just run
on an AMD CPU in theory this was only
possible because Intel had a sort of
open standard they published the details
of how their architecture worked and
this can backfire on you for example AMD
was the first to produce 64-bit Intel
compatible processors so in many cases
it actually got their name although the
official name of 64-bit Intel processors
is x86 64 Debian Linux still refers to
this architecture as amd64 and anyway
this worked because Intel has a very
very stable architecture they actually
Implement their machine instructions by
having some micro code underneath and
the micro code can change all the time
but the instructions do not in theory
you can run an original 8bit program
designed for the 8080 on today's 64-bit
processors it's actually a little more
complicated than that but still it's the
thought that counts that meant that AMD
could Target the same stable
architecture but as I mentioned PTX is
very unstable so maintaining Hardware
compatibility with Nvidia would be next
to Impossible you'd have to try to
Target the stable API which is basically
Cuda in this case the second way to try
to maintain compatibility would be to
have Library compatibility just take all
those Cuda functions and rewrite them
and have your own version while this is
definitely feasible it doesn't solve the
issue that you have all this user
written Cuda code out there and it's
also very difficult to do when the API
is really large which Cuda is like I
said they just keep adding to it so for
example when IBM tried to take their
database db2 and make it compatible with
Oracle they were able to do so because
it was a relatively small API difference
and then they were able to slurp in all
of oracle's customers when Microsoft
tried to Port Linux to run on Windows
they were successful that's what's now
called WSL windows subsystem for Linux
and that's because Linux has a
relatively small number of system calls
about 300 or so that have to be
implemented for that to happen but the
other way around when the wine project
tried to to get Windows to run on Linux
is essentially hopeless because there
are more than 2,000 system calls in the
windows kernel and it's also not a
stable API which is why wine stands for
wine is not the best oh wait a minute I
think I got that one wrong wine is not
an emulator that's right it's a library
compatibility layer third option is to
do binary translation if you have a
program written for One processor
architecture and you want to run it on a
different processor architecture then
you can technically translate every
instruction so that it works properly on
the new architecture this is very hard
technically and a lot of Maintenance
effort especially as I mentioned because
PTX is not a stable API there are some
pretty successful examples of binary
translators out there though for example
when Apple started using arm processors
or apple silicon in all of its laptops
they were faced with the issue that all
the Mac programs out there were compiled
for Intel compatible processors rather
than arm processors now Apple isn't as
afraid of breaking backwards
compatibility as Windows and Intel are
but they still had to do something about
this or the brand new laptops wouldn't
be able to run any programs so they
created Rosetta which is a complete
binary translation framework between x86
code or Intel code and arm code and
although there are definitely edge cases
a large number of programs just work out
of the box which is simply amazing given
the technical details of what it's
actually accomplishing finally the
fourth and probably most difficult route
you could take to try to achieve
compatibility is to create an entirely
new compiler this is also a difficult
task because you have to implement all
of the Cuda libraries and also pretty
much match all of its quirks and keep up
with all the new updates that Nvidia
keeps adding to the language and writing
another compiler is a really easy way to
get into legal trouble if the compiler
that you're copying belongs to a company
that's likely to sue you which Nvidia
certainly is in this instance then you
have to do what's called a complete
clean room reimplementation which means
that you go and create a compiler with
without ever referring to any code that
could possibly be copyrighted by the
other company which means no looking at
their compiler to see how it works no
running it you just have to work
entirely off of documentation from their
website for instance there's one really
famous instance of a company doing a
clean room reimplementation of a
compiler Google was out looking for a
language that it could use for its
upcoming Android smartphones and it
thought that Java would be the perfect
fit but Oracle owned all the rights to
the Java compiler and they didn't want
to let Google use it so Google did a
complete clean room reimplementation it
took a long time and unfortunately
Google's compiler was open source and
someone I think from Oracle ended up
looking at that source code and saying I
think this tiny function right here
looks like it was copied from our code
so Oracle sued Google over it and I
think Google lost that case and ended up
paying a fair amount of money to Oracle
for what was really a short function
just a few lines long but because there
was Reasonable Doubt as to whether that
function had actually been recreated or
was really copyed op from the internet
from Oracle code somewhere it got them
into a lot of trouble you can also do a
lightweight version of this which is
basically source to Source translation
so you can have a tool that takes Cuda
source code AS input and outputs source
code in another language that works with
your hardware and currently both AMD and
Intel have this sort of tool in their
Frameworks now let's talk about how some
of the direct competitors to Nvidia
namely Hardware manufacturers are going
about using these four different
techniques to try to make their systems
compatible with Cuda first is Intel
which since they started producing Arc
devices are now manufacturing dedicated
gpus of their own Intel's equivalent to
Cuda is called open API and as mentioned
they have some ability to translate Cuda
programs into open API code there was
also an Intel engineer who created this
system called zca all in his own time
which was meant to be a reimplementation
of Cuda that would run on Intel gpus the
project was shut down for a while as
Intel decided to evaluate the business
case for this software and they
eventually said nah just release it open
source we don't really want to pursue
this direction so this developer went to
amd who's the other major producer of
gpus these days and worked with AMD to
start porting it to their gpus and then
AMD came along and said let us evaluate
the business use case for this and then
eventually they also turned down the
opportunity to have a complete
reimplementation of Cuda basically both
of these companies realize that they
could get into a a lot of legal trouble
if Nvidia decided to press them on it
which they almost certainly would but
AMD and Intel aren't the only GPU
producers in the world although you may
not have heard of them there's a company
called more threads which I think is a
great name this is a Chinese company
that was founded in 2020 and then
released their first GPU products in
2022 apparently these gpus are not very
fast at all but if you're in China
remember that the US government has
banned Nvidia from selling their highest
per forming gpus to China so the bar is
lower for more threads they only have to
compete against pretty slow Nvidia gpus
so if more threads can get the costs
down then they'll probably start to look
appealing anyway the company has this
tool called mufi which is designed to
allow Cuda code to work with its GPU
architecture which they call Musa the
English internet is pretty light on
details about this system but according
to an architecture diagram I found of
the more threads product they seem to be
re implementing most Cuda components and
musfi seems to either be a full compiler
of Cuda source code or possibly a binary
translation framework my guess is
they're trying to do both they can
probably compile unmodified Cuda code
without too much difficulty if they've
already reimplemented all of the Cuda
style libraries but to a Chinese
consumer having a binary translation
tool is probably ideal because you can't
necessarily contact the provider of your
software and say hey can you please
compile for a more threads GPU when they
may not have heard of more threads the
other reason I think that they're doing
binary translation is because of
nvidia's response Nvidia banned the
disassembly of code that is linked with
Cuda let me unpack that so typically
disassembling code to understand what
the instructions are doing at the
assembly level is always possible in a
technical sense but it's often banned
from a legal sense because companies
don't want their closed Source
proprietary software from being
unraveled and replicated of course if
you're located in China you probably
don't pay much attention to these sorts
of bans and are pretty happy
disassembling a competitor's code
anyways but Nvidia went a step further
instead of banning the disassembly of
their own code like the Cuda libraries
for example which would make sense and
would have precedent at least in a
western legal setting they literally
banned you from disassembling your own
code after you've compiled it if you're
linking it with the Cuda libraries which
is bizarre I'm not sure would hold up
legally speaking but they probably did
it because they don't want people
running binary translation tools for
example something like mufi which a
company could use to make their product
compatible with more threads gpus of
course it doesn't help very much against
someone in China for example more
threads themselves from running the
disassembly of your code and therefore
translating the software for you because
whatever Nvidia says is pretty
unenforcable in China so I think this is
more of a gesture than anything else to
let the market know that they're really
serious about protecting the
intellectual property which is Cuda and
after all as one commentator put it
recompiling existing Cuda programs
remains perfectly legal so if more
threads or anyone else for that matter
manages to actually Implement a clean
room version of a Cuda compiler there's
not much that Nvidia can really do about
it so let's talk about new compilers
amazingly there's actually a company
called spectral compute based in the UK
which came out with an entire clean room
reimplementation of a Cuda compiler
their compiler is called scale it
currently targets AMD gpus although
they're planning to support even more
types of gpus in the future which I
guess means probably Intel gpus and not
more threads gpus even more amazing is
that this compiler is currently free
it's unclear whether it will stay free
because they're calling it a beta right
now and it's closed Source not open
source but that's only sensible when
you're doing a clean room compiler
reimplementation you don't want to have
to prove that this one little tiny
function here was not copied from the
internet also this compiler took 7 years
for them to build that's right it took 7
years to create a clean room room
reimplementation of a Cuda compiler now
Spectra compute is a fairly small
company they have less than 50 employees
according to LinkedIn and they do do
other things but still it just takes a
huge amount of effort to clone something
as vast as Cuda I don't know what their
intentions are but if I were them I
would be trying to drum up interest and
support for using this software get a
lot of people interested in it get AMD
really interested in it and then start
charging people for using the compiler
and get Nvidia to buy you out so they
can make the compiler free again so that
everyone keeps using their gpus anyway
AMD has basically been doing that
already through a different path AMD has
this compiler called Rock M which is
basically their answer to Cuda it's
supposed to support a lot of the same
use cases but it has been very spotty in
the past basically AMD didn't set out to
try to create a general purpose
Computing engine the way that Nvidia did
instead they just added features to rock
M that were needed by their biggest
clients so hobbyists and machine
learning Vel opers that tried to use it
found gaping holes of course their
attitude towards machine learning has
recently changed rapidly so in October
2023 AMD acquired
nod. nod. had their own optimizing
compiler which already targeted AMD gpus
so it wasn't exactly Cuda in a box but
it brought AMD much closer to actually
having a working Cuda compiler I think
they've now merged all of that into rock
M and continued development there it
seems like AMD is continuing to put a
lot of resources behind this project as
part of the research for this video I
actually spoke with an AMD compiler
engineer who was working on all of this
stuff I didn't get any details no ndas
were broken but he did say that all of
the work that they're doing is open
source and indeed most of rock m is open
source it's a typical strategy when
you're behind as I always say open
source when you're behind to try to
leverage the community to catch up to
your competitors but it's a really sound
plan by AMD and if it doesn't work out
they can always buy scale part three
should Nvidia be worried first of all
this section and indeed this entire
video is not Financial advice please
don't invest or not invest based on what
you see here on the one hand all of
these techniques that we talked about
that other companies are trying to do
are fundamentally catchup techniques
they're ways that other companies can
try to copy the market leader which is
clearly envidia and really try to breach
the software mode that Nvidia has built
for itself remember that Nvidia still
makes the best gpus on the other hand
AMD already provides arguably better
performance per dollar spent especially
on the lower end so Nvidia would
probably experience significant downward
pressure on their prices if their
competitors were playing on a Level
Playing Field so even though it's not an
existential risk to Nvidia they still
want to maintain their Cuda Monopoly as
long as they possibly can and also of
course there's Skyhigh valuation my
perspective though is actually that Cuda
is just too large and complicated to be
effectively emulated Nvidia just keeps
on adding to the framework if your scale
or Rock M then you're constantly going
to be on the back foot constantly a
generation or half a generation behind
Nvidia is also very wealthy now and can
enforce its moat in many different ways
if it comes to a bidding war Nvidia can
easily outbid AMD when it comes to
purchasing scale for example however all
that said and done even Cuda is not
actually the most ideal framework for
general purpose GPU programming why well
the same reasons that make it really
hard to copy it's super complicated
which means that a simpler language and
a simpler framework might actually
perform better similar to how arm
processors can out compete x86
processors when it comes to power
consumption and all kinds of other
metrics because x86 processors are
carrying around three or four Decades of
baggage so there's actually one extra
Dimension that we haven't talked about
yet which Nvidia should be most worried
about and that is what if a competitor
introduces a more attractive stack now
this would be very hard to do the
competitor would need to have a
significant advantage in at least one
area for their Hardware otherwise you
would just keep using the Nvidia
hardware and the Nvidia stack that
you're familiar with it's also as you
can guess extremely Capital intensive to
recreate an entire stack like this and
it takes quite a lot of time so any
company trying to do it would have to
take capital from some other line of
business that they're already successful
in AMD could afford this though because
they have pretty successful CPUs and
interestingly we can actually get a good
idea of whether and when this is
happening because again when a
competitor is playing catchup from
behind they will often release their
products open source to try to leverage
some Community involvement for that
extra little bit of effort and as it
turns out new Stacks are actually being
quietly created all the time most are
really special purpose but not all of
them this this information is from an
article by semi analysis which you can
check out in the links below basically
they highlight open AI Triton and also
pytorch 2.0 pytorch remember I said has
historically only supported Cuda as its
back end and part of that was because
there was just layer upon layer of
different operators and different
features added to pytorch until they had
this huge API that they had to maintain
but they went back and rewrote a lot of
the graph planning aspects of pytorch
they called that pytorch 2.0 and as it
happens it's much more compatible with
the way that other gpus want to do
things so suddenly pytorch which is this
aspect of the stack that Nvidia doesn't
control is making itself more compatible
with other gpus which is not something
that Nvidia wants but the really
interesting development here is open
ai's Triton basically open AI has a lot
of machine learning experts but not very
many GPU programming experts or so I
gathered so they created Triton which is
a domain specific language anguage
that's implemented on top of python as
is very common for these sorts of
languages you just write python
functions and you add a little
annotation at the front which basically
says Triton pay attention to this this
means that the same people that are
writing pytorch every day and are
therefore very familiar with python can
actually try their hand at writing
Triton code which is certainly not the
case when it comes to Cuda Cuda is
extremely complicated code to write and
you really need to think about it a lot
and you need specialized skills for it
Triton is a higher level vers version of
Cuda that nevertheless achieves pretty
similar performance and Triton does this
by turning its code that python-based
stuff that the programmer wrote into an
intermediate representation that's
compatible with the llvm compiler
framework I'll talk about that more in a
minute but it's basically something that
exists inside a compiler and then they
use the existing llvm support for
outputting PTX code if you remember PTX
is the name of the Assembly Language or
the GPU machine language for nvidia's
gpus in other words Triton is skipping
Cuda completely they don't go from
Triton code to Cuda to PTX and then run
that instead you just go from Triton
code straight to PTX and then run it
this is really dangerous for NVIDIA
because it cuts Cuda out of the equation
and makes it much easier to port to
other architectures let me stop and
explain a bit more about llvm so it will
make more sense if you're not familiar
with llvm it's basically a research
compiler that has slowly revolutionized
every aspect of compiler technology it's
the first system with an intermediate
representation for the code that's
flexible enough to handle highlevel
information and low-level information
it's now used in the V8 engine to
accelerate JavaScript in your web
browser it's used for traditional C and
C++ compilers it's used for new
compilers like the Swift programming
language that came out of apple heck
even the Linux kernel that runs in
Google and meta data centers is compiled
with llvm and basically every researcher
who's doing any kind of optimization
research is going to make sure that
their code works with llvm so there's a
faster Improvement Loop for llvm based
techniques improvements to llvm code
generation can immediately propagate to
all these other uses of the technology
and because there's only one
intermediate representation it's really
easy to write new source languages or
new output languages for example new
versions of PTX or supporting AMD gpus
as well or suppor in Intel gpus as well
Etc so as Nvidia unless you develop your
own llvm based system you're probably
going to lose in the long run but
unfortunately having an llvm based
system means that you can't really have
your own proprietary compiler and
proprietary framework anymore it's much
harder to add value there so the
existence of lvm actually really shrinks
this Moe and the fact that people are
already using it and targeting PTX
shrinks the moat even more on the other
hand though all of these comp companies
that are investing in these types of
technologies have to pick and choose
where to put their Investments for
example even Triton only supports the
things that open AI needs it to for
example they only support Linux but that
would be a very good match for most
clusters out there which I think run
some variation of Linux and as I
mentioned Cuda still has a lot of
momentum as well for example Triton was
first released 3 years ago and envidia
is still doing fine however support for
AMD gpus specifically support for
outputting Rock M 5.3 was only added to
Triton on July 12th of this year before
that open aai had no use for it because
they had only Nvidia gpus presumably so
I find it very interesting as well that
open aai presumably has decided to start
adding support for AMD gpus maybe
they're considering an alternative
supplier or maybe Sam Alman just wants
to make sure that when he finally gets
his own chip company up and running that
open AI will be able to use their gpus
with minimum possible friction so yes
Nvidia should definitely be worried
their MO seems to be getting eroded by
new technologies like llvm seems to be
getting eroded by new projects like
Triton and also projects like pytorch
that used to be exclusively Cuda focused
Now sort of spreading out and supporting
in theory other architectures besides
Cuda itself being under attack by this
clean room compiler and also AMD
potentially improving Rock m to the
level where can actually run Cuda stuff
a lot better Nvidia certainly has tons
of momentum on their side and months or
years of pre-orders to pad their bank
account but if you've looked at this
topic on Reddit recently you'll see a
lot of people saying that with pytorch 2
they could basically get their AMD GPU
up and running they still expect lots of
little issues after all deep learning
has run on essentially the same stack
since its Inception or at least since
pytorch was invented so common wisdom in
the machine Learning Community says that
Nvidia is the only feasible way even I
bought an Nvidia GPU for machine
learning so you can imagine what a
corporation would do they would just
follow the common wisdom unless of
course there is the potential for them
to save a lot of money with just a few
technical Road bumps along the way
surely those can be easily sorted out
right someone has to be the first after
all to build a billion dooll AMD cluster
finally in conclusion we talked about
the moat that Nvidia has built to
protect itself from competitors and why
the software portion of their stack Cuda
is such a big component of that Moe Cuda
reveals the low-level details that let
programmers extract maximum possible
performance out of their hardware and
because Nvidia gpus were the best
everybody just targeted Cuda and that
became a self-fulfilling prophecy on the
other side though there are lots of
companies pretty much every other
company in fact that would really like
to break this Monopoly we identified
four different ways that a company could
try to do this the first three ways
actually have potential legal
difficulties and they are Hardware
compatibility Library compatibility or
binary translation the Third Way of
creating a new compiler to recompile all
the code is also very difficult but
there's at least one company that has
succeeded in that spectral compute has
made a clean room compiler that they
call scale there are also projects like
open AI Triton that actually bypass Cuda
completely by using newer compiler
technology to do the heavy lifting for
them using the llvm compiler framework
you can bypass cud it completely still
get optimization and output Nvidia
machine code directly and presumably not
that hard to add support for AMD or
Intel GPU machine code as well because
Nvidia has so much momentum behind it I
wouldn't really worry about them in the
short run but in the medium run seems
likely to me that there will start to be
a lot more competitors and then there
will be downwards pressure on the price
that Nvidia can charge for their gpus
and that will make nvidia's stock do
really poorly and that could be a bit of
a negative cycle for them big companies
have lots of incentive to find a
different approach than just paying
whatever Nvidia asks and to be clear
they're charging really high margins for
their products they have about a
75% gross profit margin right now so
that's a long way for their prices to
fall please like And subscribe and join
our Discord Channel if you'd like to
talk to the community and to me directly
if you liked this video check out this
previous one I made where I talk about
how gpus actually evolved it's pretty
technical but it's similar to the one
you just watched so I hope you like it
well that's all I have for today thank
you very much for watching bye
