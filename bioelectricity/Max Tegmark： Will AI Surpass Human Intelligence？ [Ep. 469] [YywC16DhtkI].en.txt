it's very dangerous to bet against AI
progress I shifted from physics to AI
research with my group about 8 years ago
5 six years ago almost all my AI
colleagues were still predicting that
something as good as chat GPD 4 was
decades Away Never Say Never I want to
yeah pivot to that subject now with a
quote from your first book where you say
the following I suspect that if we can
build such Ultra intelligent machines
then the first one will be severely
limited by the software we've written
for it and we'll have comp ated for our
lack of understanding about how to
optimally program artificial
intelligence by building Hardware with
significantly more computing power than
our brains have after all our neurons
are no better or more numerous than
those of dolphins just differently
connected suggesting that software can
sometimes be more important than
Hardware I want to ask you the following
question uh you know certainly what
Albert Einstein said was the happiest
thought of his life right which was that
an observer in freef Fall Would
experience no gravitational field he
described it as giving him titillations
I want to ask you to what extent could
we train an artificial intelligent
Hardware or software a what it means to
be
happy and be what it would feel like to
be in freefall in other words are we
limited by the lack of ability or our
artificial
intelligences limited by the lack of of
embodiment and the lack of these you
know kind of theologically driven
feelings and emotions that people have
in other words can AI generate AE Albert
Einstein can it generate new laws of
physics right now it cannot I think
within 10 years very likely yes maybe
even in two years it's very important
when we talk about all the crazy stuff
that I think is likely to unfold in the
AI space that we remember we're not
talking about chat GPD 40 about the AI
of today we're talking about the AI of
Tomorrow next year 3 years from now just
like we're not talking about pocket
calculators or or the AI that beat Gary
kaspar with chess either there's been
any a
dramatic Evolution right so first we
started with these very narrow AI
systems that could kick our butt and
chest but very little else now we have
things that can arguably pass the Turing
test because they've mastered language
and knowledge to the point of fooling a
lot of people that they're that they're
human but they're still very passive
they act a lot like oracles you ask them
something they answer it maybe make you
a funny picture this year we're seeing
an explosion and people trying to make
more agentic AIS which actually have
goals and go out and do things on the
internet operate the robots of various
sorts landbased or seab based or or or
flying ones we are um very soon going to
be in in the situation where the vast
majority of of the data that comes in
into most of the AIS that they're
trained on is not just one modality like
text or whatever but very multimodal
just like for us right you are
constantly Brian taking in about one
megabit or one megabyte per second of
visual data from your retinas and
acoustic data and and sensory data
temperatures and pressures Etc and
smells and flavors and you're
synthesizing all that and that's what
you mean by you being embodied right
your brain is trained by all these
electrical signals coming in which as
far as the brain is concerned are all
the same kind of electrical signal it
doesn't matter if it comes from the ear
or the eye that's all interpretation
right if you're dreaming it still feels
like you're embodied even though it's
all fake in that case right so by
feeding in this kind of data and and
having that be something that our AIS
are trained on they can develop all the
same insights and potentially emotions
and intuitions that a human can even if
they're not actually in a robot body and
then add to that that we already have
for example a whole Fleet of Teslas that
very much have robotic bodies and are
taking in all their sensory input and
using it for training very soon we're
going to have an explosion in humanoid
robots you You' started to see them
flooding Twitter existing ones we're
going to get Optimus soon short answer
yes of course AI if it races ahead will
be able to do all the science that we do
as well as well some people might
disagree and think that there are some
Secret Sauce in our human brain that
makes us so special that we can never be
out thought but uh I I think the biggest
Insight frankly that's powered the whole
AI Revolution is just the Insight that
our brain is actually a biological
computer and that uh there are plenty of
other ways of building faster and better
computers just this close this out
though you are completely right in the
beginning also I think when you said
that um we have really sucky software in
the AI
systems we build compared to what's in
the brain when you use something like
chat GPT 40 it uses thousands and
thousands of times more energy to do a
task than than you would and your brain
all the amazing thing it does it uses
about TW 20 watts
obviously our software
our systems architectures that we use
today for our large language models and
other AI tools so-called Transformers
Etc are incredibly dumb you know
compared to what's physically possible
so one of the first things that's going
to happen when um we get AGI that can do
all the jobs better than us is it's
going to do the job of AI research
better than us and realize oh we can
redesign our Hardware to be a thousand
times more efficient and we can redefine
our AI software our architectures to be
vastly more efficient and then foom you
know there you have suddenly have
something which is vastly beyond our
capability want to run by a project that
I've been working on and we have a paper
that we're about to submit although
that's always a dangerous statement and
it concerns the following thought
experiment uh popularized by Einstein
and here's a scenario you're an
astronomer in the mid 1800s the
procession of Mercury's orbit is now
considered a problem in classical
mechanics and currently the astronomers
of your time have measured there to be a
difference of about 40 Arc seconds per
Century versus the predicted and
observed uh recession rate of Mercury's
orbit there's currently no explanation
for this unaccounted phenomenon and we
decided we'd put this into a large
machine Learning System a neural network
uh tensor flow all sorts of throw
everything we had at it with the
technology of the 21st century and see
would AI whatever that means would it
come up with a whole new concept of
gravity that gravity is not a force that
it is the by of curv SpaceTime and we've
come upon an obstacle and I wonder if
you with your mega mind can can tell me
what you think that obstacle is is
actually making me much less nervous
about the future of AI so I'm I'm a
boomer not a dumor when it comes to AI
because of this research obstacle that
we've hit it's not not usual that you
hit an obstacle and it makes you makes
you optimistic but what do you think is
wrong with this formulation of the
problem we're basically trying to derive
a whole new paradigm of gravity from The
observed data which we have going back
you know 10 centuries or more uh using
JPL databases and so forth if you had a
guess what obstacle do you think we'd
most likely hit in this problem I think
you probably hit the obstacle that um I
don't know exactly what architecture you
put in for the AI model that's that
you're running but it's probably very
much what uh conoman would call system
one still it's adjusting its weights
you're training it to fit some data Etc
but without using any symbolic reasoning
like that Conan would call system 2 if
we think about um AI now we tend to
think of of these neural networks that
can do these things as like the new
modern thing and the symbolic stuff as
like the old thing because we humans
when we did our pocket calculators which
seem very oldfashioned they could
manipulate symbols but in evolution it
was exactly the other way around do you
have any dogs right now we're about to
get one how do you know that my time
machine I looked into the but you know
like dogs are very good at catching
tennis balls Etc and Eagles probably
have way way better Vision than I do and
ability to analyze visual images this is
all very system one stuff that's not
what makes humans the alpha species on
the planet right what we humans are able
to do better than any other language is
also take this intuitive understanding
we have which is sort of fits to data
and then see patterns in it an abstract
it out into the symbolic description
Galileo if his dad threw a bunch of
balls to him when he was four years old
he could also catch them but then when
he got older he realized wait a minute
they always go in the same shape that's
a parabola I can write a formula you
know yals x^2 and he could he could
communicate it to his friends and
colleagues in mathematical language or
in Italian or or or in Latin what's made
us humans so unique the the reason it's
humans not dogs that invented the
Internet is prec this we have the
ability to not just do system one but
also reason symbolically and we can
first get intuition from this system one
stuff and then we can um abstract things
out distill out a symbolic
representation maybe this curved
SpaceTime maybe I have to get rid of
ukian space here Etc write down
Einstein's theories and then communicate
it with others and and that's the the
remaining thing we really lacking still
that's that's why we don't have AGI yet
because we're not quite there even
though a lot of people are are working
on it now we're in this sort of
schizophrenic situation where we've made
a big breakthrough also on language with
large language models the two sides
still don't really communicate with each
other a large language model cannot
introspect and understand how its own
brain works and describe things about it
so if if a large language model was
trained to catch tennis balls you know
it wouldn't be able to look inside and
figure out what the necessarily what
what the formulas are it can Discover it
straight from data maybe so so I don't
think you should blame yourself or or
the student you're working with I think
at some level AI isn't quite there yet I
think it's going in that direction hey
curious minds if you're like today's
guest Max techmark I know You' wondered
how the universe works and why math is
the language of nature well you're in
luck because today's episode is brought
to you by brilliant the ultimate
playground for lifelong Learners and
problem solvers like us brilliant isn't
just another learning platform it's a
guided Journey Through the fascinating
world of science math and computer
computer science imagine tackling
quantum mechanics or unraveling the
mysteries of neural networks like
today's guest Max techark does all while
having fun yes you heard that right
learning can be genuinely enjoyable the
brilliant app is my go-to app on my
iPhone especially useful when I've had
too much Doom scrolling on social media
plus it's actually good for you now what
sets brilliant apart it's their unique
approach to education instead of passive
lectures or watching a video You're
thrown into to interactive Hands-On
problem solving it's like being in a
mental gym where each challenge
strengthens your analytical muscles turn
your curiosity into comprehension with
math programming data and AI courses
designed to build Real World skills and
develop your intuition I just finished
through how llms work course and got to
Peak under the hood of large language
models like chat GPT understand the
concepts powering today's most
impressive technology but that's not all
I also had to blast making my own llm
which I called bbot under their tutelage
using their fascinating and fun
step-by-step process now bbot probably
won't pass the Turning test anytime soon
but just working through it gave me a
deeper appreciation for the most
transformative technology of our time
brilliant caters to all levels not just
professors like me whether you're a
curious beginner or a Season Pro looking
to sharpen your skills there's something
for everyone and the best part is you
get to learn at your own pace anytime
and any where in fact my teenage son is
now trying to follow in Max's footsteps
by learning all about llms and neural
networks and most importantly trying to
beat my high score on the app he and I
use it every day I use it on the mobile
app he uses it on his desktop and we
challenge each other to see who scores
more points now here's an exclusive
offer for our intern The Impossible
audience go to brilliant.org Dr Brian
keing to get 20% off an annual premium
subscription that's a year of unlimited
access to brillian in-depth courses and
daily challenges so don't wait head over
to brilliant.org drbryan keing Dr Brian
keing and start your journey to becoming
a better more Curious you now let's get
back to our impossibly delightful
conversation with Max well my only
argument against it coming from llm side
which we're not really using llm side uh
to do it but I think the limitation when
I told that to people I was at a
conference we talked about AI David
berlinsky and Peter teal were there and
other people the consensus was this is
the worst that AI will be and as right
now and it's growing at this
exponentially increasing rate and I said
okay hold on a second one of the reasons
it's getting better is because of its
training data set and the efficiency of
training the data is getting better
modulo the what I call the Mad bot
problem where AIS train other AIS and
that leads to like mad cow disease brain
rot and zombie AIS but ignoring that and
the zombie internet we're heading
towards where a large fraction of
everything you see on Twitter is written
by a bot that's right we'll get to that
in a moment if you have time but um but
my point is what's missing here to
construct AI AE you know artificial
Einstein is not that it doesn't know
what happened in um Fast and the Furious
12 you know that it hasn't we haven't
updated the training set now that's not
what it is there's something of a
different character I don't mean like
the ghost in the machine but I I propose
that this type of test is a better test
and it's it's a more holistic and it's a
more transparent test than the Turing
test the Turing test people claim that
it's already been solved and the past
rather but I claim constructing a new
law of nature you know something that
was wholly unknown I would actually
settle for constructing a known law of
physics in other words give it the pan
bracket and say now come up with a
commutation relate don't tell it
anything else just give it data I don't
think it can do it so I think when it
doesn't actually actually you're right
it can't do it yet but we're definitely
making some progress that I've actually
been working you'll be pleased to know
on exactly this problem with my group
here MIT for example um we worked on the
problem called symbolic regression where
you just give it an Excel spreadsheet
with tables of numbers and it tries to
figure out what formula do you have to
apply to all the column other columns to
predict the last column and it took it
took four years for Kepler to stare at
his Mars data and come up realize it's
an ellipse our our AI discovered that in
one hour we uh we gave it the Schwarz
Shield solution for non-rotating Black
Hole metric it took over a decade for
for G Strand and pan to realize that
there's a different coordinate system
where not only do you get rid of the
singularity seeming Singularity at the
vent Horizon but in fact space is
entirely flat everywhere
outside the center of the black hole it
discovered that also in in like in like
an hour we even discovered a new law in
Ozone chemistry that nobody actually
knew and and then another group of
people who actually knew something about
ozone chemistry some atmospheric
scientists wrote another paper and like
oh my God yeah this thing that those
those AI nerds at MIT discovered we can
explain why it is and they they they
generalized it and it was quite cool so
nothing at all at the the level of of
what Einstein did of course so and I
really want to down playay the
importance of the ozone thing we
discovered but we're making some
progress in in in that direction ction
for sure and um it's very dangerous to
bet against AI progress I shifted from
physics to AI research with my group
about eight years ago right five six
years ago almost all my AI colleagues
were still predicting that something as
good as chat gp4 was decades Away Never
Say Never And finally can I give you a
hard little just give you a hard time a
little bit for fun yeah please I love it
because you you were you were joking the
saying you're a boomer not a Doomer and
uh a lot of people like like Yan laon
and Andrew in like to call me a Doomer
on social media upcoming guest Yan Lon I
have some yeah yeah yeah so you C you
can ask him about this also the the um I
don't think in myself as a Doomer at all
but you mentioned things like pauses
like six six-month pauses and and you
know yeah well yeah but why you know and
and what you know so Doomer was clearly
a pejorative term invented by some
people from that crowd to make ad
homonim attack about people who
disagreed with them without ever having
so they could have something to say
without actually having to rebut any
arguments right it's just pure at homm
fear right yeah gener if if if you uh
tell me that you have some technical
questions about equation five in my last
paper you think I'm missing a factor of
two and my response is just that you
know you're
racist it feels a little bit like that
right I have been called a racist on the
podcast by by none other than Neil
degrass Tyson but I'm not going to get
into that now okay but but like dmer
first of all I'm I'm I'm very I love
technology super excited about about the
potential of of humanity to flourish
with technology which is why I've
dedicated my life to Building Technology
I don't think that should count as
with Advanced AI than Andrew Ang or Yan
Lun ever have you worked out how long it
would take to go to other galaxies and
how you could get there efficiently and
stuff like that so no I love to think
very big about things that I I find very
hopeful there are two kinds of Doom you
can have you can you can be very
pessimistic and say oh it's impossible
AI is never going to work techn
pessimism Tech you might call that or
technos skepticism there are people like
Rodney Brooks who told me some years ago
he thinks we won't get AGI for at least
300 years you know Andrew en talked
about how it's worrying about super
intelligen is like over worrying about
overp population on marks Mars that to
me is actually pessimistic you're sort
of assuming that people are too stupid
to Sol to solve technological problems
the other big split among people is is
if we get AGI or and super intelligence
whether it's automatically going to be
great or whether it might bring problems
and uh we we know that every time we
built some po some powerful technology
it could be used for good or or it could
be used for bad if you say Hey you know
um we live in this big wooden house how
about we put a smoke detector in and get
a fire extinguisher you know are you a
Doomer no I would say that you're the
one who's who has great positive vision
for how your house is not going to burn
down and you're going to actually make
sure that it doesn't burn down and if
goes well right when cars came along and
um some people were be were like hey
maybe we should put seat belts in them
car industry was very against it lobbied
really hard against it saying this is
going to destroy the car industry I say
they were the doomers they were talking
negative making very negative
prognostications which turned out to be
 because you know what actually
happened after we passed the law in the
US requiring seat belts and cars you
know what happened to Auto Sales they
exploded because it turned out the main
reason holding people back from buying
cars where they were scared and once
death started to really plummet people
got the confidence to buy way more cars
saying that uh we should treat Ai and
Powerful AI like every other technology
have some safety standards you know to
make sure that they get used for good
things and not for bad things I think
that's just exactly the the kind of
safety engineering and common sense that
we've successfully used for all other
powerful Tech in the past I didn't mean
to refer to you as a as a Doomer what I
got a little triggered because I very
often do get no I know and and it's now
impact you know it's serious when it you
know impacts a a California legislation
and and and someone in Boston you know
like yourself aines upon it and uh very
very supportingly so and I I appreciate
that the Chinese government and the
European governments both were concerned
about AI risk and have put in place
various regulations to make sure that
they don't do too much crazy stuff just
like with seat belts but for for AI us
so far has no meaningful AI regulation
at all except for an executive order
that uh that uh Biden put in place that
just says that the companies that do the
most extreme stuff just have to let the
government know at least U so now there
is this first ever law that would
actually do something it doesn't do much
in my opinion it mostly just says that
the stuff that open Ai and anthropic and
Google deep mine had basically promised
to do anyway voluntary commitments now
is actually required not just by them
but by their competitors too and then
you get this hilarious uh uproar just
like with the seat belt law you where
like open AI came out and said oh this
is going to cause companies to leave
California going to Doom people are
saying it's going to Doom the California
economy and make Etc and then I remember
that actually that's exactly what they
were saying also when the EU was
debating the eui ACT yeah we're probably
going to have to leave leave Europe then
the Act passed and surpris they're still
there all the companies and life goes on
you know just like the the immediate
death That was supposed to happen to the
car companies when seat belts were
enforced mysteriously didn't happen
either so so we're seeing all this drama
all over again except people have have
such Amnesia they always act like these
challenges with good governance of AI is
like first time in the history of that
we ever had to govern a technology like
hello what about cars what about like
codes for electricity so your house
doesn't burn down what about food safety
what about the FDA what about us what
about us as professors you know so you
and I are I joke we have the second
oldest profession after you know what I
mean back in the year 1080 there are
professors in the University of bolognia
Northern Italy and they we're you know
guys scratching on a piece of Rock with
another rock as your friend David Kaiser
calls it our profession really hasn't
changed that much are we the last of a
breed you and I um will we have you know
training by I don't even I never learned
to really code with python and I'm glad
I did I see where you're going with this
because they comment on the oldest
profession first okay go for it the
first thing I think we scientists have
to do if we are the second oldest
profession is to not become like the
oldest profession and become
intellectual prostitutes I hate to say
this but like if if you were to go to a
a public health conference and there's a
speaker up there talking about public
what public policy one should have
tobacco regulation and stuff and then
you realize halfway through the talk
that this guy is funded by Philip
Morris and nobody told you and he didn't
disclose it right and then you walk out
after this talk into the Expo area and
you see all these booths from all the
tobacco companies wouldn't that feel
that would feel like really weird you
would really feel like you are the
oldest profession that's completely
taboo you could never get away with
doing that in a public health
conference yet you know I was just at
icml in Vienna the second biggest AI
conference I was at NPS last year it's
exactly like that you have all these
speakers sometimes even speaking about
social impacts of AI and they don't
mention all the funding they get from
Big Tech and then in the coffee break
you go out to the Expo area and all the
tech companies have their booth there
there was an amazing study recently you
can find it on the archive abdalah and
abdalah are the authors where they found
that MIT is one of the worst so many
people even who say they work on AI
ethics are taking all this funding from
Facebook and companies like this and you
know that is kind of intellectual
prostitution up in Sinclair I think was
spot on when he said it's hard to make
someone understand something when their
paycheck depends on them not
understanding it and and one more one
more thing also just ask yourself
whenever you bring a new powerful
technology into the world how is it
actually going to be used do you know
Tom leer yeah the songwriter he's like
the master of dark humor you know he has
a song about V from Brown yes he goes
like once the Rockets go up who cares
where they come down that's not my
department says verer F
Brown to me just epitomizes um what some
scientists are doing now in AI yeah we
just going to build these we're going to
try to build super intelligence and get
super rich or whatever and figuring out
what to do with it that's not my
department you have uh one of your you
know kind of renowned articles in Time
Magazine from a couple years ago you
talk about the things we shouldn't do
and I I don't think at this time
everything was was done but you say
don't teach it to code don't connect to
the internet don't give a public API
don't start an arms all those things
have been done what do you say to
somebody like Yan um you know
respectfully obviously he's coming on uh
people talk about uh you know the
maximalist you mentioned the quote from
up then Sinclair he's the chief AI
scientist at meta he's obviously got a a
huge you know vested interest although
he is pivoting more according to him to
research at NYU and and and going back
to his roots in computer science but if
you were you know Mark Zuckerberg at
this point and and you really did you
weren't mendacious and you cared about
Humanity's future what would what would
you tell him to tell Yan or or what
should Yan be telling Mark I should say
this as a proud owner of a pair of meta
Rayban specs which I actually think is
the best AI product that I've used
including chat GPT because it's it it
has some virtual you know aspects of it
it's actually doing something useful all
the time but uh what would you tell Yan
or tell Mark Zuckerberg the reason I try
to never make atom attacks is is not
only because stoop being very low but
but it's also very important because I
actually believe that all of these
people think they're doing the right
thing and what they do comes from a good
place it might surprise people who only
see me having Twitter spats with with
Yan but uh whenever we meet in person we
get along great when we did the monk
debate I'm actually the one who invited
him and said and he said yeah I like to
debate with you and but I do think it's
it's a little bit hard for him to
probably subconsciously if they separate
this massive um conflict of interest
that he has especially when you when I
speak with the CEOs of these companies I
really empathize because I I I think
they all in their heart want to do the
right thing I don't think any of them
except maybe one just wants to build a
successor species that replaces Humanity
they would like to take it as carefully
as they can without being outc competed
by by their competitors but they're all
trapped in in this race to the bottom
and they all feel it where where if if
one of them were to be like hey I'm we
just going to pause this thing for two
years until we can figure out to make it
safe they will ruin their own company
and before the two years are up they
will be replaced as CEO by the
shareholders most likely it's like if
you're a tobacco executive and you
decide one morning that you know my best
friend just died of lung cancer this is
not right what I'm doing Mike now I'm
Philip Morris from now on is going to do
something else they would just get
replaced and they so the only way to fix
this is for example the US government to
step in and say Hey you know here are
the safety standards they apply to all
companies now uh things are much better
for the CEOs because they they don't
have to be the bad guy they can redirect
corporate efforts to figuring out how to
meet the safety standards so they can
make money we we talked earlier about
how how we want incentives in the world
to bring out the best in us right so
that's what I'm talking about here you
know before we had something before we
had the FDA in the US you know there was
this drug called theide are you familiar
with it yeah it was given hyro asymmetry
that led to birth defects and yeah they
they they they marketed pregnant women
and said this is great if you have
headaches and whatever during pregnancy
sickness yeah then kids were often born
without arms things like this prompted
the creation of of of the Food and Drug
Administration exactly for the same
reason that you want the incentives to
be such that here are the safety
standards for all companies regardless
of how ethical or not the CEO is and uh
whoever meets the safety standards first
they get to make a lot of money first so
so biotech companies are have have
exactly the right incentives there to
make their things safe as fast as
possible they don't have to write a
pause letter written by scientists in
biotex thing we should pause development
of thalidomide or new drugs of
questionable safety right until someone
could figure out that it's safe no it's
not the politicians this problem it's
the companies's problem if someone
starts selling a new wonder drug that's
supposed to cure all cancers the FDA is
going to be like wait a second where is
your clinical trial oh you haven't done
one yet well come back when you you have
you know that's the solution to all of
this we need the US to to tell that
American
companies here are the safety standards
we need and the Chinese company
government to say here are the Chinese
safety standards the Europeans this is
how it happened with drugs right the
Chinese also have an FDA not to make the
Americans happy but just to pre prevent
Chinese consumers from getting harmed by
Chinese companies and then once you have
these safety standards that have
independently been formulated in
different countries around the world you
almost automatically start to get
international corporation you know the
American FDA and the European EMA in
Europe they go for drinks they have
meetings to harmonize their standards so
that an American company approved for a
drug here can more easily get approved
in Europe Etc the rest sort of takes
care of itself I can hear my audience
screaming out you know the conspiracy
theorist in the audience that yeah
sometimes they're a little too cozy when
we fund gain of function research at the
Wuhan Institute of virology and and
recently came out they actually had a
polio patient potentially that that also
there but um I'm not I'm not going to
defend the regulatory capture problems
which we obviously have here which are
bad I have never met anyone in um in the
US who works in biotech who has called
for just completely getting rid of the
FDA and going back to letting anyone
sell to linomide what we should
obviously do is get rid of the revolving
doors and and prevent the regulatory
capture getting back to the most
important subject of all me and you how
will AI impact I mean I love it I have
to say part of the reason I'm an
optimist is because I really enjoy it
it's like if it's like I have you with
me 247 I don't have to sleep on your
couch anymore but you know I can ask at
anything it'll it'll even make slides
for me I've I've written scripts I never
learned python to a level that my
graduate students you know could do in
their first year of or undergraduate but
I didn't have to it's like when we were
kids they said learn Mandarin and uh
it'll be really important or learn
Japanese when I was a kid it was learn
Japanese or gonna this I never learned
it I'm glad I didn't I'm glad I
dedicated that to learning you know
cosmology and astrophysics but how is it
going to impact our profession the
oldest second oldest profession
profession being a professor teaching
this job that we call an advocation a
love do you see it do you see it
existing in this form as you and I
practice it that is a question I really
struggle with particularly this week you
know last week was the first week of
classes again because I feel MIT is
totally in denial about where this is
all going by that you mean how
education's going or something else like
protests or things like that what what
are they in denial about ultimately all
aspects of life but but even
what is the what's the value even of
having a university if AI can do all
this stuff better what is it that's
valuable for me to teach the students
now so many people are so excited now
about using llm powered AI tools to
teach students better than we can do it
but once the AI can teach the students
obviously the students are not going to
get paid to do a job that the AI can do
good enough to teach it to them either
and and um I I think I'm not going to
give you a GLI answer
to this because this is really tough but
what I do want to say is I I think
asking this the question this
way what will
happen is really the wrong way to ask it
it it sort of presupposes that you and I
are just passive bystanders here sitting
in the couch eating popcorn waiting for
the future to happen to us now you and I
and all of the people watching this uh
this podcast we're building this future
so the right question to ask is what do
we want to happen what kind of future
are we excited for us and our
descendants to live in that's where it
really need to start a shared positive
vision and then we can ask okay what
does that mean about how we should and
shouldn't
deploy our technology people often say
things like oh it's so inevitable that
uh all the jobs are going to go away
because AI will be able to do them more
cheaply or whatever none of these things
are inevitable there are many things
that we can do with technology that
we've chosen not to do human
cloning for example it could be very
profitable if I could clone make a lot
of clones of you Brian I could make a
lot of money yeah you decided no we we U
don't want to mess too much with the
foundations of our species it's not
worth the risk and we can have a lot of
fun anyway if there are activities that
we humans find very
meaningful and they give us a lot of joy
and purpose we don't have to stop doing
them just because they're are machines
that can do them like if you like
playing tennis you wouldn't replace
yourself by a tennis playing robot I
might need a surf robot cuz I I hurt my
knee on Friday if we ask ourselves what
kind of future we want to live in and we
want our kids to live in
obviously the answers we can come up
with are can be much more EX exciting if
we also allow ourselves to have a lot of
high-tech in there we were
promised Ai and robots that we going to
do all the boring chores clean up the
kitchen Etc while we could do the art
and write beautiful essays and stuff
instead now we have ai that can do art
and essays and I'm still stuck cleaning
up the kitchen myself that's right well
your youngest child's too young to do
the dishes but uh you know from past
experience you can get the older ones to
do uh autonomy autonomous task except
driving I'm not ready to make that leap
of faith yeah I would say no offense but
you were one of the greatest
cosmologists of your generation you made
original contributions predictions you
aided and eded Scoundrels like me uh and
experiment predictions ranging from
first application of a very
abstract uh logic and statistical uh
proofs in computer science bringing that
to cosmology in the early 1990s uh to
deep treatises on math and foundations
of quantum mechanics in the late 1990s
you were one of the first with Wayne
Hugh and Dan eisenstein to predict the
effects of barion acoustic oscillations
which has become a whole new Tool uh
akin to you know some of the things that
I do using the CNB do you miss it do you
miss being a day-to-day cosmologist or
you know cuz you gave up as I see it
again I'm offensive I don't mean it Max
I'm just saying you were at that level
that's very rarified and now you're
doing something extremely important is
that a sign that I should be more
worried because when someone like you
pivots a a whole career that's you know
very very high level to a completely
different direction starting from
scratch should I be worried way grety
famously said that don't you shouldn't
skate to where the puck is but to where
it's going and I did I did feel when I
was doing my PhD that it was quite
obvious that the puck then was going
towards these huge experiments coming
online micro background experiments
including with the ones you worked on
large Galaxy surveys Etc so I decided to
skate in that direction and it was
absolutely fascinating to work with you
and so many others on on harvesting all
the you know the gold that was in this
data but then as you know there were
these three big Mysteries did inflation
happen still haven't found the
gravitational
waves what is dark energy we still have
not found any evidence that W is not
just equal to minus one and it's not
just boring constant and what is dark
matter do we keep pushing down theal
limits still haven't found anything so I
started this feel that uh the Golden Age
of of cosmological data was was waning
at least a little bit there's plenty
more cool stuff to do but still coming
off the peak a little bit well at the
same time I I felt the puck was very
much going towards AI there was so was
so obvious this field was exploding on
top of that um I'm very much just driven
by curiosity and it just so much fun to
to to to work on understanding how
intelligence works and the mind and so
on and and my group at MIT now we mainly
focus on what's called mechanistic
interpretability which in less nerdy
speaking you could think it was just
artificial Neuroscience you take an AI
system that's doing something really
smart and clever and interesting and you
try to figure out how it actually works
under the hood so we had a big
conference about on that they organized
here at MIT last year and then we was
part of organizing one in in Vienna this
summer and it's crazy how fast this is
progressing it reminds me a lot of of
the Heyday of the mic background from
one year to the next oh W map came out
you know everything being revolutionized
the reason for that is quite obvious if
if you're doing Neuroscience on an
actual human brain it's painstakingly
difficult to measure the output from
even 1,000 neurons and you
have a 100 billion of them and you also
have to get ethics per board permission
to even do the experiment whereas when
you're studying an artificial
intelligence you can measure every
single neuron every single syapse like
all the time and you don't even have to
ask permission so this is is also just
very much a fun field so the the the
emotional personal answer here is yes of
course I think back fondly about the the
the the good old days when when you and
I were doing uh micro background papers
together but it's also just an enormous
amount of fun working on this question
how can we understand the inner Universe
of intelligence how it works it's uh
every bit as much fun as it was back
then with with cosmology so I've got one
question uh from the audience that I
want to ask you and then I've got four
quick response answer uh that I hope
will be rapid fire uh so the first and
maybe the only question that I want to
ask from the audience uh has to do with
the past guest noal Laurette Roger
Penrose and steuart Hammer off both of
them multi-guest uh on the podcast and
it relates to you know something that is
obviously very interesting to you which
is artificial intelligence and also the
human mind and Mathematics and of course
sir Rogers book The Emperor's New mind
was one of the first if I think it was
the first science book I ever read as a
high schooler didn't understand it but
uh he made a very powerful case that the
brain really isn't a computer and uh and
yet you know to this very day and there
were certain problems that weren't
computable and it has to do with touring
test it's very interesting and and still
quite relevant book but you're very
convinced that that approach is wrong
that the microt tual orchestrated
collapse or or uh without you know
without attacking him personally you've
been very skeptical about that can you
comment on why you don't believe that's
the correct approach or in in your
opinion is inferior to to other other
ways of getting at this question of you
know the ghost in the machine so to
speak I'm a scientist so my job is not
to believe stuff or not believe stuff it
it's to look at the day uh and make
educated guesses happy to place bets I
would have loved for the brain to be a
quantum computer because it's much
cooler than a classical computer but
back when I was a post in Princeton I
decided to just
calculate how long Quantum
superpositions would survive in a warm
wet brain and disappointingly they would
last way less Long than they would need
to if a neuron is firing not firing in a
Quantum superp position that gets
destroyed in 10 the minus 20 seconds you
know I don't know if Roger pendro is can
think 10 to the 20 thoughts per second
right I certainly can't and uh so I just
I wrote that nerd paper then some
journalists put a little bit of a mean
spin on it and and those guys I think
got a little bit annoyed but I was
really not going into this with an
agenda at all I think what's happened
since unfortunately Vindicated my
conclusion that you don't need Quantum
comp computation for human level
intelligence
because chat GPT 40 and and other large
Lang mods are able to do a lot of the
things already that we humans do
demonstrably without any Quantum
Computing they're purely classical right
so I think what this is telling us is
that even though Quantum Computing is
very cool it is possible to build very
intelligence machines also classically
yes and I guess you know that kind of
does tals with the when it makes me
think of the computational aspects of it
when I I talked to Sean Carol who's a
big proponent of the um mathematical
Universe number three Multiverse which
is a ever ready in many worlds Theory
and I asked him I want to ask you the
same question how could we
experimentally test branching rates and
and so for I mean are these things just
completely out of the realm I mean my
our colleagues at nist and other places
are measuring you know kind of atos
second level uh making clocks that
operate at the AOS level what level of
Technology would be needed to get
falsifiable or or even evidence for you
know the the everan branching view of
reality in that level three Multiverse
oh that's an easy one basically what we
should do is just try to build quantum
computers that can do things do
computations that no classical computer
could do even if it were the size of our
universe
right that would totally demolish the
idea that all the resources we have
access to somehow are are sort of
limited to our classical Universe you
know people argue now about whether we
already have demonstrated Quantum
Supremacy or not I'm going to stay out
of that mudslinging contest but I I
applaud experimentalists working hard to
really really try to do this and if you
could if you can build a
computer which can actually
run chat GPT 40 for example in
superposition and
in Quantum superposition and suppose you
can build a version that actually will
talk to you and describe how it
consciously experiences things right if
you have someone as smart as you who is
demonstrably having two different
experiences in the level three multi
worse at the same time you how much more
how much more evidence do you want than
that right than being able to talk to it
and so on we've already put atoms in two
places in once molecules the carbon 60
bucky ball nurus mavala and her
colleagues at ligo even took a mirror
that weighs one kill
and we're able to demonstrate that it
behaves Quantum
mechanically once we can get to the
point that something that that's as
intelligent as a human brain is able
to do two different things in Quantum
superposition I think that kind of
clinches it because that's what the
whole point is of U Everett and his work
so we won't need to look at microtubules
anymore that'll make uh make things a
little bit easy in the I I think people
should look at micr tuils and and like I
said in the beginning if there's ever
any cool experiment that can be done at
reasonable cost they will teach you
something new we should totally go ahead
and do it yeah this is a part of the
show I call the Fantastic final four
were basically existential questions
that I haven't asked you in our past
conversations and the first one relates
to your Countryman Alfred Nobel who
created a Nobel Prize which had a
two-fold component it gave away money
and encourage people to do stuff in
science peace literature Etc and
medicine and I've had on 21 Nobel Prize
winners Max in this short time maybe
you'll be the 22nd someday we'll see but
Alfred also said that a winner had to do
his or her work for the betterment of
mankind and that's an example of what's
called an ethical will not just a
monetary or material will in Hebrew we
call it a Zava uh the sort of things of
great wisdom that you want to leave to
your descendants not just biological but
maybe ideological like me and and all
those that come after I want to ask you
max if you were to leave as a document
or some sort of will for the future of
humanity what would you put in it or
what would it be about I would say that
we should go forth and not
only build great technology but also
create incentive structures that bring
out the best in US humans so that we use
it wisely otherwise we'll be like Vana F
Brown again once the Rockets go up who
cares where they come down that's not my
department says there a fun Brown well
speaking of technology and things that
go up and go down as you know I'm the
associate director of the Arthur C Clark
Center for human imagination at UC San
Diego you probably know the movie 2001
of Space Odyssey which has uh not a
small amount of artificial intelligence
in fact the sign in the back over there
if you can see it do you know that the
word podcast comes from that movie
Max did you know that I'm sorry Brian I
can't do that I have a computer in this
room actually I just said trigger word
I've named it how but I could say how
computer turn off the
plug now if you saw that that actually
turned off my magical neon sign but my
ultimate keing test number two maybe is
can you program an AI that will cause
itself pain will that will turn itself
off or blow its own capacitors or things
like that but I don't want to get into
all that what I want to say now is you
remember in the movie there were these
monoliths right there are these
structures and the Apes hitting it with
a bone and then if they're found on
moons of of of the planets of the solar
system I want to ask you a different
question I want say if you had a time
capsule that could last for a billion
years like these monoliths placed by a
sentinel species what would you put on
it or in it what would you put on a time
capsule that you knew was guaranteed to
last for billions of years I would just
put all the books and movies we've ever
made on there in there and then let
their descendants figure out what they
were interested in I think now here's
another question uh this one comes from
uh Richard feineman Nobel Prize winner
Richard feeman he said if there was some
cataclysm maybe caused by Ai and only
one sentence could be passed on to the
next generation of creatures what
sentence would you put on there you know
he put on the atomic hypothesis but what
would you put on what would be Max's
sort of uh Time Capsule of a scientific
variety that's you're going to be
disappointed that I'm going to pick
exactly finan sentence here and the idea
that everything is made of these tiny
particles bouncing around called atoms
etc etc because it was actually when I
read that sentence and volume one of the
fan
lectures that it finally clicked to me
and that's what made me really fall in
love with physics actually what I
previously thought was the most boring
subject in in U high school so it's
really because of this that I'm here
yeah for me it would be the the CMV an
isotropy power Spectrum you know because
that that's that actually has within it
the Atomic physics hypothesis you know
because it comes from hydrogen so it's a
little more economical Max but um that's
my choice okay another saying by Arthur
C Clark when a distinguished but elderly
scientist I'm not calling you elderly
but when a distinguished but elderly
scientist says that something is
possible they're most certainly right
when they say something is impossible
they are very probably wrong and Arthur
called these things failures of
imagination nowadays we call these
limiting beliefs I want to ask you what
have you been wrong about what have have
you changed your mind about in science
or outside of science if anything I was
thinking the other day about what I was
wrong about in my second book life 3.0
and there were actually two things first
I was wrong thinking that it would take
much longer than it actually did to get
so close to artificial general
intelligence so it actually turned out
to be easier than I had thought the
second thing I was wrong about was I
never in my wildest dreams when I wrote
that book thought that
world leaders would would let companies
get so close to taking over the world
with with ey without doing anything at
all that's why I opened that book with a
story about how some people take over
the world entirely in secrecy and then
uh Max my final question you've been so
gracious with your time it's uh
so-called thirdd law of Arthur C Clark
who said the only way of discovering the
limits of the possible is to venture a
little way past them into the impossible
I want to ask you max if you could go
back meet 20-year-old Max when he used
to be called Mad Max what would you tell
him you got 30 seconds with 20-year-old
Max what would you tell him to give him
the courage to do as you've done to go
into the impossible never underestimate
what he might be able to actually do and
if uh he has an idea that he really
believes is correct and everyone around
tells him that it's or
impossible keep pursuing it anyway let
the people talk
Max tag mark my good old friend it's
great to see you I wish we could be in
person but maybe we will be in the near
future
