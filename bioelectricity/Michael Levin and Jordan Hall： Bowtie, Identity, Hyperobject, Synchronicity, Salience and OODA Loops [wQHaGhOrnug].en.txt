I'm so delighted today to be here with
Dr Michael Levan and with Jordan Hall uh
Michael Levan is a Developmental and
synthetic biologist at tus University
and Jordan Hall is a a pioneer of
disruptive
Technologies and uh a person might say
why are we putting these two people
together but I was speaking at a
conference this weekend and I gave a
talk about how art um can be a
translator key for other Arenas and a
lady came running up to me afterwards
and she said oh my goodness you helped
me so much and I thought how could that
kind of a talk be helpful to anybody but
she said you made me remember something
from many many years ago she said when I
was younger anytime I would go to a
party I would always ask the
question what is it that you've learned
or that you do where you have gotten so
familiar with it and you that you found
out that there is no
bottom and so I said well for you what
is that and she said
milk there's no bottom to milk and when
I discovered that I decided to be a
cheese
maker and then I met a guy who was a
hairdresser and I asked him and he said
hair no bottom to
hair and uh then she said I met a
painter and I thought he was like an
artist but no he he painted houses and
he said paint there's no bottom to
paint so what I take that to mean is
that once you get into an arena and you
get down to the Deep truth of that Arena
that allows you to have a lens that's
going to help you to discover truth in
other Arenas so that's why I'm putting
you two
together so
um we had agreed on
some we had agreed on some uh topics but
before we get started on those topics
Mike I was listening to a conversation
that you had recently with Jason bongard
and Richard Watson and one of them made
the comment about Mike's bow tie
stuff so I thought maybe you could
describe what that bow tie stuff is
because I think that's one of those deep
truths that translates into a lot of
other
Arenas yeah um I think I think Josh was
referring to uh um a recent paper that
that I had in This Journal called
entropy talking about um this this
fundamental so so I'll describe it first
uh how it works for cognitive systems
and then talk about what I think it
means for development and for and for
evolution so one one way to think about
uh What uh cognitive agents do is that
that at any given moment in time you
don't have access to the Past what you
have access to are the memory engrams
that the past has left in your brain or
body or some other medium that you're
using so that means that uh as as a as a
cognitive system you're constantly uh
undergoing the process of sens making
and World construction you you at any
given moment you have these these memory
traces you you now have to figure out
what they mean what do they mean to you
so at the moment you you build a picture
and continuously rebuild a picture of
yourself and your world and your past
and so on in a way that's adaptive at
the moment it doesn't um it doesn't have
to be the same way you understood them
before and as a simple example uh I'll
I'll just use this caterpillar the
butterfly transition so um caterpillers
have a brain suitable for crawling
around so they have this like
two-dimensional they live in this
two-dimensional World basically and uh
um they they can be trained and they
will have C certain memories and then
they uh undergo a massive metamorph is
to be a butterfly now the butterfly
lives in threedimensional world it's a
hardbodied creature not a softbed
creature so the um the controller has to
be completely different um and what they
find is that they still remember the
original uh in the original training
despite the fact that that brain was
basically um completely refactored so
most of the cells were killed taken the
connections were taken apart all that
was you know uh re redone and yet the
information stays so so for years I I I
used to wonder what what turned out to
be um the less important question which
is where is the information and how do
you hold on to information when the
information medium is sort of torn up
and redone but the the the even more
interesting question is around the idea
that actually the specific memories of a
caterpillar are of no use to the
butterfly the butterfly does not want
the leaves that the caterpillar was
eating it doesn't move the way that the
caterpillar does um those exact memories
are of no use but what what uh what is
of use is a reinterpretation of the deep
lessons um so so the a generalization so
it's of leaves then food and and things
like that so what you have so this is
the bow tie right so so so there's a
couple of different ways to picture the
bow tie one way to picture it is that uh
all kinds of highly detailed experiences
come in you don't store the micro states
of all those experiences you compress
them you learn the pattern you develop a
generative model of what was going on
that's what you remember those are the
engrams that you store they've they
they're stripped of a lot of the details
on the outside so that's the that's kind
of the algorithmic part where um you you
know you you you uh you infer the
pattern and you store that but then when
it comes time to recall them uh that's a
creative act because again a lot of the
actual initial information is gone what
you have is this is this this generative
seed and so now you have to reinl it and
say what does it mean for me now and and
uh just as you know the butterfly uh
reinterprets though that information in
a way that's suitable for itself in its
new environment with its new affordances
and so on um one can think of all of us
as being in that same in that same boat
and having to kind of um uh uh re
reinterpret creatively reinterpret the
content of our own mind all the time and
this idea that that then then what's
what's interesting about biology and I
just say this one last thing and I'll
stop uh it's it's the idea that in in
biology your Your Allegiance is not to
the Fidelity of the information unlike
in our computer science where you really
want to make sure that each layer is
isolated from the layers below when
you're coding you don't think that wow
my my registers are going to float off
and and do other things you you can
depend on it biology is always dealing
with an unreliable medium right you know
as as if you're if you're a life form uh
and you're try and evolution knows that
everything is going to change not only
the environment but your proteins are
going to degrade um you you're going to
be mutated you don't really know how
many copies of any molecule you're going
to have every there's a lot of noise
there's a lot of change you have to
commit not to the Fidelity of the
information but uh more like to its
saliency right you're you're ready to
creatively confabulate a new story based
on whatever you have and so the same
thing you know in this paper I talk
about development and evolution being
part of that bow tie too the past and
the experiences that your lineage has
had in the past have created a genome
and some other stuff that you have but
you're under no obligation to interpret
the them in the same way that your
ancestors did and in fact you can't
because you know for a fact everything
is going to change over time the
environment your own you're going to be
mutated and this is why you know one of
the things we study is the incredible
plasticity of Life the fact that we can
take living things and you know I can
put a we can we can put a an eye on the
tail of a taple instead of in their in
their head and those animals can see
perfectly well and they they they learn
beh you know visual Hues you know even
though that eye is now connected not to
the brain but to the spinal cord this
radical restructuring of the central
nervous system no problem you don't need
rounds of selection and mutation out of
the box at works and we've done a
million things like that where I think
that the reason it works is because it
was never hardwired in the first place
you could never assume coming into the
world as a living being you could never
assume that things were I mean maybe
there's a few species that do that
nematodes maybe but but but most
creatures uh have this creative problem
solving where the step one is to figure
out what affordances do I have and and
how do I put myself together into a some
kind of a coherent organism and and
survive and do other interesting things
and this is why we can have xenobots and
anthr robots and uh things that have
never existed on Earth before but have
novel coherent behaviors and
morphologies and so on so that's the B I
think it's this idea that that
information gets squeezed down like like
a like a variational autoencoder you
know it gets it gets squeezed down into
this like very sparse representation and
then there's a creative act of s sense
making on the other end to say what do
my memories actually mean uh and and
what can I do with them now that's the
that's the Bai
story
Jordan um okay so let's see what I what
I noticed is
um yeah I think this is actually going
to be this is pretty
clean the the set of possible
conversations that we can have that
would be very interesting and in fact
interesting to me I think interesting to
you and to Karen and anybody watching is
quite large um we can zoom in on that
particular question and talk for example
about the the notion of perception as
also a Bai and how perception World
building how those things we just can go
off all over the place you have a lot of
fun um so what I ended up asking myself
as I was listening and I've been doing
this now for a while um I think I first
came across your stuff maybe about a
year and a half ago which implies either
I'm slow on the uptake or something
happened that enabled that connection to
be made and I've sub since discovered
that you've had conversations with
friends like John Veri andrez hriz and
probably many others that I'm not even
aware of um and I guess when Karen
suggested that our conversation could be
fruitful I was trying to figure out
what's the best conversation we could
have and what I noticed was that the way
I was trying to think about that had
this really interesting reflexivity to
it which
was um I noticed three points that that
were coming up as I was listening to you
that seemed okay these all have a
certain conservation one is the notion
of Mind space or the notion of Mind as
having a an embodiment right but mind is
having a certain how would you say
identity to it which to me began to look
like a certain level of uh discreetness
meaning that you could have a a snap
from one embodiment which was able to be
uh afforded to one quality or
Singularity of mind that there would be
a Traverse and across that Traverse you
could actually snap to another
embodiment so say for example the upper
Paleolithic transition is for example a
particular quality of embodiment in
hominids that hit a different kind of
mind that had a completely different set
of
affordances um
and that the question that kept coming
up for me which felt like they were a
really nice overlap was the question of
um what would it look like to put
together an engineering program or an
experimental program um orienting
towards the question of what would be
the form of embodiment in collective
intelligence that includes human beings
as at least one primary element at
ontological level one that would give
rise to a collective intelligence at
ontological level two they would snap to
a qualitatively novel level of
mind so that was a a question that I've
had a substantial amount of time
inquiring over in fact I think John and
I verv and I think was one of our first
conversations was on exactly that point
um and this notion that I found in your
work of a strong orientation towards
experimentation in the direction of what
we could actually then de deliver on an
engineering
deliverable um mindspace and embodiment
I thought H that might be interesting
and then what was happening just now as
I was inquiring into it I was like what
would happen if I begin to
self-referentially and try to embody a
part of a collective intelligence
including the three of us in such a
fashion that we were actually leveraging
that qualitatively distinct um mind to
inform the conversation we're having to
get us there sorry that last part is a
bit of a uh artistic flourish but
perhaps that makes
sense yeah did it make any sense that
last part yeah yeah yeah yeah yeah yeah
very very very interesting um so so do
you um yeah I'd love to I'd love to hear
your thoughts on that I mean what what
do you think is is uh both both um kind
of the the role of technology in that
sort of project and what what do you
think is possible now what has been done
um how how do you see that space so all
right so maybe some of the space of
where we've been before so as far as I
can tell there's broadly three um strong
embodiments that have kind of been able
to hold together coherently over a
diverse variety of contexts uh the one
that's the Baseline is just sort of the
human indigenous group so we are
obligate collective intelligence that we
form naturally Collective intelligences
as just human groups and we can see this
show up in for example the way that a
group of of of sports like a team of
sports people will come together and
they will produce something which
clearly has a quality of intelligence
that is different than
um just you five or 12 people showing up
randomly same thing in the military
music that kind of thing and all that
grounds back to something that I would
just call the indigenous mode of
collective intelligence which has a
certain level of capabilities and a
certain level of constraints one of the
biggest constraints is that it it is
quite Limited in its ability to scale
people there's just a certain limit on
the number of people that can
participate in that quality of
collective intelligence before it begins
to break down and there's a bunch of
breakdown elements that show up in in
that mode which we want to we can
diagnostically look at why that happens
and then we had a a forking event
historically where that scaling
limitation gave rise to a possibility of
two novel forms of collective
intelligence that scale vastly more
effectively one is uh bureaucracies and
the other which are institutional
governed by institutional forms that
enable a very large number of people to
participate governed by institutional
structures and that allows the advantage
of a large number of people and it
produces a form of collective
intelligence that has certain
capabilities of substantially larger
than indigenous groups but actually
other capabilities are substantially
weaker uh and has as as far as we can
tell has a an ASM totic level at a
certain level of scale it just doesn't
get any more effective in fact tends to
get less effective and then markets so
markets have this capability of scaling
arbitrarily as far as we can tell um but
of course quite narrow in the set of
things that they can actually process
both in terms of the complexity that
they can navigate in one particular step
and the depth that they can navigate um
so those are sort of three examples that
shown up thus far and I would say one
story of History would say that we can
even divide history into roughly three
major eras one would be the the
anthropological era
preceding um the upper Paleolithic C you
know click where something happened in
the Indigenous mode that gave rise to a
qualitatively new level of intelligence
which then of course exploded the
diaspora of humanity Homo sapiens across
the world and then another click that
happened somewhere around that magic
number of civilization buildings
agriculture that was deeply
characterized by a shift of the majority
of work well maybe that's not true but a
substantial amount of the work into
these other two modes would have been
operating more or less at the same time
together in a complex way and uh so
that's the background and we can of
course unlock any of those there's a lot
of good stuff to be had there and
hypothesis would be something like we're
in a very interesting moment now which
shows up all over the place like we can
do this with uh uh and Paradigm we
we now are aware of the notion of
Paradigm shifts in science because we're
aware of them the nature of what
Paradigm shifts look like now can't help
but have a reflexivity shift they're
going to be different in
nature um same thing in terms of this
form of of collective intelligence where
there's really weird Mo moment where the
resources or the technological substrate
that might give rise to a novel form
seem to be even super saturated in the
local environment but it may in fact
require that we do something different
uh something maybe at the level of more
conscious or more design or something
it's not quite clear exactly what that
is U precisely because we're aware of it
so we are operating at a level where
we're consciously participating in
something which as far as I can tell has
not been the case in the
past yeah I could go on arbitrarily but
think that's a pretty good time to
stop did you want to say anything Mike
um well the uh yeah I mean the only
thing I I that comes to mind right now
is that um the the market you know what
you said about markets and so there have
been a few people on Ben lions in
particular uh is uh someone who's who's
been pointing out this so so he and I
are actually um writing a paper on um
the price system as a kind of cognitive
glue and this idea I know nothing about
economics so this is you know that that
part's all him but but um but just just
the idea that uh a lot of these things
can be mapped you know there's there are
a lot of Concepts in the field of
collective intelligence and diverse
intelligence that can be that can be
used to understand this kind of stuff
and I've had other people contact me who
are working on this Market mind
hypothesis you know you know um and just
just the idea that that that the economy
again can be uh can be looked at with
tools that we have to for for for
interacting with other kinds of
intelligences so um yeah I think it's I
I think it's very interesting and just
just just in general I I think it's uh
an important research direction for
Humanity in general is to develop tools
to identify detect and communicate with
all kinds of intelligences and very
unconventional
embodiments that we are not good at
noticing and in fact that we have all
kinds of biases and prejudices against
even entertaining the notion that um uh
you know that that that these things are
kinds of minds and uh yeah you know
ecosystems and uh and economies and
power grids and all all all sorts of I
mean when whenever we look I mean we've
looked at Gene regulatory networks we've
looked at Pathways we we've looked at
simple sorting algorithms when you look
using the right tools you often find uh
some very surprising things in this in
this area and and I think uh developing
those kinds of tools so that instead of
guessing or having sort of you know
philosophical feelings about it we can
actually do experiments and say look
here here are a set of tools from
Behavioral Science uh from diverse
intelligence research that actually
gives you a better purchase on having a
a a beneficial a mutually beneficial and
and enriching relationship with this
system that is is not uh you know
available if you if you assume that it's
a that it's a basic kind of you know
mindless machine basically I would
definitely some put some chips down I
was gonna pop in here for a second um so
interestingly enough Benjamin lions got
in touch with me last week Michael I
don't know why I hadn't contacted him
just out of the blue he contacted me and
he said I'd like to talk to you so so
I'm setting up a conversation with him
for next week but I think the crossover
is on this issue of obviously markets
but also the idea of uh distributed
cognition and how that relates to price
and uh somehow in my mind right now
that's tying me back to the comment you
made earlier
about um in the development the
allegiance is not to the Fidelity of the
information because biology is an
unreliable medium but rather the
Fidelity is to its
salience and uh that ties in with John
verve's concept of relevance
realization and when John's talking
about relevance realization he's usually
talking about distributed cognition as
well so because I've been listening to
you for so many years Mike when I when I
see things I typically see them in terms
of how the cells are operating so now
the picture I have is of these cells
operating and then spring that over into
another Arena and being able to see the
larger thing so I think it translates so
beautifully to the whole social
Arena and um and how these uh different
groups
of uh I think that Jordan was talking
about how the scaling limitations give
rise to bureaucracies and markets so um
I'm just throwing that in there to see
if it brings a thread for
anybody uh what does Bend do uh he's an
economist okay so and he had
conversation with Michael where he well
it wasn't a conversation he presented a
he gave a talk at our Center yeah on
price being the cognitive glue in the
markets I think is the way he was
putting it right and uh thinking about
how in some way price may be a cognitive
glue in the the biological development
as well which I kind of like that idea
so I had two people on my channel talk
about that idea and I think he might
have seen that
video
um so I don't have you talked yet about
the cognitive glue idea Michael I I mean
maybe you want to just nail that down
and then that would give Jordan
definition to work with yeah all all I
mean is by that is um a set of policies
and mechanisms that allow competent
subunits to form together into some kind
of a an emergent Collective that's more
than the sum of its parts specifically
so so so here's a simple example um if
you have a rat and you train him to
press a lever and get a reward there's
no individual cell in that rat that has
both experiences so no individual cell
interacted with the lever because those
were the cells at the feet and the cells
in the gut got the the sugar reward uh
but so so who owns the associative
memory it's not any individual cell it's
the rat so what's the you know what
holds together the rat in a way that
enables it to have these uh uh memories
and goals and and so on that don't
belong to any of its parts well there
the conventional story is that it's the
neural bioelectricity it's the nervous
system and the activity of the of the
nerves that um that allow there to be a
rat as distinct from a pile of neurons
and so there are certain policies by
which these neurons interact so they you
know they they they activate or inhibit
each other there's a million other
things going on and um and in that case
that's what's going on we've studied
other kinds of cognitive glue for
example when you have um a collection of
a collection of cells what allows them
to be to come into alignment and work
towards something very complex in a
different space like forming an organ so
individual cells don't know what you
what a finger is or how many fingers
you're supposed to have but the the
cellular but the group of cells that are
building it absolutely does and you know
this because in animals like salamanders
when you try to deviate them from that
goal by let's say cutting off some
fingers they will or but you know they
bite each off each other's legs all the
time uh the cells will immediately
spring into action and get right and and
build it again and then they stop so
that's the kind of homeostatic set point
that they try to maintain but that's
that's that's a that's a set point in an
anatomical space that's not available to
individual cells it's only available to
the collective and so then now we have
to ask what is the cognitive glue what
are these cells doing that allows them
to to join together into a higher order
being that can see into this other space
and that can see into this anatomical
space and so we study things like um
memory anonymization through Gap
Junctions and PR sharing and some other
things that that we study as cognitive
glue but it doesn't have to be that and
it doesn't have to be bioelectrics I'm
sure there are many other modalities I
think that's very interesting right is
to ask um what other kinds of um
policies are good for making for for
creating these higher order beings that
can see into other spaces versus just a
pile of
Parts yeah yeah I mean the Gen the
generalized question of what what are
the characteristics of a a cognitive
glue mechanism independent would be uh
like a profound tool if I'm and trying
to enter into the design space of taking
some multiplicity and producing some
identity out of it um it'd be useful to
have a general theory of okay what kinds
of things are are necessary to have to
produce the right kind of cognitive glue
yeah it's interesting because my my mind
starts moving in the direction of
thinking about it in terms of
information but I'm not sure if even if
even that's the right
category think about yeah I mean I I'll
I'll you know I can give you one like a
simple example with of of the stress
sharing so um just imagine and this
there's a million ways this can play out
but just just for visualization um
there's a there's a group of cells and
there's a cell over here and it needs to
go over there okay so there's a gradient
and it's you know there's a some level
of of stress that it has that will be
minimized once it gets to where it's
going so um the other cells are happy
where they are they're plasticity is low
there you know the temperature of the
whole system is low they they've settled
they that that's it and and and there
for they're not motivated to get out of
the way or to help that cell achieve
what it needs to do one simple thing you
can do if you wanted to have a kind of
cognitive glue where the whole system
would be motivated to make sure that
everybody's in the right place is to
Simply let the stress be leaky so if the
cell out here that's that's stressed out
all it has to do is release some of that
some of those stress molecules in this
case like literally molecules that are
that serve as signals of how systemic
level stress and the cells around it now
they're stressed out and they're it's
it's not that they're altruistic it's
just that um their plasticity goes up
where they start to move around and to
be a little more willing to do new
things then the cell gets to where it's
going then everybody's stress drops so
so what it in what it in effect does is
it means that my problems become your
problem to some extent and that um you
know you may not have a special
mechanism for any kind of altruism but
just by virtue of your own stress
reduction if I'm a little leaky uh then
then you you know uh that process is
going to make everybody help out and so
we've done computational models of this
recently and we we there's a nice um
paper that my student lwin shisha
published and uh it um it it just shows
that that that kind of a system without
without any special kind of altruism
mechanism uh causes apparent alignment
of everybody everybody kind of has the
same goals and so so that's that's one
way of doing it another way of doing it
is this uh this memory anonymization
business so imagine you have two cells
and cell a sends a signal like some kind
of a let's say a diffusing chemical over
and it and it hits Cell B it's very easy
for cell b to know that this came from
outside and as long as that's how they
communicate it's very easy for them to
maintain different memories of events
and different uh different goals and so
on so they're two distinct individuals
but there's this there's this structure
in biology called The Gap Junction which
basically allows two cells to directly
link their internal Milos together and
then something very different happens
when when let's say cell a gets poked by
something and there's a calcium you know
but let's say a calcium um Spike and
that's a that's a a trace of of an
indicator that in the past they've got
injured okay so that calcium spec
propagates through the Gap Junctions to
cell b um as far as cell b is concerned
that's kind of a false memory because
cells B never got uh never got poked but
that calcium Spike doesn't have any
metadata on it about who it belongs to
and the fact that they are now connected
in this way means that it's very
difficult for them to con to to maintain
different world pictures different
memories they they you know they become
there's a little bit of a mind Mel that
happens and and and the memories are
anonymized to the point where it's not
whether A and B A or B has it it's that
the new system AB has this this
information and now you get all kinds of
interesting capabilities out of that
because you know if if I got poked over
here well the collective wants to know
about that because there are other
things you could do from from the other
side that might be that might be
relevant so right so your cognitive
likeone gets scales up both in space and
time because it takes time for signals
to to propagate so now you have a kind
of a thickness of the now moment so so
that um that spreading of memories that
uh are not Li you know not limited to
one subunit tends to and and there's a
ton of more work to be done on this I
mean it's not enough to just you know
give every piece of information to
everything I mean that doesn't work
either you have to you have to have some
some some very clever ways that
information gets gets around but but but
that but that idea that that it's not
your memories and my memories it is now
our memory in an important way it that
that really functions as also as a kind
of cognitive glue that binds us together
to a similar model of the world th to
you know align behaviors and so on do do
you have the language of udal loop from
uh strategy Theory I don't know that
please tell me tell me about that it's
really use sorry very simple it'll make
total sense but what I'm interested in
is the fact that it comes from a very
different domain so this literally comes
from uh strategy specifically military
strategy okay so is uh it's a by
hypothesis an abstraction on strategy
which is generalizable observe Orient
decide act right so a loop so a given
strategic actor initially by the way a
fighter pilot um is ultimately defined
by their the the bandwidth they can move
through that Loop and generically across
uh multiple different contexts if I can
be inside your UDA Loop that means that
I have the Strategic advantage over you
or ultimate that means is that I
actually become a Cause inside your own
udalo you are now reacting to me as
opposed to the other way around and
basically if you can get to that
location then for the most part in any
other strategic context you will
ultimately have a strategic advantage
and as it turns out this this scales
meaning that the the Marine Corp has
adopted this as a methodology so not
just fighter pilots but entire uh groups
of of entities and they actually think
about it in terms of what's the UDA Loop
of the entire of a of a of an
organization and what does it look like
to design things that have that kind of
UT Loop um and what does it look like
what what are the design characteristics
that will increase the ud Loop so for
example during the global war on terror
um what we discovered was that our
special operations groups udal Loop was
meaningfully slower than the distributed
intelligence embodied in um the terror
networks and this was quite practical
like by the time that we had discovered
perceive right or observe that a
particular Terror network was coalescing
in an act in a particular location and
had gone through the the process of
observing orienting on it deciding what
we were going to do and then acting on
it they had already executed on what
they were going to do were gone so you
literally we were in a game of of H
wacka ball that we couldn't catch up on
and so the this necessitated a conscious
movement to a different level of
operations which was at the level of
learning meaning The Joint Special
Operations Command had to say hey we
need to actually go through a process of
of becoming a different kind of
collective intelligence that has a
categorically Superior capacity to
develop faster tighter udal Loop which
they did by the
way and then I was thinking about this
so then the metaphor I was going to use
is something like an UDA Loop envelope
so I'm seeing this in the sense of
almost like a what's the right way of
describing it um like a standing wave
where because I think you had three
different discrete elements at a minimum
one was something happening at at the
physical level of the frame that we're
operating at so here you were speaking
it was effectively molecular biology
Vis cells what you calling the Gap
Junction which opens up an affordance of
a a a new form of perception in this
case the experience of the calcium
actually is in creates a memory engram
at the level of a wi right it's a new
form of perception particularly for for
this guy over here uh and in principle
at least enables the activation of the
exploration of the new possibility
landscape of agency of the we and so you
have a new a new affordance for
perception and a new affordance for
agency which thens to say we def we've
defined an udal Loop envelope if that
makes any sense which I'm saying is that
there's something about the this New
Path that's available that is available
as a Wii which they begins to create a
reinforcement mechanism around the the
the union or The Binding of the wig and
so the cognitive glue has a uh a way of
developing itself over time including
both the front and the back end of the
that that process
yeah that's that's that's really
interesting I hadn't I hadn't heard of
that before um I wonder I need I need to
think through what the uh relationship
is between the size of that Loop and
something that we track which is the
cognitive L cone being the just the size
of the largest goal that A system can
pursue so in space and time right what
what is the radius of the biggest thing
you could possibly care about and you
can think of what that looks like for a
you know a bacterium for example is
really only concerned at a very small
spatial extent of whatever the local you
know chemist chemical concentrations are
and it has a little bit of a memory
going back and maybe a little bit of
predictive capacity going forward but
that's it so it's got a a pretty pretty
small cognitive lone and then you get
something something like a dog which has
a bigger spatial extent that it's
interested in uh it has a bigger
temporal extent never going to care what
happens three months from now um You
Know Two Towns over that's that's you
know outside the cognitive lone but it
but but it but it has you know it has a
defined set and then you can you can
think about a human right and in humans
I think that's actually one of these
kind of um uh phase transitions is when
your cognitive lone gets bigger than
your own lifespan and and you realize
that actually guaranteed you have some
goals that are not going to be
accomplished in your own Lifetime right
and uh which is not the case for for for
for most animals and so um that no doubt
leads to all kinds of interesting
psychological pressures and whatnot but
but then but then you can you know like
one thing I think about and I have some
some some colleagues who um kind of
think about the Buddhist tradition a lot
and we we think about this idea of like
what what what does it mean to commit to
enlarging your cognitive lyone in
particular um with respect to this
notion of compassion right like how you
know in in a in a in a standard human
has only so many so only so much ability
to care about in the linear range to
care about um you know some set of
beings and if it's more than that you
know you're not twice as sad or 10 times
as sad you're just kind of this is this
is all you can really handle but but
what you know what would it mean whether
biologically technologically or or in
some other way um to expand that to the
point where you know you you you
literally can carry care about um as for
example the Buddhist say um you know all
of the sensient life forms and that kind
of thing so yeah so I so I wonder you
know I wonder how the size of that Loop
that you just described intersects with
the size of the goals that that are
given entity is capable of working
towards yeah the the the the two
concepts fit together quite nicely I've
I've I've very much liked the the
consequences of your definition of
cognitive light cone by precisely the
degree to which agency is
included you know obviously I've had
conversations with a number of people
who I think have been influenced at the
kind of from more Eastern tradition and
I said well in in principle I can invoke
in myself a feeling that I can call
compassion for every Quantum state in
the
universe but in practice that's actually
not even really a thing yeah and so we
have to we have to have a have a concept
that includes that whole set as bound
together as a single unit otherwise
we're just uh we're virtue signaling to
ourselves right we're actually trading
salients for relevance y um and so are
you familiar with the concept of hyper
object uh tell tell me I mean the
geometry or something else no no no it's
uh the basic idea is it's it's a it's a
uh a system usually a complex system
where the amount of complexity is
strictly outside
of the cybernetic capacity of a
cognitive light comb so to I'm gluing
some new words together but makes it
that more a more compact definition uh
typically speaking well me just finish
the definition and go back to the
typically speaking uh so for example in
the context of a dog um something like
traffic patterns is a hyper object
traffic patterns are just outside of the
cognitive like kind of a dog and so a
dog may be impacted by traffic patterns
they may get hit by a car but their
ability to relate to it in any uh
cybernetic way is is
zero and the term was coined in
relationship to the set of objects that
are now happening to the species Homo
sapiens in relationship to the maximum
amount of control capacity in our
current level of collective intelligence
so it was discovered that things like
climate change um are hyperobjects that
they are strictly outside of our
cognitive light cone they live within
the zone of our uh kind of our
compassion Zone we can be aware like dog
we can be aware of them and we can yearn
to want to deal with them properly but
we in fact cannot currently interact
with them inside our cognitive light
cone as
defined um and there's about maybe 12 or
13 of these that have sort of been
identified and they're they're mutually
implicated so it's better to think of
them as a single giant hyper object but
each one is is can also be perceived as
such and that's helpful sometimes uh and
this gives rise to why the the original
question was what I was focused on
meaning there's a sort of a clear and
present reality that we're in this
unusual circumstance that the
consequence of the previous stage of our
collective intelligence has output
through its agency a new level of
complexity in our lived environment that
it can't deal with but that we must deal
with and relatively soon and we can go
on but for example one of the things
that you'll notice is when we try to
interact with something which is outside
of our cognitive light cone the
consequences of our our agency is at
best random and more often actually
produces a variety of secondary and
tertiary consequences that make the
situation worse um and so a big exam a
big set of the explanations for why
things have been happening Geo I say
geopolitically but at the level of
society and culture over the last 80 or
so years a lot of what's happening is a
leakage of agency on events that are
outside of our cognitive light cone
using the best Capac we have um and that
obviously creates a weird terminal
event so Mike I don't want to destroy
your thread of whatever you're thinking
right now but I did want to ask you do
you think that this idea of the hyper
object might relate to
um how an individual cell relates to the
whole of the body because the body
itself would be outside the cognitive
light cone of the
cell yeah yeah I mean it it happens uh
even below the cell level so so below
the cell level you have molecular
networks that also have learning
capacity and and uh you know several
other things that uh uh will be coming
out of our lab soon um and then you've
got cells and tissues and and organs and
so on I mean this is this is all over
the place and uh we've had interesting
discussions internally about what what
would it take for example for a
subsystem to gain evidence that it was
part of a larger system right so I mean
I think we build these things all the
time we build social Financial
structures we build Internet of Things
We we do all these uh and we have pretty
much no ability to know what what kind
of intelligence we're creating what will
be its competencies what will be its
goals um you know and I think it's
really important for us to develop a
science of that like CR like critically
important um and so you know we were we
were like I I I I don't know that you
can ever know what you're part of
there's probably some sort of girdle
style you know version that that
basically you can't ever know for sure
but I bet you could gain evidence for it
you know um and uh I think you know I
was trying to visualize what what would
that look like and I was visualizing um
you know kind of two two two neurons in
the brain talking to each other and one
is kind of
a a you know kind of a a materialist
reductionist and one is a little bit
more iCal and the one says you know um I
I sometimes feel like we're part of this
greater thing and there's there's some
something going on here in the other
says n you're crazy it's all it's all
you know chemistry and and the our
universe doesn't care about us there's
nothing else going on there's no purpose
there's no there's no it's a Mindless
Cosmos that we live in and and the other
one says yeah but but you know we there
are these like depolarization waves that
come through and I almost feel like
we're being you know uh trained or
something like it wants something you
know there is there is mind out there
somewhere and and so yeah I don't think
you can prove it but I wonder if what
what it would feel like I think is is um
synchronicity you know that that that if
you drill down to the physical causality
you don't find anything and it just
looks like random stuff that happens but
if you take a step back and look at the
broader patterns and and you have to be
a mind yourself for this you know you
have to be you have to have the the
capacity to recognize these things or or
you'll never you you never see it but
but but you look back and say wow at
this higher level there is something
going on and and the other way kind of
there's a there's a more mundane kind of
version of this too that I was thinking
about recently which is you know from
the if you if you drill down inside a so
so you've got a computer and it's
running I don't know Microsoft Excel or
something and and it's calculating some
some some stuff and you drill down and
the and and and and the one transistor
is that's somewhere in there what what
what does it see well all it ever sees
is the laws of physics like like yes the
you know the the electron do what they
do and it's Maxwell's equations and
whatever they're just doing what they do
but isn't it amazing that at the same
time this whole thing is actually exting
this crazy mystical thing called an
algorithm you know what algorithm how
how is there going to be you know the
the there's no magic down here the
physics are determined it's just going
to do what it does and yet there's this
there's this other level this this in
ineffable um algorithm that in some way
makes the electrons dance and and and
thinking about that that level is is
profoundly important um not just to
understand what's going on but more
importantly to make new stuff you know
to to to do the next thing if you don't
if you think it's all the laws of
physics you're never going to code
anything new you know you're not exactly
wrong um if you if you if you reverse
engineer something that someone else had
done but you're never going to code
anything new like that so um yeah so so
I feel like you know that may be what it
would it would that's the closest
concept I think we have is something
that that feels to us like synchronicity
that that there's a a larger pattern
here that is not going to be derivable
from the um from the lowest levels that
we have
observe um another pattern that seems to
show up is a um significant decrease in
effort with a increase in Effectiveness
yeah so these happen for example in the
context of say dancing like two dancers
who are learning how to dance together
when something has happened where they
are actually dancing together they both
perceive and and report a significant
decrease in the amount of effort
necessary to dance and a transition
There's an actual process of practice
and then something like entrainment or
harmonization which is very subtle you
can't actually ever enumerate the total
set of things that are associated with
that it's an extremely complex
phenomenon but it's something one you
can get better at and two everybody goes
through it when they do it and when you
go get to that critical point something
occurs where there's actually now an
identity and that identity is larger
than the two individuals and it's doing
something that radically reduces their
perception of effort and to outside
Observers increases the quality of what
they're doing together yeah same happens
with say again like jazz band a sports
team any collaborative group actually
every collaborative group notices that
there is some kind of protocol of
relationality that produces this
experience of coming together into
something like an identity that has a
double whammy of decreasing the amount
of effort that each individual
experiences and increases the
effectiveness of the group so I think
You' see that as well yeah super
interesting I mean quantifying or or at
least characterizing effort I think is
is is really important and um how we've
been thinking about is in the in the
case of uh some of the biomedical
interventions that we uh that we try to
develop
um we have these uh let's say let's say
you know we develop uh this this thing
where you can you can um induce a
particular Biel electrical state that
then causes an atopic eye to grow you
know a whole eye or a limb or something
else um what you can what and then and
then people say well sure but but
Downstream it's just you know turning
genes on and off so ultimately that's
really what it is so why don't you just
you know sort of skip all the stuff on
top and get right down to the you know
to the molecules and and and there if
you quantify effort you see it
immediately because if I were to try to
micromanage you know 10,000 genes as a
function of time I mean maybe that could
be possible and someday maybe but but
but you spend much less effort by
communicating with the system at a
higher level to to to give signals that
say build an eye here that then
propagate down and you're not there
trying to you know uh 3D print
everything and put all the cells where
they go and all that stuff so so I that
that is I I completely agree with you
that that if you track the amount of
effort that it takes to make something
happen you can find um levels of um
optimal levels of of being that are not
equivalent you know and and and
certainly not I mean Dennis Noble you
know talks about um uh no no privileged
level of causation right so in different
systems sometimes it is the low level
the lowest level that does all the work
but usually at least in biology usually
not
that's uh that's great yeah that's um
really nice because you can actually you
can quantify and you notice the
difference
yeah and that's that's from a another
thing that we can notice in our
contempor the socioeconomic level I
think everybody literally everybody
tends to notice this anthropologically
and that is the amount of of Burden
cognitive burden on individual members
of our society is going up right so
actually more and more we can also look
at it institutionally like why are many
of our institutions breaking down one of
the reasons why they're breaking down is
the amount of effort that needs to go
through that institution has increased
continuously over the past 50 years or
so somewhere since the late 7s that
began to accelerate um and there's a
that that has again has this really
interesting math to it um there's
ultimately one of two possibilities at
the end state of that either those
systems are going to begin to break down
inelegantly I either I I either you're
not going to be able to continue to
handle that amount of increase or there
needs to be the emergence of some new
level that has this effect of radically
decreasing the amount of burden on one
level and increasing its local
Effectiveness by being able to operate
at a level that just has a completely
different relationship with
effort yeah so one one of the things
that I talked a lot with h Glenn my
physicist friend about is this idea of
the inside and the outside that
there there's a nesting that takes place
at these various levels so if you take
for example a watch the inside of a
watch is filled with all sorts of
complicated things but then the outside
of the watch is much more easily
manipulated by the owner of the watch
they just turn it on and they look at it
and they can read the time and but then
you think of that owner now is now the
inside and they're pretty complicated
until you get up to the next level and
then you have maybe societal controls or
something like that but
if I think of this in terms of um these
patterns that you're talking about let's
say for example dance the inside of
dance is learning all the rules and all
the skills and everything that it takes
to become an effective dancer and
there's a lot of effort there but once
you get to the outside where now you
have you have integrated all that effort
so now it becomes effortless for you as
a couple but let's say now that couple
is part of a larger group of dancers
that have to put their patterns together
as a group they're going to have to
learn a new set of rules that's very
complicated and difficult but then you
get to the outside of that and it's
effortless so I'm wondering if there
isn't something like that happening at
all these scales with cells and and uh
yeah yeah yeah I I I totally think there
is because uh you know I I think what
happen I mean okay um imagine imagine
that you wanted to um train train a rat
to uh do a circus trick of some sort
right uh you wanted the rat to do this
this complicated thing one way you could
do it is to try to um run it like a
puppet and so figure out every muscle
motion that it has to do and then trace
the neurons back and then those through
the brain and all the and and then
eventually you know get to what what
what stimuli you need to give it or what
you could do that that would take you
know probably the sun would burn out
before you actually you know figure out
all the all all those things or you can
just train the rat and the reason is is
that it it gives you this amazing
learning interface that abstracts all of
that it does all the hard work of taking
what you want and encoding it into the
internal micr states that make it happen
you don't need to worry about any of
that you're just you're not searching
the space of um neuronal activations
you're searching a much easier space of
behavior shaping cues and and right and
so so I think I think in biology um
there are two opposing forces one is you
want the you want that kind of
encapsulation in all the layers because
you you want the system to be easily
controllable to itself so you want to
run your own parts that way right and so
so that that abstraction um and
encapsulation and modularity you want
that the the thing I think that limits
that probably um is uh if you're too
understandable you're too easily hacked
and so if these interfaces are powerful
and easy to use and so on some parasite
cheeter exploiter whatever is going to
is going to now be hacking you all the
time and so I think those two things
kind of go go back and forth but but
overall I
definitely um think that there's a uh
you know in in in in these kinds of
systems the
complexity when they're when they're
simple they're easily managed then they
get complex and there's this like
uncanny valley when they're they're very
complicated and they're really hard to
deal with but then if you push through
that you get systems that are cognitive
systems that offer this kind of learning
communication and whatever where now
it's much easier again you know um and
and figuring out where you know can you
can you find that point and can you find
what is the what is the the the the high
level interface that I can use that
isn't the micromanagement one and I
think biology definitely does that I
think I think it makes these these uh
EAS easier interfaces specifically so
that the system can use them itself but
then you get to use it too as a you know
as an external
interactor just one throw in really
quickly I think that's the crossover
with Benjamin Lions um
looking at markets through the Austrian
economic lens is that the the uh the
keans and G braans and all those guys
they analyze the markets down to the
finest detail but the the uh Austrian
economists they analyze Human Action
it's two different entire levels it's
like you're talking about with the with
the rat um and I think that that's maybe
the thing with the UDA Loop too because
the the ud Loop the reason that we were
going slower than those uh was it
Taliban or Hamas who was it was going a
whole bunch of different groups but
let's just go because they had the
distributed cognition going just like in
the market just like with the price
mechanism in the market that just it
propagates on its own because of all the
Human Action involved and and it it
propagate so much faster than what you
can analyze it than what you can break
it down
I don't know if I'm making sense but
well what the let me say sort of restate
that last part so what was ultimately
happening was that you had a competition
between a form of collective
intelligence that was more fully
leveraging the signal propagation
dynamics of the market and a form
collective intelligence for a variety of
reasons that was ultimately gated by the
signal propagation capabilities of a
bureaucracy um and so what happened was
is there's there's things you and what H
and you can evolve or let you say okay
you can design novel capacities in
either substrate um you can think of
like for example I don't know something
like eBay or Uber are mechanisms that
are able to play with the the the market
meshwork element and then construct
something on top of that that structure
that and use that in a certain way so
they're blending these two functions
together so you know let's say our team
our team JSO was sitting with a
particular bureaucratic fundamental and
had to substantially increase the more
meshwork they liter the technique is
called network of networks so they had
to innovate a much more networked
methodology because the adversary was
already using a much more Network
methodology and it turns out that a
properly structured network has certain
capabilities in terms of velocity of of
action and actual bandwidth of of
propagation of perception that more
vertically oriented World War II style
bureaucracies just can't do it doesn't
have the same Lev concentrated Energy
Delivery they can't build nuclear
weapons or deliver them but that wasn't
the nature of that
conflict I think this is why
poetry teaches people more than long
lectures because the Poetry opens you up
to this space
where the Tumblers sort of fall into
place on their own without having to
think it get through piece by piece
so can I say back to you a different way
because I I'm interested if this unlocks
anything so the way I've long thought of
it is that uh it's because poetry is
actually more fundamental every form of
Pros is actually a form of narrow
poetry but not every form of poetry is a
form of PR so it's basically when you're
communicating in poetry what you're
doing is you're communicating a more at
a more fundamental substrate and so
you're learning the more fundamental
substrate and that carries a
substantially different quality
Pros is a subset of poetry that has very
specific capabilities it's more sort of
narrow and vertical it's quite good for
organizing cookbooks and you know
planning trips to Disneyland but that's
what it's good for and it's not as
anywhere near as good as if convening
meaning so Mike I know you have to go in
uh two or three minutes is there any way
that uh you think of the movement of
your cells as being
poetry uh sure I mean well I I'll I mean
I I know nothing about poetry but I'll
but I'll just I'll just say two things
that that come to mind one one is that
in that um in that bti paper I talked
about um different kinds of writing
scientific papers language poetry in
particular uh as the middle of that bow
tie you know this this incredibly
compressed uh thing that you you will
then have to creatively uh uncompress
and apply in your own mind to whatever
meaning it has to you and and it will be
on you to sort of pull the details out
of it that are not there in a linear way
the way that you just said you know with
a cookbook where the the the Fidelity
there really is to the specifics of the
information if you know if I say you
know this many cups of whatever like it
really has to be that versus versus in
in a you know in in a in a deeper
compression you get some sort of an
aphorism even or you know a deep truth
encoded in a really tight um kind of
message that you will then have to
unpack and you may unpack in all kinds
of you know interesting ways and and the
other thing about um poetry and art in
general is that you know if we think
about the uh the the what what schmer
called the the hard problem of
Consciousness you know why is it
different than than than all the other
science that we do um part of part of
the issue is if you think about what
should the output be if if you had a
correct Theory Of Consciousness what
what would it output because if it
outputs facts about um brain States and
and uh and uh functional activity well
that's behavior and Physiology that
isn't Consciousness so so we already
have those things so so what is it that
it should output
and one thing that it can output is
protocols for putting you in the same
conscious state or at least you know as
close as you're ever going to get to
something else and then and now you know
right so so so if that were to be
possible so one could imagine that the
output of a proper um of a good theory
of Consciousness is poetry it is Art so
that when you you know it's not a story
about your your your neurons or whatever
it's a it's it's literally a protocol
for you to experience some of that state
and and now you know now now now you've
gotten something out of that the theory
of Consciousness because now wow okay
and I think it was maybe lisis Carol or
somebody who said that you know if you
if if you want to explain um fear don't
don't write about fear just tell them
something that'll make them scared and
and that's that's the idea right is that
is that you you you're you're using a a
protocol to to transfer your state to
them you're not um going around in this
kind of like uh you know um a third
person
description that's terrific well I want
to honor your time Mike and I want to
thank both of you so much for joining me
and if you decide you want to get
together again let me know or get
together on your own I know Mike you
have your academic Channel which is I
wish you'd open up the comments on there
because it Springs so many ideas to M I
just want to write right right yeah yeah
no unfortunately I I've seen like yeah I
I don't have the wherewithal to to to to
monitor that stuff at
Alles I can't I can't I can't deal with
what's come on there yeah but I do I do
want to point everybody towards your
academic Channel because the stuff
that's going on there is just amazing
and thank you so much um on the actually
on the blog the the comments are open on
the blog and and and weirdly enough that
um it's thought forms. lifee and and th
those comments have actually have been
very um high level there's actually I've
gotten tons of use just personally
selfishly I've gotten tons of use out of
it because people people put up all like
really good ideas and and thoughts and
so on so that's actually that actually
worked well oh put all that in the
description section and thank you guys
thank you so much talk to you soon yeah
I'm sorry I'm sorry I have to run Jordan
it was awesome to meet you thank you so
much thanks Karen by bye talk soon bye
