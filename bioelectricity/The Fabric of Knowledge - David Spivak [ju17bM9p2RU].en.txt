we're talking about like probably the
most pressing one of the more pressing
things on the planet which is like how
do we uh what is intelligence how do we
come to common sense of things how do we
like navigate our world and I think
creativity seems to come from this
privilege of having like a space in here
that you don't get you will never get in
here unless you're really really bad um
uh and so like creating space seems to
be like vience or whatever seems to be
where there's still room the brave
search API brings affordable developer
access to an independent index of over
20 billion web pages powered by real
anonymized human page visits to filter
out data and refreshed daily with tens
of millions of new pages we'll get
started with 2,000 free queries monthly
at brave.com SL API David it's an honor
to have you on the show oh thanks for
having me David you're you're um
incredibly L for category Theory what is
category Theory what is category Theory
category theory was invented in the' 40s
it's 1940s it's about um basically they
wanted mathematicians were talking about
natural this and natural that but they
didn't know what natural meant and so in
order to Define this notion of natural
that everyone was using they they kind
of invented categories functors and
natural Transformations so but what is
it about it's about like uh systems of
relationships so you You' got like a
bunch of things so let's say you have a
category of things and what do I mean by
that you these things belong together
like fish or whatever or like things you
can eat or like things that are alive
right but it's not just that there's a
bunch of them but there's when you have
a bunch of fish like they relate to each
other and so a category for a
mathematician is not just a bunch of
things but also how they relate yeah
yeah so so you mentioned Funk doors and
and you know things are two categories
yeah tell us about that yeah so if you
have a whole world of things that relate
to each other let's say numbers and
number one number can be less than
another number and you have another
system of things that relate to each
other like um uh sets of things like all
the trees we can see or whatever and
that one thing can be a subset of
another like the big trees as a subset
of all the trees the set of big trees
then there is a functor relating these
two world Worlds the world of trees and
which and sorry of sets and subsets and
the world of numbers and the funter is
called count so you take your set you
count how many things are in there you
get a number and when one thing is a
subset of another then the smaller one
has fewer things like it's kind of
obvious and what category Theory likes
to do is make what's obvious like a
mathematical artifact so you don't have
to hold it what all what people other in
other mathematical Fields do is they
like hold all the really hard things in
their head and then
and they think you're kind of dumb to be
doing like making really hard things
obvious I'm not sure they would really
say they'd agree with this but this is
like my stereotype and and in category
Theory what we try to do is take all the
things that are most obvious and make
sure those are really said well and so
funter is this very simple story of like
I have one world I have another world
and I have a mapping that takes all my
objects here Maps them to objects here
takes all my relationships here and Maps
them to relationships here that's what
it funes what's the relationship between
all of this and you know abstraction and
complexity yeah so abstraction is would
you say it's kind of like being able to
take some concrete situation and extract
something that's repeatable in many
contexts so in math like you know you
have lots of different threes this this
thing has three but this thing also has
three and and so you want to like
extract and say three is just a thing
I'm going to want to talk about from now
on or whatever so you extract it but one
thing that you do with abstraction is
then you can use that abstraction to
come back so someone says like what's
your situation you tell them I I have
too many weeds in my garden that's just
an abstraction now and then they say
well try using a a travel or something
now you take like you bring that
abstract idea back to reality and pick
up an actual travel that was like over
here and not over here like this one and
so like abstractions about pulling back
out to something where more people
understand what to do do or it's easier
to like get your head around what to do
and then coming back and like using that
to to make a difference so so what's the
difference between abstraction and
knowledge abstraction and
knowledge I don't really know what
knowledge is usually it feels a little
bit Frozen as like a collection of like
when I hear knowledge it's like I have
these fro it feels Frozen to me in a
certain way abstraction feels like a a
process and knowledge feels like a an
item but maybe I'm missing what you mean
oh that's fascinating well I I think of
intelligence as being um reasoning
efficiency which is kind of like
abstraction efficiency so so it's it's
model building it's saying um I'm trying
to make sense of the world and and I'm
coming up with this model and then and
then I can share that model with other
people yeah yeah so sense making is
something I I think a lot about and I
think about it in terms of collectives I
think you mentioned Mike Levan before we
started um and he says like all
intelligence is collective intelligence
yes I think all sense making is
collective sense making um so our
whether it's just you and me making
sense of like hey what's category Theory
you have to do with ML or whether it's
like all the neurons in my brain trying
to make sense of something I think
there's something where we give an
account I like tell you something in a
language that you understand not in my
own private language but in a kind of
public language and by doing that or my
neurons are doing that they're like
speaking in this kind of in a way that
like their neighboring neurons probably
have some IDE a what's being said and by
doing that they can kind of start to
account for the the what's what's there
and what's not so like you're saying you
know I have some new situation I want to
build a model of it everyone's like oh
that's a bear you know that's a that's a
tiger whatever like okay it's definitely
an animal I don't know so you start to
put together like all these different
senses of what's going on like
individual senses but there's something
left out and there's like no but why is
it why is it switching the necer cube
why is it switching or whatever yeah and
and so like like this sense making thing
is when you're like ah I see this is
actually I can see it either way or I or
this is what it is and you get a sense
that starts to stabilize and you do that
because your accounting settles like if
I don't know if you're old enough to
know what a checkbook is what I am and
like we would like you'd do this thing
where you're like ah it's settled I got
a zero I the amount I put in was equal
to the amount that is in there now and
the difference is zero and there's
something about that where like now you
can proceed way more
like your it makes way more sense as you
go so so yeah I feel like there's
something about like account settling
that makes sense there are some beliefs
I have let's say we we're playing The
Language game now and we're we're
converging on some understanding and
that might be a private understanding
between us the alternative might be that
we're converging on universal truths
about how the world works there's an
analytical pathway from the physical
world and the knowledge we discover
whereas another way of looking at it is
is that we're just discovering all of
this complex knowledge and it's
compounding and becoming more and more
complex as time goes on and it's not
really grounded by the physical world
that we live in right right I mean I
think if we were doing things that were
completely
ungrounded no one would be it wouldn't
work very well right like so I I um like
if you in order to do something that's
mimetically fit where in in the sense
that it spreads and like makes a
difference it has to be something where
it's interesting and like relevant to
people otherwise they don't have time
for it right and so um I think things
can sit for long periods of time where
like no one knew about it and it was
kind of like sitting there but you those
are like kind of miraculous like wow we
found this like secret writings of the
you know but usually the more common
case for sure is that like people
understand the value of something within
some amount of time and like so I think
um as we're building all this stuff up
if we're not continually compressing it
and finding something not just
compressed like a zip file but
compressed in a way that's flexible with
like as a model that like compress we
they take the the submarine and we
compress it to something that the the
captain can like steer so that so that
the captain's like innate ability to
think of being a p being a self and like
avoiding danger can become like the car
or become the submarine like um as we
compress in ways that like fit
fit with a thing we're trying to do then
those are the valuable ones that like
people want to share so I think like
we're not just talking about like that
building's architecture you and me right
now we're talking about like probably
the most pressing one of the more
pressing things on the planet which is
like how do we uh what is intelligence
how do we come to common sense of things
how do we like navigate our world
and I think the fact that we're doing
something so universally universally
applicable
um is because that's what you think will
get an audience right and that's what
you think people want to hear and so I
think that's not a coincidence it's like
we're we're only doing things that
matter or we're probably not like really
getting to do them very well I wonder
what the role of physicality is here
because as physically embodied agents
our knowledge acquisition efficiency is
higher there are many just physical
Concepts in the real world that that
contribute to abstractions that that we
use embodiment is important yeah and if
we built an a AI system let's say an 11
style Collective um intelligence how
hard would it be to build that virtually
versus having real physical agents in
the real world yeah I mean I think I I I
heard I don't know it it seems to no
longer be true because they they are
doing image recognition with with um
with uh AI but at some point I'd heard
this story about like uh they gave blind
people a camera they the camera created
little pin Pricks on the tongue or on
the back
um and if the camera was positioned and
just like aiming at something the people
would never learn what it was or if it
just like rotated around the room but if
it was on their head so that when when
they turned it would um like the camera
would turn with their head then they
would be able to like actually start to
see and so the idea which so like AI can
do this because it just has a trillion
of something or whatever but like this
was when you you're a human brain um was
that like by being embodied by actually
caring about where they're looking and
like by deciding that and having the
motor as part of the perception Loop uh
they learned in a way they just couldn't
otherwise and so I feel like being an
embodied agent another thing we have
that like agents out there don't have is
risk um we if we didn't have anything
that was at risk if this podcast could
not possibly go bad or whatever or good
then then we wouldn't be able to like
create I think like there's something
about the risk and the care uh that we
put in like those things seem to be very
tightly coupled that like um create
somehow I've spoken with kle friston
quite a lot you know the active
inference guy and he talks about these
um like it calls it a cybernetic
framework where you have a perception
action Loop and there's this feedback
loop and and the agents in in virtue of
just trying to stay alive they're
they're interacting with the world so
they're kind of modifying their
perception ual field trying to reduce
prediction errors and and this gives
rise to some very sophisticated Behavior
where the agents need to learn about the
world they need to understand the word
yeah yeah yeah I really like that I
really like the idea that like um part
so let's say you're trying to prove
things about the world you're trying to
understand the world one assumption
you're allowed to use is that you exist
like when when in in in in math like you
have a theorem right and like what what
is your assumptions for the theorem well
like the more assumptions you have the
more theorems you can prove if you say
like let's assume you know that our
numbers are between 1 and 10 then you
have like tons of theorems like about
those numbers because like 4 plus 6 is
10 and 3 plus two is five whatever you
can make all sorts of theorems but if
you say I just have some numbers what do
I get to prove you prove less things I
don't know if that made sense but the
point is one great assumption is that I
exist therefore something like me could
exist so that's kind of a huge
assumption you can add for free because
kind of like diart yeah right so um
and so what I heard from him was like
like I can kind of assume that since I
exist that gravity must be such that
these knees make sense and this these
lungs make sense and that what I want
usually if I really need it will happen
because if it didn't happen I'd be dead
already right and so like you he he kind
of uses that to to bridge as I
understand it to bridge utility like
what I want with what I predict I
predict I can eat that food and and and
then and then this idea of like the the
prediction error being the control
signal to like I predict I will have
that thing and then if not then I just
take the diff difference and like do
that with my motor thing so um I find
that to be a really compelling idea as
like it's very simple and like and gets
a lot done yes it's it's really
interesting because in philosophy you
know like we talk about um value and and
metaphysics and epistemology and so on
and this this idea of the of
intelligence is beautiful and and agency
which is that it it's it's just about
this big dynamical system where it can
be modeled as if parts of it are
minimizing prediction errors but then
what emerges out of that is value you
know so what is moral and knowledge what
do we what do we know and what kind of
relationship do you think there is
between something that just minimizes
its prediction errors and something that
acts in a moral way or that knows how
the world works yeah I don't know I
don't I don't
fully buy it which doesn't mean that
I've understood it and and thumbs down
it I just haven't understood it well
enough to to fully buy it um that like
predic minimizing prediction error is
enough to get um what I care about going
like um like there's there's a there's a
little kid and he's in a sand box and
he's like shoveling sand right for and
your and the mom comes and like we need
to go to the store now and like takes
the and he starts crying yeah like he
cared about something with that sand he
was doing something and like
I can't I don't know maybe there's a
great way to like back that out get that
from like prediction error reduction or
whatever there there very well might be
but like I don't I think there's
something important about care and
understanding like what is it what is
lost when that kid like gets pulled away
that like I don't know if I can like get
everything I need from from prediction
error reduction yeah this is so
interesting because the way KL friston
manages this is he talks about balancing
energy and entropy or you know exploit
and exploration but many other people
talk about it in terms of open-endedness
and creativity and Serendipity and
interestingness and of course in in a
collective intelligence you have many
specialized agents following their own
thing not NE because they're a gental
they're not necessarily being pressured
by other agents in the system but that
means the system as a whole discovers
interesting new knowledge yeah yeah yeah
yeah I mean it's possible that like so
one qu one claim could be that this
minim prediction eror minim ation
scheme solves the entire universe and we
just have to run it super hard and like
all philosophical questions like
dissolve like everything um I don't know
if that's the claim but like I I wonder
like what is the question that it leaves
open for me the the thing that usually
is the most um productive is or most
cool is like having a
question and
um and like what's the question for at
that point what's the question and what
is the
question yeah what is the question the
question what is the question why is
questioning so productive like why why
did dayart like spend that time like
okay so wait what's the question I don't
know I don't know if he said that he's
like what you know how how do I know I
exist I don't even remember what he was
like he just doubted he doubted
everything right he just put everything
into question but like when when when we
question when we ask like what am I for
example that's a great question like
what am I you you I don't know if it's
like a prediction error reduction thing
exactly it's the sort of thing that
leads someone to a brilliant idea like
prediction error reduction or like
predictive processing but just asking
what I am is like itself
somehow open an openness yeah yeah I
wonder whether this is related to the
difference between ontology and an
epistemology because that they is just
what is there there's this physical
world that we live in and the way we
describe it is just using models right
we we're just modeling and the question
seems to determine the model that we use
and and it seems like you can ask a
myriad of different questions yeah yeah
but um exactly so like which question we
ask determines that and but these
questions seem to come from or arise in
us and sometimes they arise in like a in
a quiet space if we like meditate or
like make room to think right yes so um
there's something about spaciousness
also like that that yeah like that that
really matter like questioning open
questioning is is a spaciousness that
that like one I I think it's really an
important thing that in in ml and like
Ai and stuff like that we it feels
recently I've had this image of just
like when I was a little kid playing
soccer I just wanted to kick the ball
really hard and I didn't care like about
passing it to someone it was just
kicking it cuz like that's what I knew
how to do yes and like I I want to make
sure that we are like aiming towards um
towards something of value and instead
of saying like and I know what value is
to me the thing that I love about life
is that I get to like have some openness
and have some question of my own and so
I I feel like I want to maintain that
there's an openness of like what we
don't know uh yes and whatever it is
that we create as opposed to like let's
just solve it all and like now it'll
finally be locked into place you know
but I guess this comes back to the
question about subjectivity the way you
framed it is much nicer which is that
there are potentially an infinite um
number of questions we could ask and all
of those give rise to this epistemic
framework and we can build on that
framework and build on it and it just
unravels into this sea of complexity and
maintaining that openness to discover
new questions I think is is really
important but the reason it's subjective
is there's no criteria for weighing one
over the other yeah well no there but
there might be so I remember I was at
some design Theory conference and the
guy said some someone came up and he his
presentation was like what do we owe the
future we owe them a future in other
words an openness like if we close it
for them then we didn't give them
anything so like one thing you could ask
to kind of keep open or like to yeah
like what do we offer what do we want to
offer I feel like what we one thing we
might offer is like openness of like a
non finish
to to the scheme we come up with right
it is it related to this idea that you
know children become less creative as
they grow up and there's a creativity
test and kids do very well on it and and
a lot of that is because after lots of
successive sense making we crystallize
all of these models and the way we
understand the world our our space of
cognition is the traversal of these
crystallized models and and that cone
you can Traverse in a cone and all of
the stuff outside of the cone is no
longer traversable so so it's almost
like we're we're locking in the space of
of ideas yeah yeah and so if our if our
AI is going to lock in how we're going
to see the world or it's going to lock
in how the world is going to work
then that seems no good to me and like
this thing where you're saying like okay
now I understand what it's like to be
human now I want to try being a tadpool
like instead of like oh that's worse how
about no it's brand new like you
actually get to start over as a tadpool
that's wonderful like like keeping open
you know whole new Realms of of being or
something like that is seems like the a
a positive thing to to aim for instead
of just kicking the ball really hard
yeah say like no but if I kick the ball
here will it keep an openness yes but
where is the Wellspring of
creativity you know where does it come
from yeah I mean it seems like so
spaciousness so like my phone has things
for me to do on it my computer has
things for me to do on it there's all
sorts of things that want my attention
and that want to have access to my
what's it called Mind share right yes
um and it's something I have to do for
myself to like keep a barrier and that's
what my Skin's job is and that's my
brain like like a lot of things it's
like a house's job is to keep a barrier
from like if you're outside in the
street you're you're
you're right next to all of the sounds
and all of the everything right so like
I think creativity seems to come from
this privilege of having like a space in
here that you don't get you will never
get in here unless you're really really
bad um uh and so like creating space
seems to
be like silence or whatever seems to be
where there's still room yes and did I
get it did I inue it from what you said
that things like language models and
current AI not only that technology in
general it extends our mind in quite a
pentious way and in a way it constrains
our our thinking is is that something
you worry about um a little bit yeah I
mean it's
really yeah I've heard that if you have
a book idea you shouldn't tell anyone
about it because a lot of what makes you
want to write the book is like getting
to say the thing and if you tell a lot
of people your story and like explain it
all then you won't really care anymore
and sometimes I feel like when I'm
talking to AI I'm like kind of getting
my ideas out there and like then they
kind of like H it's okay I don't really
need to tell anybody else yeah um so I
guess I worry about that they they're
kind of like they have my attention and
they don't I don't give myself space as
much yeah um there's like an averaging
thing that a AI like llms are kind of
the average of all human thought in some
sense and so there's something kind of
bland about them in that way yeah yeah
it's interesting what you said about
holding on to your idea I think
there's a consensus mechanism in the way
we organize companies and run
governments and and so on and that
Waters down ideas yeah exactly yeah if
you look at yeah you find there are
people who make a difference and usually
because they do a really weird thing for
no reason like Greta thunberg just
sitting there I don't know how much of a
difference she's made in the end or how
much she will make but one think she did
was she just like sat there like I'm not
going to school on Fridays or whatever
um but like not just you know any any
you know some of our worst villains in
history like just did a freaking weird
thing um but also creative so I I think
uh there's something about just being a
like I'm going to do this thing every
day because I want to do it and I don't
I don't have to explain why I'm using
like my
investment like whatever I have to to do
that thing and how would you model this
mathematically obviously with your with
your background what is what is the
calculus for a good creative IDE
did I don't know
um I think so every idea that actually
works has to work like that's another
theory so like it has to like uh I like
the word conception like the in in a
biological conception is like the
smallest thing that then can live in
that very very protected environment can
live right um and then if you have an
idea right you have conception like ah
but can that idea live do your does your
mind care about it enough or is it like
oh well that was cool you know and but
if it can live there it's like if it
says like don't forget to write me
down if the idea was something that
didn't say don't forget to write me down
it doesn't get doesn't find blood supply
or whatever yeah so then like so a
really good idea I think I'm really
interested in self-fulfilling prophecies
um um if I say like you know you will
you will do this thing and then you
actually do it like that's kind of like
like um I will be there tomorrow at 5: I
I actually by saying that it does self-
fulfill I wasn't going to be there at 5
but then by saying I was going to be
there at five I will be there at five
and like there's something about like
what makes a prophecy a prediction
self-fulfilling so that yeah well it's
got to be compelling to the environment
that it lives in like that concept
conceived idea in my mind had to be
compelling to my my brain real estate so
like if you create the transistor or
whatever you invent this new thing it
has to be compelling to you know your
friend who's like yeah I'll drive you to
the Venture Capital whatever I don't
know whatever um enough that you get the
the little protected thing gets driven
to somewhere where it can like expand
and grow and yeah yeah I mean it's
related to persuasion like for example
you could say I want to lose weight I
want to go to the gym I'm going to take
positive actions in my life and if you
mimetically share that idea that also
creates social pressure and it becomes a
self-filling prophecy but but we're just
thinking in terms of of just psychology
in humans I could invent gpus gpus
created this Basin of Attraction which
led to all of these successive things
like did the Deep learning Revolution
and and so on so there's just this
Inception of the right idea just creates
this massive Chain Reaction yeah yeah
you have to really understand the
reality and what it wants to create
right like like with conception like the
womb or whatever wants to hold a baby in
it like that's what it was kind of made
for right uh a uterus or something but
like like if if I'm if I'm Edison right
he had to understand the social context
of the light bulb to make a light like
he made a light bulb but then no one
wanted to light bulb so we had was it
him who went around with like light
bulbs on his head and stuff like that
he's like it's like you have to
understand what'll make people or
Virginia slim cigarettes the guy who
invented um the guy like Freud's nephew
who like created PR or whatever he's
like okay uh women don't want to smoke
because that's bad but they think that's
ugly or whatever but we'll I understand
the social context I'll do this thing so
like I'm not saying only good ideas
spread I think like bad ideas spread too
and I think it's really important that
we at this point in our lives like have
motivation where we don't just kick the
ball as hard as we can but like try to
aim to a good future but that said like
I think um understanding what wants to
be created like what good world like
imagine the world has good in it like
hopefully you already feel that way then
does that world need anything that I can
do and if you can find some thing that's
not too hard like you can do it we have
these little rocket boosters like we're
in a we have just a a little bit of fuel
but like with my little bit of fuel can
I like create something of of value for
a world that I like that's the sort of
conception that can grow it's so strange
because I mean Steve Jobs always said
the last thing you should do is give the
users what they want and this whole
thing seems to defy mathematical
modeling because you were just saying
before about this chain reaction and
wouldn't it be interesting if you could
predict the thing that created this
Chain Reaction this disruption but
open-ended systems seem to have I mean
there was a deep mine paper which I
interviewed the guys at icml and they
said an open-ended system um is is a
system that produces a sequence of
artifacts that are um learnable and
novel and that was their way of of of
modeling it yeah but so there has to be
some kind of Divergence but YouTube
started as a video dating website they
had no idea that it would end up the way
it is I'm not sure it's it was would
have been possible to predict it
exaptation type thing have you heard of
that word oh no what's that um it's
basically that like you create something
for one purpose but it's actually very
well adapted and it's kind of like
pre-adapted to the thing that does
something else yeah um yeah but I'm not
I don't think I'm doing it justice but
yeah that's that's very
interesting yeah very cool and um eating
eating oh God it's a tough one yeah yeah
and in in my mathematical modeling I
find eating to be surprisingly hard the
fact that like we're we're hiring so a
lot of
times we imagine that we are an agent
and then there's the environment we're
interacting with it but like when you
eat you this this food actually becomes
part of you yeah and starts to be a
machine that does stuff like it amino
acids turn into proteins that actually
do everything in your body um or oxygen
like like we think like in some sense
oxygen is something we need just as much
as we need ourselves it's just that it's
so replaceable in our environment that
we pretend that it's not us but in fact
it's part of me to have oxygen around me
if I didn't have oxygen all around I
wouldn't me I'd be shriveled up yes
right so like
um uh I find the idea of like consuming
a machine to
be somehow very difficult to understand
I mean what's interesting about this is
that I think of particles of potato as
being aert in the same way that viruses
are are inert but you can still think of
them as a super organism and they they
supervene on us we die viruses die
language is is also an organism which
supervenes on us so um if we die
language dies but then it becomes a
modeling thing because bits of potato
surely you can't think of them as an
agent or could you yeah yeah how far
down does agency go and what is agency
is
agency the thing that cares about
something or the thing that just acts
out something that like a travel agent
uh somehow just does whatever you want
them to do they're willing to go do the
hard work or whatever um so I don't know
know exactly what people mean by agent
when they talk about like software
agents or AI agents they seem to be
talking about something where you give
it a goal and then it goes and tries to
get that goal accomplished for you but
like our agencies were are I think you
used the word intentionality earlier
yeah so so I would call that a strong
agent so so the basic agent is in some
sense the the the causality comes from
inside the thing is we we if you speak
with a physicist they would be quite
horrified about this because they they
they just say well no there's a light
cone particle interactions and that's
the only causality that matters but you
speak to a philosopher and they say no
there's a useful way of partitioning the
world up into into groups of things and
we should call those things agents yeah
yeah I mean so useful I i' I've been on
this uh word care so care you know what
do you care about so there's there are
some s there are some care words like
important is a care word uh value is a
care word um good like like but another
one is useful people say all models are
wrong but some are useful like what do
you mean useful useful for what it's you
have to have care and so um in my talk
tomorrow in fact I'm I'm thinking of
like power in electricity which is like
voltage times current I'm thinking of
intelligence as the current it's like
kicking the ball hard but care is like
the voltage it's the potential that you
might be able to actualize like this
difference like I could like I could
actually help that child grow up into
someone great or something and when you
see some potential you want to actualize
that's care you care you care about
something and um I think this
intentionality and Care is somehow a
missed part of the intelligence question
everyone's working on the current and
not the voltage um the why the why seems
to pass through like I don't know what
causes care to come and go I find that
to be like one of the most
interesting questions like
intentionality some people will say like
oh I just got imbued with some
intentionality and I like strawberries
more than grapes or whatever m but I
think this idea of like care like even
if you do want to say everything's
reductive it's all just dopamine and
serotonin and blah blah blah something
puts dopamine online in a body in a
physical Universe like something spent
the time to like get a system as good as
dopamine going or like uh DNA has you
know how I don't know I yeah it has
these Fork Fork um I mean four nucle
nucleotide bases and then three of them
form a codon so that's four to the power
three possibilities but they code for 20
amino acids so there's a mapping from
like 60 to 20 that's 20 of the 60
possibilities and apparently the one
that our DNA uses is information
theoretically optimal for like error
reduction or
detrimental so what that means to me is
that either God did that or that there
was a search process before genetics
even got online to like get this thing
working right that all of our ancestors
like got this really come so like these
intention the intention to get that
right comes before like that's a
language thing too like the L the
intention to get language working goes
all the way down to
DNA that there's a there's an
interesting tension between Serendipity
and um kind of um this puritanical idea
that that we found the right solution
because I read Richard Dawkins book
selfish Gene and he he gave some
examples of the way the brain evolved
all sorts of stupid things happen like
there are these big um nerves that
connect dist parts of the brain together
and that just shouldn't have happened
but because we evolved from monkeys and
the way it is in their brain that that's
just the way the way it happened but
then the question is do do you think
that the way the way things are in the
world as they've evolved is it just is
it just quite random and we've just
happened on quite a good solution or
could there be a much more optimal
solution I H I think it's like so it's
um you wanted to get this interview done
and you found this location and it has
airplane noise and blah blah blah like
but you want get the thing done but you
found you what it's called satisficing
the um hert Simon thing so like uh yeah
it it it did this you made this shape
somehow when you're talking about what
the brain did um it took some path but
it got the thing accomplished and so and
the thing it got accomplished it found a
way or like you know it found some path
to that and that the thing that it got
accomplished I don't think was random
like having eyesight at all or having
hearing or having those integrated or
whatever it is the thing that you're
talking about which could be some random
thing but that thing was important
enough that it like found this really
long path to get it done I don't think
that it's like I think um what I think
is is that there are some I don't know
what the answer is of what is actually
being searched for by This Global thing
I or if there's a just one thing that it
is but like there are some there are
some like monotonically increasing
values since the beginning of life on
Earth that like for example um High what
I call High Precision energy routing so
in the beginning maybe there was just
like tides and like water just flew
wherever it did and now and then like
rabbits or whatever like could like move
their muscle and like direct the energy
to like find the food and then the food
would like route itself to the cells and
now we like have you know billions of
voltages that are high Precision routed
through computers like so I think if you
look over time maybe high prec like the
Precision energy routing goes up and
just keeps going up m or like Carl Sean
said the universe knows itself like
through us we are the cosmos knowing
itself I think that amount of whatever
it is that Cosmos knowing itself has
been monotonically increasing so I'm not
trying to say it's like
philosophically you know or entropy
production yeah like long-term entropy
like I'm not saying is the there's some
things that seem to
be trying to be made like the universe
knowing itself if you like kind of more
woo point of you or high Precision
energy routing if you're like no I need
material like something even that I
don't know what high Precision energy
routing means but you get a feeling for
it when you think of voltages or
whatever yeah what's interesting of your
approach is with we tend to use quite
anthropomorphic language you know we
talk about this this phenomenal sense of
of um what's moral and what do we feel
is is right but but evolution itself
almost has a sense of of wants and
values and through this incredible
Orchestra of of activity it has you
canalized modularized abstracted created
this this pathway and and you're kind of
arguing that it it's it's leading
somewhere oh yeah yeah so I you were
mentioning Mike Levan so Mike I I really
like his work I also like um someone
named Eric Smith who was at the Santa Fe
Institute have you heard of him yeah
yeah I think so yeah yeah so so he he
has a vid he has some videos that I
thought were incredible that explained
like uh a hurricane for example there's
a potential there's there's a potential
difference there's a temperature
difference there is the hot uh ocean and
there's a cold atmosphere and there's
this laminer like layered air and it's
like oh man I can't like I could get so
much if I could only equalize these well
a hurricane like somehow starts locally
but creates this eye and that eye is
just a tube that a Vortex it just sucks
the hot air right up there and equalizes
it yeah um so he's like nature creates
pretty complex things um ra Bayard conve
convection I if you heard of that but
like it can create pretty complex things
and he says at early life he thinks it
Happ he's a metabolism first instead of
RNA world he thinks I think that's crazy
I think he thinks that's crazy too um uh
he calls that control first metabolism
first is that life started in maybe deep
sea vents where like some uh CO2 and H2O
or something was coming out of these
Vents and like life was or maybe it was
meth I forget now life was the simplest
smallest little chemistry lab that could
get from this high energy state to a
lower energy state M and like all we've
been doing is like oh there's some oil
over there like let's like get it you
know like the ants are like oh there's a
picnic over there let's get it and so
like this ability to coordinate action
to like actualize
potential is is something we
develop do you do you think we're
different in any way that we might build
Ai and we we might build very very
intelligent Ai and we might skip quite
far ahead in this process of of
evolution do you think there's something
significant about that yeah sometimes
sometimes I think it's like as big as
multicellularity like it's a big big
deal um sometimes I think it's even
bigger deal like it's like at the level
of like life creating from physics which
I don't think I mean how big a leap was
that from physics to life was it
infinite I don't think it was it was
finite so like this is also finite
sometimes I think it's printing press
level but usually I'm more more than
printing press like I think this is more
like
sociality itself like one of the big
like I don't know what are the big ones
so life
multicellularity um you carry it versus
Pro so you carry it what it ate the
procar right it like ate the it merged
with the mitochondria yeah that's a
pretty cool trick um so I I think it I
don't know how big a deal this is but it
feels to me like our maap what's
happening to me from my point of view is
written language we were able to
solidify like what makes energy turn
into matter it gets solid right sense it
seems like spoken language is just
action we're just like moving around our
bodies and one part of our body is a
voice box that vibrates fast but when
you write it it becomes solid in a
certain sense and can be passed around
as a solid and that happened what four I
don't know how many thousands of years
ago yeah we got written language I think
that was like then we're like the
printing press but printing press is
just written language but faster and I
think AI is also just written is just
language written language as a thing
like last time that happened was DNA DNA
is a written language it's acgt and it
makes all the it's the building blocks
of every protein in your body everything
in your body right it's the it's the
code for it doesn't mean it does
everything like the cell does stuff too
but so the environment does stuff too
but written language is a big deal and
it feels like the second time that's
happened yeah it's interesting because
it's a phase change so so DNA was was a
form of memetic information sharing
language was a form of memetic
information sharing which started about
you know let's say 100 thousand years
ago and it just created this dramatic
kind of Social complexification and it
and it triggered our brains to grow very
large I mean if if if you're a fan of
the the the social theory of of language
man I certainly am but but but you think
AI could be the same again yeah and I I
I think I'm differentiating written
language I'm not sure how important that
is maybe it's not that important but
like something about written language
turns it from just an
action into a frozen artifact that can
be manipulated like a tool or something
it's
something like a termite can work with
rocks but it can't work with language I
don't know if it can I don't know if it
can but like I don't think it
manipulates the pheromones or whatever
that it's using to like decide where to
deposit the Rocks as an object but when
you make written language you get an
object I feel like something's different
about that but I'm not sure yeah I is it
like the um the memory and the
plasticity so now knowledge can survive
many generations so we're building on
the shoulders of giants but the thing is
like DNA
it's really slow yeah whereas whereas
language I mean you can acquire new
knowledge right now yeah it's kind of
like eating again when you when you hear
something I'm saying or I hear something
you're saying I can eat that and like be
that starts to not just be a fact in a
knowledge base which is why I don't
really love the word knowledge it's like
an it becomes like a machine that can
can act on new information and transform
it yeah yeah and so like when like what
do how does language like plus what does
plus mean it means you have two groups
of cows and a fence between them and you
remove the fence that's plus right but
like that's how plus works it works like
removing a fence whereas times works by
making a grid you have like this by this
and you like have two options instead of
like these two options um the rules of
plus and times just
follow those activities of like making a
grid or like removing a fence and now
everything I do with those plus and
times very very quickly
is like doing all these crazy you know
manipulations of of fences or whatever
um I think language like lets us
experiment really quickly like that
didn't sound right the way you said that
didn't sound right I don't know what it
was but it didn't sound right it's
actually telling us about like a
simulation that we could run and see a a
problem with that um it's weird as well
because when you look at the the
philogyny of culture and language it's
very Divergent it's gnarly um I mean as
a mathematician might horrify you just
how many inconsistencies there are like
how do you J toose that in your mind
between we want to think that there is
like a a code of the universe there's
some abstract structure that generalizes
in all possible situations but things
like language it it doesn't seem to work
that way well when when someone's
speaking
uh and they're making all sorts of
inconsist like if I I think about myself
during this interview I'm like I'm sure
I'm like weaving all over the place I
hope it makes any sense at all but like
you start to get a Vibe right like like
I don't know what you just said but I
think you were being mean or I think you
were not you yeah I was pointing over
there um like that's a a feeling that
you can get and then you're like
listening and then you hear it again or
you know like you T you taste that taste
again right and so like you don't have
to I think language is more like an
attractor it's like um eal MC s is an
attractor for people who want to say
physics fast right like I wanted to say
physics fast so I said equals MC like it
it it brings you in and then lets you be
there for a while and just point at
something and so I think like language
even this natural language you're
talking about where it's like Woolly and
wild and no one knows what it really
means it's still attracting our
attention and we can watch where the
person is moving our attention and we
can feel them like proving that they're
smarter than us or we can Pro check that
we can see we can feel them like saying
they're offering something to us or
whatever whatever they're doing we can
start get a we can start to be attracted
into that Basin of our like
understanding of what this interaction
is supposed to be yes yes David SPAC has
been an honor to have you on Folks at
home should check out your your MIT
category theory was exist it's on the
topos Institute Channel Institute
channel has it all now yeah it's really
really good so Folks at home um please
check that out and and David has been an
honor thank you so much it's been great
thanks a lot awesome awesome well
