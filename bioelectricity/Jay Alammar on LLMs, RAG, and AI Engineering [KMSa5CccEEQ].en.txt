a lot of the most exciting things that
AI is able to do even more recently are
not generative in nature these are
things like semantic search and and
reranking and these are let's say a lot
of the more stable highly reliable use
cases that you know businesses and
Enterprises can do so I'm I'm interested
in that side I learn in public um I'm
here so this is I'm coming into my third
year um where I get to see how people
sort of build worldclass light language
models I get to build with them and then
teach the developer community and
Enterprise customers how to problem
solve with language models what the use
cases are Jay Alamar renowned for his
talent in visualizing complex AI
Concepts yes he was the guy who wrote
the famous Illustrated transform article
back in the day he now brings his
expertise to the Forefront of AI
development at cooh here I first got
into Transformers cuz I read Jar's blog
and now I to work with him he knows who
I am that is so cool in this episode
you'll discover why retrieval augmented
generation could be the key to more
reliable context aware AI real world
examples of how businesses are using
this technology to gain a Competitive
Edge and the ethical implications of
these advancements and how the industry
is addressing them Jay now advises
Enterprises and the developer community
on practical applications of large
language models will dig into how this
transition from an educator to Industry
inside it at coh here has broadened his
perspectives on AI Jay walks us through
cooh here's Mission and at the end of
the show he tells us about his exciting
new book on natural language processing
enjoy the
show so what really excites me about Co
here is you're the only llm company that
that's actually helping people with the
last mile true it's a bunch of it's a
bunch of different things so language
models have been this incredible I say
dramatic
advancement in the ability of software
to do things that software was just
basically not able to do 5 years ago um
and then very quickly that people
started wanted to wanting to use uh
language models for factual generation
for example asking questions which is
why a lot of this focus on on rag is one
of the main things uh at at at coh here
for on retrieval augmented generation
retrieval augmented generation is the
most useful uh application of language
models today and one that most sought
after I would say so it is the idea of
augmenting a language model with some
more information so it can answer
questions uh more truthfully and have
let's say access to a data source that
can supply it with relevant information
so the model and its Generations can be
more factual and more truthful and let's
say grounded into uh a specific data set
that is that is relevant for you and so
that's the case where the model instead
of answering right away it does a search
step in the beginning uh that system
does a search step in the beginning that
gets some context and then the question
is is presented that's the simplest form
of it but we have a road map that takes
this to the next level and the next
level on the let's say technical side
that includes investing in retrieval so
the search that comes before uh the the
generation uh so that extends to
embedding models ranking models rankers
are the fastest way to inject the
intelligence of a language model into an
existing search system they work in a
very simple way it's one API call after
an existing search system it just takes
let's say the top 100 results that that
search system produced it just changes
the order it says hm this result number
30 is actually the most relevant to this
uh query and so I'm going to put it at
number one and that vastly improves
every existing search system by just
having that one API one API call at the
end and then the generation models that
are also sort of tuned for citations for
uh uh paying attention to what you give
it in the context and answering
questions from from that context and
because these models are let's say
General problem solving tools people
need additional tools to build on top of
them and so we've you know we support
them with notebooks code examples but
most recently one of the most recent
things we've we've deployed is the
cohere toolkit which is basically the
playground that we've been building and
polishing for the last two years but
it's highly optimized for Tool use for
multi-step rag or multi-step tool use
where the model can continue to ask
questions and search the web or search a
data source until it finally finds that
answer for for you know the a more
complex task that people ask of language
models rather than just here's a
question give me an answer or here's
that request give me back the the text
so it's very exciting to give people a
way to sort of build a production ready
there's a web application there people
can just download and and throw onto
Docker and equip it with with tools um
and then build something on The Cutting
Edge of what's possible with llms today
yes I I liken this to the Apple Vision
Pro which is that you have to build the
platform first and then you need a lot
of developer imagination for that
Innovation to happen and right now what
are the most interesting uses of of
tools that you've
seen so I love to think about so the in
the evolution of of how people use llms
it was okay you have this model that can
write or that can chat um and then how
do you get around this problem of
hallucination and so retrieval augmented
generation is maybe the top use case now
that a lot of Enterprises and large
companies sort of need to tackle when
they chat with their own own own data
and I really love how Tulu sort of
expands that and to is the natural
extension or abstraction of it where
with rag you can like we mentioned the
model can ask follow-up questions and so
that's multi-step U Rag and that extend
ends very nicely to to to the idea of
tool use where yes you can use a search
engine yes you can use let's say
searching of a you know postr databas
postgress database or or notion uh but
if you can search notion why can't you
even post to notion or do things that
are a little bit more advanced and
sophisticated and just on on the edge of
what's possible with with with with
software today um and so the first
natural extension of tool use um Beyond
drag is to say okay retrieve information
from these three different sources you
have these three data sets for questions
about HR reach out to uh ask or search
within let's say notion for questions
about um let's say World Knowledge go
search the web and so identify giving a
model let's say three or four sources uh
and the knowledge of where to retrieve
or what source to use uh to answer what
kinds of of of of questions and so
that's let's say the beginning um and
then that opens up the door for things
like okay the model can generate code as
well and then it can run that code
within a within a python environment
which then opens up things like
visualization and let's say uh data
analysis and we have we have some
examples like that we're running people
through in in the program today we're
starting to see some very sophisticated
kind of architectures of of language
models coming out they might be agentic
um as you say sophisticated forms of of
tool use um dynamically fine-tuning
domain specific language models having
um a mixture of deployment so you know
mixture of SAS and and on Prem and even
on mobile devices and so on so it feels
to me that it's a bit of a myth that all
of this comes for free there's a lot of
serious engineering that that needs to
go into this um what what what are you
guys doing around kind of like helping
people bridge that Gap yeah especially
when you think about the Enterprise you
know it's very easy for you to see a
cherry-picked example on Twitter that
you know Works six out of 10 times uh
but for companies to put these uh
applications into into production they
need to have a really good understanding
of what is reliable behavior and so
that's where we sort of ADV advocate for
what what are the best use cases to
start with for example and so that's one
area where for example reranking is the
most reliable and robust first use case
for a language model that you can uh
throw out and you know have in
production within a a weekend um and
sort of have expected good results and
dramatic up lift um very quickly uh
investing in search so not thinking of
language models just as let's say chat
uh or conversational agents think about
generation Beyond chat which is let's
say summarization extraction um and then
think about Beyond generation which are
these
maybe underestimated um applications
that build on top of embeddings um like
like semantic search and like
classification and so having a uh
thinking about language models and their
broad set of capabilities Beyond just um
just a conversational agents is is a
good let's say um way to think about and
prioritize the use cases that you go
with and then you keep building and
building on top of these capabilities
and how you evaluate them and how the
team sort of internally in each company
uh knows how to uh build and deploy and
evaluate these use cases Jay what do you
do at cooh
here I learn in public um I'm here so
this is I'm coming into my third year um
where I get to see how people sort of
build worldclass large language models I
get to build with them and then teach
the developer community and Enterprise
customers how to problem solve with
language models what the use cases are
uh and so I go to developer conferences
and speak there I write guides and
articles and code examples um where it
just following this fascination of where
llms are going to go next and what new
things are they making possible we have
80 folks coming here today in in Toronto
who are you speaking to so I'm speaking
to in general Builders people who are
building with with large language models
I try to make my talks accessible to
everybody to have a good sort of uh
sense uh but then I go a little bit more
uh to The Cutting Edge when we talk
about the latest retrieval augmented
generation systems so there's a simple
rag template of search and then generate
uh but our incredible rag team sort of
has a road map of how do you improve
these systems you know what are the
failure points of them do they fail on
the generation side or on the retrieval
side so we talk about a few Advanced uh
retrieval augmented generation uh steps
that can improve uh existing rag systems
these can include things like query
rewriting and so what is the right query
to send to to to to search and instead
of sending a whole paragraph that that a
user wrote for example what are the
right keywords to use there so that's
one area that dramatically continues to
says improve a a rag system um as well
as asking follow-on questions which is
multihop rag or multi-step rag uh that
the system is able to um do that uh as
well as the thinking about data sources
as tools where you define to a language
model that these types of questions
should be directed to this uh data
source uh which is more likely called
routing now so which source is able to
to the model is able to source that
information from and then how that
extends to the next to Beyond drag which
is tool use which are the real the next
Paradigm of what is going to be possible
to do with with software and language
models that will continue to be let's
say seems to be
um going to allow models to do things
that are dramatically
better and more um ambitious than what
is possible just with language models
without tools so Jay um what are your
Reflections you know since the Advent of
large language models two years ago I
would go to some of these events and I
would tell people why language models
are interesting um I don't need to do
that anymore people have already uh have
an
interaction uh with a large language
model of of some sort and they don't
even have to be developers I think
everyone has now uh touched the power of
element which is a drastic let's say
adaptation for for the technology and so
the things that we need to raise
awareness for uh have changed with time
uh and so in the beginning yeah two
three years ago my talks were this is
what a language model does this is why
they're cool um now we have to educate
them on on other things which is which
are to say um you know maybe you should
be thinking about retrieval augmented
generation instead of asking the model
questions and uh relying on the World
Knowledge sort of coded into the model's
parameters U as well as advocating for a
lot of other use cases that are more
reliable for for Builders to build with
AI things like embeddings like search
like reranking um like generation Beyond
just conversation and chat things like
summarization extraction um and so my
conversation with a lot of U developers
are like these are the various uh sets
of new capabilities that language models
uh enable you to do and and so uh think
of them as Primitives uh New Primitives
to think about on how to problem solve
rather than thinking about this one
blackbox text in text out uh model just
you know breaking them down to these
capabilities and then you compose these
pipelines or or more intelligent systems
that build on top of them you see in
Industry these two things sort of
emerging as probably two different jobs
the machine learning engineer and the AI
engineer where one you maybe problem
solving on the model training level and
having access to that model and on the
other maybe you're working on let's say
chaining multiple llm apis together
maybe fine-tuning an existing model and
so depend it really depends on where you
are in that in that in that value chain
we're seeing a lot more it's a lot more
accessible for people to be AI Engineers
because then you can be you can come to
it from any software engineering
background or from from from from data
science and you can build actual tools
there and get very quick
results there so if you're coming from
that uh standpoint your the tools that
you have are prompt engineering and
possibly fine tuning as as a second one
while if you're an mle and you have
access to the model uh then it's about
how much compute do you have are you
going to be able to um you know continue
training a base model or are you just
doing the um follow on let's say post
training uh fine tuning are you for
example doing the uh instruction tuning
uh um of the model or or the let's say
preference doing rlf or DPO or sort of
so yeah that will definitely depend on
where you come at it from and I I would
see the majority of people would have
access to tackle it just from The Prompt
maybe a little bit of fine tuning
interesting so the space is evolving all
the time so a few years ago you needed
millions and millions and millions of
dollars and you needed to presumably
have a data acquisition and processing
pipeline that's where a lot of the work
goes and you you know in the olden days
you need you needed to pay for an API
coher have completely changed that
you've now released a model so people if
they pay the commercial license they can
actually use the model they can create
derivative models they can fine-tune
models they can build out these
application architectures where they do
some of the um you know the prompt
engineering prompt injection and
presumably fine-tune models on domain
specific um data that they have locally
they might want to run some of it on
premises some on mobile maybe some in
the Cloud um what is co here doing to
kind of help people build that endtoend
story it is really the the vision is to
give people the flexibility uh some
people some companies for example they
want to focus on their own problem and
they want an llm provider uh that deals
with the deployment for them uh and so
that's a class of of of people who want
to build who want to do what new
capabilities these models are enabling
software to do without necessarily
building up a a machine learning uh Team
internally and let's say hiring a squad
of um machine learning and in data
Engineers for example so that's one one
category of of of companies and it's
it's a spectrum it's just like software
adoption you see a lot of companies that
hire their own software teams others
that rely on on on external uh software
or and others that use software as a
service and for the industry thinking
about AI as just an extension of
software is a useful lens to have and so
for the deployment options of of AI that
that coher thinks about um the the the
coher platform is let's say the easiest
way to just get an API key and start
building and interacting with the model
uh through the playground and through
through coral and then you can take it
to the next level and do the the SDK and
sort of play around with with the code
uh a little bit um but then when you're
talking about enterpris and large
companies they really care about things
like data privacy uh and so that's where
the private deployments come into come
into hand and where the model can
actually go to the the data instead of
the other way around uh and so coh
here's Focus here is on on multiple
things but one of the key aspects is
being sort of on all the major clouds so
wherever your data lives the models can
can can go there and you can build these
these uh systems very easily so you're
not let's say uh linked to one one cloud
or another um and that includes let's
say multiple also formats of how these
private deployments um so they can be in
your own let's say virtual um private
cloud or it can be through services like
uh Amazon Bedrock or or um oracles gener
gen generative AI Service uh and so
giving people the flexibility of
wherever you are and how you want to
sort of build um and then then the next
level of it is absolutely the the the
research let's say release of the models
which are the most let's say Advanced uh
users of these systems that have the
capabilities that have the the the
people who sort of know how to um maybe
evaluate uh these models or or extend
them uh they have access to to to to the
research weights uh to be able to
evaluate that use case and um you know
take things to the next level the
industry still needs to learn a lot of
things on along the way and it's
definitely getting easier in some
aspects and let's say more difficult in
in in other aspects so now you have
these models that can solve a lot of
arbitrary problems that you can throw at
them at at a high an increasingly uh
better rate um with time and also they
start to show you potential of tackling
things that more and more were not
possible with software before just like
how you know maybe summarization we
didn't have as good summarization
systems five years ago or 10 years ago
as as we do now or or chat or or these
other models but I'm a very strong
advocate of bringing in the best
practices of software engineering into
building with llms so whatever llm
backed applications or pipelines or
agentic things that you're doing it's
always good to think about unit tests
about software testing about regression
uh about assertions in the flow uh there
are some ideas there from different
Frameworks for example that inject that
into the flow of of uh of llm back sort
of uh applications and so more and more
yeah we should never let's say yeah
stray too far from um from these best
practices of of of of software
engineering and and proper testing and
sort of um ensuring the reliability of a
of of a system yeah it's so interesting
because um I mean we've always spoken a
good game about unit testing and
software engineering best practices but
you know what it's like in in in reality
and then I guess like the two components
of this is is first of all there's an
argument that we don't need to hire data
scientists anymore because there are
Foundation models you know so let's say
I'm working in a in in a bank or
something and I want to um check
receipts and I I would have had a a
computer vision engineer come in and
take a vision model and fine-tune it and
build out this whole predictive
architecture and now we can just use a
foundation model right we can compose
together all these things even things
like recommendation engines presumably
there will be Foundation models for that
as well in the future and the other lens
is that software is becoming a little
bit like Neuroscience now it was before
we had serverless architectures and we
had you know like if if you were
sophisticated you could build like an
agential Software System using the actor
model or something like that but now
this is real it's here and it feels like
we're we we're building these
inscrutable living systems and we're
kind of putting probes in and we're
observing things we don't no one person
really understands how it all works um
is that something to be excited about or
what what do you
think that's a good question
on so
I'm I'm driven most about my curiosity
uh in this in this field that really
what pulled me very close into into Ai
and machine learning uh and what
continues to sort of drive me about this
new class of of tool basically uh that
is able to do things that we're not used
to uh in inanimate objects sort of being
able to and then what new opportunities
that sort of opens up for for for people
on the individual level on the company
level on the economy level and hopefully
on on the species level as well um and
so that's a little bit of my my my my
guiding antenna and along the way yeah
there's a lot of things that we need to
um be be conscious of
and part of it is some of our biases for
example that go into it you know the the
first thing a lot of people thought
about when they started to see this
piece of software that they can uh chat
with is to assign it some level of
personhood and trust it you know you
still find people who when they
encounter a new language model they ask
it what company developed you what data
were you trained on and sort of applying
this let's say cognitive bias of this is
a generator of of text that is coherent
it might be analogous to to to a human
mind um and
so you know being conscious of of let's
say responsible and ethical Ai and um
the the various let's say important
ideas there and how to think about about
these models is something that needs a
lot more awareness in the general public
people closer to NLP sometimes have a
little bit more exposure to that but
since these these Technologies are are
touching the the general public now I
think a lot of this awareness needs to
be um to be out there uh a lot more so I
would say yeah that that would be maybe
the first um reaction I would I would
get to that line of reasoning yeah I
think part of this is the inscrutability
so we we can build explainability
technology but it's kind of it's no you
know you can't explain these things it's
a bit of a post Hawk confabulation but
you can't explain human brains either so
I have a theory of mind and that's how I
figure out what you're doing but it's
almost certainly wrong and in the same
way that it's wrong about language
models I think it it might be a new kind
of generational Gap you know when
computers came out you know my
grandmother wouldn't have understood
what on Earth was going on and in a way
I have confidence for the future because
I think while we don't understand you
know young kids growing up with this
technology they will learn I mean some
of it's just the the kind of the the
naive um novelty effect right because
you know when when you start to see some
of the failure mode you kind you know I
think that illusion erods but I do have
hope for the future that we will kind of
learn how to think about this technology
and integrate it yeah yeah yeah
absolutely and you start to see it like
as more people in the hacker community
in Tech Community sort of really care
about reliable behavior of these models
you start to see these Frameworks these
ideas these uh guard rail uh tools for
example or or llm assertions in in the
flows of these pipelines uh so yes
the the incredible amount of of U life
that's in this you know AI hacking
ecosystem and uh what how people are
sort of figuring out not just business
models and ideas and types of
applications but uh but also best
practices of uh of these that's
commendable and U any work in
interpretability continues to be uh you
know fascinating and and needed uh
alongside all of those uh practical
tools you start
to quickly see the potential of where
these type of Technologies you know are
taking the software industry and so the
sooner people start to build the right
uh Concepts the right understanding uh
the right let's say Primitives to
problem solve with uh the better
position they'd be in
to use these in their existing let's say
jobs or projects that they're working on
uh and sort of be it's kind of like the
people who invested very early in mobile
applications when you know before
smartphone sort of exploded or in the
cloud as well so you that trend is very
clear that it's there's dramatic
potential for dis ruption of existing
um standards let's say in the in the
market and so the sooner you invest in
that um the better you will be equipped
to to to capturing the next wave of of
opportunities and and possibilities what
advice would you give to someone
starting out in machine
learning share what you learn publicly W
with whatever format that you were
comfortable with be it Twitter create
videos cre you know snap or or Tik Tok
videos whatever format that you like
share what you learn don't let impostor
syndrome sort of stop you from from
sharing what you learn uh whatever you
were learning whatever you've just
learned last month is worthy of sharing
because when you started it was
intimidating to you you didn't know what
that was and a lot of people are still
in that U mind frame now um so don't
don't give in the to the curse of
knowledge of I know it it must be easy
no just feel free share what you learn
even if you only share a curated list of
what the websites that you found useful
that is good content just share what you
learn what worries you most about the
use of AI in
society there's a lot of attention
to you know what areas we should
pay attention to um a lot of them are
still kind of invisible or they don't
get as much um so there's a lot of
recomend a systems right now let's say
are are machine learning so they're not
necessarily generative AI but they do
control a lot of the information that
flows into people's heads um so these
are the recommendations the recommenders
on on social media um on uh these are
systems that yeah control the a lot of
the flow of information um but you can
take that to other recommendation
systems in maybe any app that you use um
these are not uh necessarily yeah these
these generative AI of of the Next
Generation but
they're super impactful um on you know
you have you have people consuming
content for hours every day and a lot of
that is decided by these uh by these
algorithms um that grabs my attention in
terms of AI
safety what got me started really to
switch into machine learning is the
release of tensor flow as as an open
source uh so I took that as an
opportunity to to pick things up so so
open- Source uh machine learning has
been um a big thing uh that time was the
rise of deep learning so these deeper
and deeper models that was uh the you
know the big rage at the time so deep
learning for for a while was um starting
to work and starting to make software do
things that are um absolutely tremendous
and then from that the rise of language
models really took it to the next level
and you know I wrote The Illustrated
Transformer at the time it was a paper
it was a new form of attention like a a
third one there were a couple of pretty
popular attention models at the at the
time but then with time the importance
of the paper and the model kept
increasing Bert comes out GPT comes out
other models comes out and they get
bigger and bigger and and then they go
and eat computer vision and they they go
other places so uh yeah that like the
rise of Transformers and and language
models and just how scale
gives them capabilities that um are a
little surprising I think that's that's
one of the things
that I find fascinating and I think
surprised a lot a lot of people in the
ecosystem with this explosion in in
large language models a lot of people
are just starting to um come across
these uh these are not necessarily
people in the field or like researchers
or even software engineers and it's easy
for people who are coming into that to
misunderstand what this is and when
people when a lot of people who are not
close to the field here artificial
intelligence they think okay this is
software in the form of a human mind and
the chat interface maybe also leads them
on to think that um and so they try to
say okay tell me about yourself as a
kind of of of model and how were you
trained and what company sort of trained
you and there are a lot of things that
we ascribe to these models when we are
sort of first coming uh in that we we
find our you common failure modes that
people should be we should raise
awareness of how to think about these
models how they were trained um and what
they are good at and what they're not
good at and what things are
cherry-picked that make a really amazing
screenshot on social media um and what
things are reliable behavior that you
can actually build into a product a lot
of people learn that the hard way they
see something they say okay the model
can do this uh let me build a product
that does that and then it's very
difficult for them to get that reliably
uh in you know 99% of the cases or 95%
of the of the use cases so we try to
raise awareness um on on these things
but also to have people not focus
specifically on just the generative
Parts a lot of the most amazing things
that AI can do uh and the recent
developments are also on the
representation side and what you can do
with these with these representation
things like semantic search
classification classification these are
both reliable but also they can get give
you let's say spec specifically in
business applications and and real world
applications give you reliable
performance and improve existing systems
very quickly um so yeah when people
think about yeah chat models it's good
to take a step back and look at the
whole view of what AI can do and have
that lens of of of reliability and
whenever you come across an impressive
demo just ask because we keep falling
into that um this is not the first deep
learning frenzy like we've seen we've
been promised self-driving cars by 3
years ago like maybe six different car
companies said they would have
self-driving cars by 2020 um this was
back in 2016 when you know one of the
previous deep learning frenzies happened
so let's let's learn from the past and
um have sort of some some realistic um
timelines for for different use cases
some use cases the models are ready now
um others later but it's it's one of the
uh it's an observation that people
should build that in as as this
technology develops and have that
Discerning Eye of asking is this
cherry-picked or is this reliable
Behavior can you kind of sketch out the
Continuum between that old school
thinking of semantic search and you know
nowadays people are saying oh just have
a large context window and do everything
in in the language model yeah that's
that's a a great point so yes the the
that reference is is to sentence birth
yeah that sort of was was developed by
Nils and when people want to build with
llms there are multiple approaches you
can build at the very top of this deack
and where you're just a consumer of a
commercial uh llm you just send prompts
and get text back that's that's one way
of of doing it but then you can also dig
deeper and become a builder of systems
that use these uh and if you want to be
a builder with llms uh one of the
biggest things I advise people to do is
have a sense of what embeddings are and
what things you can do with them because
that's a lot closer to
engineering uh than prompt engineering
is uh you can get a lot of these um
again these these reliable behaviors and
semantic search is one of the best cases
so even for the future of generation
semantic search is going to be very
important as you talk about retrieval
augmented generation and then search
augmented generation so um
embeddings s Empower semantic search in
in let's say two ways so there's this
idea of dense retrieval which is where
you you you you have your text archive
you have the embeddings of each uh text
in your in your uh data archive when you
get a query you embed that and then you
just find the nearest neighbors um and
that's been dramatically improved the
last you know 3 four years since Bert so
Bert doesn't really do very Bert
standard uh let's say not not sentence
Bert um it focuses on uh token
representations and token embeddings uh
but using it for retrieval requires
additional training which is what the
sentence birt um papers brought which is
this contrastive training step of saying
these two are are these two sentences
are similar and then these two sentences
are not similar yeah and then when you
think about that objective one question
you might ask is is a question and its
answer all always semantically similar
or can they be different um and they can
indeed be different and that's why if
you're focused on text embeddings for
search you want to um train additionally
on data like like that so your a query
can fall into um the embedding space
point that is close to its answer uh so
these are optimizations that came into
um embeddings that improve semantic
search using embedding or let's say this
first family of semantic search using um
dense retrieval uh is is this the the
other concept is this idea of rankers
which are usually maybe it's one of the
easiest ways to plug in the intelligence
of a large language model in any
pipeline you have a search system you
know every app that you build will most
likely have a have a search component of
it a search engine to search so you
don't necessarily have to be building
the next web uh search engine and the
easiest way to plug ANL and a large
language model in that is to say okay
these are my search results that my
current system provided these are the
top 100 results you pass them to a
ranker that just readjust them uh the
order uh of them uh in relevance to the
uh the search query um and so yeah
that's I would say these are two very
easy ways to plug into plug the
intelligence of language models uh
Beyond just you know generation steps
and you can build let's say real systems
with that and coh here aims to make it
easier to do both through an embedding
model and a ranking model and rear
ranking endpoint and model sort of
specifically focused on these in in
multiple languages
now if you want to do Generation
generation can can solve some some
problems and some use cases but not all
they're both Tools in your toolbox um
and nothing sort of replaces necessarily
everything um if you have a long context
window let's say you want to ask
questions about the documentation of of
a of a piece of software um is it really
efficient if you have a thousand
questions that you keep sending the
entire documentation text to the model
for it to sort of process it every time
you ask a question um that seems to be
you know a lot of wasted compute because
you're just sending the same thing over
and over again that you can easily
replace Now by let's say a a retrieval
augmentation where you store it the
embeddings are there they capture the
text and the meaning of the information
in it and then you can use it to
retrieve the text whenever you need it
whenever you need that sort of um
detailed uh look at it and you can
present it to the model in in that stage
again so yeah that's if you wanted to
take a step back from from generation
and build these tools in your toolbox um
this is one one great way that I
advocate for thinking about llms for
Builders I advocate that if you want to
start building with llms build a
semantic search engine because having
that mental dexterity of what you can do
with embeddings and what semantic uh
search is is able to give you uh just
opens so many doors for you down the
line where you're not just yeah sending
prompts and changing the text here and
telling the model that it's the best
poet in the world and and trying to you
know get get better poetry out of it can
you talk about actually your role as an
educator in this field what motivates
you to put so much effort into creating
all these educational resources and you
can talk about the llm university as
well but it's not just that you've been
doing this for years now um why do you
think it's important I learn so much
more when I try to explain something um
it I can read a paper but if I don't try
to explain it I will only get you know
maybe 10% % really or 20% for for
example but if I have to explain it in
detail uh you know part of your brain is
like you know I don't want to put this
out there and be wrong let me make sure
let me double check let me you know
triple check this sentence that I said
um and that sort of you know when I
identified something as this is an
important idea I need to have a really
good sense of it um the writing and
education is has one result of it is
just me learning more deeply on this um
and then then it just comes out of a
there's a sense of gratitude to the
people who have helped me understand
these things so the incredible blog
posts of of other people who have um you
know explained things U just you know
childhood Heroes like I don't know Carl
Sean and and and Fineman and people who
have explained these these very complex
ideas to the general public in in very
um compassionate ways that are um you
know don't expect you to
be very advanced in that field uh but
also people in the field so learning
machine learning myself like things like
people like Andre kpa's blog was was
incredible like the first time I
understood like text generation via
rnn's was was one of uh Andre kpa's
unreasonable effectiveness of rnn's I
believe was the blog post um Andrew tras
had an incredible one was was like
neural networks in 11 lines of code and
if you can condense that whole concept
in 11 lines of python um that that's
really when neural networks sort of
Chris Ola has had also you know a bunch
of really good um blog posts on lstms
and um and then my now colleague Louis
Sano has incredible videos explaining
things uh on on YouTube so convolutional
neural networks were let's say hard to
understand I'm not going to say
convoluted uh his explanation of them I
thought was uh was extremely helpful
which is um why yeah something like um
LMU llm University is something that is
really special for me because I get to
collaborate on it with him and with
another uh incredible Creator moror Amor
who created another visual um book about
it's a visual introduction to to deep
learning so these are some of my
favorite machine learning Educators out
there who have like a real deep sense of
explaining things and Exposition and
like making things simple and but also
visual communication as well and uh LMU
is like the collaboration of the three
of us to say okay you want to learn
about large language models here are the
main concept that you need to do in a
very accessible visual way um and it's
like we're available also on the coher
Discord to answer any questions so if
you're going through the materials and
you have any questions we're we're happy
to sort of um answer those questions and
it's just the release is just the start
we're continuing to create more content
for it Louis Rano is uh man he he is
he's amazing um he was an inspir for me
actually um I can remember many of his
videos in particular actually the um he
did one on collaborative filtering which
everything you just said like amazing
visualizations and I've always aspired
to make content like that but I think it
it just requires a certain kind of you
know I mean he's really really good at
it but similarly you did something
interesting because there there were
people like you know um like Josh starma
stat Quest and and Louis Sano and they
they they kind of like make really
really structured pedagogical content
and what you did with the illustrator
Transformer is you kind of did that but
you're talking of I don't know I guess
you're going into more depth the depth
that's in there is the depth that I
wanted to understand it in uh that's
that's one one component because I can
just explain the architecture but not go
into you know some of the other details
but I wanted to to wrap my head around
around a lot of the other main Concepts
um some of the things actually uh came
from the authors themselves so after I
had a I sent it to the authors and I'm
like okay let's uh you know what do what
do you think about this are there any
corrections things that and they
actually gave me some really good
feedback they focused uh so I had to
write some new sections so you know it
didn't have the section on the residual
connections for example I think that
that came after some um feedback from
from some of the authors but also some
corrections to a lot of the which is
another life hack that I so as I
advocate for people to write and explain
papers you know send that material to
the authors their emails are right there
in the paper and you'd be doing them a
favor of publicizing their work and you
will get really good feedback from them
um so yeah my goals were to understand
it um and to let's say to to at a really
close depth and at the time was also
working at Udacity um so you know I had
to explain it and sort of to the level
of code and having people train models
that that are kind of like that and so
that forced me to really understand it
all the way to um what a a student who
coming up and wanting to actually
develop something like this um know the
top 10 15 Concepts it's not everything
but it's like it will get you on the
path so you know much of your work in
explaining AI relies on visuals and
graphics and interactive elements and
you know so first of all why do you
think it's so important and how can
Visual and interactives help build
intuition in a way that just text or
math formulas cannot yeah so I think it
does a a few things um it communicates a
lot of information quickly like we have
insane bandwidth for for visual um
understanding that you know text maybe
not uh isn't able to give that give us
uh that same thing as a at a glance uh
so the amount of bandwidth that you can
put into a very welld designed uh
conceptual figure um I found has been
sort of um really helpful to people but
it also has these other effects of it
can be scanned very quickly a lot of
people when they are in the beginning
they they're deciding to read your your
article they haven't really committed to
to reading it yet uh what I find I do is
I would scan the article to see okay
what are the the headlines what are the
images and seeing the images the list of
images seems to be like the first
reading that somebody does and if it
just gives them some idea it would build
a little bit more confidence uh to go
deeper and deeper um and so I find that
also to be entertaining as I'm reading
something the monotony of the text I
read you know one or two paragraphs and
then you give me a visual it seems like
this reward sort of um uh system that
you're you're receiving the information
on multiple channels and it's sort of
breaking your your your system sort of
and your focus into reading text and
then the visuals and the text and the
visuals
um they're hard to do and I have to
iterate a lot on them so every image you
see is usually the sixth or seventh sort
of iteration of that image so it's also
a thinking process because usually the
first image I create out of it is wrong
is not enough is has some issues and
only after I do that am I able to
connect some other idea to it and then
so yeah a lot of the times you would
want to arrive at the final thing but no
the the creating the IM is is part of my
sort of thinking process um of of
understanding a paper or understanding a
concept I'm really looking forward to a
future where every concept that you want
to understand is you can find uh really
good good explanations on it that
they're closer to your learning style um
so when I write I have to think about
different audiences uh somebody who is
an expert somebody who is a uh not an
expert um I wrote a paper on on just the
broad communication of of of machine
learning ideas um and I I have a graph
in there where I'm like thinking about
the general public The Specialist and
the super specialist where a machine
learning paper is really taking a a
super specialist up a little bit into
the frontier that's all its its job but
if you're writing Exposition you want to
get the general public all the way to
the frontier but how do you do that in
500 Words it's you know it's nearly
impossible so I think of okay maybe we
break it down into different levels of
of abstraction so the general audience
can maybe understand the first third and
then there's a a mental sort of step
after that where the Specialists can
continue to read but whatever your
background is you come away
understanding a little bit deeper you're
you're you're in but then you're not
presented with hopefully with any jargon
that you weren't expecting before or
walls of formulas that would intimidate
you if you're not or you know lots of
blocks of of code that you have to parse
if you're notu a nauy programmer so I
try to delay the complexity as much as
possible and sort of have all of these
audience in mind um in that process how
the hell do you keep up with all of this
stuff you know what are your um go-to
communities and
so it's it's definitely difficult uh
machine learning uh advances very
quickly um and right now the last you
know several months it's been there's so
much more focus on it from every Circle
uh in technology in business in just the
general public uh but the just curation
just like really focused curation and
you know selecting specific fields to to
really focus on um I consume a lot of
Twitter specifically but only the people
that I follow so not not the
recommendations um and I curate the
people that I follow um you know very
closely for things that I that I look
for and a lot of it is uh yeah for for
learning for NLP specifically as well so
you know even catching up with NLP alone
is uh is is an incredible task so uh you
know I've had the the opportunity to not
focus as much on on reinforcement
learning or or computer vision or or
these other things but then yeah now NLP
is eating the world and large language
models are are are going everywhere um
so yeah just being brutal and using
those signals as voting mechanisms if I
see a paper come up on my timeline three
four five times you know that's some
social proof of of of the people who in
the past have have provided good signals
um and so that's been uh a useful method
for me so far what's coming next I mean
what what do you see as the main
limitations and Transformers and what
might replace
them so there does seem to be some sort
of at least maybe convergence uh in
terms of just architecture research that
there hasn't been you know major jumps
in how the architect ures uh are in the
last you know years year or two let's
say U there's a lot more that can be
done on the engineering side so people
can build so many more we haven't even
be be begun to exploit the kinds of
architectures uh of systems not models
that you can build with with these
things so if you have a generation model
follow you know that does this one
generation step and then uses a search
step and then another prompt that does
something so the universe of of
application that can be done with the
existing systems is just beginning we're
just beginning to touch
the uh surface of of what what that is
like so I will I do see a lot of
engineering um catching up and product
uh and from product business and let's
say a business model uh that catches up
with with that um um development in in
models um but then yeah the next things
are like what other where can we get
data once you get all of the do say
internet data how do you train even
better models um and for that ideas like
M multimodality are is exciting
embodiment and um you know social
interactions how how these models can
sort of get some um information from
from social interaction that they have
in the world and you know could could
some random person in their garage just
either replace a Transformer or maybe
even decompose a train transformer into
a sort of neuros symbolic architecture
or something which runs on the laptop so
I mean there's a lot of this
quantization uh is that it's making
these models uh smaller and smaller um
and fine tuning is another way that you
can get some some of the behavior of a
very large model in a in a smaller model
you you see a lot of hardware and Chip
manufacturers thinking specifically
about the Transformer architecture and
how sort of that can work better on
their on on their chips um and even on
the edge wasn't there let's say a
Arduino llama uh so yeah the hacker
Community seems to be doing let's say
incredible work at at shrinking these
things down deploying them at on the
edge and and more and more sort of
devices um that's that's very
interesting to see so this article you
wrote was back in the days of you know
vaswani in 2017 he wrote The Illustrated
Transformer it was for translation it
was an encoder
decoder and in the intervening years
what has stood the test of time
so that's a really good uh segue into
this so yes it was an encoder decoder
now to explain it uh the format of
language models that is most dominantly
uh used now is the text generation model
and so that's at least a good starting
point to explain those to people and so
the focus is not on a decoder encoder
decoder model but only on a text
generation uh decoder model and so that
simplifies it and whatever you learn
here will translate into other things so
that's one way that sort of um explains
that and then there were these idea
there were a lot of different um
improvements uh suggested on the
architecture uh in the in the previous
years but a few of the things that
really stood the test of time are things
like positional encoding so things like
rope uh positional uh encoding uh and
there are things around the efficiency
of the attention uh Network and and uh
attention player so um things like
grouped query attention and how that
works uh and a few other let's say
smaller differences but these would tend
to be maybe some of the three major
areas that that have changed in the last
six or seven years interesting are there
any high level insights you know if if
you were building let's say you were
rebuilding gpt2 from scratch or
something like that um you know how many
layers do do we need like what kind of
insights could people have about the
architecture I think there are a lot of
insights there are some on the
architecture a lot of it has not really
changed but there's a lot more insights
on the data and the how the data should
be curated and the training phases I
think that's where a lot of the focus
uh and how the Improvement on these
models can uh can can really be taken to
to the next level and so these three
steps of training so language modeling
is only the first of these three steps
and then you have the supervised uh
fine-tuning or instruction tun tuning
and then you have the the the preference
or rhf and the more higher quality data
that you have across these um these
various uh steps that's the better so
these tend to play a much bigger role
than let's say the the architecture
itself which which on the whole stays
very close to to where it was uh five or
you know seven years ago Jay tell me
about the book that you're writing yes
so Hands-On large language models is
coming out from O'Reilly and my
co-author uh and myself Martin honors we
write about Transformer language models
llms in general how to use them for
applications that's let's say a big
chunk of of the book if you're a
software engineer or data scientist or
somebody who wants to use llms we talk
about that extensively uh across various
use cases and then we also go into how
these models work under the hood how
they're built and it includes one thing
that is let's say an updated version of
the Illustrated Transformer it's this
this blog post that um you know millions
of people have have uh read on my blog
but that was about seven years ago so it
was very interesting to revisit the
Transformer and see how we would explain
it now uh and what changed uh in this in
this time period so look out for it it's
going to be um August
2024 uh is is the hope to get the print
version uh we hope you like it and we'd
love any feedback on it when you're
writing a book like this how do you do
the kind of fundamental
research so one thing that's helpful
here is that we're thinking about
applications um and in applications
are informed by the use cases that we
see in industry and the use cases that
people build with and the use cases that
you see in the developer uh ecosystem
and so that's what informs let's say the
major major part of it because we're
writing a a book for you know the for a
large cross section of of people
developers data Sciences data scientists
and and other llm builders uh and so we
don't need to go very deep into sort of
the what's the The Cutting Edge or the
or the theoretical uh but we can focus
on what's applied what has a lot of use
cases what has been sort of tried time
and time again and and sort of grown in
adoption in in actual industry and so
that made the selection choice of of use
cases a lot easier awesome um so
you've already released several chapters
of this book where can people find it
yes the oil platform has this early
release uh program I think about five or
six chapters uh of the book are already
in the early release uh on the o
platform so everybody can go to the to
oilly sign up there and get access to to
that book and more and more chapters
will continue to roll out until our our
release date uh in September and What's
the title of the book handson large
language models and the animal that you
get because that's a fascinating aspect
of writing for O'Reilly uh our animal is
the kangaroo so you don't get to choose
it there's a very secret method that
oilly uses to to choose that uh we're
very happy with with the kangaroo anding
up on the cover of our book amazing Jay
thank you so much thank you so much
