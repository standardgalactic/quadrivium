um thank you thank you so much for that
very kind introduction um I'm Katherine
Li and I'm going to talk to you about
Pro um so I come from a bit of a
roundabout background I I started in
maths and computer science and then
became enthralled by the language
problem and decided to do a PhD in
linguistics and then went back to
informatics and then now I'm back in
linguistics and so what I'm really
interested in is spoken communication
and I think a lot has happened in the
past few years even in the last year um
in terms of where in terms of speech
technology and language technology that
actually allows us now to start to think
about some very very hard questions and
speech communication so I want to talk
to you about some things that I think
are worth thinking about now um that
really very happily align with what I'm
very interested in so
um a lot of the stuff that we've seen in
in the past so I started really doing
speech technology about 10 years ago
before that I was really much more
focused on Linguistics um and so what we
have seen for a long time is a version
of speech technology that mediates
communication through text so here was a
tweet that was just from last year from
Jim fan who was very excited to say look
we have these new technologies now we
have really good ASR um speech to text
whisper you have chat GPT to do your
dialogue management and then you have
other TTS systems like Valley to do um
speech generation so uh what we have
here is a classic sort of spoken
dialogue systems chain we have speech to
text we do all our natural language
understanding within the text realm and
then we generate text and then uh turn
that to Speech but okay so if you that
that's that's a reasonable approach but
um it's I would argue that it's missing
a lot so when I saw this tweet I
thought that essentially so um what I'm
going to talk to you about today is all
those things that are kind of missing
when you strip away every and just focus
on the text okay so here's our classic
speech to text problem so we have um
some uh
recording uh we usually try to get some
sort of um representation of it uh so
that from which we can get some text out
um so let me play this for you first of
all okay so this because I use Google
slides and that's uh my fault uh this
might take a little time so
okay so hopefully you could hear that a
little bit or at least you could hear
the um the general sound of it um so
what maybe so we have the caption name
now so you kind of preempted me but um
so this is what he actually said so I
said to him when you left do you
remember I told you I said to him don't
forget Dave if you ever get in trouble
give this call you never know you're
luck right so that was a a real turn
from a real speech Corpus British
conversational speech Corpus um don't
ask as me where that Copus came from
because I don't know um but we have it
in Edinburgh so you can ask Peter Bill
who's not here um so see this is the
classic sort of situation we have our uh
waveform we have our intermediate
representation and then we have words so
uh you know even 5 years ago people were
mainly focusing on just getting the
words out so no punctuation no
capitalization so that was another task
that people worked on as a sort of
post-processing
Step um so
we kind of know that you know to make
sense of this we need some more
information so to actually read that
text you really kind of need some
punctuation there there's an embedded
quote in there so there attributed
speech and we kind of want to know what
that is so we can say whether that
information was something that came from
a specific speaker or whether they're
quoting someone else so these sorts of
things are important if we want to sort
out what sources of information are
there and so you can see this is kind of
a a complicated quote um there are
several different points where could
have been a quote but in the end you can
kind of if you could hear it properly
you can hear um that it's the last bit
that is the
quote so um at the first stage we at
least need some punctuation
right um so let's look a little bit at
where we are now so uh that that quotes
uh reference whisper um hopefully you
can see this um but so if we put the
large beach model onto whisper you can
see it does pretty well actually it only
gets two words wrong um it doesn't
change the semantics too much it says if
you remember rather than do you remember
and it says we never know your luck
rather than you know your luck as we get
to smaller models we start to get some
issues so it says to I said to him he
left if you remember I told you I said
to him don't forget So This Is Where It
gets weird I I'm here to get in trouble
give us a call you never know your life
right so okay that's not the message
that he said um so even if the so here
the word rate is pretty low here it's
getting a bit uh worse and okay here is
bit cheeky but okay so the multilingual
model it got it got wrong right it got
the language wrong so this is probably
thinking as
well okay so it's not completely solved
we can do really well with big models
with the smaller models It's Not So So
Sol let's say Okay so let's let's look
at text to speech instead so that's kind
of going back the other way given a text
produce the waveform so let's listen to
some samples um so we have a few here so
if we don't put in the punctuation um
let's let's just listen to it so this is
fast pitch this is LJ so this is a uh a
voice that you probably know very
well okay so it's a bit hard to
understand she's not really doing any
queuing of like how you should put the
words together uh I uh I chose some
samples from the 11 Labs voice because
um you know it's it's touted as a
state-ofthe-art voice and um it's very
easy to make samples there um so you can
have a listen
so this is
Fred I said to him when you left do you
remember I told
you don't forget if you ever get in
trouble give us a call never
okay so it's a bit better he's he's
making doing some sort of semantic uh or
syntactic clustering um so that's a red
speech voice that's that's advertised as
a audiobook voice and the Archer is a a
conversational voice let's see how
conversational this
sounds I said to him when left do you
remember I told you I said to him don't
forget d if you ever get in trouble give
us a cold you never know your luck okay
so that's not that bad actually that's
pretty good it's um um given that it's
got no punctuation it's it's clustering
things together but some things you
might hear from that that's missing are
well it's getting the overall tone kind
of weird um in a way so in the actual
conversation and there's no no no way
that the TTS system could know this the
speaker is actually talking about this
as an anecdote that's kind of funny
right he's it's a bit cheeky right so
he's he's basically telling Dave that um
he'll help him out when he's like ah I
won't really like so so it's kind of
missing that tone um with punctuation um
um you don't actually get that much
difference you get a bit of difference
in the fast pitch voice I won't play it
for you just for um um the time but um
you can start of hear like some of these
voices sound perhaps a little bit
accidentally uh uh unhappy let's
say I said to him when we left do you
remember I told you I said to him don't
forget da if you ever get in trouble
give us a call never
all right so he sounds a little bit
annoyed I would say okay let's let's
listen to
Archer I said to him when he left do you
remember I told
you I said to him don't forget Dave if
you ever gets in trouble give us a call
you never know your luck okay so that
one's also okay is it conversational I
think it sounds more conversational than
the red speech I I'll just okay I no
okay I won't play LJ it's it's it's
quite far behind but um so the thing is
like when you're generating things there
these different strands of attention
that are pulling of like what do you
want to convey so is it just the
structural stuff or do you also need to
Pro do you also want to transfer the
other things so the aect what what are
you actually trying to convey in the
conversation some of these things can be
very
subtle okay so in
general there there's lots of things
that are missing when we just strip out
all of the information that's not just
the words right so
so that's that's kind of that's
yesterday's news nowadays we're focusing
on you know native speech models so that
you you want to really keep as much of
information about the speech as possible
and you know if you've been keeping up
with the news a lot of companies are
going in this direction for dialogue
we'll get back to that later but for now
what I want to talk about is a little
bit about proerty so what what is
proerty actually um so um the reason I
think this is important is for all these
reasons but um why I want to talk about
it in some detail is just that it's very
complicated right and I think it's good
for for us as a field to try to think
about like how these Technologies relate
to these issues of communication that
really come up when you're studying
frity so frity how we say what we say so
we often talk about this in terms of
ination so pitch is it high is it low
loudness is it loud is it soft timing am
I talking really fast or really slow
right so they are they're not always
independent right but they can um you
can you can vary them these sorts of
pictures we also talk about voice
quality so am I kind of harsh in my
voice or am I breathy right so this is
about our articulators and how we're how
we're using them to express different
things okay so in general we're talking
about super segmental aspects of speech
so stuff that you don't get from the
words or the phones themselves so super
segments you know more than just the
segments where the segments what we mean
of phones essentially
okay so we have basically as I said
there's kind of two main aspects if you
read PA Taylor's book you know about
this so there's a structural bit so
that's what a lot of linguist focus on
so what's the phology of a language
what's the international phology of the
language what are what's the grammar
there that's that's driving what we see
how do we put things together how do we
signal what um how do we how do we learn
how do we know how to put things
together in order to get the actual
message to get across but there's also
this effectual bit so this is how we
feel how we feel in a in a dialogue how
do we feel towards the people we're
talking to how do we feel about what
we're talking about how do we feel about
other things in the world and you can
see that we're kind of missing something
when we just use text because we kind of
invented all these things to put into
the text to show these um so um we're
also working on emoji very interesting I
won't talk about it too much today but
it is very interesting it's not the same
as proy but it's very
related okay so just some examples So
Pro communicates um linguistic structure
let's see if I can sorry it's a little
bit quiet should have sampled again and
play it again
and so if you can hear that a little bit
so what you can basically what I want
you to take away from this is like Okay
so this grouping together of Clauses um
into prootic phrases it can be through
pauses we can singal things through
lowered pitch register and you can see
this quote is actually kind of signaled
by a very long period of lower pitch
register so he's talking low and fast
right through here so that's how it's
signaling so this is something that you
can't really ask the um TTS systems to
do at the moment at the moment they're
generating different variations but we
don't have that much control over what
they
do okay so here's another here's another
one so Pro uh communicates effect this
is from the TV show unbreakable
commission she's going to say the same
thing
twice oh okay maybe that doesn't
work you
okay so you can hear hopefully that is
different right different so um you
can't tell
when um so no so so okay so she's doing
it with her voice right the second one
is sarcastic but how do we know that's
sarcastic um it's because if we know the
show and we know our our pop culture now
um she's refering to Chandler right so
who's Chandler Chandler is this dude
right from the TV show Friends and what
we know about Chandler he's very um
famous for being sarcastic and having a
very specific way of talking so um let
me just switch it out for a
second sorry there there was a little
bit of an issue with
no
no
CH okay draw on me with chalk right so
um that's the that's the very typical
chanler being intonation that um gives
you sarcasm and so if we hear this again
we can kind of see what this is so uh
this is um kimy saying we really care in
both iterations
okay it doesn't like that
one okay fine um so I'll do it for you
so she says we really care we really
care right so uh in the second one you
can see um the pitch Contour there this
is just like a screenshot from PR
obviously but so you can see the blue
line is the pitch um the pitch Contour
um the fzero Contour and um you can see
in the first case it's much shorter in
the second case we really extend the
real you can see the the pitch is much
higher in terms of the Excursion um and
it's really drawn out and there's a
slight pause there right there's a
slight break there so you can see this
in the acoustic features does that mean
that's how you do sarcasm all the time
of course not right so this is just one
way of um expressing this sort of thing
that's dependent on having a specific
understanding of popular
culture okay so um the phonetic detail
here really matters that's this is my
main argument so if you're going to do
this as a conversational analyst and
transcribe it all out you might add a
lot of stuff to your transcript right so
this is a Jefferson style transcription
don't judge me if you're a conversation
analist um so um but just to say like
this if you want to actually really
Express this sort of thing in text in a
fine detail you have to do a lot of work
to get there um and in real life um how
do we express these things Often by
deliberate misspellings for example so
there's some work by my dad that we're
doing on like how people Express these
things and actually people you know
misspell things they do sorts of
elongations they do deliberate disfluent
writing in order to express this sort of
stuff so let's see how this sounds with
an another 11 Labs voice this is
hope I'm so sorry okay that's just a
normal one
I'm so
sorry I'm so
sorry I'm so sorry okay so I didn't so
that that does sound a bit sarcastic but
actually that was not actually that I
didn't ask it to be I just did this and
then you know um the way it you can do
this do sampling essentially so there's
not that much control so if I do it
again it comes out quite
differently I'm so sorry okay so she
does sound maybe a little bit sarcastic
but definitely not as much as the first
one so if you want to actually produce a
specific type of um proerty in order to
produce a specific sort of aect what
you're going to be ending up doing is
spending all your credits uh generating
lots and lots of samples right unless
you have some sort of form of
control okay so hopefully that shows you
that you know Pro expresses affect um
and it's also contextually dependent how
we interpret it but the other thing is
pro out of context evokes context right
so if you just give something a sample
for somebody to listen to they'll
project what context it came from who
said it what are they like so this is
some work by zachari um he looked at um
getting
uh neurosynthesis more expressive and
looking at whether we could actually
codify this variation in terms of
international codes a little bit before
everyone else is doing it um so this is
four different Renditions of the word of
the phrase I'm sorry and you can think
to yourself where do you think they
would come
from sorry
I'm
sorry I'm
sorry I'm
sorry so so so some of the uh what zck
did which was really nice which he did
actually do some qualitative analysis of
this and ask people what they thought
right and so it was very very
complicated we were actually hoping they
would say like oh they moved the focus
from here to here and that sort of stuff
but what they actually said was very
complicated so one was like a brother
and a sister talking and fighting and
you know one wanting to Apologize One
the other to apologize the other one
doesn't really do it and lots of things
like that sorry so so you know it it was
a fake apology that was the thing that
it was described at as uh not not all of
them but some of them right you could
probably you know just put a label of
that on some of them and so that's maybe
something you don't want to have your
TTS system do make fake apologies or
signal that they are fake apologies um
so out of context you don't really know
what people are are are projecting onto
speech which is a which is a problem um
and another issue is that um a
longstanding issue that we've been
talking about in linguistics is the fact
that all these things point to different
sorts of Social and social identity
right so you can use the way that you
speak to signal that you're in a
particular group right but also the way
you speak people can you know project a
particular group onto you and they can
also project a lot of different
stereotypes onto you uh based on this so
one very famous one is up talk so this
is rising uh pitch at the end of your
sentences and I'm from Australia if you
didn't know so I do this when I'm at
home right so um so this is often
associated with young women 's voices
and uh you know the many many debates
about oh this uh this signals that women
are too subservience women should be
more um forceful in their talk or it
signals that they you know require
social validation and stuff like that
but actually men do it a lot too right
people just don't focus on that um and
also I'll I'll play you an example
sorry sorry okay
I I think it's
prent
people I think Junior High School people
would tend to use that and now as you
get older in high school it's pretty
much disaar I haven't heard it for a
while okay so she's talking about up
talk right but she's she's doing it
herself but saying that um people don't
do it right so it's really hard actually
to have introspection about the sorts of
things that you do in the way that you
communicate like it's it's quite
subconscious in a lot of ways um um but
that's just an example for you this is
from the language log it these things
are really difficult to disentangle like
what what is what um what do you
actually do in speech and also how
people perceive you in speech but this
seems to be coming more and more to the
front and we will get to it by the end
right so
um so I mean don't read all the slide
but it's just to say that Pro is very
complicated it it signals a lot of
different things so the main argument
I've been making to you is it signals
structure but there's lots of different
types of structure and people worked on
lots of different things to do with that
it signals aects so things like emotions
attitudes and intentions but we have to
think about like how that is directed is
it just general or is it directed
towards specific people so is it a
stance for example towards a specific
person and it also signals things like
social context so this is very
complicated POS does a lot on a very
like constrainted signal and it also um
where where you have like competing
sorts of things that you need a lot of
you need a lot of stuff to interpret
what's going on is essentially the thing
and so what we can think about now is
whether our current spech Technologies
do do these things like can we make them
do these things do they take account of
these things when we're doing language
understanding and so when we're moving
from the point of just like getting
speech to be nice sound good sound not
glitchy to actually thinking about what
is being communicated and whenever you
have a voice and it sounds human like or
even if it doesn't sound that human it's
communicating whether you want it to or
not okay so I made this slide um a few
years ago but um I think things will
calm down a little in a way it's it's
kind of strange but so there were a lot
of claims in around early
20121 uh uh that newts was
indistinguishable from Human speech so I
wanted to find like one quote about this
but there just like every paper in
speech at 2021 was had this at the first
paragraph So indistinguishable from
Human speech indistinguishable from
natural speech indistinguishable from
Human recordings etc etc etc and this is
all like good work but everybody was
talking about how was indistinguishable
from Human speech at that point right so
the question is indistinguishable from
what like indistinguishable from natural
speech in what sense right so where
where does this come from so it really
comes from I think well people here can
correct me right but um from some some
findings from the T Tru papers so um T
tronu you know your classic
now classic oh so old right
2018 so um this is true one of my
students said they read a very old paper
from 2017 and I had to like light
so so okay so we have like evaluation of
the system um on mean opinion scores so
giving ratings of one to five on
naturalness so how good is this and we
have okay so ground truth that's the
actual the actual speaker from a a human
and then the tatron stuff and so we can
have a
listen STS
Li
Wars okay so do you know which one was
generated and which one was the
human yeah okay so it was the second one
right it got the proc a little bit
different actually but you can see why
people would say that they're both from
a person right they sound pretty
similar okay so it sounds sounds great
but you know it's it's really a very
narrow test right so if you're saying
like are they are they similar are they
same yeah they they sound pretty good
right but they don't really sound the
way that um people talk in real life
they don't sound like I'm talking now
they don't sound like we'll talk later
that sort of thing so that's fine I mean
it's it's a really there's a place for
it I think I'll argue later but um but
the the idea that this this means like
the TTS is solved is it was a bit of a
false flag I would say so um so the
question is natural in what context so
um you know linguists have been
pondering like what the relationship
between context and proed is for for
many a decade now hundreds of years
maybe I don't know so um but what we can
say is that we can construct contexts
based on information Structure Theory
semantics and pragmatics in the formal
sense um from which we can really
predict where what the prootic um
structure will be pretty pretty well
actually so this is a study I did in my
PhD times um and given like some very
short context or even longer contexts if
we knew what the information structure
was we could predict what the what how
they how people would say it really well
um I will play some for you
this might
beet so I I'll just read them actually
so Emily didn't bring Aang no Emily did
bring a morang okay and so that's a
direct contradiction an indirect
contradiction I'm annoyed because nobody
brought a dessert people would then
generally say Emily did bring a
merang um and the clarification question
Emily bought a merang what Emily did
bring a morang right so this is um this
is the examples here but there were many
others and the basic Point here was that
there were distinct prootic patterns so
when I got when we when we did this
production study we didn't give them the
capitalization or anything we just gave
them the text and they very um very
consistently um put the the prominence
and the Rises where where we thought
they would put them um which is what's
represented here in the in the in the
punctuation but they didn't have that um
so that's very consistent okay so if we
do this evaluation we bring this into
TTS evaluation
um we wanted to see whether so this is
work with Elijah guer is a student of
mine who's who was a linguistic student
uh in his undergrad um so if we simply
give them a very simple text prompt like
a question and then uh give the TTS the
TTS was not generated in context right
um how would people rate them so would
there be a difference in how people
rated them and where would they where
would they put the errors so
um so the question here was like fast
pitch versus ailia at the time so fast
pitch was generally rated higher in
naturalness than ailia but um you can
listen to
some No Holly ate the cupcakes so did
John ate the cupcakes No Holly ate no
the
cupakes
no all right so you can see if we got
people to rate to Mark words where they
thought that it was a prootic issue an
international issue um using this rapid
Pro transcription Paradigm and you can
see I won't play the festival one that
was the one just to show like people did
um attend to Pro separate from quality
issues um so people did kind of focus on
different parts of the um the the DTs
stimula as we expected where there was a
clash an an unexpected prominence or
something like that and in general um
when we evalu when we measured this
error rates it was pretty much you know
it was pretty good correlation to asking
people subjectively um what they thought
the procity was like on a on a rating
scale but it also gave us the extra
information of where they thought the
errors were so that was kind of nice and
the other thing was that the system
ranking was different based on um
whether we had this question answer pair
type uh evaluation or whether we just
had your basic Liber TTS so audio books
with LJ so I will play this because it
is indicative
Al a dra
on sometimes but generally
exted okay so is it good uh probably not
but can you really tell from that
fragment I mean it's not you don't
really know what it's trying to
communicate it's the problem
um okay so the issues around the
audiobook text were generally around the
um prootic breaks and the ones around
the questions were what we expected so
um lacking contrasted focus and that
sort of thing so this is is an incorrect
um prominence placement given that you
know the question is don't did John eat
the cupcakes uh you'd expect no Holly
ate the cupcakes right so the prominence
to be there rather than on cupcakes um
but what one thing that we found kind of
interesting was that people also rated
this no as being an era which was it
seemed just excessively expressive at
that point so no holy the cupcakes right
so um why would the TTS system do that
so even though it isn't technically
wrong in terms of the information
structure or anything like that people
found it like a bit weird um so in in
general the expectations created by this
question answer structure projected
pretty strong tight tight constrictions
of what the pro could be um does that
mean we can always predict the pro given
the context uh no unfortunately not so
in this case we have a a case where the
the context discourse configuration is a
very strong predictor but in general
people don't talk like this right people
are much more indirect and much more
unpredictable um and in general procity
um effects but also reflects speaker
expectations so um it can affect how
dialogues proceede for example but we
can't always predict that from the from
the previous context because people are
autonomous beings right so you don't
know what's going to be surprising to
someone so um but based on the proy you
might have a difference in what you want
to do next so here's two um switchboard
conversations or telephone conversations
having the really in
them okay so in that case there really
seemed to be a real challenge a question
he doesn't really believe that people
are nicer um that that the person would
like love it better than Dallas and then
this one you can listen to
okay so you can you could I think sorry
if you could hear that at all it was uh
B oh really and then he basically just
moves on right so it seems like in that
case you don't really need to to to
follow up what it saying so one question
for this was like okay so is there a
specific prootic form that predicts what
what you know triggers an answer or not
and it seems not actually it's it's more
complicated than so but in general
bigger procity um for the really um
means that it's more likely that you're
engaged and you want it you want it to
be actually interpreted as a question um
and in general if we look at discourse
semantics and we it's it's very what we
have to do is think about like what are
the different attitudes that we could
associate with this and if we get the if
we ask um about certain ones so if we
just ask generally about uncertainty for
example which is often associated with
pitch rises in English we might not get
a very clear answer but if we ask about
specific aspects of uncertainty then we
can see that there's a difference and so
we did some experiments doing
manipulation of the proy on different
qword so really well okay sure right so
these are things that people say quite
often in conversation and ask people um
given the procity do people find what
what was said credible was it expected
or uh unexpected surprising or and do
you think that the person wanted more
people to talk about it more and what we
found was that um yeah basically you
have some sort of very strong indicator
based on the lexical semantics of the
keyword or the discourse marker however
you want to call it um and then the
procity kind of uh could alter that so
but generally not in terms of
credibility more in terms of like
whether you wanted somebody to speak
more so if I say really um probably
you're always going to think that um um
I want you to say more about that unless
I really uh kind of flatten it out and
similarly if I say something like Okay
um generally if I say okay then that's
an agreement but if I say okay right it
probably means that I agree but I I want
you to say something more about that it
can be a very disturbing experience if
you say something to somebody and they
like okay right so Pro can can signal a
little bit more than that so you have to
be careful but it also has to uh you
have to take into account the lexical
content okay so I'll just go through
here okay so here are some
challenges so we want to model
expectations um so we want some
probabilistic ways to model lexical and
prootic variation um evolving in the
dialogue so that we can figure out what
the expectations are at different points
so this means we need context dependent
representations um we need models of
variation so we need to be able to
generate expected and unexpected prootic
variation um so we don't want to just
focus on average pro so I think people
in the field know this which I'm been
trying to get away from average POS for
ages um but the big thing that I think
um know linguist can bring and help is
to think about the maps to perception
right so methods to map from the
variation we have in our models and the
expectations we have from our models um
to to actual speaker attitudes and
intents and things like that so um so
the main thing here is that we don't
have a very nice onetoone tune to
meaning map so it's not just like all
questions rise all statements fall all
emotional um all Angry uh s utterances
sound this way or happy ones sound this
way CU it does it doesn't work like that
if you looking you know real
data okay
so for the rest of it I I'll just go I I
want to talk a little bit about some
work that we're doing a bit more
currently but first of all um a
flashback to where we were in 2015 so
this is worked by my student l in 10
she's not a student anymore um she's
she's she's in Australia working for
csro so um but just to give you an
indication where we were so we were
basically handcrafting a lot of features
so this is for for emotion recognition
so these are really big massive sets of
acoustic features that were you know you
can get from open Smile to kit that sort
of stuff and what we were finding at
that time was these massive massive
feature sets were being beaten by much
smaller ones so this EG Maps one 88 hand
selected ones and even this very small
set of um Global restic features um
which were just four four features that
were selected by Daniel Bone right and
that did really well so obviously this
idea of just throwing in drawing and
everything was not going to work we did
find that um you know hierarchically
bringing information together was
helpful and that seems to be reflect it
in what we see now within more newer
models okay so we don't want to do that
anymore we want to find representations
that actually you know work on a bigger
scale and so these things will probably
be quite familiar to you by now so from
the lexical end we have our large
language models like birth so these are
really good at building long context if
you give it enough data you can use long
context can get representations that
represent um contextualized um text uh
but we don't really know that we don't
know exactly what they capture about
dialogue from the acoustic side uh we
have an extension of that so we have
another form of self-supervised learning
this is web to too um so you're
essentially you know doing the same sort
of thing you're masking out some bits of
the audio and trying to to fill that in
again and from there getting a pretty
decent representation of speech which
you can use for ASR very nice um um so
and in there the layers encode something
about lexical and prootic information we
know this because it works really well
for uh emotion recognition but all this
information is entangled so we don't
really know what the pro is doing and
what what's being um given there by
thetical information which is also
there okay so we wanted to try and
detangle this a little bit and bring
like of the perception back in so this
is worked by um SAR wbd and Peter Bell
and myself so we want to understand how
to model um expectations essentially and
the question is does access to procity
actually change the expectations of
what's plausible and so the approaches
to use large language models to find
equally plausible continuations in the
dialogue and then perceptual experiments
to see what you know whether audio
constraints this or
not okay
so okay so here's what it kind of looks
like so in the text form it's like a
little text chat these are fragments
taken from switchboard and then people
rate you know whether the thing that's
coming up next is likely to be something
that actually happened or not and we
found that people could do this actually
pretty well but you can see that it's
not just they knew which one was the the
true one sometimes things that weren't
the true response actually um had pretty
high
ratings um and then if we look at the
language models we can see that you know
Bert find tune to this task uh do pretty
well actually does better than the
humans at picking the true response so
that's the top um one
um the highest rank response and seeing
whether it was the one that actually
happened in the dialogue um but the
human judgments tell us that multiple
utterances can actually be plausible
continuations right so the the framing
of this as a the response selection task
as it had been which was always just to
pick the you know find what actually
happened in the dialogue it's not really
uh reflective of how we work so
sometimes people can do things that are
very unexpected so you'd expect there to
be multiple ways of um multiple things
that could happen in a in a dialogue
that could be equally
plausible um so had a look at this so um
doing the lexical bit versus the audio
bit so whether hearing the the the
continuation in audio or lexical we
basically found for the subset um that
were lexically ambiguous so people
didn't really know which ones were
following um we did get an improvement
in accuracy from like basically clean
none by Design to you know a bit more if
they had access to acoustic but the most
interesting thing I think from this is
that um even if they weren't getting
better at picking the true continuation
they were getting more consistent about
which what they thought the true
continuation would be and we measured
this with entropy so we get less entropy
in the audio
condition um for the non-ambiguous set
we found something kind of interesting
they actually got worse sometimes at
picking the true one but again we see
they're more consistent in what what
they thought was going to happen
okay
so so this is kind of interesting so we
have this kind of idea now that people
that given access to the audio people
have specific expectations about what's
going to happen next um but we also
found some interesting things about you
know how people expectations people have
about text versus speech so um in
particular these case of one-word
responses so in these cases the onew
response was actually the real
continuation but people didn't seem to
think it was rated as highly in the
lexical case as in the audio case and
I'll play them for you and you can think
about
it we TR to do it as well as we
can
and no
so that one's kind of funny right
so so red it seems yeah hearing it
sounded somehow sounded more realistic I
don't know cuz she sounded so annoyed I
don't know like but um so maybe people
are writing them low because they are so
speechy there are things that really
characterize how we talk to each other
these sorts of short um responses that
seeing them in text just seemed kind of
weird um and then we also have the
similar sort of thing with other speech
features so this was rated uh in the
audio cases this was rated much
higher okay so that reads a little bit
weird but it sounds fine I
thinket it it's very secret
so that wasn't an actual continuation
but
um okay so that wasn't that that wasn't
naturual continuation either but you can
see this one because it kind of matched
what was going on and um the overlap was
there because uh this actual turn
overlapped it pre its real previous turn
a lot um so this seemed fine it got a
boost um when people heard the audio and
this one when they heard the audio they
thought it sound worse right so there's
some sort of um deviation from expects
in expectations there so some sort of in
congruity that you laughed right you
found it funny um so there's something
weird going on there that is is is
triggering a response and you know it's
kind of not quite
right okay so if I have some time I will
go through a few more things so
basically we found a bunch of stuff
about expectations and the audio does
constrain it and we can use language
models to help us think about that but
that doesn't really you might have
noticed a slight slight of hand I
started talking about non-lexical and
audio rather than procity right so um in
order to try and figure this out we've
also had another line of work um looking
at um using synthesis to try and like
explore the space a bit more and so in
terms of speech synthesis you know can
we use this to kind of figure out what's
going on with the attitudes if we try
and really push push the space out and
so we looked at Wells so just the word
well in a corpus of conversational
speech and clustered them and you can
hear some
differences
okay okay they don't want to play but um
so it's like well well well you know
that sort of thing so they did find some
kind of nice clusters and what were
really interested in these things that
kind of happen in the
periphery um and we asked people after
much hanging around ringing to um to we
tried to figure out like what was a good
uh attitude to try test us with so um we
synthesized different variations of this
from the different clusters um so well
yeah well no well I don't know um so um
and ask people to rate whether they how
how you know whe the level of
disagreement or agreement that the
speaker was expressing on a 100 point
scale and what we found was like the
actual big effect here came from
duration as you might might might expect
right but we also find some effects of
like the the height the F zero height so
the pitch height um and the curvature of
the of the pitch but you can really hear
it in the duration hopefully you can
hear well
yes well yes right so in this case where
you have these tentative features so
elongation and that sort of stuff um the
the the agreement becomes lower and the
similar for the negation side so if you
have the sort of well no then the the
ratings go towards toward the middle in
terms of like the speaker is less
certain about their agreement and stuff
like that so
um so in general like the point for this
is that um we need some sort of fine
going control here it's not just about
you know fzero and um that sort of thing
but we need to have some fun going show
and actually looking at the outliers so
looking at the potentially in congruous
procity is actually helpful for
understanding what this space of meaning
looks like with respect to specific
lexible content and
um and and procity so we can do this and
it's really fun and it's really nice to
explore variation in speech but we also
have some other things to think about so
I will go a few minutes over but I think
it's worth talking about it so something
other things that we've been um thinking
about is I mean do we need human
likeness here for example so this is
work by student Alice Rost sorry the
previous work was with Johann Omani and
this is with Alice Ross um and she did
some experiments looking at you know how
people rate realism so humanlike versus
things like pleasantness and you can see
here the humanlike ratings for this LJ
speech with fast pitch they didn't
actually get that high but the pleasant
ratings were always higher right so
maybe we don't actually need Super
realistic voice vo es if they're doing
their job and so why might we be um not
very interested in that so I'm going to
play it from the other
plans okay I'll just do it the other
way okay so this is chat GPT for uh GPT
40 as I'm sure you all know
the
ter so this is what I wrote down what do
you
see a I see I love chat that's so sweet
of
you yeah app all
the okay soorry so I say so you can see
there like so the the big the thing was
like you know native speech model but
also that um but it's a chat it's a
chatty voice right and she she has a
very human proy but you can also see
there at the end she's doing some weird
stuff right she's obviously been trained
to behave in a specific way and you know
there there's been some litigation here
potential litigation here um but you can
see what is a real evaluation look like
okay in the news it's flirty people
thinks it's flirty right they think it's
bad to be flirty right so what could go
wrong it's flirty it's flirty it's
flirty it's bad um but I like this one
it says it's giving people the ick I
think that's the correct way to think
about it right so so it's not really
about naturalist now it's about the
ick okay so just one more I'm so sorry
um so so what do we think human like who
exactly so this is a voice
actor hi I'm a fulltime voice actor
Mone
this someone's trying to make you
em supposed to sound like you're just
talking to a friend okay so human like
who right which of her voices and then
what about other accents gender age
Health social status there's a lot of
work here that we can draw on from
social list so um I recommend that you
look at what from Nina Nina's right
there go and talk to her today I think
that um um there's a lot that we need to
you know bring in from Linguistics but
also particularly social Linguistics and
social science um because these these
issues they're happening in the real
world right now right so it's not really
the case that we're just playing with LJ
but also um you know when people don't
rate LJ as 100% human that's kind of
awful she's a person right she's a
person who recorded a lot of audio books
for us
so okay
so I will skip over this but basically
to say that um you found the examples is
funny I heard you laughing right so one
way to think about this is their
deviations from expectations from Norms
so people argue that incongruity is the
basis of humor right so so maybe that's
a good way to think about like what is
happening what how are we interacting
with um with with these speech samples
today with these speech Technologies
today and when we ask about naturalness
it's basically asking about an imaginary
possibly stereotype speaker and so we
need to really think through that and a
lot of this stuff comes from proed comes
from how we say what we say right so
looking at the unexpected stuff looking
at people voices also that are you know
not necessarily represented that well in
our current speech technology is a good
thing to do okay so takeaways finally um
so the fine gr prootic detail is
interesting phonetics is useful um but
you need the words too semantics and
pragmatics are useful um the recent
methods from speech representation make
it quite um you know quite a lot easier
actually now to think about these things
we're at a point where we can actually
use this technology to do Linguistics
research believe it or not but the
theory of spoken communication is still
you know still being formed so we have
to think about that then um so what I
really want you to think about is we can
make this map between what what
technology is and how it relates to
humans and we can do this through
thinking about human perception but we
can also think about it how we interact
with these Technologies in the world um
and I you know look at the outliers okay
okay so many many people helped me with
this work they're not to blame right so
um yes that's that's that's that's my
the end of my talk that if you have one
take away I made this meme I'm so proud
of it so um thank you thank you very
much
than
